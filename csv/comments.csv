"id","issue_id","comment_body","commenter_login","commenter_id","created_at","comment_body_processed"
187,83,"@nodejs/crypto ","aduh95",14309773,"2025-01-03 11:13:53","nodejs crypto
"
188,83,"The key challenge is that openssl does not implement a standard interrupt for this operation. It does allow passing a callback that can be used to interrupt it but we are not currently using it. A fix would be to implement that callback, have it check for pending exit on each call and have it interrupt the operation to generate/check the primes","jasnell",439929,"2025-01-03 17:08:32","key challenge openssl implement standard interrupt operation allow pass callback use currently use fix implement callback check pending exit call interrupt operation generate check prime
"
189,83,"Ok, I've got a fix PR here: https://github.com/nodejs/node/pull/56460 ...

Note that this only partially addresses the issue as openssl will still become unresponsive when generating overly large primes. The key issue is that the generation method performs a certain amount of work before it invokes the callback we can use to check to see if we should continue. But, for reasonably sized primes, this allows the operation to be more readily interupted.","jasnell",439929,"2025-01-03 23:29:51","fix address issue openssl unresponsive generate large prime key issue generation method perform work invoke callback check continue reasonably size prime allow operation readily interrupt
"
190,84,"It is a regression from https://github.com/nodejs/node/pull/53803 cc @jasnell because it comes from a misunderstanding about how std::vector/LocalVector should be used (if it's going to be populated later, the size should not be passed into the constructor, or it will only append the new elements to a bunch of empty handles, instead of to an empty vector)","joyeecheung",4299420,"2025-01-10 18:13:04","regression misunderstanding std::vector LocalVector use populate later size pass constructor append new element empty handle empty vector
"
191,84,"Actually https://github.com/nodejs/node/pull/53803 also broke error reporting, because it did something like `if (!...IsNothing())` to check for exceptions.","joyeecheung",4299420,"2025-01-10 18:26:17","broke error report check exception
"
192,85,"@nodejs/vm ","targos",2352663,"2024-12-26 08:39:15","nodejs vm
"
193,85,"I would like to contribute to solving this issue. Please assign it to me so I can start working on it.","rahul3002",69434755,"2024-12-31 02:31:06","contribute solve issue assign start work
"
194,85,"> I would like to contribute to solving this issue. Please assign it to me so I can start working on it.

Go for it.","juanarbol",17013303,"2025-01-02 20:33:19","contribute solve issue assign start work
"
195,85,"@gurgunday Did you solved this issue? ","rahul3002",69434755,"2025-01-03 05:50:15","solve issue
"
196,85,"The cached data is not supposed to be mixed up between `vm.Script` and `vm.compileFunction`. I think this is rather a V8 issue that it didn't reject the incorrect code cache.","legendecas",8500303,"2025-01-03 15:06:48","cache data suppose mix vm.script vm.compilefunction think v8 issue reject incorrect code cache
"
197,85,"Fixed by https://github.com/v8/v8/commit/96ee9bb9e830f6430d6a6e18fd2f7b2a9e214469","legendecas",8500303,"2025-01-06 13:48:38","fixed
"
198,86,"Also encountered this issue, a fix will be great","noamski",15819156,"2024-12-15 19:53:11","encounter issue fix great
"
199,86,"Good finding, this regression starts to appear on 22.12 and 23.3","jakecastelli",38635403,"2024-12-16 11:49:08","good finding regression appear
"
200,86,"Fixed by https://github.com/nodejs/node/pull/56282/commits/acda05d5b2dd1e2002ad280fdbcc7620e5d63c98.","lpinca",1443911,"2024-12-19 17:20:49","fix
pull
commit
"
201,86,"@lpinca The fix you mentioned didn't land in node 22, was there a reason ?","Betalos",16080229,"2025-01-20 08:42:58","fix mention land node reason
"
202,86,"This should be backported soon to 22.x - https://github.com/nodejs/node/pull/56282","jakecastelli",38635403,"2025-01-20 22:45:44","backport soon
"
203,88,"Verified.

```
> new TextDecoder('us-ascii').decode(new Uint8Array([0x32, 0x44]))
<Buffer 32 44>
> new TextDecoder('windows-1252').decode(new Uint8Array([0x32, 0x44]))
<Buffer 32 44>
> new TextDecoder('latin1').decode(new Uint8Array([0x32, 0x44]))
<Buffer 32 44>
```","lemire",391987,"2024-12-11 00:57:36","Verified
"
204,88,"This is related to https://github.com/nodejs/node/pull/55275

@mertcanaltin Can you check?

I think that the C++ function returns a buffer, not a string.","lemire",391987,"2024-12-11 01:02:25","think c++ function return buffer string
"
205,88,"> This is related to #55275
> 
> @mertcanaltin Can you check?
> 
> I think that the C++ function returns a buffer, not a string.

hello I'm looking into this, I'll post an improvement
","mertcanaltin",37827216,"2024-12-11 08:16:40","think c++ function return buffer string look post improvement
"
206,88,"hello, I am fixed this problem after then ı testet my local enviorement, ı see improvement this problem 

```sh
➜  node git:(mert/fast-path-fix) ./node
Welcome to Node.js v24.0.0-pre.
Type "".help"" for more information.
>  b = new Uint8Array([97, 108, 101])
Uint8Array(3) [ 97, 108, 101 ]
> decoder = new TextDecoder('ascii')
TextDecoder { encoding: 'windows-1252', fatal: false, ignoreBOM: false }
> decoder.decode(b)
'ale'
> 
```

many thanks for reporting the bug and for the suggestions.","mertcanaltin",37827216,"2024-12-11 09:00:50","fix problem test local environment see improvement thank report bug suggestion
"
207,88,"@mertcanaltin @lemire since this is an impactful regression rolling out as part of `v23.4.0`, are there plans to fast follow shipping a fix in a `v23.4.1` release?","lutzroeder",438516,"2024-12-11 22:35:58","impactful regression plan fast follow ship fix release
"
208,88,"@lutzroeder It is definitively getting fixed in the next release. As to whether this next release is labelled `v23.4.1` or not... I do not know.

There is also a related issue: https://github.com/nodejs/performance/issues/183

That last one is troubling as well.","lemire",391987,"2024-12-12 06:00:37","fix next release label know relate issue trouble
"
209,89,"I can reproduce, but I'm not sure #55392 is the cause (it's not an order problem):

```
> volta run --node 20 node -e ""void dns.lookup('localhost', {all:true}, console.log)""
null [ { address: '::1', family: 6 }, { address: '127.0.0.1', family: 4 } ]
> volta run --node 22.11.0 node -e ""void dns.lookup('localhost', {all:true}, console.log)""
null [ { address: '::1', family: 6 }, { address: '127.0.0.1', family: 4 } ]
> volta run --node 22.12.0 node -e ""void dns.lookup('localhost', {all:true}, console.log)""
null [ { address: '::1', family: 6 } ]
> volta run --node 23 node -e ""void dns.lookup('localhost', {all:true}, console.log)""
null [ { address: '::1', family: 6 } ]
```","targos",2352663,"2024-12-10 11:58:40","reproduce sure cause order problem volta run node node void dns lookup localhost all true console log null address family address family address family address family
"
210,89,"@nodejs/dns

The other DNS-related change in v22.12.0 was https://github.com/nodejs/node/pull/55430","targos",2352663,"2024-12-10 11:59:34","nodejs dns dns relat change
"
211,89,"Duplicate of https://github.com/nodejs/node/issues/56137. I think this is the result of a c-ares update.","lpinca",1443911,"2024-12-10 13:40:30","result c ares update
"
212,89,"Duplicate of https://github.com/nodejs/node/issues/56137","aduh95",14309773,"2024-12-10 22:17:39","duplicate
"
213,90,"Bisecting points to ecedcba357603a68530a0106d5bc0eb76bb89bcd as the first bad commit.
","lpinca",1443911,"2024-12-11 08:35:24","bisect point first bad commit
"
214,91,"It seems in this case the module being loaded by require() is recognized as ESM (due to the presence of `const require`) by syntax detection and went into require(esm), which is kind of odd because require(esm) is still behind a flag in 22.11.0, it might be another glitch from the syntax detection unflagging.

But anyway, it makes the process exit because the evaluation promise is created by V8 and once rejection happens it goes straight into the unhandled rejection handler, so we need to do some fixup later to remove it from the pending unhandled rejections.","joyeecheung",4299420,"2024-12-03 15:33:44","module load require recognize esm presence const require syntax detection require esm kind odd require esm flag glitch syntax detection unflagging make process exit evaluation promise create v8 rejection happen straight unhandled rejection handler need fixup remove pending unhandled rejection
"
215,91,"Fix in https://github.com/nodejs/node/pull/56122 (there is a separate bug in which `require(esm)` is not disabled if the module syntax detection indicates the module is ESM, but considering this has been happening on v22.x for quite a while, it is probably not too urgent to fix it).","joyeecheung",4299420,"2024-12-03 16:08:33","fix separate bug require esm disable module syntax detection module esm happen v2x urgent fix
"
216,92,"We could mark it as legacy and decide to not fix the issue, as long as the promise version is correctly async we can probably get away with the callback version being wrongly sync.","aduh95",14309773,"2024-11-26 22:45:36","mark legacy decide fix issue promise version correctly async probably get away callback version wrongly sync
"
217,92,"> We could mark it as legacy and decide to not fix the issue, as long as the promise version is correctly async we can probably get away with the callback version being wrongly sync.

If a sync version has a feature and its callback equivalent call doesn't... looks like a bad UX to me. Have we considered a new function instead? It seems more appropriate: `fs.recursiveReaddir()`","RafaelGSS",26234614,"2024-11-27 17:10:53","mark legacy decide fix issue promise version correctly async probably get away callback version wrongly sync sync version feature callback equivalent call bad ux consider new function appropriate fs recursiveReaddir
"
218,92,"Nevermind, I have a PR almost ready to fix this. ","RafaelGSS",26234614,"2024-11-27 19:51:46","pr ready fix
"
219,93,"IIUC, a minimum reproducible example is like this.

```
const fs = require('node:fs');
const fd = Symbol(""adjlyxzmfd"");
fs.fstat(fd, () => {});
```

I think we should validate `fd` either in JS or C++","jazelly",28685065,"2024-11-26 03:14:44","minimum reproducible example like validate fd javascript cplusplus
"
220,94,"Even simpler reproduction:

```mjs
import { test, beforeEach } from 'node:test'

beforeEach((t) => t.mock.timers.enable());

test(() => test());
```
```
$ node repro.js
```

It's failing here:
https://github.com/nodejs/node/blob/be5a500ae39baba2747be1b94972ef8d224fcb49/lib/internal/test_runner/mock/mock_timers.js#L396-L413","avivkeller",38299977,"2024-11-14 13:09:05","simpler reproduction test beforeeach enable test fail
"
221,94,"With above example, `#createDate` is called 2 times. So when I change `configurable` of `[kMock]` to true, above example is working. But I'm not sure that this approach is right.

https://github.com/nodejs/node/blob/be5a500ae39baba2747be1b94972ef8d224fcb49/lib/internal/test_runner/mock/mock_timers.js#L401","deokjinkim",5592478,"2024-11-14 15:53:24","example call time change configurable approach sure right
"
222,94,"I don't think we should set it to `true`.

IMO The appropriate response should be an error that the mock is already enabled, as is done if you try to enable it twice.","avivkeller",38299977,"2024-11-14 16:12:35","think set true appropriate response error mock already enable try enable twice
"
223,94,"A better way to look at this is:
```js
import { test } from 'node:test'

test((outer) => {
    outer.mock.timers.enable()
    test((inner) => inner.mock.timers.enable())
});
```

When `outer` changes the `Date` object, it sets these properties.

Then, when `inner` wants to change the `Date` object, it copies those properties, before trying to set them:
https://github.com/nodejs/node/blob/be5a500ae39baba2747be1b94972ef8d224fcb49/lib/internal/test_runner/mock/mock_timers.js#L380-L383

IMO there are two paths that can be taken here:
A) Throw an error that the object has already been mocked
B) Exclude those properties, and overwrite the mock.

I'm inclined for (A).

","avivkeller",38299977,"2024-11-14 22:54:54","melhor forma olhar erro objeto ja ter sido simulado excluir propriedades sobrescrever simulacao inclinado a
"
224,94,"Opened #55858","avivkeller",38299977,"2024-11-14 23:05:14","Opened issue
"
225,95,"We use `n auto` with a `.nvmrc` file set to `lts/hydrogen` - this results in our builds failing, would be nice if this is fixed quickly so we don't have to update all our builds.","juanheyns",1027219,"2024-11-12 22:21:27","build fail nice fix update build
"
226,95,"Thank you for reporting.","neo-rivan-mota",145389182,"2024-11-12 22:23:52","thank report
"
227,95,"GitHub actions running on 18 without a minor version declared will fail.

```shell
runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [18.x]
```","taniarascia",11951801,"2024-11-12 22:40:02","GitHub action run version minor version declare fail
"
228,95,"Netlify builds with node 18 are failing as well","c-castillo",1154738,"2024-11-12 23:23:35","Netlify build node 18 fail
"
229,95,"breaking a lot of stuff in our infra as well due to heavy use of `n` version manager","jaymefSO",32715263,"2024-11-12 23:34:08","break stuff infra due heavy use version manager
"
230,95,"Is there any ETA on a fix for this? This breaks deployments and wondering if we should look into updating all our builds","jay-motwani-trend",148412715,"2024-11-12 23:40:58","fix break deployment update build
"
231,95,"In the meantime one could use a mirror which will currently install 18.20.4:
```
NVM_NODEJS_ORG_MIRROR=https://mirrors.dotsrc.org/nodejs/release/ nvm install 18
```","buffcode",2863518,"2024-11-12 23:48:43","meantime use mirror currently install 18


"
232,95,"cc @nodejs/releasers ","anonrig",1935246,"2024-11-13 00:54:39","nodejs releaser
"
233,95,"Binaries aren't present in the staging bucket https://dash.cloudflare.com/07be8d2fbc940503ca1be344714cb0d1/r2/default/buckets/dist-staging so nothing got copied over when the release was promoted cc @nodejs/build @nodejs/web-infra ","flakey5",73616808,"2024-11-13 01:00:49","binarie present stage bucket nothing got copy release promote nodejs build nodejs web infra
"
234,95,"https://direct.nodejs.org/dist/v18.20.5/ has it

~~cc @nodejs/build or anyone with write access to Cloudflare can y'all delete the worker route that points /dist/ and /download/release/ to the worker? This should point to the right place https://dash.cloudflare.com/07be8d2fbc940503ca1be344714cb0d1/nodejs.org/workers~~","flakey5",73616808,"2024-11-13 01:05:40","delete worker route point dist download release worker point right place
"
259,97,"If you load the database in a seperate client, is the `""titles""` table existent?","avivkeller",38299977,"2024-10-28 23:08:42","load database seperate client title existent
"
260,97,"yes I load in ""DB Browser (SQLite)"" and it show correctly
![Capture3](https://github.com/user-attachments/assets/2489034d-633e-4d8a-8230-d813bc06ac54)
","sharafabacery",52586357,"2024-10-28 23:11:22","load db browser sqlite show correctly
"
598,138,"I've opened a revert PR #53904 if this needs to be reverted.","avivkeller",38299977,"2024-07-17 18:49:52","revert pr need revert
"
235,95,"I don't know why the web UI shows fewer files, but it seems to me all files are there now, e.g.

```console
$ curl -I https://nodejs.org/dist/v18.20.5/node-v18.20.5.tar.gz
HTTP/2 200 
date: Wed, 13 Nov 2024 00:49:25 GMT
content-type: application/gzip
content-length: 86241753
cache-control: public, max-age=3600, s-maxage=14400
etag: ""4d8368a8627558bb6beb363c36fb4a9f""
last-modified: Tue, 12 Nov 2024 00:43:46 GMT
accept-range: bytes
strict-transport-security: max-age=31536000; includeSubDomains; preload
x-content-type-options: nosniff
server: cloudflare
cf-ray: 8e1ac307af25be13-DUB
```","aduh95",14309773,"2024-11-13 01:07:31","know web ui show file file
"
236,95,"> I don't know why the web UI shows fewer files, but it seems to me all files are there now, e.g.

+1 files are in dist-prod now

![image](https://github.com/user-attachments/assets/2a68aaf8-419b-4304-aea7-429285e17f65)

Directory listing won't show the files in the colos that cached the response","flakey5",73616808,"2024-11-13 01:09:43","file web ui show file file dist prod directory listing show file colo cache response
"
237,95,"Also for future reference please ping the web-infra and build teams as well if this happens","flakey5",73616808,"2024-11-13 01:21:01","future reference ping web infra build team happen
"
238,95,"> Binaries aren't present in the staging bucket https://dash.cloudflare.com/07be8d2fbc940503ca1be344714cb0d1/r2/default/buckets/dist-staging so nothing got copied over when the release was promoted

Maybe related: https://github.com/nodejs/node/pull/51394 wasn't backported to v18.x","aduh95",14309773,"2024-11-13 01:27:03","binary present staging bucket nothing get copy release promote relate backport v18x
"
239,95,"> Maybe related: https://github.com/nodejs/node/pull/51394 wasn't backported to v18.x

That would make sense, also @targos just did a recent change that updated the upload part to use rclone #55617.","flakey5",73616808,"2024-11-13 01:30:20","make sense recent change update upload part use rclone
"
240,95,"A long term fix, perhaps, would be to only update the index.tab/index.json files _after_ the files are available?

If someone can point me to where I might work on that, I'd be happy to.","ljharb",45469,"2024-11-13 01:32:51","fix update index file file available happy work
"
241,95,"> A long term fix, perhaps, would be to only update the index.tab/index.json files _after_ the files are available?
> 
> If someone can point me to where I might work on that, I'd be happy to.

They're generated in the same file that the SHASUMS256.txt is which is needed for promoting the release, I don't see a reason that it _needs_ to be there however https://github.com/nodejs/build/blob/924eacbaf8444248d9e93afacebc006b1dd0eec3/ansible/www-standalone/tools/promote/_resha.sh#L57 There might be something I'm forgetting though on the promotion process","flakey5",73616808,"2024-11-13 01:40:29","fix update index file file available someone point happy generate file shasums256 txt need promote release reason need promotion process forget promotion process
"
242,95,"> A long term fix, perhaps, would be to only update the index.tab/index.json files _after_ the files are available?
> 
> If someone can point me to where I might work on that, I'd be happy to.

FWIW a while ago I documented how the [release process worked](https://github.com/nodejs/build/blob/main/doc/release-overview.md) (in mermaid, with links to the scripts). Like all documentation, it's now out of date (it was written when we were still self-hosting the website (now Vercel) and before any of the R2 work)🙂. However the broad outline still applies -- we were very careful not to break the existing flow for the R2 work (so even in this case, all files were correctly uploaded to the Digital Ocean droplet -- the issue here was that we missed backporting https://github.com/nodejs/node/pull/51394 to v18.x-staging which meant the builds were staged on the DO droplet but not in R2).

","richardlau",5445507,"2024-11-13 02:00:25","fix update index tab index json file file available point work happy document release process work mermaid link script documentation date write self host website vercel r work outline apply careful break exist flow r work file correctly upload digital ocean droplet issue miss backport build stage do droplet r
"
243,95,"It looks like the issue has now been fixed. I can see the files now in https://nodejs.org/dist/v18.20.5/","jay-motwani-trend",148412715,"2024-11-13 04:14:47","look issue fix see file
"
244,95,"I think we can close this now since the incident is resolved. We still need to make sure #55617 gets backported to the v18 branch however to avoid this from happening again w/ future v18 releases

Btw - thanks to all of you reporting the issue, and apologizes as well!","flakey5",73616808,"2024-11-13 06:40:31","close incident resolve need make sure backport v18 branch avoid happen future v18 release thanks report issue apologize
"
245,95,"> still need to make sure #55617 gets backported to the v18 branch

Looks like it should be backported to 20.x and 22.x too?
* https://github.com/nodejs/node/blob/d5fa767689a080256a63a08d8c45b6c29f5e701e/Makefile#L11
* https://github.com/nodejs/node/blob/985262a4a8221d993df82e134623d8437d92b4c5/Makefile#L11","trivikr",16024985,"2024-11-13 07:05:02","need make sure get backport v18 branch look like backport need make sure get backport
"
246,95,"https://github.com/nodejs/node/pull/55617 has the lts-watch labels and will be backported. I agree we can close this issue.
","targos",2352663,"2024-11-13 08:14:13","agree close issue
"
247,96,"> The call happens only once for the first call and the callbacks are not called instead an error is thrown like for sync function

AFAICT this is not the case. While I'm able to reproduce the issue, *no* call appears to use the callback, and an error is thrown.

This is because `getValidatedPath` does not return the error to the callback, but instead throws it.","avivkeller",38299977,"2024-10-30 20:52:36","call happen once first call callback call error throw sync function case able reproduce issue call appear use callback error throw getvalidatedpath return error callback throw
"
248,96,"@RedYetiDev In our case, we often call this function with `/`, the second call does not even throw an error, so `try/catch` doesn't help in this case","alexander-akait",4567934,"2024-10-30 21:02:26","case often call function second call throw error try catch help case
"
249,96,"I'll bisect.","juanarbol",17013303,"2024-10-31 03:47:15","bisect
"
250,96,"Same in macos","juanarbol",17013303,"2024-10-31 04:24:02","macos
"
251,96,"The regression seems to be introduced by https://github.com/nodejs/node/pull/54160

Maybe here? https://github.com/nodejs/node/pull/54160/files#diff-5cd422a9a64bc2c1275d70ba5dcafbc5ea55274432fffc5e4159126007dc4894R735-R741","juanarbol",17013303,"2024-10-31 04:53:16","regression introduce
"
252,96,"The regression is reverted, I'm closing this issue.","juanarbol",17013303,"2024-11-03 04:45:55","regression revert close issue
"
253,96,"@juanarbol When will be the patch released?","snitin315",46647141,"2024-11-03 05:07:58","patch release
"
254,97,"> Error: no such table: titles

That seems to be the problem?","cjihrig",2512748,"2024-10-28 22:23:07","error table problem
"
255,97,"The table in database is exsiten ","sharafabacery",52586357,"2024-10-28 22:25:22","table database exist
"
256,97,"Not according to SQLite 😄 ","cjihrig",2512748,"2024-10-28 22:31:12","accord sqlite
"
257,97,"@cjihrig nice😀","sharafabacery",52586357,"2024-10-28 22:45:33","nice
"
258,97,"@cjihrig  could problem because of windows os?","sharafabacery",52586357,"2024-10-28 23:08:05","problem window os
"
261,97,"> could problem because of windows os?

Windows is supported and tested, but it's possible. What if you update `Connectdb('../database.db')` to use backslashes?","cjihrig",2512748,"2024-10-28 23:25:18","problem window os possible update connectdb backslash
"
262,97,"it solves the problem thanks","sharafabacery",52586357,"2024-10-28 23:43:41","solve problem
"
263,97,"Hi @sharafabacery, I wanted to look into this issue but couldn't reproduce it (I tried Node 22.10.0, and 23.1.0). I used the code you've provided in the description and the attached database. Could you please try to run the code with the attached db?
[database.zip](https://github.com/user-attachments/files/17674664/database.zip)
","huseyinacacak-janea",110401522,"2024-11-08 07:11:05","hi want look issue reproduce try node use code provide description attach database please try run code attach db
"
264,97,"when I get back to code last week I change the path to `basedir/databasefile.db` it works fine could be problem happen when compile ts to js ,but if need to explore the code here the repo https://github.com/sharafabacery/hisnmuslimTs","sharafabacery",52586357,"2024-11-10 11:38:31","code week change path basedir databasefile db work problem happen compile ts js need explore repo
"
265,97," Since this seems to be working now, I'll close the issue. Feel free to reopen if needed.","StefanStojanovic",9998547,"2024-11-14 12:37:09","work close issue reopen need
"
266,98,"I can't reproduce a increase of that scale. I ran your code, and I got:
```
report: 2.095ms
report: 14.098ms
report: 25.988ms
```

When running at a larger scale, everything seems consistent:
```
Report (after fetching 0 times): 15.347ms
Report (after fetching 1 times): 24.828ms
Report (after fetching 2 times): 29.105ms
Report (after fetching 3 times): 27.147ms
Report (after fetching 4 times): 31.67ms
Report (after fetching 5 times): 29.602ms
Report (after fetching 6 times): 31.013ms
Report (after fetching 7 times): 29.853ms
Report (after fetching 8 times): 31.42ms
Report (after fetching 9 times): 26.445ms
Report (after fetching 10 times): 24.994ms
Report (after fetching 11 times): 27.865ms
Report (after fetching 12 times): 30.993ms
Report (after fetching 13 times): 30.189ms
Report (after fetching 14 times): 30.977ms
Report (after fetching 15 times): 29.551ms
Report (after fetching 16 times): 26.54ms
Report (after fetching 17 times): 25.168ms
Report (after fetching 18 times): 27.516ms
Report (after fetching 19 times): 27.163ms
Report (after fetching 20 times): 29.243ms
```","avivkeller",38299977,"2024-10-28 21:11:40","reproduzir aumento escala executar código consistent fetch tempo
"
267,98,"Which env are you on? Native linux? I'm reproducing it on windows and WSL (it always takes +20seconds for me after each fetch in both envs), this 20 seconds have to come from something env related","Tofandel",6115458,"2024-10-28 21:14:40","env reproduce windows wsl take fetch env relate
"
268,98,"> Which env are you on? Native linux?

Yes. My machine is:
```
  System:
    OS: Linux 6.10 Kali GNU/Linux Rolling 2024.3
    CPU: (12) x64 AMD Ryzen 5 5600G with Radeon Graphics
    Memory: 18.63 GB / 27.31 GB
``` ","avivkeller",38299977,"2024-10-28 21:18:50","machine linux system cpu memory
"
269,98,"> When running at a larger scale, everything seems consistent:

That's actually in line with me except your time increase is only 15ms

If I run 5 fetch it doesn't take more than 40 seconds, so it seems it's only a factor for the 2 first fetch","Tofandel",6115458,"2024-10-28 21:21:22","run large scale consistent line time increase 15ms run fetch take 40 second factor fetch
"
270,98,"I *am* experiencing an increase, just at a much much smaller scale, so maybe something is going on?","avivkeller",38299977,"2024-10-28 21:23:35","experience increase small scale something
"
271,98,"Yes, I'd like to help debugging If I can but I'm not sure how, I'm not a C++ dev and there doesn't seem to be any output from `NODE_DEBUG_NATIVE` and compiling from source takes very long (it's been compiling for 2 hours right now)","Tofandel",6115458,"2024-10-28 21:25:18","help debug sure c++ dev output compile source long
"
272,98,"> , I'm not a C++ dev and there doesn't seem to be any output from NODE_DEBUG_NATIVE and compiling from source takes very long (it's been compiling for 2 hours right now)

I can do some research, but I'm also not a CPP dev. As for compile times, as a rule-of-thumb, if you aren't already, make use of multithreading (`make -j4` where `4` is the number of threads), and configure with ninja (`./configure --ninja`)","avivkeller",38299977,"2024-10-28 21:28:41","nao cpp dev saida node debug native compilacao fonte demorar pesquisa cpp dev tempo compilacao regra polegar usar multithreading make j numero thread configurar ninja
"
273,98,"I'm using `make -j8` but it's still taking forever, I'll increase to -j16 next time

Is there caching between builds and only the first build will take this amount of time or is it going to take this long every time I make a single change?","Tofandel",6115458,"2024-10-28 21:54:52","make take long time cache build first build take long time make single change
"
274,98,"I always build with `ninja` and `ccache`, and there's caching between builds for me, IIRC that's due to `ccache`.","avivkeller",38299977,"2024-10-28 22:07:01","build ninja ccache cache build due ccache
"
275,98,"Does it reproduce if you configure [`process.report.excludeNetwork`](https://nodejs.org/docs/latest-v22.x/api/report.html#configuration)? (see https://github.com/nodejs/node/issues/46060 for why that option was added.)","richardlau",5445507,"2024-10-28 22:12:12","reproduce configure process report excludeNetwork option add
"
276,98,"Yes it was in the description
> This still happens even with node --report-exclude-network

Though it does look like the exact same issue and so it might not be fully solved","Tofandel",6115458,"2024-10-28 22:24:01","happen node report exclude network look exact issue fully solve
"
277,98,"I'm curious, what does the profiling output look like? (`node --prof <file>` followed by `node --prof-process <log file>`)","avivkeller",38299977,"2024-10-28 23:47:18","curious profiling output look node prof file node prof process log file
"
278,98,"```js
await fetch('https://example.com', {keepalive: false})
console.log(process._getActiveHandles()[1]);
console.time('report');
process.report.getReport();
console.timeEnd('report');
```

<details>
<summary>Here is the ouput of `NODE_DEBUG=net node --report-exclude-network test.mjs`</summary>

```txt
NET 763280: pipe false undefined
NET 763280: connect: find host example.com
NET 763280: connect: dns options { family: undefined, hints: 32 }
NET 763280: connect: autodetecting
NET 763280: _read - n 16384 isConnecting? true hasHandle? true
NET 763280: _read wait for connection
NET 763280: connect/multiple: will try the following addresses [
  { address: '93.184.215.14', family: 4 },
  { address: '2606:2800:21f:cb07:6820:80da:af6b:8b2c', family: 6 }
]
NET 763280: connect/multiple: attempting to connect to 93.184.215.14:443 (addressType: 4)
NET 763280: connect/multiple: setting the attempt timeout to 250 ms
NET 763280: connect/multiple: connection attempt to 93.184.215.14:443 completed with status 0
NET 763280: afterConnect
NET 763280: _read - n 16384 isConnecting? false hasHandle? true
NET 763280: Socket._handle.readStart
NET 763280: _read - n 16384 isConnecting? false hasHandle? true
<ref *1> TLSSocket {
  _tlsOptions: {
    allowHalfOpen: undefined,
    pipe: false,
    secureContext: SecureContext { context: SecureContext {} },
    isServer: false,
    requestCert: true,
    rejectUnauthorized: true,
    session: null,
    ALPNProtocols: <Buffer 08 68 74 74 70 2f 31 2e 31>,
    requestOCSP: undefined,
    enableTrace: undefined,
    pskCallback: undefined,
    highWaterMark: 16384,
    onread: undefined,
    signal: undefined
  },
  _secureEstablished: true,
  _securePending: false,
  _newSessionPending: false,
  _controlReleased: true,
  secureConnecting: false,
  _SNICallback: null,
  servername: 'example.com',
  alpnProtocol: 'http/1.1',
  authorized: true,
  authorizationError: null,
  encrypted: true,
  _events: [Object: null prototype] {
    close: [
      [Function: onSocketCloseDestroySSL],
      [Function (anonymous)],
      [Function (anonymous)]
    ],
    end: [ [Function: onReadableStreamEnd], [Function (anonymous)] ],
    error: [ [Function (anonymous)], [Function (anonymous)] ],
    newListener: [Function: keylogNewListener],
    connect: undefined,
    secure: [Function: onConnectSecure],
    session: [Function (anonymous)],
    secureConnect: undefined,
    readable: [Function (anonymous)]
  },
  _eventsCount: 7,
  connecting: false,
  _hadError: false,
  _parent: null,
  _host: 'example.com',
  _closeAfterHandlingError: false,
  _readableState: ReadableState {
    highWaterMark: 16384,
    buffer: [],
    bufferIndex: 0,
    length: 0,
    pipes: [],
    awaitDrainWriters: null,
    [Symbol(kState)]: 10004740
  },
  _writableState: WritableState {
    highWaterMark: 16384,
    length: 0,
    corked: 0,
    onwrite: [Function: bound onwrite],
    writelen: 0,
    bufferedIndex: 0,
    pendingcb: 0,
    [Symbol(kState)]: 17563908,
    [Symbol(kBufferedValue)]: null,
    [Symbol(kWriteCbValue)]: null
  },
  allowHalfOpen: false,
  _maxListeners: undefined,
  _sockname: null,
  _pendingData: null,
  _pendingEncoding: '',
  server: undefined,
  _server: null,
  ssl: TLSWrap {
    _parent: TCP {
      reading: [Getter/Setter],
      onconnection: null,
      [Symbol(owner_symbol)]: [Circular *1]
    },
    _parentWrap: null,
    _secureContext: SecureContext { context: SecureContext {} },
    reading: true,
    onkeylog: [Function: onkeylog],
    onhandshakestart: [Function: noop],
    onhandshakedone: [Function (anonymous)],
    onocspresponse: [Function: onocspresponse],
    onnewsession: [Function: onnewsessionclient],
    onerror: [Function: onerror],
    [Symbol(owner_symbol)]: [Circular *1]
  },
  _requestCert: true,
  _rejectUnauthorized: true,
  autoSelectFamilyAttemptedAddresses: [ '93.184.215.14:443' ],
  [Symbol(alpncallback)]: null,
  [Symbol(res)]: TLSWrap {
    _parent: TCP {
      reading: [Getter/Setter],
      onconnection: null,
      [Symbol(owner_symbol)]: [Circular *1]
    },
    _parentWrap: null,
    _secureContext: SecureContext { context: SecureContext {} },
    reading: true,
    onkeylog: [Function: onkeylog],
    onhandshakestart: [Function: noop],
    onhandshakedone: [Function (anonymous)],
    onocspresponse: [Function: onocspresponse],
    onnewsession: [Function: onnewsessionclient],
    onerror: [Function: onerror],
    [Symbol(owner_symbol)]: [Circular *1]
  },
  [Symbol(verified)]: true,
  [Symbol(pendingSession)]: null,
  [Symbol(async_id_symbol)]: 10,
  [Symbol(kHandle)]: TLSWrap {
    _parent: TCP {
      reading: [Getter/Setter],
      onconnection: null,
      [Symbol(owner_symbol)]: [Circular *1]
    },
    _parentWrap: null,
    _secureContext: SecureContext { context: SecureContext {} },
    reading: true,
    onkeylog: [Function: onkeylog],
    onhandshakestart: [Function: noop],
    onhandshakedone: [Function (anonymous)],
    onocspresponse: [Function: onocspresponse],
    onnewsession: [Function: onnewsessionclient],
    onerror: [Function: onerror],
    [Symbol(owner_symbol)]: [Circular *1]
  },
  [Symbol(lastWriteQueueSize)]: 0,
  [Symbol(timeout)]: null,
  [Symbol(kBuffer)]: null,
  [Symbol(kBufferCb)]: null,
  [Symbol(kBufferGen)]: null,
  [Symbol(shapeMode)]: true,
  [Symbol(kCapture)]: false,
  [Symbol(kSetNoDelay)]: true,
  [Symbol(kSetKeepAlive)]: true,
  [Symbol(kSetKeepAliveInitialDelay)]: 60,
  [Symbol(kBytesRead)]: 0,
  [Symbol(kBytesWritten)]: 0,
  [Symbol(connect-options)]: {
    rejectUnauthorized: true,
    ciphers: 'TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:DHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA256:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!SRP:!CAMELLIA',
    checkServerIdentity: [Function: checkServerIdentity],
    minDHSize: 1024,
    highWaterMark: 16384,
    path: undefined,
    servername: 'example.com',
    session: null,
    localAddress: null,
    ALPNProtocols: [ 'http/1.1' ],
    socket: undefined,
    port: 443,
    host: 'example.com',
    singleUse: true
  },
  [Symbol(no ref)]: false,
  [Symbol(writing)]: false,
  [Symbol(reset)]: false,
  [Symbol(blocking)]: false,
  [Symbol(parser)]: Parser {
    llhttp: [Object: null prototype] {
      memory: Memory [WebAssembly.Memory] {},
      _initialize: [Function: 8],
      __indirect_function_table: Table [WebAssembly.Table] {},
      llhttp_init: [Function: 9],
      llhttp_should_keep_alive: [Function: 47],
      llhttp_alloc: [Function: 11],
      malloc: [Function: 49],
      llhttp_free: [Function: 12],
      free: [Function: 12],
      llhttp_get_type: [Function: 13],
      llhttp_get_http_major: [Function: 14],
      llhttp_get_http_minor: [Function: 15],
      llhttp_get_method: [Function: 16],
      llhttp_get_status_code: [Function: 17],
      llhttp_get_upgrade: [Function: 18],
      llhttp_reset: [Function: 19],
      llhttp_execute: [Function: 20],
      llhttp_settings_init: [Function: 21],
      llhttp_finish: [Function: 22],
      llhttp_pause: [Function: 23],
      llhttp_resume: [Function: 24],
      llhttp_resume_after_upgrade: [Function: 25],
      llhttp_get_errno: [Function: 26],
      llhttp_get_error_reason: [Function: 27],
      llhttp_set_error_reason: [Function: 28],
      llhttp_get_error_pos: [Function: 29],
      llhttp_errno_name: [Function: 30],
      llhttp_method_name: [Function: 31],
      llhttp_status_name: [Function: 32],
      llhttp_set_lenient_headers: [Function: 33],
      llhttp_set_lenient_chunked_length: [Function: 34],
      llhttp_set_lenient_keep_alive: [Function: 35],
      llhttp_set_lenient_transfer_encoding: [Function: 36],
      llhttp_message_needs_eof: [Function: 46]
    },
    ptr: 76304,
    client: Client {
      _events: [Object: null prototype],
      _eventsCount: 4,
      _maxListeners: undefined,
      [Symbol(shapeMode)]: false,
      [Symbol(kCapture)]: false,
      [Symbol(nodejs.stream.destroyed)]: false,
      [Symbol(onDestroyed)]: null,
      [Symbol(closed)]: false,
      [Symbol(onClosed)]: [],
      [Symbol(dispatch interceptors)]: [Array],
      [Symbol(url)]: URL {},
      [Symbol(connector)]: [Function: connect],
      [Symbol(pipelining)]: 1,
      [Symbol(max headers size)]: 16384,
      [Symbol(default keep alive timeout)]: 4000,
      [Symbol(max keep alive timeout)]: 600000,
      [Symbol(keep alive timeout threshold)]: 2000,
      [Symbol(keep alive timeout)]: 4000,
      [Symbol(server name)]: null,
      [Symbol(local address)]: null,
      [Symbol(resuming)]: 0,
      [Symbol(need drain)]: 2,
      [Symbol(host header)]: 'host: example.com\r\n',
      [Symbol(body timeout)]: 300000,
      [Symbol(headers timeout)]: 300000,
      [Symbol(strict content length)]: true,
      [Symbol(maxRedirections)]: undefined,
      [Symbol(maxRequestsPerClient)]: undefined,
      [Symbol(kClosedResolve)]: null,
      [Symbol(max response size)]: -1,
      [Symbol(max concurrent streams)]: 100,
      [Symbol(http context)]: [Object],
      [Symbol(queue)]: [Array],
      [Symbol(running index)]: 0,
      [Symbol(pending index)]: 1,
      [Symbol(resume)]: [Function (anonymous)],
      [Symbol(on error)]: [Function (anonymous)],
      [Symbol(Intercepted Dispatch)]: [Function: Intercept],
      [Symbol(connecting)]: false,
      [Symbol(needDrain)]: true,
      [Symbol(socket)]: [Circular *1]
    },
    socket: [Circular *1],
    timeout: FastTimer {
      _state: 0,
      _idleTimeout: 300000,
      _idleStart: -1,
      _onTimeout: [Function: onParserTimeout],
      _timerArg: WeakRef {},
      [Symbol(kFastTimer)]: true
    },
    timeoutValue: 300000,
    timeoutType: 5,
    statusCode: 200,
    statusText: 'OK',
    upgrade: false,
    headers: [],
    headersSize: 0,
    headersMaxSize: 16384,
    shouldKeepAlive: true,
    paused: false,
    resume: [Function: bound resume],
    bytesRead: 0,
    keepAlive: '',
    contentLength: '648',
    connection: '',
    maxResponseSize: -1
  },
  [Symbol(listeners)]: [
    [ 'error', [Function (anonymous)] ],
    [ 'readable', [Function (anonymous)] ],
    [ 'end', [Function (anonymous)] ],
    [ 'close', [Function (anonymous)] ]
  ],
  [Symbol(socket request counter)]: 0,
  [Symbol(maxRequestsPerClient)]: undefined,
  [Symbol(client)]: Client {
    _events: [Object: null prototype] {
      drain: [Function: onDrain],
      connect: [Function (anonymous)],
      disconnect: [Function (anonymous)],
      connectionError: [Function (anonymous)]
    },
    _eventsCount: 4,
    _maxListeners: undefined,
    [Symbol(shapeMode)]: false,
    [Symbol(kCapture)]: false,
    [Symbol(nodejs.stream.destroyed)]: false,
    [Symbol(onDestroyed)]: null,
    [Symbol(closed)]: false,
    [Symbol(onClosed)]: [],
    [Symbol(dispatch interceptors)]: [ [Function (anonymous)] ],
    [Symbol(url)]: URL {
      href: 'https://example.com/',
      origin: 'https://example.com',
      protocol: 'https:',
      username: '',
      password: '',
      host: 'example.com',
      hostname: 'example.com',
      port: '',
      pathname: '/',
      search: '',
      searchParams: URLSearchParams {},
      hash: ''
    },
    [Symbol(connector)]: [Function: connect],
    [Symbol(pipelining)]: 1,
    [Symbol(max headers size)]: 16384,
    [Symbol(default keep alive timeout)]: 4000,
    [Symbol(max keep alive timeout)]: 600000,
    [Symbol(keep alive timeout threshold)]: 2000,
    [Symbol(keep alive timeout)]: 4000,
    [Symbol(server name)]: null,
    [Symbol(local address)]: null,
    [Symbol(resuming)]: 0,
    [Symbol(need drain)]: 2,
    [Symbol(host header)]: 'host: example.com\r\n',
    [Symbol(body timeout)]: 300000,
    [Symbol(headers timeout)]: 300000,
    [Symbol(strict content length)]: true,
    [Symbol(maxRedirections)]: undefined,
    [Symbol(maxRequestsPerClient)]: undefined,
    [Symbol(kClosedResolve)]: null,
    [Symbol(max response size)]: -1,
    [Symbol(max concurrent streams)]: 100,
    [Symbol(http context)]: {
      version: 'h1',
      defaultPipelining: 1,
      write: [Function: write],
      resume: [Function: resume],
      destroy: [Function: destroy],
      destroyed: [Getter],
      busy: [Function: busy]
    },
    [Symbol(queue)]: [ [Request] ],
    [Symbol(running index)]: 0,
    [Symbol(pending index)]: 1,
    [Symbol(resume)]: [Function (anonymous)],
    [Symbol(on error)]: [Function (anonymous)],
    [Symbol(Intercepted Dispatch)]: [Function: Intercept],
    [Symbol(connecting)]: false,
    [Symbol(needDrain)]: true,
    [Symbol(socket)]: [Circular *1]
  },
  [Symbol(error)]: null
}
report: 20.420s
NET 763280: _read - n 16384 isConnecting? false hasHandle? true
```

</details>

<details><summary>And the result from profiling</summary>

```txt
Statistical profiling result from isolate-0x73e9000-761109-v8.log, (18803 ticks, 99 unaccounted, 0 excluded).

 [Shared libraries]:
   ticks  total  nonlib   name
     16    0.1%          /usr/lib/x86_64-linux-gnu/libc.so.6
      4    0.0%          /usr/local/bin/node
      1    0.0%          /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30

 [JavaScript]:
   ticks  total  nonlib   name
      1    0.0%    0.0%  JS: ~Client node:internal/deps/undici/undici:7698:18
      1    0.0%    0.0%  JS: ~<anonymous> node:internal/crypto/util:119:32
      1    0.0%    0.0%  Builtin: ToBooleanForBaselineJump
      1    0.0%    0.0%  Builtin: LoadIC
      1    0.0%    0.0%  Builtin: KeyedLoadIC

 [C++]:
   ticks  total  nonlib   name
  18602   98.9%   99.0%  __poll@@GLIBC_2.2.5
     30    0.2%    0.2%  _IO_fwrite@@GLIBC_2.2.5
     10    0.1%    0.1%  __write@@GLIBC_2.2.5
      8    0.0%    0.0%  epoll_pwait@@GLIBC_2.6
      7    0.0%    0.0%  _IO_file_xsputn@@GLIBC_2.2.5
      6    0.0%    0.0%  std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@@GLIBCXX_3.4.9
      6    0.0%    0.0%  __libc_malloc@@GLIBC_2.2.5
      2    0.0%    0.0%  brk@@GLIBC_2.2.5
      2    0.0%    0.0%  __pthread_rwlock_unlock@GLIBC_2.2.5
      1    0.0%    0.0%  syscall@@GLIBC_2.2.5
      1    0.0%    0.0%  std::_Hash_bytes(void const*, unsigned long, unsigned long)@@CXXABI_1.3.5
      1    0.0%    0.0%  pthread_cond_signal@@GLIBC_2.3.2
      1    0.0%    0.0%  __pthread_rwlock_rdlock@GLIBC_2.2.5
      1    0.0%    0.0%  __pthread_mutex_unlock@GLIBC_2.2.5

 [Summary]:
   ticks  total  nonlib   name
      5    0.0%    0.0%  JavaScript
  18678   99.3%   99.4%  C++
      4    0.0%    0.0%  GC
     21    0.1%          Shared libraries
     99    0.5%          Unaccounted

 [C++ entry points]:
   ticks    cpp   total   name
  18602   99.7%   98.9%  __poll@@GLIBC_2.2.5
     30    0.2%    0.2%  _IO_fwrite@@GLIBC_2.2.5
      7    0.0%    0.0%  _IO_file_xsputn@@GLIBC_2.2.5
      6    0.0%    0.0%  std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@@GLIBCXX_3.4.9
      6    0.0%    0.0%  __libc_malloc@@GLIBC_2.2.5
      5    0.0%    0.0%  __write@@GLIBC_2.2.5
      2    0.0%    0.0%  __pthread_rwlock_unlock@GLIBC_2.2.5
      1    0.0%    0.0%  brk@@GLIBC_2.2.5
      1    0.0%    0.0%  __pthread_rwlock_rdlock@GLIBC_2.2.5
      1    0.0%    0.0%  __pthread_mutex_unlock@GLIBC_2.2.5

 [Bottom up (heavy) profile]:
  Note: percentage shows a share of a particular caller in the total
  amount of its parent calls.
  Callers occupying less than 1.0% are not shown.

   ticks parent  name
  18602   98.9%  __poll@@GLIBC_2.2.5
  18602  100.0%    JS: ~getReport node:internal/process/report:37:12
  18602  100.0%      Script: ~<anonymous> file:///home/tofandel/test.mjs:1:1
  18602  100.0%        Builtin: AsyncFunctionAwaitResolveClosure
  18602  100.0%          Builtin: CallApiCallbackGeneric
```
</details>","Tofandel",6115458,"2024-10-29 00:06:37","get report


"
279,98,"If I run `process._getActiveHandles()[1].destroy()` before the report (which contains a TLSSocket) then it is generated straight away, so it doesn't like the fact that there is open sockets, the question is why is the tls socket still open when the request is finished? And why an open socket causes getReport to hang for 20 seconds?","Tofandel",6115458,"2024-10-29 00:08:50","run process getactivehandles destroy report contain tls socket generate straight away like fact open socket question tls socket open request finish open socket cause getreport hang second
"
291,99,"Unfortunately, we can't reproduce as this requires API tokens and such, do you happen to have a reproduction (even if it's not minimal) without the login process?","avivkeller",38299977,"2024-10-25 20:49:16","reproduce require api token reproduction login process
"
292,99,"I tried without login but then it did not trigger the bug.
```js
import {Bot, ChatMessage} from ""@skyware/bot"";
var bot = new Bot();
var message = new ChatMessage({text: ""asdf"", sender: {did: ""did:plc:u4gngygg2w5egsigxu5g7byu""}}, bot);
console.log(message);
```
```
$ node bug.mjs 
ChatMessage {
  bot: <ref *1> Bot {
    _events: [Object: null prototype] {},
    _eventsCount: 0,
    _maxListeners: undefined,
    agent: RateLimitedAgent {
      handle: [Function: bound handle] AsyncFunction,
      proxy: undefined,
      limiter: [RateLimitThreshold],
      labelers: [Set]
    },
    handler: CredentialManager {
      serviceUrl: 'https://bsky.social',
      fetch: [Function: fetch]
    },
    cache: {
      profiles: QuickLRU(0) [[]] {},
      posts: QuickLRU(0) [[]] {},
      lists: QuickLRU(0) [[]] {},
      feeds: QuickLRU(0) [[]] {},
      labelers: QuickLRU(0) [[]] {},
      starterPacks: QuickLRU(0) [[]] {},
      conversations: QuickLRU(0) [[]] {}
    },
    eventEmitter: BotEventEmitter {
      _events: [Object: null prototype],
      _eventsCount: 9,
      _maxListeners: undefined,
      bot: [Circular *1],
      strategy: 'polling',
      pollingInterval: 5,
      lastSeen: 2024-10-25T22:49:04.592Z,
      pollingController: AbortController {},
      firehose: undefined,
      jetstream: undefined,
      emitting: true,
      [Symbol(shapeMode)]: false,
      [Symbol(kCapture)]: false
    },
    chatEventEmitter: undefined,
    chatProxy: undefined,
    langs: [ 'en' ],
    profile: undefined,
    [Symbol(shapeMode)]: false,
    [Symbol(kCapture)]: false
  },
  id: undefined,
  conversationId: undefined,
  senderDid: 'did:plc:u4gngygg2w5egsigxu5g7byu',
  sentAt: undefined,
  sender: undefined,
  conversation: undefined,
  text: 'asdf',
  facets: undefined,
  embed: undefined
}
```



This code triggers the bug without any extra steps, but requires password.
```js
import {Bot} from ""@skyware/bot"";

var bot = new Bot();
await bot.login({
	identifier: ""testeststet.bsky.social"",
	password: ""...""
});

var conv = await bot.getConversationForMembers([""did:plc:u4gngygg2w5egsigxu5g7byu""]);
var message = await conv.sendMessage({text: ""test""});

console.log(message);
```
```
$ node bug.mjs 
node:internal/assert:20
  throw new ERR_INTERNAL_ASSERTION(message);
        ^

Error [ERR_INTERNAL_ASSERTION]: Error [ERR_INTERNAL_ASSERTION]: Error [ERR_INTERNAL_ASSERTION]: TypeError: Converting circular structure to JSON
    --> starting at object with constructor 'Bot'
    |     property 'eventEmitter' -> object with constructor 'BotEventEmitter'
    --- property 'bot' closes the circle
    at JSON.stringify (<anonymous>)
    at get [Symbol.toStringTag] (file:///home/ubuntu/bskychatbot/node_modules/quick-lru/index.js:291:15)
    at formatRaw (node:internal/util/inspect:857:18)
    at formatValue (node:internal/util/inspect:841:10)
    at formatProperty (node:internal/util/inspect:1946:11)
    at formatRaw (node:internal/util/inspect:1055:9)
    at formatValue (node:internal/util/inspect:841:10)
    at formatProperty (node:internal/util/inspect:1946:11)
    at formatRaw (node:internal/util/inspect:1055:9)
    at formatValue (node:internal/util/inspect:841:10)
This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at Function.fail (node:internal/assert:20:9)
    at handleMaxCallStackSize (node:internal/util/inspect:1557:10)
    at formatRaw (node:internal/util/inspect:1063:12)
    at formatValue (node:internal/util/inspect:841:10)
    at formatProperty (node:internal/util/inspect:1946:11)
    at formatRaw (node:internal/util/inspect:1055:9)
    at formatValue (node:internal/util/inspect:841:10)
    at formatProperty (node:internal/util/inspect:1946:11)
    at formatRaw (node:internal/util/inspect:1055:9)
    at formatValue (node:internal/util/inspect:841:10)
This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at Function.fail (node:internal/assert:20:9)
    at handleMaxCallStackSize (node:internal/util/inspect:1557:10)
    at formatRaw (node:internal/util/inspect:1063:12)
    at formatValue (node:internal/util/inspect:841:10)
    at formatProperty (node:internal/util/inspect:1946:11)
    at formatRaw (node:internal/util/inspect:1055:9)
    at formatValue (node:internal/util/inspect:841:10)
    at inspect (node:internal/util/inspect:365:10)
    at formatWithOptionsInternal (node:internal/util/inspect:2304:40)
    at formatWithOptions (node:internal/util/inspect:2166:10)
This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at Function.fail (node:internal/assert:20:9)
    at handleMaxCallStackSize (node:internal/util/inspect:1557:10)
    at formatRaw (node:internal/util/inspect:1063:12)
    at formatValue (node:internal/util/inspect:841:10)
    at inspect (node:internal/util/inspect:365:10)
    at formatWithOptionsInternal (node:internal/util/inspect:2304:40)
    at formatWithOptions (node:internal/util/inspect:2166:10)
    at console.value (node:internal/console/constructor:348:14)
    at console.log (node:internal/console/constructor:385:61)
    at file:///home/ubuntu/bskychatbot/bug.mjs:12:9 {
  code: 'ERR_INTERNAL_ASSERTION'
}

Node.js v20.18.0
```

Perhaps I can give you password to test account privately?","ledlamp",103386533,"2024-10-25 22:59:58","try login trigger bug code trigger bug require password cause error circular structure json bug node incorrect usage node internal open issue github nodejs
"
402,118,"Interesting. I'll see if I can narrow down a specific commit. The issue starts with v22.0.0. @nodejs/v8 does this have something to do with V8? I can't reproduce in Chrome.","avivkeller",38299977,"2024-09-18 22:26:03","interesting narrow specific commit issue start v22.0.0 nodejs v8 something v8 reproduce chrome
"
280,98,"If I run 
```
import https from 'node:https'

await new Promise((r) => https.get('https://example.com', () => r()));
console.time('report');
process.report.getReport();
console.timeEnd('report');
```

Then the program only exits after 5minutes (which is the default timeout)

```
NET 769960: pipe false null
NET 769960: connect: find host example.com
NET 769960: connect: dns options { family: undefined, hints: 32 }
NET 769960: connect: autodetecting
NET 769960: _read - n 65536 isConnecting? true hasHandle? true
NET 769960: _read wait for connection
NET 769960: connect/multiple: will try the following addresses [
  { address: '93.184.215.14', family: 4 },
  { address: '2606:2800:21f:cb07:6820:80da:af6b:8b2c', family: 6 }
]
NET 769960: connect/multiple: attempting to connect to 93.184.215.14:443 (addressType: 4)
NET 769960: connect/multiple: setting the attempt timeout to 250 ms
NET 769960: connect/multiple: connection attempt to 93.184.215.14:443 completed with status 0
NET 769960: afterConnect
NET 769960: _read - n 65536 isConnecting? false hasHandle? true
NET 769960: Socket._handle.readStart
NET 769960: _read - n 65536 isConnecting? false hasHandle? true
report: 20.724s
NET 769960: _read - n 65536 isConnecting? false hasHandle? true
NET 769960: _final: not ended, call shutdown()
NET 769960: afterShutdown destroyed=false
NET 769960: destroy
NET 769960: close
NET 769960: close handle
NET 769960: emit close

```

Is it normal that https.get causes node to never exit (unless I set headers: { 'Connection': 'close' })?","Tofandel",6115458,"2024-10-29 00:39:38","program exit minute default timeout connect host example dns option family hint autodetecting read connect attempt address addressType connect multiple connection attempt status socket read start final shutdown destroy close handle emit close normal https get cause node exit unless set header connection close
"
281,98,"Seems related to WSL based on the comments:
https://github.com/npm/cli/issues/7868
https://github.com/npm/cli/issues/7814","jeremyVignelles",3399355,"2024-10-29 09:29:21","relate wsl base comment
"
282,98,"I can reproduce it directly on Windows as well and not just WSL I think it's directly related to windows network stack because it's been reported as happening on docker as well, which I'm guessing were all docker running in windows 

If I change the request to go to localhost for example, then this issue doesn't happen, the only difference I see is one read (or timeout) is still happening after the getReport takes place

localhost:
```
NET 777218: pipe false null
NET 777218: connect: find host localhost
NET 777218: connect: dns options { family: undefined, hints: 32 }
NET 777218: connect: autodetecting
NET 777218: _read - n 65536 isConnecting? true hasHandle? true
NET 777218: _read wait for connection
NET 777218: connect/multiple: only one address found, switching back to single connection
NET 777218: connect: attempting to connect to 127.0.0.1:80 (addressType: 4)
NET 777218: afterConnect
NET 777218: _read - n 65536 isConnecting? false hasHandle? true
NET 777218: Socket._handle.readStart
NET 777218: _read - n 65536 isConnecting? false hasHandle? true
report: 2.206ms
NET 777218: _final: not ended, call shutdown()
NET 777218: afterShutdown destroyed=false
NET 777218: destroy
NET 777218: close
NET 777218: close handle
NET 777218: emit close
```

Example.com
```
NET 778100: pipe false null
NET 778100: connect: find host example.com
NET 778100: connect: dns options { family: undefined, hints: 32 }
NET 778100: connect: autodetecting
NET 778100: _read - n 65536 isConnecting? true hasHandle? true
NET 778100: _read wait for connection
NET 778100: connect/multiple: will try the following addresses [
  { address: '93.184.215.14', family: 4 },
  { address: '2606:2800:21f:cb07:6820:80da:af6b:8b2c', family: 6 }
]
NET 778100: connect/multiple: attempting to connect to 93.184.215.14:443 (addressType: 4)
NET 778100: connect/multiple: setting the attempt timeout to 250 ms
NET 778100: connect/multiple: connection attempt to 93.184.215.14:443 completed with status 0
NET 778100: afterConnect
NET 778100: _read - n 65536 isConnecting? false hasHandle? true
NET 778100: Socket._handle.readStart
NET 778100: _read - n 65536 isConnecting? false hasHandle? true
report: 20.108s
NET 778100: _read - n 65536 isConnecting? false hasHandle? true
NET 778100: _final: not ended, call shutdown()
NET 778100: afterShutdown destroyed=false
NET 778100: destroy
NET 778100: close
NET 778100: close handle
NET 778100: emit close
```

If I turn on a VPN or connect to a different network the issue still persists but with different timings","Tofandel",6115458,"2024-10-29 09:51:26","reproduce windows wsl relate windows network stack report docker docker run windows change request localhost issue happen difference read timeout getReport take place connect attempt address family connect attempt complete status time vpn connect network issue persist different timing
"
283,98,"I made an intersting discovery, I had the twingate service running on the machine (which is some kind of VPN for tunneling, though only for specific domain names or ip, which should not have covered this specific ip), with it off it now takes ""only"" 2seconds on WSL and 5s on windows instead of 20seconds for both, it's still way too long though


I tried again and indeed as soon as I enable any kind of VPN the issue is very pronounced","Tofandel",6115458,"2024-10-29 11:07:55","discovery twingate service run machine kind vpn tunnel specific domain name ip cover specific ip seconds wsl second window second long try enable kind vpn issue pronounce
"
284,98,"> ```
> Linux Tofandel 5.15.146.1-microsoft-standard-WSL2 #1 SMP Thu Jan 11 04:09:03 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
> 
> ```js
> console.time(""report"");
> process.report.getReport();
> console.timeEnd(""report"");
> await fetch('https://example.com/');
> console.time(""report"");
> process.report.getReport();
> console.timeEnd(""report"");
> await fetch('https://example.com/');
> await fetch('https://example.com/');
> console.time(""report"");
> process.report.getReport();
> console.timeEnd(""report"");
> console.time(""report"");
> process.report.getReport();
> console.timeEnd(""report"");
> ```

If I replace await fetch with await https.get with https = require('https') it runs through quick. The problem probably is in the fetch function.","fuhlich",159451960,"2024-10-30 09:07:47","linux to fandel problema fetch função
"
285,98,"No I already rulled that out, both https.get and fetch have the issue, the issue has to do with sockets that are still open when getReport runs

Your usage of https.get is just probably wrong because it does not return a promise and cannot be awaited you need to promisify it, so likely your get report runs before the request actually happens

See my comment a bit above
```js
import https from 'node:https'

await new Promise((r) => https.get('https://example.com', () => r()));
console.time('report');
process.report.getReport();
console.timeEnd('report');
```

You can try this","Tofandel",6115458,"2024-10-30 09:12:16","already rule both issue issue socket still open getReport run usage probably wrong return promise await promisify likely report run request happen comment promise get report time report time try
"
286,98,"I can also rule out a WSL only issue as it happens on a native Ubuntu 20 as well (on a completely different network, on a server in a datacenter)

But only the first time it is run. Also the node process not exiting with https.get starts happening on node 20 (and node 22) but doesn't happen on node 18 (on ubuntu still)

So yes it seems the common factor is any request that makes a DNS query still causes getReport to hang","Tofandel",6115458,"2024-10-30 09:20:08","issue occur native ubuntu node process exit https get start happen node node happen node ubuntu request dns query cause getreport hang
"
287,98,"I overlooked that, my mistake.","fuhlich",159451960,"2024-10-30 09:22:11","overlook mistake
"
288,98,"After debugging from source, the very long time comes entirely from https://github.com/nodejs/node/blob/6dea41d2f7073f110486beb0dc7d793cdcf59160/src/node_report.cc#L205

This is what https://github.com/nodejs/node/issues/46060#issuecomment-1369007289 was talking about, and looking at the `exclude-network` option that was added, it doesn't address this section at all

Specifically any open TCP or UDP UV still tries to query reverse dns records there
https://github.com/nodejs/node/blob/6dea41d2f7073f110486beb0dc7d793cdcf59160/src/node_report_utils.cc#L178-L181

https://github.com/nodejs/node/blob/6dea41d2f7073f110486beb0dc7d793cdcf59160/src/node_report_utils.cc#L29","Tofandel",6115458,"2024-10-30 13:10:11","debug source long time come talk exclude network option address section open tcp udp uv query revers dns record
"
289,99,"Hi! Can you provide a minimal reproduction without the external library? ","avivkeller",38299977,"2024-10-25 20:19:10","provide minimal reproduction external library
"
290,99,"No, I don't know how to.","ledlamp",103386533,"2024-10-25 20:47:45","know
"
761,156,"Thanks for looking into this @juanarbol.","ehmicky",8136211,"2024-05-29 05:57:19","look
"
293,99,"No. I would prefer not to transfer information privately. Rather, someone will see this and help to provide a minimal reproduction. I'll also try myself.

Hopefully, in a few days, we'll have a minimal reproduction.","avivkeller",38299977,"2024-10-25 23:08:27","prefer transfer information privately someone see help provide minimal reproduction try hope day minimal reproduction
"
294,99,"This seems to reproduce the issue:

```js
const { inspect } = require('node:util');
const y = {
  get [Symbol.toStringTag]() {
    return JSON.stringify(this);
  }
};
const x = { y };
y.x = x;
inspect(x);
```

You can get an even simpler repro stack trace if you `inspect(y)` instead of `x`.

It's because [this line](https://github.com/nodejs/node/blob/e312d60e3f81dfa26d5922f3c23a371b2b2ce343/lib/internal/util/inspect.js#L865) triggers a getter that throws in the `quick-lru` module. Independent of any cycle detection, this doesn't seem to be handled correctly at the moment.
","cjihrig",2512748,"2024-10-26 00:00:07","reproduce issue get even simpler repro stack trace inspect line trigger getter throw quick lru module independent cycle detection seem handle correctly moment
"
295,100,"The assertion is failing because it expects the URL's protocol to be `file:`, when it is `http:`","avivkeller",38299977,"2024-10-24 22:03:12","assertion fail expect url protocol file http
"
296,100,"I would like to work on this. In the function ```moduleResolve``` in  lib/internal/modules/esm/resolve.js when the protocol of the parsed parentURL is not ```file``` the parentURL is returned. Instead of just returning the parentURL, can we do something like this in the function ```moduleResolve```:

```javascript
  if (resolved.protocol !== 'file:') {
     throw new ERR_INVALID_URL_SCHEME(resolved.protocol);
  }
```","cedrick-ah",75441977,"2024-10-25 09:00:04","work function moduleResolve lib internal module esm resolve js protocol parsed parentURL file parentURL return return parentURL something function moduleResolve resolved protocol file throw ERR INVALID URL SCHEME resolved protocol
"
297,100,"No, That wouldn't work. Under the hood, the issue is because it's trying to read the package configuration for the URL, which it can't do. There are cases where a URL can be used, this is not one of them.","avivkeller",38299977,"2024-10-25 09:43:18","work issue try read package configuration url case url use
"
298,100,"> The assertion is failing because it expects the URL's protocol to be `file:`, when it is `http:`

According to this, can we then check for the URL protocol in ```throwIfInvalidParentURL```?","cedrick-ah",75441977,"2024-10-25 09:52:42","assertion fail expect url protocol file http check url protocol throwifinvalidparenturl
"
299,100,"I believe @JakobJingleheimer may know more than I (regarding the package.json reading) (if not, sorry for the ping)","avivkeller",38299977,"2024-10-25 10:04:42","believe JakobJingleheimer know package.json read ping
"
300,100,"The provided code sample looks like a loader hook. If so, `import.meta.resolve()` is not available within loaders.","JakobJingleheimer",3012099,"2024-10-25 15:20:51","code sample look loader hook import meta resolve available loader
"
301,100,"The code sample just demonstrates the different behavior for resolving a bare specifier in `http:` context. For other input there is either a result or a catchable error, but in this case the assertion error crashes the node process.","ph-fritsche",39068198,"2024-10-26 10:39:24","code sample demonstrate different behavior resolve bare specifier http context input result catchable error case assertion error crash node process
"
302,100,"> The provided code sample looks like a loader hook. If so, `import.meta.resolve()` is not available within loaders.

Regardless, it shouldn't crash at the CPP level. It should probably through a module not found error?","avivkeller",38299977,"2024-10-26 11:00:04","code sample look loader hook import meta resolve available loader crash cpp level module found error
"
303,101,"The relevant code is in `packages/babel-core/lib/config/files/module-types.js`.

What is going on is that:
- in `loadCodeDefault`, we go in the `auto .js` branch
- it calls `loadCjsDefault`, which `require`s `plugin.js`
- that require call throws due to TLA
- In the `catch` inside `loadCodeDefault`, `async ??= yield* isAsync()` is `true` to we suppress the error
- It falls through, and calls `loadMjsFromPath` in the `auto .mjs` branch
- `loadMjsFromPath` calls `import_(url)`, which calls `import(url)`

However, a minimal reproduction of `try/catch` around `require()` falling back to `import()` does not trigger the assertion.","nicolo-ribaudo",7000710,"2024-10-23 15:53:18","code package babel core lib config file module type go load code default auto js branch call load cjs default require plugin js require call throw tla catch inside load code default async yield is async true suppress error fall call load mjs path auto mjs branch load mjs path call import url call import url minimal reproduction try catch around require fall back import trigger assertion
"
304,101,"Minimal reproduction:
```js
try {
  require(""./file-with-tla.mjs"");
} catch {
  import(""./file-with-tla.mjs"").then(console.log, console.error);
}
```","nicolo-ribaudo",7000710,"2024-10-23 15:55:18","reproduction minimal file tla mjs require import then log error
"
305,101,"```js
// tla.js
await new Promise(resolve => resolve());
```
```js
try {
    require(""./tla.js"");
} catch {
    import(""./tla.js"");
}
```","avivkeller",38299977,"2024-10-23 16:12:42","promise resolve require import tla js
"
306,101,"Failing assertion:
https://github.com/nodejs/node/blob/7b5d660bb184afdc8d723a856484e648bf7f17ae/lib/internal/modules/esm/module_job.js#L358","avivkeller",38299977,"2024-10-23 16:13:34","Failing assertion
"
307,101,"Thanks for reporting it, fix in https://github.com/nodejs/node/issues/55502","joyeecheung",4299420,"2024-10-23 16:33:05","report fix issue
"
308,102,"PRs are always welcome :-)","avivkeller",38299977,"2024-10-18 17:25:29","pr welcome
"
309,102,"@RedYetiDev I just make a PR for this issue. It's my first PR ^_^","leviscar",18376002,"2024-10-18 20:39:56","make PR issue first PR
"
310,102,"@leviscar thanks for making a PR, I did some research and have one minor correction:

https://github.com/nodejs/node/pull/55450/files#r1807010918","sparecycles",719818,"2024-10-18 21:01:48","thanks make pr research minor correction
"
321,103,"I've made a minimal reproduction: 
```js
const walk = require('ignore-walk');
const { resolve, join } = require('path')
const packageDir = resolve('../testing') + '/';

walk({
    path: join(packageDir, 'dist'),
    parent: {
        root: packageDir,
        result: new Set([]),
    },
}, console.log)
```","avivkeller",38299977,"2024-10-16 23:24:53","minimal reproduction require ignore walk resolve join packageDir resolve testing walk path join packageDir dist parent root packageDir result set console log
"
322,103,"This seems to be an issue with some logic in `ignore-walk`. I'll continue investigating the root cause.","avivkeller",38299977,"2024-10-17 00:02:59","issue logic ignore walk investigate root cause
"
403,118,"It's probably caused by https://github.com/nodejs/node/pull/50107","targos",2352663,"2024-09-19 06:27:23","probably cause
"
404,118,"CC @H4ad ","avivkeller",38299977,"2024-09-20 20:16:50","haad
"
405,119,"Spec: <https://dom.spec.whatwg.org/#create-a-dependent-abort-signal>","avivkeller",38299977,"2024-08-29 16:54:18","spec criar dependente abort signal
"
681,146,"I'm going to compile a debug build on one of the Hetzner machines to get a meaningful stack trace.","targos",2352663,"2024-05-02 15:19:01","compile debug build machine meaningful stack trace
"
311,103,"I can't reproduce. Does the file that it's looking for exist?
```console
$ node -v 
v23.0.0
                                                                                                                                                                                                                                
$ cat package.json
{
    ""name"": ""package"",
    ""version"": ""0.0.0""
}                                                                                                                                                                                                                                
$ npm pack
(node:112161) ExperimentalWarning: Support for loading ES Module in require() is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
npm notice
npm notice 📦  package@0.0.0
npm notice Tarball Contents
npm notice 49B package.json
npm notice Tarball Details
npm notice name: package
npm notice version: 0.0.0
npm notice filename: package-0.0.0.tgz
npm notice package size: 140 B
npm notice unpacked size: 49 B
npm notice shasum: 9b86ea669576bef9600e739c770b2e5635f75482
npm notice integrity: sha512-sKnSxYIx7NX5u[...]PXtisbzPyqMIA==
npm notice total files: 1
npm notice
package-0.0.0.tgz
```","avivkeller",38299977,"2024-10-16 18:51:27","reproduce file exist
"
312,103,"> I can't reproduce. Does the file that it's looking for exist?

It's looking for `/ist/index.cjs` while it's `dist/index.cjs`, @RedYetiDev 
The first letter is lost for some reason","RobinTail",13189514,"2024-10-16 18:52:44","reproduce file exist look ist index cjs dist index cjs letter lose reason
"
313,103,"Why is it looking for that file? Can you provide your `package.json` file and directory structure? ","avivkeller",38299977,"2024-10-16 18:53:23","why look file provide package json file directory structure
"
314,103,"I've been able to reproduce now:
```console
$ node -v 
v23.0.0
                                                                                                                                                                                                                                
$ cat package.json
{
    ""name"": ""package"",
    ""version"": ""0.0.0""
}

$ tree                                                                   
.
├── dist
│   └── index.cjs
└── package.json

$ npm pack
(node:114615) ExperimentalWarning: Support for loading ES Module in require() is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
npm warn tarball tarball data for file:/path/ (null) seems to be corrupted. Trying again.
npm warn tarball tarball data for file:/path/ (null) seems to be corrupted. Trying again.
npm error code ENOENT
npm error syscall lstat
npm error path /path/ist/index.cjs
npm error errno -2
npm error enoent ENOENT: no such file or directory, lstat '/path/ist/index.cjs'
npm error enoent This is related to npm not being able to find a file.
npm error enoent
npm error A complete log of this run can be found in: /home/user/.npm/_logs/2024-10-16T18_55_56_185Z-debug-0.log
```","avivkeller",38299977,"2024-10-16 18:54:54","reproduce node version cat package name version npm pack experimental warning support load es module require experimental feature change node trace warnings warning create npm warn tarball tarball data file null seem corrupt try npm warn tarball tarball data file null seem corrupt try npm error code enoent npm error syscall lstat npm error path path ist index cjs npm error errno npm error enoent enoent no such file directory lstat path ist index cjs npm error enoent relate npm able find file npm error enoent complete log run find home user npm logs z debug log
"
315,103,"Looks like a Node.js side issue. I downgraded my npm to v10.8.3 (the version w/ Node.js v22.9.0) and the error still occured. I then downgraded my Node.js to v22.9.0, and kept npm at v10.9.0, and the error no longer occured.

CC @nodejs/npm","avivkeller",38299977,"2024-10-16 18:55:44","node js issue downgrade npm version error downgrade node js version error occur
"
316,103,"> Why is it looking for that file? Can you provide your package.json file and directory structure?

I don't know why, but it does not in any other Node.js version.

package.json is here:
https://github.com/RobinTail/express-zod-api/blob/test-node23/package.json

directory structure, @RedYetiDev 

```
$ tree -d -L 1
.
├── dist
├── example
├── migration
├── node_modules
├── src
├── tests
└── tools
```","RobinTail",13189514,"2024-10-16 19:03:50","why look file provide package json file directory structure know node js version package json directory structure
"
317,103,"Here's the stacktrace
```js
READ /.../ist/index.cjs
    at Object.lstat (node:fs:1549:15)
    at Object.lstat (/node/deps/npm/node_modules/graceful-fs/polyfills.js:309:16)
    at [stat] (/node/deps/npm/node_modules/tar/lib/pack.js:181:13)
    at [processJob] (/node/deps/npm/node_modules/tar/lib/pack.js:278:19)
    at [process] (/node/deps/npm/node_modules/tar/lib/pack.js:232:23)
    at [addFSEntry] (/node/deps/npm/node_modules/tar/lib/pack.js:174:18)
    at Pack.write (/node/deps/npm/node_modules/tar/lib/pack.js:150:23)
    at Pack.add (/node/deps/npm/node_modules/tar/lib/pack.js:129:10)
    at addFilesAsync (/node/deps/npm/node_modules/tar/lib/create.js:95:9)
    at create (/node/deps/npm/node_modules/tar/lib/create.js:109:3)
    at module.exports (/node/deps/npm/node_modules/tar/lib/create.js:39:7)
    at /node/deps/npm/node_modules/pacote/lib/dir.js:76:26
```

Intrestingly, a few calls before this is:
```js
READ /.../dist/index.cjs
    at Object.lstat (node:fs:1549:15)
    at Object.lstat (/node/deps/npm/node_modules/graceful-fs/polyfills.js:309:16)
    at PackWalker.stat (/node/deps/npm/node_modules/ignore-walk/lib/index.js:177:8)
    at PackWalker.stat (/node/deps/npm/node_modules/npm-packlist/lib/index.js:192:18)
    at /node/deps/npm/node_modules/ignore-walk/lib/index.js:153:14
    at Array.forEach (<anonymous>)
    at PackWalker.filterEntries (/node/deps/npm/node_modules/ignore-walk/lib/index.js:149:16)
    at PackWalker.filterEntries (/node/deps/npm/node_modules/npm-packlist/lib/index.js:173:18)
    at PackWalker.onReaddir (/node/deps/npm/node_modules/ignore-walk/lib/index.js:78:14)
    at /node/deps/npm/node_modules/ignore-walk/lib/index.js:54:42
    at /node/deps/npm/node_modules/graceful-fs/graceful-fs.js:228:16
    at FSReqCallback.oncomplete (node:fs:188:23)
```

---

**Update**

The failing call is the call to `libpack` from `libnpmpack` in 

https://github.com/npm/cli/blob/62c71e5128a01283f97bd62da30ddc673bddda0b/lib/commands/pack.js#L49

More specifically, the call to `tarball` in https://github.com/npm/cli/blob/62c71e5128a01283f97bd62da30ddc673bddda0b/workspaces/libnpmpack/lib/index.js#L31","avivkeller",38299977,"2024-10-16 20:04:33","stacktrace read dist index cjs object lstat node fs object lstat node deps npm node modules graceful fs polyfills js stat node deps npm node modules tar lib pack js processjob node deps npm node modules tar lib pack js process node deps npm node modules tar lib pack js addfsentry node deps npm node modules tar lib pack js pack write node deps npm node modules tar lib pack js pack add node deps npm node modules tar lib pack js addfilesasync node deps npm node modules tar lib create js create node deps npm node modules tar lib create js module exports node deps npm node modules tar lib create js node deps npm node modules pacote lib dir js read dist index cjs object lstat node fs object lstat node deps npm node modules graceful fs polyfills js packwalker stat node deps npm node modules ignore walk lib index js packwalker stat node deps npm node modules npm packlist lib index js node deps npm node modules ignore walk lib index js array for each packwalker filterentries node deps npm node modules ignore walk lib index js packwalker filterentries node deps npm node modules npm packlist lib index js packwalker onreaddir node deps npm node modules ignore walk lib index js node deps npm node modules ignore walk lib index js node deps npm node modules graceful fs graceful fs js fsreqcallback oncomplete node fs call libpack libnpmpack call tarball github npm cli lib commands pack js libnpmpack lib index js
"
318,103,"Same/Similar issue here that just started occuring today when trying to install renovatebot's pre-commit hook (https://github.com/renovatebot/pre-commit-hooks) which has been working for me up until today.
<img width=""1916"" alt=""image"" src=""https://github.com/user-attachments/assets/77897e91-08c3-4652-a9ec-7cb97b31218d"">

Worth noting, similar to the `ist` vs `dist` mentioned earlier in the thread, if you look closely at this error message, it's looking for a path that includes `ode_env-default` rather than `node_env-default`
","jasonwashburn",35488541,"2024-10-16 20:21:08","issue start occur today install renovatebot pre commit hook work today note similar mention thread look closely error message look path include ode env default node env default
"
319,103,"This is a reminder that ""me too"" comments only add noise. For everyone considering commenting, please only comment **if you have something _meaningful_ to add to the conversation**.

If you're experiencing this issue, please 👍 the issue or a comment you agree with. There is no need to comment if you are also affected by the this.","avivkeller",38299977,"2024-10-16 20:25:53","meaningful add conversation experience issue agree affect
"
320,103,"Self-note: We should add `pack` and other common commands to the test suite of https://github.com/nodejs/citgm/tree/main/test/npm (PRs welcome)","ovflowd",12037269,"2024-10-16 20:51:34","add pack common command test suite pr welcome
"
369,111,"@nodejs/test_runner - sounds like a simple fix, that is, assuming this is just one statement that clears the screen?","avivkeller",38299977,"2024-09-19 12:57:31","nodejs test runner sound simple fix assume statement clear screen
"
323,103,"`git bisect` is pointing to efbba60e5b8aed95b2413ff4169632bf3605c963 / https://github.com/nodejs/node/pull/54224
```
$ git bisect log
git bisect start
# status: waiting for both good and bad commits
# bad: [e2242b4e256082e01d8df6a4155ddc80e146c123] 2024-10-16, Version 22.10.0 (Current)
git bisect bad e2242b4e256082e01d8df6a4155ddc80e146c123
# status: waiting for good commit(s), bad commit known
# bad: [20d8b85d3493bec944de541a896e0165dd356345] deps: upgrade npm to 10.9.0
git bisect bad 20d8b85d3493bec944de541a896e0165dd356345
# status: waiting for good commit(s), bad commit known
# bad: [cde6dccb656ad8ad134c2e509c584711156a908c] tools: refactor js2c.cc to use c++20
git bisect bad cde6dccb656ad8ad134c2e509c584711156a908c
# status: waiting for good commit(s), bad commit known
# good: [d2479fa020866f038785fb7373baf2621d7cc1c5] vm: return all own names and symbols in property enumerator interceptor
git bisect good d2479fa020866f038785fb7373baf2621d7cc1c5
# good: [7c58645aca2b53d15dbf698efa43cf934a436d91] lib: move `Symbol[Async]Dispose` polyfills to `internal/util`
git bisect good 7c58645aca2b53d15dbf698efa43cf934a436d91
# bad: [e4692eee75af720640beb557d9279adc0f3e648d] benchmark: --no-warnings to avoid DEP/ExpWarn log
git bisect bad e4692eee75af720640beb557d9279adc0f3e648d
# good: [d38dc99a95fd9dfd634bb938a53871719115fb50] src: add Cleanable class to Environment
git bisect good d38dc99a95fd9dfd634bb938a53871719115fb50
# good: [415905712e59c0d8d7270de27a3b789a121968cd] test: improve test-internal-fs-syncwritestream
git bisect good 415905712e59c0d8d7270de27a3b789a121968cd
# bad: [a65105ec284023960e93b3a66f6661ddd2f4121f] test: adjust tls test for OpenSSL32
git bisect bad a65105ec284023960e93b3a66f6661ddd2f4121f
# good: [f468509cf6f6ebc7d753e8f30686fe0c6b609dc5] zlib: add typings for better dx
git bisect good f468509cf6f6ebc7d753e8f30686fe0c6b609dc5
# bad: [efbba60e5b8aed95b2413ff4169632bf3605c963] path: fix bugs and inconsistencies
git bisect bad efbba60e5b8aed95b2413ff4169632bf3605c963
# good: [c3e1c31baa8f4a59ef49ea0d0429ec55efe2ca81] build: upgrade clang-format to v18
git bisect good c3e1c31baa8f4a59ef49ea0d0429ec55efe2ca81
# first bad commit: [efbba60e5b8aed95b2413ff4169632bf3605c963] path: fix bugs and inconsistencies
```

cc @huseyinacacak-janea","richardlau",5445507,"2024-10-17 00:03:14","git bisect point efbba60e5b8aed95b2413ff4169632bf3605c963 git bisect log git bisect start status wait good bad commit bad e2242b4e256082e01d8df6a4155ddc80e146c123 version current git bisect bad e2242b4e256082e01d8df6a4155ddc80e146c123 status wait good commit bad commit know bad 20d8b85d3493bec944de541a896e0165dd356345 dep upgrade npm git bisect bad 20d8b85d3493bec944de541a896e0165dd356345 status wait good commit bad commit know bad cde6dccb656ad8ad134c2e509c584711156a908c tool refactor js2c cc use c 20 git bisect bad cde6dccb656ad8ad134c2e509c584711156a908c status wait good commit bad commit know good d2479fa020866f038785fb7373baf2621d7cc1c5 vm return own name symbol property enumerator interceptor git bisect good d2479fa020866f038785fb7373baf2621d7cc1c5 good 7c58645aca2b53d15dbf698efa43cf934a436d91 lib move symbol async dispose polyfill internal util git bisect good 7c58645aca2b53d15dbf698efa43cf934a436d91 bad e4692eee75af720640beb557d9279adc0f3e648d benchmark no warning avoid dep expwarn log git bisect bad e4692eee75af720640beb557d9279adc0f3e648d good d38dc99a95fd9dfd634bb938a53871719115fb50 src add cleanable class environment git bisect good d38dc99a95fd9dfd634bb938a53871719115fb50 good 415905712e59c0d8d7270de27a3b789a121968cd test improve test internal fs syncwritestream git bisect good 415905712e59c0d8d7270de27a3b789a121968cd bad a65105ec284023960e93b3a66f6661ddd2f4121f test adjust tls test openssl32 git bisect bad a65105ec284023960e93b3a66f6661ddd2f4121f good f468509cf6f6ebc7d753e8f30686fe0c6b609dc5 zlib add typing better dx git bisect good f468509cf6f6ebc7d753e8f30686fe0c6b609dc5 bad efbba60e5b8aed95b2413ff4169632bf3605c963 path fix bug inconsistency git bisect bad efbba60e5b8aed95b2413ff4169632bf3605c963 good c3e1c31baa8f4a59ef49ea0d0429ec55efe2ca81 build upgrade clang format v18 git bisect good c3e1c31baa8f4a59ef49ea0d0429ec55efe2ca81 first bad commit efbba60e5b8aed95b2413ff4169632bf3605c963 path fix bug inconsistency
"
324,103,"> `git bisect` is pointing to [efbba60](https://github.com/nodejs/node/commit/efbba60e5b8aed95b2413ff4169632bf3605c963) / #54224

```js
path.resolve(""/path/"");
// v23.0.0: ""/path/""
// v22.9.0: ""/path""
```","avivkeller",38299977,"2024-10-17 00:58:56","git bisect point efbba60 path resolve v23 path v22 path
"
325,103,"IMHO path separators shouldn't be preserved since that would make the resolution of identical paths (one with `/` and one without) return different results. See my revert for more info","avivkeller",38299977,"2024-10-17 01:18:07","path separator shouldnt preserve make resolution identical path one return different result see revert info
"
326,103,"I just spent 4 hours of my time trying to debug a new CI setup to publish a package because of this as its affecting all of the `{current-, 23-,}bookworm-slim` docker images. it initially manifested itself in `npm publish` as looking into the ***parent directory*** for the `README.md`, which of course failed and there was zero indication as to why it was even leaving the CWD (which was correct in the output after it failed!). I then manually added a `""readme"": ""foobar""` to the `package.json` to get it to skip that, and then it failed in the same broken way as above, removing the `d` from `dist/` when going to collect the files in the directory to create the package. so to help anyone else looking for why `npm error enoent ENOENT: no such file or directory, open '<parent of cwd path>/README.md'` is happening, this is it. moving to using the `node:22-bookworm-slim` image immediately worked with no changes needed.","repnop",24203105,"2024-10-17 04:18:04","spend hour debug new CI setup publish package affect bookworm slim docker image initially manifest npm publish look parent directory README md fail zero indication leave CWD correct output fail manually add readme foobar package json skip fail broken way remove dist collect file directory create package help anyone look npm error enoent ENOENT file directory open parent cwd path README md move use node bookworm slim image immediately work change need
"
327,104,"There's an obvious bug here:

https://github.com/nodejs/node/blob/51d81466efc00417711558a08d0ff4206d8bf174/lib/dns.js#L194-L197","targos",2352663,"2024-10-15 08:41:53","obvious bug
"
328,105,"Hm, the memory is being allocated just for refs - potentially pointing to nothing?

Something like this would work?

```js
const finalizers = new SafeFinalizationRegistry((signal) => {
  signal[kDependantSignals].forEach(ref => {
    if (!ref.deref()) {
      signal[kDependantSignals].delete(ref);
    }
  });
});
```

Then in the [loop](https://github.com/nodejs/node/blob/main/lib/internal/abort_controller.js#L239) having this 

```js
// ...
for (let i = 0; i < signalsArray.length; i++) {
  const signal = signalsArray[I];
   finalizers.register(resultSignal, signal);

  // ...
```

### Executing this repro after this (maybe naive?) change

```
./node test.js
100000 - 102.05 MiB - 29116 signals
200000 - 110.38 MiB - 26503 signals
300000 - 110.88 MiB - 21856 signals
400000 - 110.95 MiB - 17219 signals
500000 - 110.41 MiB - 12624 signals
600000 - 110.17 MiB - 8016 signals
700000 - 110.00 MiB - 3414 signals
800000 - 112.42 MiB - 33650 signals
900000 - 111.17 MiB - 29002 signals
1000000 - 111.22 MiB - 24377 signals
1100000 - 111.31 MiB - 19735 signals
1200000 - 110.69 MiB - 15108 signals
1300000 - 110.69 MiB - 10480 signals
1400000 - 110.50 MiB - 5784 signals
1500000 - 110.33 MiB - 1181 signals
1600000 - 111.47 MiB - 31432 signals
1700000 - 112.11 MiB - 26792 signals
1800000 - 112.16 MiB - 22141 signals
1900000 - 112.17 MiB - 17532 signals
2000000 - 111.53 MiB - 12900 signals
2100000 - 111.53 MiB - 8255 signals
2200000 - 111.08 MiB - 3607 signals
2300000 - 113.48 MiB - 33826 signals
2400000 - 112.30 MiB - 29157 signals
2500000 - 112.30 MiB - 24488 signals
2600000 - 112.30 MiB - 19846 signals
2700000 - 111.75 MiB - 15259 signals
2800000 - 111.77 MiB - 10527 signals
2900000 - 111.44 MiB - 5933 signals
3000000 - 111.28 MiB - 1325 signals
```","geeksilva97",15680379,"2024-10-10 18:42:10","memory allocate ref potentially point nothing work finalizer new safe finalization registry signal signal kdependantsignals foreach ref ref deref signal kdependantsignals delete ref loop signal signalarray length signal signal finalizer register resultsignal signal execute repro change node test mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal mib signal
"
329,105,"Ref: https://github.com/chromium/chromium/commit/d5b7539036199ad653125222f061f39c66e91a86 - I think it would be the ""settled"" case(?)","geeksilva97",15680379,"2024-10-10 18:47:41","think settled case
"
330,105,"Is anyone working on this issue?","siddhant0410",63441006,"2024-10-13 18:56:14","work issue
"
331,105,"Can confirm that we have a problem on this, however, it is not `AbortSignal` instances that are being leaked, it's `WeakRef`s. Specifically, the set of dependent signals known to the `AbortSignal` are kept in an internal `Set` using `WeakRef`s. The `AbortSignal`s are being properly gc'd but the `Set` is never cleaned out of the `WeakRef`s making those leak.","jasnell",439929,"2024-10-13 21:51:41","confirm problem however weakref specifically set dependent signal know abortsignal use weakref abortsignal properly gc set never clean weakref make leak
"
332,105,"> Is anyone working on this issue?

I have a pr opened to address this issue.","geeksilva97",15680379,"2024-10-13 22:07:56","anyone work issue pr open address issue
"
333,105,"> > Is anyone working on this issue?
> 
> I have a pr opened to address this issue.

So if I want to work on this issue do I need to contact someone or I can start working right away?","siddhant0410",63441006,"2024-10-14 07:21:40","work issue pr address issue want work issue need contact someone start work
"
334,105,"> > > Is anyone working on this issue?
> > I have a pr opened to address this issue.
> So if I want to work on this issue do I need to contact someone or I can start working right away?

@siddhant0410 The PR here https://github.com/nodejs/node/pull/55354 by @geeksilva97 already fixes this issue, so there's nothing else to do here but wait for the PR to be merged and backported.","mika-fischer",426158,"2024-10-14 07:38:39","work issue pr address issue want work issue need contact start work right away pr fix issue nothing wait pr merge backport
"
335,105,"> > > > Is anyone working on this issue?
> > > > I have a pr opened to address this issue.
> > > > So if I want to work on this issue do I need to contact someone or I can start working right away?
> 
> @siddhant0410 The PR here #55354 by @geeksilva97 already fixes this issue, so there's nothing else to do here but wait for the PR to be merged and backported.

Thanks for the update!","siddhant0410",63441006,"2024-10-14 07:47:12","work issue pr address issue want work issue need contact start work right away pr fix issue nothing wait pr merge backport update
"
336,106,"These also **aren't** reference equal AFAICT. If you deepStrictEqual the errors, they _should_ fail.","avivkeller",38299977,"2024-10-08 01:53:27","deepStrictEqual error fail
"
370,111,"I'm taking a look","pmarchini",49943249,"2024-09-19 13:04:18","look
"
337,106,"Yeah, maybe my description wasn't clear. Assertion failure is expected, but its error message is what I wanted to point out. 

Indeed, `are not reference-equal` is a correct statement, but I felt it's misleading because, when using `assert.deepStrictEqual`, I wouldn't usually concerned with ""reference-equality"".

One more example here when dropping `cause` on one side, it shows the same message. In this case, `Values have same structure` sounds misleading then.

```ts
> assert.deepStrictEqual(new Error(""a""), new Error(""a"", { cause: new Error(""y"") }))
Uncaught:
AssertionError [ERR_ASSERTION]: Values have same structure but are not reference-equal:

[Error: a]
```

","hi-ogawa",4232207,"2024-10-08 03:52:01","assertion failure expect error message point indeed correct statement mislead use deepStrictEqual usually concern reference equality example drop side show message case value structure sound mislead
"
338,106,"@hi-ogawa thank you for the report! This is indeed an issue with comparing errors.

`cause` is still relatively new and when `AssertionError` was written in it's current way, errors did not have that property. It's a non-enumerable property and to hide the compared `errors` stack frames the error is [copied](https://github.com/nodejs/node/blob/d881fcba86f72ff506eea53a5eca9a0ab2e4a02f/lib/internal/assert/assertion_error.js#L355-L361) in a way that it does not contain the stack trace and cause anymore. Afterwards it's compared regularly. This now also hides the `cause` and that causes the faulty above error message.

This could be fixed by removing the copying and instead cutting off the stack frames [after inspection](https://github.com/nodejs/node/blob/d881fcba86f72ff506eea53a5eca9a0ab2e4a02f/lib/internal/assert/assertion_error.js#L84-L86) but before they are compared.","BridgeAR",8822573,"2024-10-12 14:05:20","compar error issue assertionerror write error property non enumerable property hide compare error stack frame error copy way contain stack trace cause compare regularly hide cause cause faulty error message fix remove copy cut stack frame inspection compare
"
339,108,"Can you try with node 22.9? I believe this was fixed quite recently.","ronag",3065230,"2024-09-26 14:52:08","try node fix recently
"
340,108,"Can you please include a reproduction?","mcollina",52195,"2024-09-26 16:01:05","include reproduction
"
341,108,"@ronag @mcollina I have edited the issue, please see the minimal reproducible code.","System233",20336040,"2024-10-08 07:14:15","edit issue minimal reproducible code
"
342,108,"Shall we move this to Node?","metcoder95",10200776,"2024-10-08 18:32:57","move node
"
343,108,"Transfered.","mcollina",52195,"2024-10-09 06:21:20","transfer
"
344,108,"Interesting comment on this https://github.com/denoland/deno/issues/24842#issuecomment-2265771975","geeksilva97",15680379,"2024-10-10 04:29:30","comment issue
"
345,108,">  if AbortSignal.any does not have an event listener added, AbortSignal.any will eventually be released and there will be no memory leak.

Part of the issue with this reproduction code may be that event listeners should be removed; otherwise, [gcPersistentSignals](https://github.com/nodejs/node/blob/main/lib/internal/abort_controller.js#L87) will retain those.

If that's the case I think the issue becomes the same as reported for `AbortSignal.any`.","geeksilva97",15680379,"2024-10-10 12:42:57","abortsignal event listener memory leak event listener remove gcpersistentsignals issue abortsignal
"
346,108,"> Part of the issue with this reproduction code may be that event listeners should be removed; otherwise, [gcPersistentSignals](https://github.com/nodejs/node/blob/main/lib/internal/abort_controller.js#L87) will retain those.
> 
> If that's the case I think the issue becomes the same as reported for `AbortSignal.any`.

If you add an event listener directly to `AbortSignal`, no memory leak occurs, but only on `AbortSignal.any`.
I did fix the problem temporarily by removing the event listener on `AbortSignal.any`.","System233",20336040,"2024-10-10 13:08:35","issue reproduction code event listener remove gcPersistentSignals retain case issue report AbortSignal add event listener AbortSignal memory leak occur AbortSignal any fix problem remove event listener AbortSignal any
"
347,108,"I can confirm that leaving a listener attached to the `AbortSignal` of an `AbortController` does not cause a leak, but leaving a handler attached to the `AbortSignal` returned by `AbortSignal.any` does cause a leak.

Better repro:
```js
function printMemoryUsage(msg) {
    console.log(msg, `${(process.memoryUsage().rss / 1024 / 1024).toFixed(2)} MiB`);
}

printMemoryUsage('Mem before loop');
let i = 0;
const run = () => {
    const ac = new AbortController();
    // NOTE: Not removing this listener does not cause a leak
    ac.signal.addEventListener('abort', () => {});
    const composedSignal = AbortSignal.any([ac.signal]);
    const handler = () => {};
    // NOTE: Not removing this listener DOES cause a leak
    composedSignal.addEventListener('abort', handler);
    // NOTE: Properly removing the listener fixes the leak
    // composedSignal.removeEventListener('abort', handler);
    if (++i % 100_000 === 0) {
        printMemoryUsage(`Mem after ${i} iterations`);
    }
    setImmediate(run);
};
run();
```","mika-fischer",426158,"2024-10-10 14:49:16","confirm leave listener attach abortsignal abortcontroller cause leak leave handler attach abortsignal return abortsignal any cause leak repro remove listener cause leak remove listener fix leak
"
348,108,"~~GC takes a while to trigger~~
Sorry, I ran the test and the GC triggers faster than I expected to keep the memory at a certain level


","System233",20336040,"2024-10-10 18:57:29","gc take while trigger sorry run test gc trigger fast expect keep memory certain level
"
349,108,"> GC takes a while to trigger

Sure, but this seems to be a real leak. Run this with `--expose-gc --trace-gc`:
```js
function printMemoryUsage(msg) {
    console.log(msg, `${(process.memoryUsage().rss / 1024 / 1024).toFixed(2)} MiB`);
}

printMemoryUsage('Mem before loop');
let i = 0;
const run = () => {
    const ac = new AbortController();
    // NOTE: Not removing this listener does not cause a leak
    ac.signal.addEventListener('abort', () => {});
    const composedSignal = AbortSignal.any([ac.signal]);
    const handler = () => {};
    // NOTE: Not removing this listener DOES cause a leak
    composedSignal.addEventListener('abort', handler);
    // NOTE: Properly removing the listener fixes the leak
    // composedSignal.removeEventListener('abort', handler);
    if (++i % 100_000 === 0) {
        if (globalThis.gc) {
            console.log('Running GC');
            globalThis.gc(true);
        }
        printMemoryUsage(`Mem after ${i} iterations`);
    }
    setImmediate(run);
};
run();
```

I pretty quickly come to:
```
...
Running GC
[345584:00000161757C1000]    51263 ms: Scavenge 3926.7 (4090.7) -> 3922.4 (4094.5) MB, pooled: 0 MB, 8.46 / 0.00 ms  (average mu = 0.348, current mu = 0.288) testing;
Mem after 4800000 iterations 4143.23 MiB
[345584:00000161757C1000]    51283 ms: Scavenge 3931.0 (4094.5) -> 3926.6 (4098.5) MB, pooled: 0 MB, 7.92 / 0.00 ms  (average mu = 0.348, current mu = 0.288) task; 
[345584:00000161757C1000]    51304 ms: Scavenge 3935.1 (4098.5) -> 3930.7 (4102.2) MB, pooled: 0 MB, 8.76 / 0.00 ms  (average mu = 0.348, current mu = 0.288) task; 
[345584:00000161757C1000]    51323 ms: Scavenge 3939.3 (4102.2) -> 3934.9 (4106.7) MB, pooled: 0 MB, 7.69 / 0.00 ms  (average mu = 0.348, current mu = 0.288) task; 
[345584:00000161757C1000]    51344 ms: Scavenge 3943.5 (4106.7) -> 3939.1 (4110.5) MB, pooled: 0 MB, 8.07 / 0.00 ms  (average mu = 0.348, current mu = 0.288) task; 
[345584:00000161757C1000]    54025 ms: Mark-Compact (reduce) 3939.1 (4110.5) -> 3870.3 (4079.5) MB, pooled: 0 MB, 2667.97 / 0.00 ms  (+ 0.9 ms in 0 steps since start of marking, biggest step 0.0 ms, walltime since start of marking 2681 ms) (average mu = 0.296, current mu = 0.238) finalize incremental marking via task; GC in old space requested
[345584:00000161757C1000]    54035 ms: Scavenge (interleaved) 3871.3 (4079.5) -> 3870.8 (4082.5) MB, pooled: 0 MB, 7.10 / 0.00 ms  (average mu = 0.296, current mu = 0.238) allocation failure;
[345584:00000161757C1000]    54046 ms: Scavenge (interleaved) 3871.9 (4082.5) -> 3871.3 (4082.5) MB, pooled: 0 MB, 7.63 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54057 ms: Scavenge (interleaved) 3872.4 (4082.5) -> 3871.8 (4082.5) MB, pooled: 0 MB, 7.86 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task;
[345584:00000161757C1000]    54069 ms: Scavenge (interleaved) 3872.9 (4082.5) -> 3872.3 (4086.5) MB, pooled: 0 MB, 8.54 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54086 ms: Scavenge (interleaved) 3875.0 (4086.5) -> 3873.6 (4086.5) MB, pooled: 0 MB, 10.88 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54102 ms: Scavenge (interleaved) 3875.5 (4086.5) -> 3874.5 (4086.5) MB, pooled: 0 MB, 11.84 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54118 ms: Scavenge (interleaved) 3876.8 (4086.5) -> 3875.6 (4094.5) MB, pooled: 0 MB, 10.99 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54145 ms: Scavenge (interleaved) 3880.9 (4094.5) -> 3878.1 (4094.5) MB, pooled: 0 MB, 15.03 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54172 ms: Scavenge (interleaved) 3882.0 (4094.5) -> 3880.0 (4094.5) MB, pooled: 0 MB, 17.21 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54197 ms: Scavenge (interleaved) 3884.5 (4094.5) -> 3882.1 (4110.5) MB, pooled: 0 MB, 15.34 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54243 ms: Scavenge (interleaved) 3892.8 (4110.5) -> 3887.2 (4110.5) MB, pooled: 0 MB, 21.79 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54282 ms: Scavenge (interleaved) 3895.0 (4110.5) -> 3890.9 (4110.5) MB, pooled: 0 MB, 20.91 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54303 ms: Scavenge 3900.0 (4110.5) -> 3895.4 (4110.5) MB, pooled: 0 MB, 8.11 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54323 ms: Scavenge 3903.7 (4110.5) -> 3899.5 (4110.5) MB, pooled: 0 MB, 8.37 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54343 ms: Scavenge 3908.1 (4110.5) -> 3903.7 (4110.5) MB, pooled: 0 MB, 7.47 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54362 ms: Scavenge 3912.2 (4110.5) -> 3907.8 (4110.5) MB, pooled: 0 MB, 7.53 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54382 ms: Scavenge 3916.4 (4110.5) -> 3912.0 (4110.5) MB, pooled: 0 MB, 7.43 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54401 ms: Scavenge 3920.5 (4110.5) -> 3916.1 (4110.5) MB, pooled: 0 MB, 7.85 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54421 ms: Scavenge 3924.7 (4110.5) -> 3920.3 (4110.5) MB, pooled: 0 MB, 7.77 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54441 ms: Scavenge 3928.9 (4110.5) -> 3924.5 (4110.5) MB, pooled: 0 MB, 7.53 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54461 ms: Scavenge 3933.0 (4110.5) -> 3928.7 (4110.5) MB, pooled: 0 MB, 8.22 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54481 ms: Scavenge 3937.2 (4110.5) -> 3932.8 (4110.5) MB, pooled: 0 MB, 8.11 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54501 ms: Scavenge 3941.4 (4110.5) -> 3937.0 (4113.0) MB, pooled: 0 MB, 8.10 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54521 ms: Scavenge 3945.5 (4113.0) -> 3941.1 (4117.0) MB, pooled: 0 MB, 8.37 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54542 ms: Scavenge 3949.7 (4117.0) -> 3945.3 (4120.7) MB, pooled: 0 MB, 8.21 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54562 ms: Scavenge 3953.8 (4120.7) -> 3949.4 (4124.5) MB, pooled: 0 MB, 7.95 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    54582 ms: Scavenge 3958.0 (4124.5) -> 3953.6 (4128.7) MB, pooled: 0 MB, 7.96 / 0.00 ms  (average mu = 0.296, current mu = 0.238) task; 
[345584:00000161757C1000]    57366 ms: Mark-Compact 3962.2 (4128.7) -> 3914.0 (4128.5) MB, pooled: 0 MB, 2771.99 / 0.00 ms  (average mu = 0.236, current mu = 0.170) task; scavenge might not succeed
[345584:00000161757C1000]    60320 ms: Mark-Compact 3926.8 (4128.5) -> 3917.0 (4116.7) MB, pooled: 12 MB, 2924.26 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; scavenge might not succeed
[345584:00000161757C1000]    60358 ms: Scavenge (interleaved) 3929.8 (4116.7) -> 3923.1 (4116.7) MB, pooled: 12 MB, 13.40 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    60408 ms: Scavenge (interleaved) 3929.8 (4116.7) -> 3926.3 (4116.7) MB, pooled: 12 MB, 37.48 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    60450 ms: Scavenge (interleaved) 3935.9 (4116.7) -> 3930.9 (4116.7) MB, pooled: 12 MB, 24.14 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    60489 ms: Scavenge (interleaved) 3939.1 (4116.7) -> 3934.8 (4116.7) MB, pooled: 12 MB, 22.74 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    60530 ms: Scavenge (interleaved) 3943.7 (4116.7) -> 3939.1 (4116.7) MB, pooled: 12 MB, 24.70 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    60553 ms: Scavenge 3947.6 (4116.7) -> 3943.3 (4121.0) MB, pooled: 8 MB, 8.18 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    60572 ms: Scavenge 3951.9 (4121.0) -> 3947.5 (4124.7) MB, pooled: 4 MB, 7.43 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    60592 ms: Scavenge 3956.0 (4124.7) -> 3951.6 (4128.5) MB, pooled: 0 MB, 7.97 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task; 
[345584:00000161757C1000]    63380 ms: Mark-Compact 3960.2 (4128.5) -> 3936.4 (4128.2) MB, pooled: 0 MB, 2775.07 / 0.00 ms  (average mu = 0.114, current mu = 0.093) task; scavenge might not succeed

<--- Last few GCs --->

[345584:00000161757C1000]    60592 ms: Scavenge 3956.0 (4124.7) -> 3951.6 (4128.5) MB, pooled: 0 MB, 7.97 / 0.00 ms  (average mu = 0.133, current mu = 0.010) task;
[345584:00000161757C1000]    63380 ms: Mark-Compact 3960.2 (4128.5) -> 3936.4 (4128.2) MB, pooled: 0 MB, 2775.07 / 0.00 ms  (average mu = 0.114, current mu = 0.093) task; scavenge might not succeed


<--- JS stacktrace --->

FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory
----- Native stack trace -----

 1: 00007FF733B2C21B node::SetCppgcReference+15995
 2: 00007FF733A94BD8 DSA_meth_get_flags+93288
 3: 00007FF734620AA1 v8::Isolate::ReportExternalAllocationLimitReached+65
 4: 00007FF73460D8A6 v8::Function::Experimental_IsNopFunction+2918
 5: 00007FF734459560 v8::internal::StrongRootAllocatorBase::StrongRootAllocatorBase+31552
 6: 00007FF73445322D v8::internal::StrongRootAllocatorBase::StrongRootAllocatorBase+6157
 7: 00007FF73444EAC5 v8::internal::ThreadIsolation::JitPageReference::Size+190789
 8: 00007FF733DC803D BIO_ssl_shutdown+189
```","mika-fischer",426158,"2024-10-10 19:11:30","gc take while trigger sure seem real leak run expose gc trace gc note remove listener cause leak note remove listener cause leak note properly remove listener fix leak run gc mem iteration mem iteration scavenge mb pooled ms average mu current mu test scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task mark compact reduce mb pooled ms ms step since start mark biggest step ms walltime since start mark ms average mu current mu finalize incremental mark via task gc old space request scavenge interleaved mb pooled ms average mu current mu allocation failure scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge interleaved mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task scavenge mb pooled ms average mu current mu task mark compact mb pooled ms average mu current mu task scavenge might succeed mark compact mb pooled mb ms average mu current mu task scavenge might succeed scavenge interleaved mb pooled mb ms average mu current mu task scavenge interleaved mb pooled mb ms average mu current mu task scavenge interleaved mb pooled mb ms average mu current mu task scavenge interleaved mb pooled mb ms average mu current mu task scavenge interleaved mb pooled mb ms average mu current mu task scavenge mb pooled mb ms average mu current mu task scavenge mb pooled mb ms average mu current mu task scavenge mb pooled mb ms average mu current mu task mark compact mb pooled mb ms average mu current mu task scavenge might succeed scavenge mb pooled mb ms average mu current mu task mark compact mb pooled mb ms average mu current mu task scavenge might succeed  js stacktrace fatal error ineffective mark compacts near heap limit allocation fail javascript heap memory native stack trace node setcppgcreference dsa meth get flags v8 isolate reportexternalallocationlimitreached v8 function experimental isnopfunction v8 internal strongrootallocatorbase v8 internal strongrootallocatorbase v8 internal threadisolation jitpagereference size bio ssl shutdown
"
350,108,"> Sure, but this seems to be a real leak. Run this with

Yes, I can get the same test results here, I didn't make it clear just now that I was testing the GC speed after uncommenting the `//composedSignal.removeEventListener('abort', handler); ` line, sorry.","System233",20336040,"2024-10-10 19:24:21","leak test result gc speed uncomment line sorry
"
351,108,"I was looking into this. This is done by definition: https://github.com/nodejs/node/blob/main/lib/internal/abort_controller.js#L278-L281

I wonder if changing this would violate the [spec](https://dom.spec.whatwg.org/#abort-signal-garbage-collection)","geeksilva97",15680379,"2024-10-14 14:19:11","look definition wonder change violate spec
"
371,111,"My guess is https://github.com/nodejs/node/pull/53450 introducing `colors.clear` in the dot reporter is the culprit, but I have not tested.","cjihrig",2512748,"2024-09-19 13:21:47","guess introduce color clear dot reporter culprit test
"
372,111,"@cjihrig, just tried, yes, the root cause is `clear`","pmarchini",49943249,"2024-09-19 13:27:30","tried root cause clear
"
682,146,"I’m on macOS and repro it consistently btw","wooorm",944406,"2024-05-02 15:27:01","macos repro consistently
"
352,108,"> I was looking into this. This is done by definition: https://github.com/nodejs/node/blob/main/lib/internal/abort_controller.js#L278-L281
> 
> I wonder if changing this would violate the [spec](https://dom.spec.whatwg.org/#abort-signal-garbage-collection)

It seems that `gcPersistentSignals` exists solely to address the issue where `AbortSignal.timeout()` would block the process from exiting?

https://dom.spec.whatwg.org/#abortsignal-abort-algorithms 
>For the duration of this timeout, if signal has any event listeners registered for its abort event, there must be a strong reference from global to signal.

I don't understand why this needs to be made so complicated. My intuition tells me that Node.js does not need to implement this functionality deliberately, as setTimeout itself can directly hold a strong reference to AbortSignal.timeout, thus preventing AbortSignal from being garbage collected due to the lack of a strong reference. Additionally, AbortSignal.any should also hold a strong reference to the signals.

Furthermore, I have another question: When AbortSignal.timeout is active and there are abort event listeners present, the DOM standard states that AbortSignal must not be garbage collected at this time. Since AbortSignal cannot be garbage collected during this period, shouldn't AbortSignal.timeout be able to block the process exit? Currently, AbortSignal.timeout does not block the process exit.
","System233",20336040,"2024-10-14 16:34:46","wonder change violate spec seem gcpersistentsignals exist solely address issue abortsignaltimeout would block process exit duration timeout signal event listener register abort event strong reference global signal understand need make complicate intuition node implement functionality deliberately settimeout directly hold strong reference abortsignaltimeout prevent abortsignal garbage collect lack strong reference additionally abortsignalany also hold strong reference signal abortsignaltimeout active abort event listener present dom standard state abortsignal garbage collect period abortsignaltimeout able block process exit currently abortsignaltimeout block process exit
"
353,108,"IMO the issue here and the issue with an `AbortSignal.timeout` that has not timed out yet are completely different. It helps to consider the ""settled"" concept for signals as defined here: https://github.com/chromium/chromium/commit/d5b7539036199ad653125222f061f39c66e91a86
- With the AbortSignal.timeout, the signal *will* trigger in the future, therefore it is not ""settled"":
  - Because it has listeners and is not settled, it must not be GCed.
- However in the case here, the source signal is ""settled"" as soon as the `AbortController` is GCed.
  - Because nobody can call `abort` on the `AbortController`, the signal cannot possibly trigger in the future.
  - Because all source signals are settled, the any signal is settled as well and will never trigger.
  - Therefore the handler can never be called.
  - Therefore all of them can be GCed.","mika-fischer",426158,"2024-10-14 16:53:50","issue problema abortsignal timeout diferente considerar conceito settled sinal definir listener settled gc gc source signal settled abortcontroller gc chamar abort abortcontroller signal disparar futuro source signal settled signal settled disparar handler chamar gc
"
354,108,"See especially here for more details: https://docs.google.com/document/d/1LvmsBLV85p-PhSGvTH-YwgD6onuhh1VXLg8jPlH32H4/edit?pli=1#heading=h.7ut6obnf9fz0","mika-fischer",426158,"2024-10-14 16:56:26","detail
"
355,108,"> See especially here for more details: https://docs.google.com/document/d/1LvmsBLV85p-PhSGvTH-YwgD6onuhh1VXLg8jPlH32H4/edit?pli=1#heading=h.7ut6obnf9fz0

Thanks for the reference, @mika-fischer . This week I'll take a look into this. I've got some ideas.","geeksilva97",15680379,"2024-10-28 02:12:02","Thanks reference week look idea
"
356,108,"FYI, PR is done","geeksilva97",15680379,"2024-11-28 15:18:26","pr feito
"
357,109,"> A JavaScript value value is a platform object if [Type](https://tc39.es/ecma262/#sec-ecmascript-data-types-and-values)(value) is Object and if value has a [[PrimaryInterface]] internal slot.

> The primary interface of a [platform object](https://webidl.spec.whatwg.org/#dfn-platform-object) is the value of the object’s [[PrimaryInterface]] internal slot, which is the most-derived [interface](https://webidl.spec.whatwg.org/#dfn-interface) that it [implements](https://webidl.spec.whatwg.org/#implements).

Request's webidl declaration does not extend anything, therefore it's a platform object.

Hopefully this may help someone.","KhafraDev",42794878,"2024-09-26 18:43:21","javascript value platform object type object value primaryinterface internal slot primary interface platform object value object primaryinterface internal slot derive interface implement request webidl declaration extend platform object hope help someone
"
358,109,"@nodejs/web-standards @joyeecheung ","KhafraDev",42794878,"2024-09-26 18:43:51","nodejs web standard
"
359,109,"As you've pointed out, the behavior where structuredClone(new Response()) succeeds in Node.js but throws a DataCloneError in the browser is indeed intriguing. This difference stems from the fact that the Response object is classified as a platform object, which, by design, is not serializable. In the browser environment, trying to clone such objects will rightfully lead to an error, aligning with the Web Platform's handling of non-serializable entities.



when using structuredClone, we should expect it to fail for these types of objects, as seen in the browser.

 Web Platform Tests (WPT) reflect this behavior accurately, consider modifying the test cases. Here's a potential approach for your tests:


structuredCloneBatteryOfTests.push({
  description: 'Serializing a non-serializable platform object fails',
  async f(runner, t) {
    const request = new Response();
    await promise_rejects_dom(
      t,
      ""DataCloneError"",
      runner.structuredClone(request)
    );
  }
});
Monitoring Pull Request #55178: The pull request #55178, which focuses on decorating undici classes as platform interfaces, may provide helpful adjustments to address this inconsistency. Keeping an eye on the developments of this PR could lead to insights that may resolve the underlying issue.


I appreciate your efforts in bringing this issue to light, and I look forward to further discussions as we work towards a resolution.","sOnU1002",113360927,"2024-10-01 10:03:37","behavior structuredclone response succeed node throw datacloneerror browser intriguing difference stem fact response object classify platform object design serializable browser environment try clone object rightfully lead error align web platform handle non serializable entity use structuredclone expect fail type object see browser web platform test wpt reflect behavior accurately consider modify test case potential approach test serialize non serializable platform object fail request response promise rejects dom datacloneerror runner structuredclone request monitor pull request pull request focus decorate undici class platform interface may provide helpful adjustment address inconsistency keep eye development pr could lead insight may resolve underlying issue appreciate effort bring issue light look forward further discussion work resolution
"
360,109,"I am a bit curious how undici will adopt [this](https://github.com/nodejs/node/pull/55234) to address this issue. Don't get me wrong, it will address the issue, but the process will probably be like:
1. release that PR
2. land a new commit on undici to mark all classes uncloneable, which might be semver-major
3. node waits for that undici release and bump the deps

The whole thing could be dragged a bit long, and I am thinking should we consider [the fast win](https://github.com/nodejs/node/pull/55178) with a TODO to drop it once the above process is settled?","jazelly",28685065,"2024-10-04 02:35:31","curioso undici adotar questão errado questão processo provavelmente liberar pr aterrissar novo commit undici marcar classe uncloneable semver major nó aguardar lançamento undici aumentar dependências coisa arrastar longo pensar considerar vitória rápida todo descartar processo resolver
"
361,109,"It won't be a semver-major issue, changes that are made for spec-compatibility are usually considered bug fixes. This bug was only caught in a WPT - the behavior is far too niche to justify the performance overhead of constructing every Response, Request, FormData, Headers, etc.","KhafraDev",42794878,"2024-10-04 03:40:22","issue change spec compatibility bug fix bug catch wpt behavior niche justify performance overhead construct response request formdata header
"
362,109,"@jazelly just confirming the Unidici PR fixed this, and it'll be good-to-go when the next version of Undici releases?","avivkeller",38299977,"2024-10-18 00:15:56","confirm unidici pr fix good go next version unidici release
"
363,109,"Yes, once that's released and bumped in node, this should be resolved.","jazelly",28685065,"2024-10-18 00:19:14","yes release bump node resolve
"
364,109,"I'm gonna close this, as while the latest Node.js doesn't have the Undici needed, it's no longer actionable as an issue. Thx!","avivkeller",38299977,"2024-10-18 00:21:30","close latest node need longer action thx
"
365,110,"@nodejs/fs ","avivkeller",38299977,"2024-09-22 10:04:11","nodejs fs
"
366,110,"Similar issue: #51955","avivkeller",38299977,"2024-09-22 10:04:28","issue similar
"
367,110,"I'm looking into this. A notable difference is that the *incorrect* dirent is created from `DirentFromStats`, while the correct dirent is created from `Dirent`. 

See #55071","avivkeller",38299977,"2024-09-22 23:07:12","looking notable difference incorrect dirent create dirent
"
368,111,"able to reproduce @RedYetiDev ","pmarchini",49943249,"2024-09-19 12:56:24","reproduce
"
373,112,"For reference, a smaller reproduction is:
```mjs
import { Readable, Transform } from 'node:stream';

Readable.from([{}]).pipe(new Transform({
    transform(chunk, _, cb) {
        this.push(chunk);
    }
}));
```

AFAICT this is working as intended. Per [the docs](https://nodejs.org/api/stream.html#object-mode), if object mode is `false`,  ""streams created by Node.js APIs operate exclusively on strings, [\<Buffer>](https://nodejs.org/api/buffer.html#class-buffer), [\<TypedArray>](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray) and [\<DataView>](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView) objects"". 

CC @nodejs/streams ","avivkeller",38299977,"2024-09-14 17:06:45","working intend object mode false stream node api operate exclusively string buffer typedarray dataview
"
374,112,"@RedYetiDev Thanks for taking a look!

> AFAICT this is working as intended.

The part that I feel is not working as intended is that there is no way to catch the error that is produced when the pipe attempts to start flowing.

It should be possible (and in my opinion, would be preferrable) to throw synchronously in the `Readable.pipe()` call when the modes don't match between source and destination.

Individual streams cannot change their object mode once constructed. From the [documentation on object mode](https://nodejs.org/docs/latest/api/stream.html#object-mode):

> Stream instances are switched into object mode using the `objectMode` option when the stream is created. Attempting to switch an existing stream into object mode is not safe.

So, it should be sound to throw in `Readable.pipe()`. (I.e., there shouldn't be a case where the check would fail in `Readable.pipe()` but things would have actually worked out right when data eventually started flowing.)

The reason I provided a longer repro step was to demonstrate different places in the control flow where an error _could_ be caught.","joelrbrandt",908679,"2024-09-14 17:25:14","modo objeto funcionar pretender erro capturar fluxo iniciar possível preferível lançar sincronicamente readable pipe chamada modo objeto corresponder fonte destino fluxo individual mudar modo objeto construir documentação modo objeto seguro lançar readable pipe caso verificação falhar readable pipe funcionar dado começar fluir razão passo reprodução longo demonstrar lugar diferente fluxo controle erro capturar
"
375,112,"I agree we are missing a try/catch in pipe.","ronag",3065230,"2024-09-14 18:15:30","agree miss try catch pipe
"
376,112,"@ronag 

> I agree we are missing a try/catch in pipe.

Thanks for taking a look!

I assume you mean ""we're missing a check and a `throw` in `Readable.pipe()`""? There's no exception propagating through `.pipe`, so a `catch` won't address the issue. The exception happens when the pipe is flowing and the Readable attempts to write to the Writable. That happens [here](https://github.com/nodejs/node/blob/a65105ec284023960e93b3a66f6661ddd2f4121f/lib/internal/streams/readable.js#L1007-L1014), and there's no way to catch that exception (that I am aware of).

Anyway, if folks feel this is indeed a bug, and that the right fix is to add a check and throw in [`Readable.prototype.pipe()`](https://github.com/nodejs/node/blob/a65105ec284023960e93b3a66f6661ddd2f4121f/lib/internal/streams/readable.js#L909), I'm happy to put up a PR by EOD tomorrow. This'll be my first time contributing to node, though, so I might need some guidance. 😄 ","joelrbrandt",908679,"2024-09-14 18:57:09","agree miss try catch pipe assume mean miss check throw readable pipe exception propagate catch exception happen pipe flow readable attempt write writable happen way catch exception aware folk feel bug right fix add check throw readable prototype pipe happy put pr eod tomorrow first time contribute node might need guidance
"
377,112,"```js
  function ondata(chunk) {
    debug('ondata');
    try {
      const ret = dest.write(chunk);
      debug('dest.write', ret);
      if (ret === false) {
        pause();
      }
    } catch (err) {
      dest.destroy(err);
    }
  }
```","ronag",3065230,"2024-09-14 19:31:04","function ondata chunk debug ondata try ret dest write chunk debug dest write ret false pause catch err dest destroy err
"
378,112,"@ronag got it. Thanks.

Should there also be a check and throw at `Readable.prototype.pipe()`?

I'll add some tests and put up a PR.","joelrbrandt",908679,"2024-09-14 20:03:45","check throw readable prototype pipe add test pr
"
379,112,"I think it will add a noticeable overhead if that is done for every data chunk. Also, I think this is an unrecoverable programmer error so a crash is expected. Can't we just add a check for the source and destination streams in `Readable.prototype.pipe()`? I think this is also not necessary, but at least it is less invasive.

I mean something like this:

```diff
diff --git a/lib/internal/streams/readable.js b/lib/internal/streams/readable.js
index 17f8e53ad5..75dc350b59 100644
--- a/lib/internal/streams/readable.js
+++ b/lib/internal/streams/readable.js
@@ -910,6 +910,17 @@ Readable.prototype.pipe = function(dest, pipeOpts) {
   const src = this;
   const state = this._readableState;
 
+  if (
+    (state[kState] & kObjectMode &&
+      !dest._writableState[kState] & kObjectMode) ||
+    ((state[kState] & kObjectMode === 0) &&
+      dest._writableState[kState] & kObjectMode)
+  ) {
+    throw new Error(
+      'The piped streams do not have the same objectMode stetting'
+    );
+  }
+
   if (state.pipes.length === 1) {
     if ((state[kState] & kMultiAwaitDrain) === 0) {
       state[kState] |= kMultiAwaitDrain;

```","lpinca",1443911,"2024-09-15 05:41:41","add noticeable overhead data chunk unrecoverable programmer error crash expect add check source destination stream readable prototype pipe necessary invasive mean add check source destination stream object mode setting pipe stream object mode setting
"
380,112,"Just note that you can pipe non object mode into object mode but not the other way around.","ronag",3065230,"2024-09-15 06:27:07","note pipe object mode object way
"
395,116,"If someone wants to pick this up, this diff plus the test case provided in the bug report should get you started:

```diff
diff --git a/lib/internal/test_runner/coverage.js b/lib/internal/test_runner/coverage.js
index 7ef5702072..4348ea06c3 100644
--- a/lib/internal/test_runner/coverage.js
+++ b/lib/internal/test_runner/coverage.js
@@ -388,8 +388,12 @@ class TestCoverage {
             continue;
           }
 
-          newUrl ??= startEntry?.originalSource;
-          const mappedLines = this.getLines(newUrl);
+          const mappedLines = this.getLines(startEntry.originalSource);
+          if (!mappedLines) {
+            throw new Error('insert better error message here');
+          }
+
+          newUrl ??= startEntry.originalSource;
           const mappedStartOffset = this.entryToOffset(startEntry, mappedLines);
           const mappedEndOffset = this.entryToOffset(endEntry, mappedLines) + 1;
           for (let l = startEntry.originalLine; l <= endEntry.originalLine; l++) {
```","cjihrig",2512748,"2024-09-14 21:21:35","someone want pick diff plus test case provide bug report get start class testcoverage getlines startentry originalsource mappedlines throw error insert better error message newurl startentry originalsource mappedstartoffset entrytooffset startentry mappedlines mappedendoffset entrytooffset endentry mappedlines
"
396,116,"> throw new Error('insert better error message here');

What even is the issue? Is it:

> a particular source module at a path is missing","avivkeller",38299977,"2024-09-14 21:29:23","error message insert particular source module path miss
"
683,146,"@woorm ARM or Intel?","targos",2352663,"2024-05-02 15:29:12","arm intel
"
381,112,"@lpinca @ronag in my incredibly limited (only one machine / architecture) and not statistically valid (only run a few times, manually) benchmarking, I don't see a performance difference due to the addition of the `try/catch` in `ondata`. (See some manual runs below.)

Assuming there _isn't_ performance overhead, is there a preferred approach (try/catch in onData vs check in .pipe)?

Happy to put up a PR for either.

Also, are [these instructions](https://github.com/nodejs/benchmarking/blob/HEAD/docs/core_benchmarks.md) still current for running benchmarks on CI? (I see the repo they are in is archived.) Also, will I have permissions to trigger such a run on CI? Or does a maintainer need to do that?

### manual runs of benchmark

_Note: I built node with `./configure --node-builtin-modules-path ""$(pwd)""`. Then, I added a `console.log(""[local build]..."")` to `Readable.prototype.pipe` to ensure I was actually running the modified code in the benchmark._

#### local build, unmodified `ondata`

```
[~/devel/node] (main) $ ./node --version
v23.0.0-pre
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js                               
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 29,249,159.338211797
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 29,197,094.442971323
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 29,029,514.30719613
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 28,273,879.594224814
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 29,225,075.268889103
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 27,992,464.42857583
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 28,337,883.925193656
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with unmodified ondata
streams/pipe.js n=5000000: 29,188,259.898103785
```

#### local build, modified `ondata` with try/catch

```
[~/devel/node] (main) $ ./node --version
v23.0.0-pre
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with modified ondata
streams/pipe.js n=5000000: 28,868,575.624709625
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with modified ondata
streams/pipe.js n=5000000: 29,417,366.983859424
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with modified ondata
streams/pipe.js n=5000000: 28,880,720.458452556
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with modified ondata
streams/pipe.js n=5000000: 28,618,137.460068755
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with modified ondata
streams/pipe.js n=5000000: 28,907,380.567654
[~/devel/node] (main) $ ./node benchmark/streams/pipe.js
[local build] .pipe with modified ondata
streams/pipe.js n=5000000: 29,311,473.430494733
```

#### v22.8.0 installed through nvm

```
[~/devel/node] (main) $ node --version
v22.8.0
[~/devel/node] (main) $ node benchmark/streams/pipe.js  
streams/pipe.js n=5000000: 28,344,122.315635882
[~/devel/node] (main) $ node benchmark/streams/pipe.js
streams/pipe.js n=5000000: 28,975,323.889792357
[~/devel/node] (main) $ node benchmark/streams/pipe.js
streams/pipe.js n=5000000: 28,917,007.4656484
[~/devel/node] (main) $ node benchmark/streams/pipe.js
streams/pipe.js n=5000000: 28,974,708.162682924
[~/devel/node] (main) $ node benchmark/streams/pipe.js
streams/pipe.js n=5000000: 28,985,794.415783517
[~/devel/node] (main) $ node benchmark/streams/pipe.js
streams/pipe.js n=5000000: 28,888,451.761676144
```","joelrbrandt",908679,"2024-09-15 16:33:38","see manual run below assume performance overhead preferred approach try catch ondata check pipe happy put pr instruction current run benchmark ci see repo archive permission trigger run ci maintainer need manual run benchmark note build node configure node builtin modules path pwd add console log local build readable prototype pipe ensure run modify code benchmark local build unmodified ondata local build modify ondata try catch v install nvm
"
382,112,"If there is no performance overhead I would argue that both suggestions should be applied.","ronag",3065230,"2024-09-15 16:44:17","performance overhead suggestion apply
"
383,112,"With the check in place, under what circumstances might `writable.write()` throw an error?

> Also, are [these instructions](https://github.com/nodejs/benchmarking/blob/HEAD/docs/core_benchmarks.md) still current for running benchmarks on CI? (I see the repo they are in is archived.) Also, will I have permissions to trigger such a run on CI? Or does a maintainer need to do that?

See https://github.com/nodejs/node/blob/main/doc/contributing/writing-and-running-benchmarks.md. A collaborator needs to start the benchmark CI.","lpinca",1443911,"2024-09-15 17:11:27","check place circumstance writable write throw error instruction current run benchmark ci permission maintainer need collaborator need start benchmark ci
"
384,112,"> With the check in place, under what circumstances might `writable.write()` throw an error?

""Streamlike"" objects.
 ","ronag",3065230,"2024-09-15 17:43:41","check place circumstance writable write throw error streamlike object
"
385,113,"> Silently exits.

What's the exit code though?","aduh95",14309773,"2024-09-14 13:58:12","exit codigo
"
386,113,"`0`:
```
$ node repro.js && echo $? 
(node:6296) [MODULE_TYPELESS_PACKAGE_JSON] Warning: file:///repro.js parsed as an ES module because module syntax was detected; to avoid the performance penalty of syntax detection, add ""type"": ""module"" to /package.json
(Use `node --trace-warnings ...` to show where the warning was created)
0
```","avivkeller",38299977,"2024-09-14 14:58:40","node repro js echo
module syntax detect avoid performance penalty syntax detection add type module package json
warn create
"
387,115,"As it currently stands, your issue lacks enough information to be easily reproduced. Please edit your issue to include additional information, such as specific (minimal) code snippets that will allow this issue to be easily reproduced.","avivkeller",38299977,"2024-09-04 19:31:01","issue lack information easily reproduce edit issue include information specific minimal code snippet easily reproduce
"
388,115,"This issue/PR was marked as stalled, it will be automatically closed in 30 days. If it should remain open, please leave a comment explaining why it should remain open.
","github-actions[bot]",41898282,"2024-09-05 00:51:35","issue mark stall automat close day remain open leave comment explain remain open
"
389,115,"Hey, I've marked this issue as `stalled` (though that bot doesn't appear to work), just so collaborators know that this issue is waiting for more information.","avivkeller",38299977,"2024-09-05 00:51:50","mark issue stall collaborator wait information
"
390,115,"@joyeecheung wdyt? Should we replace the `else` with `else if (getOptionValue('--experimental-require-module'))` in https://github.com/nodejs/node/blob/0301309493b2a4e80796517bdb46ec55202a4800/lib/internal/modules/cjs/loader.js#L1377-L1381","aduh95",14309773,"2024-09-05 09:24:24","joyeecheung wdyt replace else else if getOptionValue experimental require module
"
391,115,"That function should only be used if the option is turned on in the first place (otherwise it should’ve gone elsewhere to throw ERR_REQUIRE_ESM instead of going into this function), I am not sure whether that solves anything without more information of the repro","joyeecheung",4299420,"2024-09-05 10:59:55","function use option turn first place otherwise go elsewhere throw err require esm function sure solve information repro
"
392,115,"> I am not sure whether that solves anything without more information of the repro

@Mongsplaatjies can you provide a minimal reproducible example of the code that caused this error?

---

For reference, the failing assertion is:
<https://github.com/nodejs/node/blob/0debdac9da67d744f4706a1c8ccb537b44ce3647/lib/internal/modules/esm/loader.js#L329>","avivkeller",38299977,"2024-09-05 11:59:02","sure solve information repro provide minimal reproducible example code cause error reference fail assertion
"
393,115,"I'm able to reproduce thanks to @dgozman with the following script:

```sh
rm -rf repro
mkdir repro
cd repro

echo 'import ""fs""' > imported.ts
node -e 'require(""./imported.ts"")'

cd ..
rm -rf repro
```","aduh95",14309773,"2024-09-09 12:56:30","reproduce script import fs node require import
"
394,116,"See also #54444, which resolved a similar error, so maybe they are somewhat related?","avivkeller",38299977,"2024-09-04 15:26:29","see resolve similar error maybe relate
"
397,116,"In that snippet, `startEntry.originalSource` is the name of a file that does not exist for whatever reason. `getLines()` handles this case, but this code didn't properly check the return value.","cjihrig",2512748,"2024-09-14 21:36:07","snippet startEntry originalSource file exist code properly check return value
"
398,116,"Working on this now.","avivkeller",38299977,"2024-09-20 23:18:06","work
"
399,117,"Hey @hyunbinseo , I believe this issue is caused by the following regex matching pattern: https://github.com/nodejs/node/blob/main/lib/internal/test_runner/utils.js#L54 -> ```*[.-_]test```

I've created a repro and proposed a possible solution in this pull request: #54728.","pmarchini",49943249,"2024-09-03 06:47:00","issue caus regex match pattern repro propos solution pull request
"
400,118,"CC @nodejs/web-standards ","avivkeller",38299977,"2024-09-18 17:05:00","nodejs web standard
"
401,118,"> In Node.js, the above snippet logs false, however, in other environments, it logs true.

the code snippet from above logs `true` in `v18.20.4` and `v20.17.0`, and `false` for `v22.9.0`.","dnalborczyk",2903325,"2024-09-18 19:05:24","node js snippet log true v18 false v22
"
1440,251,"Fix in #45495","panva",241506,"2022-11-17 14:49:06","fix
"
406,119,"Dependent abort signal that allow one or more 'AbortSignal' object to depend on each other
the dependent signal will automatically aborted if the parent is aborted . So the links explains the behavior that AbortSignal should behave like that but it fails assertion when signal has already been aborted . 
Looks like you can test the case by skipping the signal if aborted or check if the signal is aborted creating an exception handler
this 2 case can be tested to see if the impact and early test if we modification can be made to this 
if you have any other way please discuss?
@RedYetiDev 
 ","shubhamsugara22",37795429,"2024-08-30 19:13:20","depend abort signal allow one 'abortsignal' object depend each dependent signal automatically abort parent abort link explain behavior abortsignal behave fail assertion signal already abort look test case skip signal abort check signal abort create exception handler case test impact early test modification make way discuss
"
407,119,"I'm sorry, I'm not exactly following your comment, could you elaborate?

The issue, to clarify, is that in internal assertion is thrown in a place where a signal should be returned (to be WPT compliant).","avivkeller",38299977,"2024-08-30 19:15:21","issue clarify internal assertion throw place signal return wpt compliant
"
408,119,"😞  Sorry for that i meant this: 
What is understood 
A dependent abort signal is designed so that when the parent signal is aborted, the dependent signal should automatically follow suit. The DOM specification outlines this behavior, but it seems that Node.js currently fails this internal assertion when a signal has already been aborted.
Solution we can try ?
One possible way to address this would be to check if the signal has been aborted before attempting to create a dependent signal. If it has, we could skip it or handle it with an exception. This would help ensure compliance with the WPT. We could start by testing these approaches to see if they resolve the issue.

If you have any other suggestions or ideas on how to ensure WPT compliance while avoiding this assertion, I'd love to discuss them!","shubhamsugara22",37795429,"2024-08-30 19:26:10","abort signal parent signal abort dom specification node js fail assertion signal abort solution check signal abort skip exception wpt test approach resolve issue suggestion idea wpt compliance assertion discuss
"
409,119,"Ahh okay. If you have an idea/improvement, opening a PR is a great way to contribute ","avivkeller",38299977,"2024-08-30 19:31:36","idea improvement contribui
"
410,119,"yeah , thanks will try to open one for this 
","shubhamsugara22",37795429,"2024-08-31 13:40:11","try open
"
411,120,"```console
$ touch repro.cjs  
$ touch test.mjs 
$ node --experimental-require-module --import=./test.mjs repro.cjs
(node:179265) ExperimentalWarning: Support for loading ES Module in require() is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
node:internal/assert:14
    throw new ERR_INTERNAL_ASSERTION(message);
          ^

Error [ERR_INTERNAL_ASSERTION]: This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at assert (node:internal/assert:14:11)
    at ModuleLoader.requireCommonJS (node:internal/modules/esm/translators:290:3)
    at callTranslator (node:internal/modules/esm/loader:436:14)
    at ModuleLoader.moduleProvider (node:internal/modules/esm/loader:442:30)
    at async ModuleJob._link (node:internal/modules/esm/module_job:106:19) {
  code: 'ERR_INTERNAL_ASSERTION'
}

Node.js v22.7.0
```","avivkeller",38299977,"2024-08-26 21:58:01","error internal assertion nodejs bug incorrect usage nodejs internal open issue stack trace
"
412,120,"The failed assertion is <https://github.com/nodejs/node/blob/3a71ccf6c473357e89be61b26739fd9139dce4db/lib/internal/modules/esm/translators.js#L243>","avivkeller",38299977,"2024-08-26 21:59:28","failed assertion
"
413,120,"I think part of my WIP for synchronous hooks can fix this by handling the translations more correctly (i.e. properly distinguishing `require(esm) -> require(cjs)` v.s. `import cjs -> require(cjs)` in the loader), it will need to be split out as a refactoring first though.

> For example, to use module customization hooks when ECMAScript and CommonJS module types need to be mixed.

require(esm) from CJS roots won't support the asynchronous module customization hooks, just like require(cjs) from CJS roots / `createRequire()` doesn't support them either. The plan is to add an in-thread, synchronous variant of the customization hooks that support all types of module loading universally instead https://github.com/nodejs/loaders/pull/198 while the async variant will continue to be limited in the kind of module loading it can affect.","joyeecheung",4299420,"2024-08-27 13:39:17","hook fix translation properly distinguish require esm require cjs import cjs require cjs loader need split refactoring example use module customization hook ecmascript commonjs module type need mix require esm cjs root support asynchronous module customization hook require cjs cjs root createrequire support plan add in thread synchronous variant customization hook support type module load universally async variant continue limit kind module load affect
"
414,120,"> require(esm) from CJS roots won't support the asynchronous module customization hooks

Good point. I would probably have run into that next, if I hadn't gotten this error.

For my case, I would also be using dynamic import from a CJS root, which should allow the async hooks if I understand correctly.","kylesmile",5431741,"2024-08-27 15:15:12","require esm cjs root support asynchronous module customization hook good point probably run error case use dynamic import cjs root allow async hook understand correctly
"
415,120,"It's basically this

```js
// main.cjs
import('./a.mjs');   // module.register() hooks are triggered when loading a.mjs
require('./b.mjs');  // module.register() hooks won't be triggered when loading `b.mjs`. Need to wait for the upcoming module.registerHooks() API.
```","joyeecheung",4299420,"2024-08-27 15:23:02","main cjs import a mjs require b mjs
"
416,120,"I tested a bit and noticed actually the assertion has been bogus since https://github.com/nodejs/node/pull/52047, so opened https://github.com/nodejs/node/pull/54592 to remove it.","joyeecheung",4299420,"2024-08-27 15:52:31","test assertion bogus remove
"
417,121,"> I found the function that triggers this error in Nodejs. It seems it was changed last week in a commit to update V8:
> 
> [nodejs/node@`4f1c27a`/deps/v8/src/ic/ic.cc#L251 (blame)](https://github.com/nodejs/node/blame/4f1c27af8c09c45ac7dcb7c48146aa9392cebde8/deps/v8/src/ic/ic.cc#L251)
> 
> This is where the error actually happens: [nodejs/node@`4f1c27a`/deps/v8/src/objects/feedback-vector.cc#L1125 (blame)](https://github.com/nodejs/node/blame/4f1c27af8c09c45ac7dcb7c48146aa9392cebde8/deps/v8/src/objects/feedback-vector.cc#L1125)
> 
> Reported it upstream: [nodejs/node#54573](https://github.com/nodejs/node/issues/54573)

Quote from @aminya in the other thread. CC @nodejs/v8

---

While we wait for them to respond, do you happen to have a reproduction without the use of dependencies like `parcel`?

If not, could you run the same code with the `NODE_DEBUG=*` environment variable, and provide the output?","avivkeller",38299977,"2024-08-26 20:59:22","find function trigger error nodejs seem change last week commit update v8 error happen report upstream wait respond happen reproduction without use dependency parcel run code node_debug environment variable provide output
"
704,148,"Thanks. I'll follow up once https://github.com/nodejs/node/pull/52609 lands.","anonrig",1935246,"2024-04-28 23:41:15","follow land
"
418,121,"No, I don't have a simpler reproduction. Parcel also uses Nodejs Add-on API, so @devongovett should be able to help add a reproduction with a debug build of Parcel","aminya",16418197,"2024-08-26 21:07:13","reproduction nodejs addon api devongovett help add reproduction debug build parcel
"
419,121,"No worries!

A few things to help narrow this down:
1. `NODE_DEBUG=*` will enable debug logging in Node.js, could you try running the same command with that in your environment?
2. If parcel has a debug logging system, It'd really help to narrow down where this is coming from.","avivkeller",38299977,"2024-08-26 21:08:57","worry thing help narrow debug enable debug log node try run command environment parcel debug log system help narrow come
"
420,121,"Here's the log with `NODE_DEBUG=*`

```
node ./node_modules/parcel/bin/parcel.js 
```

[errors.log](https://github.com/user-attachments/files/16753803/errors.log)

Looks like Parcel's caching code triggers this.
```
@parcel+cache@2.0.0-canary.1719_@parcel+core@2.0.0-canary.1717_@swc+helpers@0.5.12_/node_modules/@parcel/cache/lib/FSCache.js]
```


https://github.com/parcel-bundler/parcel/blob/0e08d8c69243e104aaba52c2393d528bb6872450/packages/core/cache/src/FSCache.js","aminya",16418197,"2024-08-26 21:15:26","cache code trigger  parcel cache fscache
"
421,121,"I get errors in `v8::internal::StringTable::OffHeapStringHashSet::KeyIsMatch`. These occur in multiple different call stacks, e.g. in `napi_set_named_property`:

```
* thread #13, stop reason = EXC_BAD_ACCESS (code=1, address=0xa5fa)
  * frame #0: 0x000000010077e3f4 node`bool v8::internal::StringTable::OffHeapStringHashSet::KeyIsMatch<v8::internal::Isolate, v8::internal::SequentialStringKey<unsigned char> >(v8::internal::Isolate*, v8::internal::SequentialStringKey<unsigned char>*, v8::internal::Tagged<v8::internal::Object>) + 32
    frame #1: 0x000000010077b0ac node`v8::internal::Handle<v8::internal::String> v8::internal::StringTable::LookupKey<v8::internal::SequentialStringKey<unsigned char>, v8::internal::Isolate>(v8::internal::Isolate*, v8::internal::SequentialStringKey<unsigned char>*) + 128
    frame #2: 0x000000010045f640 node`v8::internal::FactoryBase<v8::internal::Factory>::InternalizeString(v8::base::Vector<unsigned char const>, bool) + 176
    frame #3: 0x000000010046fbdc node`v8::internal::Factory::InternalizeUtf8String(v8::base::Vector<char const>) + 76
    frame #4: 0x00000001002dc950 node`v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::NewStringType, int) + 128
    frame #5: 0x0000000100094210 node`napi_set_named_property + 208
    frame #6: 0x00000001194c5130 parcel-node-bindings.darwin-arm64.node`napi::js_values::_$LT$impl$u20$napi..js_values..object..JsObject$GT$::set_named_property::h5084994e2531749c + 88
    frame #7: 0x00000001194d0e34 parcel-node-bindings.darwin-arm64.node`parcel_resolver::_::_$LT$impl$u20$serde..ser..Serialize$u20$for$u20$parcel_resolver..Resolution$GT$::serialize::h904a07a7bb6368f1 + 392
    frame #8: 0x00000001194bccc4 parcel-node-bindings.darwin-arm64.node`parcel_node_bindings::resolver::Resolver::resolve_result_to_js::h68ad0611506b3f03 + 488
    frame #9: 0x00000001194cb620 parcel-node-bindings.darwin-arm64.node`parcel_node_bindings::resolver::__napi_impl_helper__Resolver__1::__napi__resolve::h830643ec2ac2f150 + 648
```

Or in the `v8.deserialize` API:

```
  * frame #0: 0x000000010077e308 node`bool v8::internal::StringTable::OffHeapStringHashSet::KeyIsMatch<v8::internal::Isolate, v8::internal::InternalizedStringKey>(v8::internal::Isolate*, v8::internal::InternalizedStringKey*, v8::internal::Tagged<v8::internal::Object>) + 28
    frame #1: 0x000000010077d2f4 node`v8::internal::Handle<v8::internal::String> v8::internal::StringTable::LookupKey<v8::internal::InternalizedStringKey, v8::internal::Isolate>(v8::internal::Isolate*, v8::internal::InternalizedStringKey*) + 132
    frame #2: 0x000000010077d0e8 node`v8::internal::StringTable::LookupString(v8::internal::Isolate*, v8::internal::Handle<v8::internal::String>) + 324
    frame #3: 0x000000010079c148 node`v8::internal::ValueDeserializer::ReadJSObjectProperties(v8::internal::Handle<v8::internal::JSObject>, v8::internal::SerializationTag, bool) + 604
    frame #4: 0x000000010079894c node`v8::internal::ValueDeserializer::ReadJSObject() + 268
    frame #5: 0x0000000100797674 node`v8::internal::ValueDeserializer::ReadObjectInternal() + 820
    frame #6: 0x000000010079725c node`v8::internal::ValueDeserializer::ReadObject() + 64
    frame #7: 0x000000010079c440 node`v8::internal::ValueDeserializer::ReadJSObjectProperties(v8::internal::Handle<v8::internal::JSObject>, v8::internal::SerializationTag, bool) + 1364
    frame #8: 0x000000010079894c node`v8::internal::ValueDeserializer::ReadJSObject() + 268
    frame #9: 0x0000000100797674 node`v8::internal::ValueDeserializer::ReadObjectInternal() + 820
    frame #10: 0x000000010079725c node`v8::internal::ValueDeserializer::ReadObject() + 64
    frame #11: 0x000000010079c1f8 node`v8::internal::ValueDeserializer::ReadJSObjectProperties(v8::internal::Handle<v8::internal::JSObject>, v8::internal::SerializationTag, bool) + 780
    frame #12: 0x000000010079894c node`v8::internal::ValueDeserializer::ReadJSObject() + 268
    frame #13: 0x0000000100797674 node`v8::internal::ValueDeserializer::ReadObjectInternal() + 820
    frame #14: 0x000000010079725c node`v8::internal::ValueDeserializer::ReadObject() + 64
    frame #15: 0x000000010079c440 node`v8::internal::ValueDeserializer::ReadJSObjectProperties(v8::internal::Handle<v8::internal::JSObject>, v8::internal::SerializationTag, bool) + 1364
    frame #16: 0x000000010079894c node`v8::internal::ValueDeserializer::ReadJSObject() + 268
    frame #17: 0x0000000100797674 node`v8::internal::ValueDeserializer::ReadObjectInternal() + 820
    frame #18: 0x000000010079725c node`v8::internal::ValueDeserializer::ReadObject() + 64
    frame #19: 0x000000010079718c node`v8::internal::ValueDeserializer::ReadObjectWrapper() + 32
    frame #20: 0x00000001002cc358 node`v8::ValueDeserializer::ReadValue(v8::Local<v8::Context>) + 268
    frame #21: 0x0000000100172e70 node`node::serdes::DeserializerContext::ReadValue(v8::FunctionCallbackInfo<v8::Value> const&) + 100
    frame #22: 0x0000000100d4f118 node`Builtins_CallApiCallbackGeneric + 184
```

Or just in the parser:

```
  * frame #0: 0x000000010077caf8 node`v8::internal::OffHeapHashTableBase<v8::internal::StringTable::OffHeapStringHashSet>::RehashInto(v8::internal::PtrComprCageBase, v8::internal::StringTable::OffHeapStringHashSet*) + 124
    frame #1: 0x000000010077b340 node`v8::internal::StringTable::EnsureCapacity(v8::internal::PtrComprCageBase, int) + 268
    frame #2: 0x000000010077b104 node`v8::internal::Handle<v8::internal::String> v8::internal::StringTable::LookupKey<v8::internal::SequentialStringKey<unsigned char>, v8::internal::Isolate>(v8::internal::Isolate*, v8::internal::SequentialStringKey<unsigned char>*) + 216
    frame #3: 0x00000001002f07fc node`void v8::internal::AstValueFactory::Internalize<v8::internal::Isolate>(v8::internal::Isolate*) + 152
    frame #4: 0x00000001007a468c node`v8::internal::Parser::ParseFunction(v8::internal::Isolate*, v8::internal::ParseInfo*, v8::internal::Handle<v8::internal::SharedFunctionInfo>) + 1688
    frame #5: 0x00000001007c51c0 node`v8::internal::parsing::ParseFunction(v8::internal::ParseInfo*, v8::internal::Handle<v8::internal::SharedFunctionInfo>, v8::internal::Isolate*, v8::internal::parsing::ReportStatisticsMode) + 276
    frame #6: 0x000000010035c14c node`v8::internal::Compiler::Compile(v8::internal::Isolate*, v8::internal::Handle<v8::internal::SharedFunctionInfo>, v8::internal::Compiler::ClearExceptionFlag, v8::internal::IsCompiledScope*, v8::internal::CreateSourcePositions) + 828
    frame #7: 0x000000010035ca88 node`v8::internal::Compiler::Compile(v8::internal::Isolate*, v8::internal::Handle<v8::internal::JSFunction>, v8::internal::Compiler::ClearExceptionFlag, v8::internal::IsCompiledScope*) + 236
    frame #8: 0x000000010085b230 node`v8::internal::Runtime_CompileLazy(int, unsigned long*, v8::internal::Isolate*) + 136
```

Could this be a v8 bug? The stack traces above make me think it isn't specific Parcel's native addons.","devongovett",19409,"2024-08-31 21:02:17","error occur multiple call stack napi_set_named_property v8 deserialize api parser v8 bug stack trace suggest specific parcel native addon
"
422,121,"CC @nodejs/v8 @nodejs/node-api ","avivkeller",38299977,"2024-08-31 21:06:57","nodejs v8 node api
"
423,121,"It appears that worker_threads may also be involved here. I cannot reproduce when I disable multi-threading in Parcel. Haven't managed to produce a smaller reproduction yet unfortunately...","devongovett",19409,"2024-08-31 21:09:58","worker thread involve reproduce disable multi thread manage produce small reproduction
"
424,121,"👋 Hey, v22.8.0 was just released, is this reproducible in that version?","avivkeller",38299977,"2024-09-03 14:09:34","Hey versão reproduzir
"
425,121,"I have same error while building project made with `npx create-instantsearch-app`

```
$ npm start

> ui@1.0.0 start
> parcel index.html --port 3000

(node:57375) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.
(Use `node --trace-deprecation ...` to show where the warning was created)
Server running at http://localhost:3000
⠸ Building favicon.png...
malloc(): invalid size (unsorted)
Aborted (core dumped)
```

It still works at 22.6","wtfnukee",45035322,"2024-09-04 21:03:55","build project error work
"
426,121,"> 👋 Hey, v22.8.0 was just released, is this reproducible in that version?

Yes, the parcel builds still fail on Node 22.8.0","aminya",16418197,"2024-09-04 21:28:31","reproducible version parcel build fail node
"
427,121,"I can confirm this is reproducible on Node 22.8.","LeoniePhiline",22329650,"2024-09-05 11:12:02","confirm reproducible node
"
428,121,"> Haven't managed to produce a smaller reproduction yet unfortunately...

Hey, does anyone happen to have a smaller reproduction?","avivkeller",38299977,"2024-09-05 11:57:57","manage produce small reproduction anyone happen small reproduction
"
429,121,"I just got a similar error message with Parcel but on Node 20.17 on macOS:
```
node(2214,0x7ff8463907c0) malloc: Incorrect checksum for freed object 0x7fee87078e00: probably modified after being freed.
Corrupt value: 0x5b00000000000002
node(2214,0x7ff8463907c0) malloc: *** set a breakpoint in malloc_error_break to debug
/bin/sh: line 1:  2214 Abort trap: 6           parcel build src/index.html --public-url ./ --dist-dir build
```","mischnic",4586894,"2024-09-08 08:39:33","node malloc incorrect checksum freed object probably modify free corrupt value set breakpoint malloc_error_break debug abort trap parcel build src index html public url dist dir build
"
430,121,"The stacktraces in https://github.com/nodejs/node/issues/54573#issuecomment-2323042402 seems to suggest that it might be a more generic bug - maybe some kind of memory corruption - but it is difficult to tell what's going on without a minimal reproduction that doesn't use third-party dependencies.","joyeecheung",4299420,"2024-09-19 17:25:00","stacktrace suggest generic bug memory corruption difficult tell minimal reproduction use third party dependency
"
431,121,"I've reduced at least one of these cases down to a simple reproduction. It requires two typed arrays which are serialized using `v8.serialize`, and it crashes during `v8.deserialize`.

```js
let v8 = require('v8');

let data = {
  nodes: new Uint32Array(451),
  edges: new Uint32Array(1155)
};

v8.deserialize(v8.serialize(data));
```

On macOS with Node v22.9.0 I get:

```
node(28671,0x1ef3ff240) malloc: Incorrect checksum for freed object 0x134848210: probably modified after being freed.
Corrupt value: 0x0
node(28671,0x1ef3ff240) malloc: *** set a breakpoint in malloc_error_break to debug
Abort trap: 6
```

Output from lldb:

```
* thread #1, queue = 'com.apple.main-thread', stop reason = signal SIGABRT
  * frame #0: 0x000000018ac8a600 libsystem_kernel.dylib`__pthread_kill + 8
    frame #1: 0x000000018acc2f70 libsystem_pthread.dylib`pthread_kill + 288
    frame #2: 0x000000018abcf908 libsystem_c.dylib`abort + 128
    frame #3: 0x000000018aad967c libsystem_malloc.dylib`malloc_vreport + 896
    frame #4: 0x000000018ab014a8 libsystem_malloc.dylib`malloc_zone_error + 100
    frame #5: 0x000000018aae5f90 libsystem_malloc.dylib`free_list_checksum_botch + 40
    frame #6: 0x000000018aad2874 libsystem_malloc.dylib`small_free_list_remove_ptr_no_clear + 960
    frame #7: 0x000000018aacfe68 libsystem_malloc.dylib`free_small + 580
    frame #8: 0x00000001005b80f8 node`v8::internal::BackingStore::~BackingStore() + 328
    frame #9: 0x00000001002f142c node`std::__1::__shared_ptr_pointer<v8::internal::BackingStore*, std::__1::default_delete<v8::internal::BackingStore>, std::__1::allocator<v8::internal::BackingStore>>::__on_zero_shared() + 20
    frame #10: 0x00000001004321a8 node`v8::internal::ArrayBufferSweeper::~ArrayBufferSweeper() + 200
    frame #11: 0x00000001004a5948 node`v8::internal::Heap::TearDown() + 480
    frame #12: 0x000000010040a4b4 node`v8::internal::Isolate::Deinit() + 892
    frame #13: 0x000000010040a060 node`v8::internal::Isolate::Delete(v8::internal::Isolate*) + 168
    frame #14: 0x000000010012ad24 node`node::NodeMainInstance::~NodeMainInstance() + 76
    frame #15: 0x00000001000ac0bc node`node::Start(int, char**) + 724
```","devongovett",19409,"2024-09-28 22:10:09","reduc least case simple reproduction require two type array serialize v8serialize crash v8deserialize node macos node get malloc incorrect checksum freed object probably modify free corrupt value set breakpoint malloc_error_break debug abort trap thread queue com apple main thread stop reason signal sigabrt frame libsystem kernel dylib pthread kill frame libsystem pthread dylib pthread kill frame libsystem c dylib abort frame libsystem malloc dylib malloc vreport frame libsystem malloc dylib malloc zone error frame libsystem malloc dylib free list checksum botch frame libsystem malloc dylib small free list remove ptr clear frame libsystem malloc dylib free small frame node v8 internal backingstore backingstore frame node std shared ptr pointer v8 internal backingstore std default delete v8 internal backingstore std allocator v8 internal backingstore on zero shared frame node v8 internal arraybuffersweeper arraybuffersweeper frame node v8 internal heap teardown frame node v8 internal isolate deinit frame node v8 internal isolate delete frame node nodemaininstance nodemaininstance frame node node start
"
446,121,"```patch
diff --git a/lib/v8.js b/lib/v8.js
index b687d8709c..a0145d0588 100644
--- a/lib/v8.js
+++ b/lib/v8.js
@@ -368,7 +368,7 @@ class DefaultDeserializer extends Deserializer {
     }
     // Copy to an aligned buffer first.
     const buffer_copy = Buffer.allocUnsafe(byteLength);
-    copy(this.buffer, buffer_copy, 0, byteOffset, byteOffset + byteLength);
+    this.buffer.copy(buffer_copy, 0, byteOffset, byteOffset + byteLength);
     return new ctor(buffer_copy.buffer,
                     buffer_copy.byteOffset,
                     byteLength / BYTES_PER_ELEMENT);
```
this seems like enough to stop it from crashing??","ramidzkh",19631324,"2024-10-03 23:46:30","copy buffer buffer copy byteoffset bytelength crash
"
447,122,"Update: UTF+8 is fine. It's specifically on ASCII extended set. 

I tried other versions:
```
""name"": ""aa"" # works fine
""name"": ""дмитрий"" # works fine
""name"": ""💩"" # works fine
""name"": ""¿"" # doesn't work
""name"" ""éñüçßÆ"" doesn't work
```

Our best guess is ASCII extended set UTF-8 encoded vs normal ASCII extended set are getting mixed up and corrupted","nikhilro",22201788,"2024-08-24 16:51:06","update utf fine specifically ascii extend set try version name work name work name work name work name work guess ascii extend set utf encode normal ascii extend set get mix corrupt
"
432,121,"Looks like a legit bug. With v22.9.0 under valgrind on linux:
```
==1208870== Invalid write of size 1                                                                                                                            
==1208870==    at 0x6A94A13: memmove (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)                                                              
==1208870==    by 0xF3C7D5: node::Buffer::(anonymous namespace)::SlowCopy(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/bnoordhuis/bin/node)           
==1208870==    by 0x1D4F5E1: Builtins_CallApiCallbackGeneric (in /home/bnoordhuis/bin/node)                                                                    
==1208870==    by 0x1D4D8DD: Builtins_InterpreterEntryTrampoline (in /home/bnoordhuis/bin/node)                                                                
==1208870==    by 0x1D4B4DB: Builtins_JSEntryTrampoline (in /home/bnoordhuis/bin/node)                                                                         
==1208870==    by 0x1D4B202: Builtins_JSEntry (in /home/bnoordhuis/bin/node)                                                                                   
==1208870==    by 0x139F142: v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) (in /home/bnoordhuis/bin/node)                                                                                                                                     
==1208870==    by 0x13A00B4: v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) (in /home/bnoordhuis/bin/node)                                                                   
==1208870==    by 0x12505A5: v8::Object::CallAsFunction(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) (in /home/bnoordhuis/bin/node)                                                                                                                                                              
==1208870==    by 0x1035357: node::serdes::DeserializerContext::ReadHostObject(v8::Isolate*) (in /home/bnoordhuis/bin/node)                                    
==1208870==    by 0x178890F: v8::internal::ValueDeserializer::ReadHostObject() (in /home/bnoordhuis/bin/node)                                                  
==1208870==    by 0x17912E3: v8::internal::ValueDeserializer::ReadObjectInternal() (in /home/bnoordhuis/bin/node)                                              
==1208870==  Address 0x2a37d26c is 0 bytes after a block of size 4,620 alloc'd
==1208870==    at 0x6A8A899: malloc (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)
==1208870==    by 0xE73905: node::NodeArrayBufferAllocator::Allocate(unsigned long) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1484424: v8::internal::Heap::AllocateExternalBackingStore(std::function<void* (unsigned long)> const&, unsigned long) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x15D2C2E: v8::internal::BackingStore::Allocate(v8::internal::Isolate*, unsigned long, v8::internal::SharedFlag, v8::internal::InitializedFlag) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1299AC6: v8::internal::(anonymous namespace)::ConstructBuffer(v8::internal::Isolate*, v8::internal::Handle<v8::internal::JSFunction>, v8::internal::Handle<v8::internal::JSReceiver>, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, v8::internal::InitializedFlag) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x129B23E: v8::internal::Builtin_ArrayBufferConstructor(int, unsigned long*, v8::internal::Isolate*) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1DEC3B5: Builtins_CEntry_Return1_ArgvOnStack_BuiltinExit (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1D4A88E: Builtins_JSBuiltinsConstructStub (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1EA2A1C: Builtins_CreateTypedArray (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1DD877A: Builtins_TypedArrayConstructor (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1D4E3BB: Builtins_InterpreterPushArgsThenFastConstructFunction (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1EE22A8: Builtins_ConstructHandler (in /home/bnoordhuis/bin/node)
...
==1208870==  Address 0x2a341f62 is 1 bytes after a block of size 6,513 alloc'd
==1208870==    at 0x6A8FCD3: realloc (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)
==1208870==    by 0x1787590: v8::internal::ValueSerializer::ExpandBuffer(unsigned long) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1787717: v8::internal::ValueSerializer::WriteRawBytes(void const*, unsigned long) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x103646C: node::serdes::SerializerContext::WriteRawBytes(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1D4F5E1: Builtins_CallApiCallbackGeneric (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1D4D8DD: Builtins_InterpreterEntryTrampoline (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1D4B4DB: Builtins_JSEntryTrampoline (in /home/bnoordhuis/bin/node)
==1208870==    by 0x1D4B202: Builtins_JSEntry (in /home/bnoordhuis/bin/node)
==1208870==    by 0x139F142: v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x13A00B4: v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x12505A5: v8::Object::CallAsFunction(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) (in /home/bnoordhuis/bin/node)
==1208870==    by 0x10351DB: node::serdes::SerializerContext::WriteHostObject(v8::Isolate*, v8::Local<v8::Object>) (in /home/bnoordhuis/bin/node)
```","bnoordhuis",275871,"2024-09-28 22:37:21","legit bug v22.9 valgrind linux invalid write size byte block size alloc'd byte block size alloc'd
"
433,121,"I did a git bisect and found that https://github.com/nodejs/node/commit/9f8f26eb2ff36f9352dd85643073af876b9d6b46 (#54087) is the first faulty commit

<details>
<summary>Asan log</summary>

Compiled with `./configure --debug --enable-asan --v8-lite-mode --ninja`.

```
=================================================================
==940543==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x523000014e71 at pc 0x5c456d061247 bp 0x7ffea8486770 sp 0x7ffea8485f30
READ of size 6449 at 0x523000014e71 thread T0
    #0 0x5c456d061246 in __asan_memmove (/git/nodejs/node/out/Debug/node+0x6461246) (BuildId: 78039db21b075505da13c25549fe81d89b95ea50)
    #1 0x5c456d4b8386 in node::Buffer::(anonymous namespace)::SlowCopy(v8::FunctionCallbackInfo<v8::Value> const&) /git/nodejs/node/out/Debug/../../src/node_buffer.cc:590:3
    #2 0x5c4570440aa1 in Builtins_CallApiCallbackGeneric snapshot.cc

0x523000014e71 is located 0 bytes after 6513-byte region [0x523000013500,0x523000014e71)
allocated by thread T0 here:
    #0 0x5c456d063290 in realloc (/git/nodejs/node/out/Debug/node+0x6463290) (BuildId: 78039db21b075505da13c25549fe81d89b95ea50)
    #1 0x5c456f3bfc84 in v8::internal::ValueSerializer::ExpandBuffer(unsigned long) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:415:29
    #2 0x5c456f3bec0d in v8::internal::ValueSerializer::ReserveRawBytes(unsigned long) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:400:10
    #3 0x5c456f3bec0d in v8::internal::ValueSerializer::WriteRawBytes(void const*, unsigned long) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:390:7
    #4 0x5c456d82af08 in node::serdes::SerializerContext::WriteRawBytes(v8::FunctionCallbackInfo<v8::Value> const&) /git/nodejs/node/out/Debug/../../src/node_serdes.cc:282:20
    #5 0x5c4570440aa1 in Builtins_CallApiCallbackGeneric snapshot.cc
    #6 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc
    #7 0x5c457043bfdb in Builtins_JSEntryTrampoline snapshot.cc
    #8 0x5c457043bd02 in Builtins_JSEntry snapshot.cc
    #9 0x5c456e469f41 in v8::internal::GeneratedCode<unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, unsigned long**>::Call(unsigned long, unsigned long, unsigned long, unsigned long, long, unsigned long**) /git/nodejs/node/out/Debug/../../deps/v8/src/execution/simulator.h:178:12
    #10 0x5c456e469f41 in v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) /git/nodejs/node/out/Debug/../../deps/v8/src/execution/execution.cc:418:22
    #11 0x5c456e4686f4 in v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) /git/nodejs/node/out/Debug/../../deps/v8/src/execution/execution.cc:504:10
    #12 0x5c456de6de00 in v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) /git/nodejs/node/out/Debug/../../deps/v8/src/api/api.cc:5485:7
    #13 0x5c456d829726 in node::serdes::SerializerContext::WriteHostObject(v8::Isolate*, v8::Local<v8::Object>) /git/nodejs/node/out/Debug/../../src/node_serdes.cc:160:43
    #14 0x5c456d829878 in non-virtual thunk to node::serdes::SerializerContext::WriteHostObject(v8::Isolate*, v8::Local<v8::Object>) /git/nodejs/node/out/Debug/../../src/node_serdes.cc
    #15 0x5c456f3c6057 in v8::internal::ValueSerializer::WriteHostObject(v8::internal::Handle<v8::internal::JSObject>) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:1200:18
    #16 0x5c456f3cb359 in v8::internal::ValueSerializer::WriteJSArrayBufferView(v8::internal::Tagged<v8::internal::JSArrayBufferView>) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:1006:12
    #17 0x5c456f3c23cc in v8::internal::ValueSerializer::WriteJSReceiver(v8::internal::Handle<v8::internal::JSReceiver>) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:645:14
    #18 0x5c456f3c0e6b in v8::internal::ValueSerializer::WriteObject(v8::internal::Handle<v8::internal::Object>) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:502:14
    #19 0x5c456f3c69bf in v8::internal::ValueSerializer::WriteJSObject(v8::internal::Handle<v8::internal::JSObject>) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:706:10
    #20 0x5c456f3c2146 in v8::internal::ValueSerializer::WriteJSReceiver(v8::internal::Handle<v8::internal::JSReceiver>) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:622:16
    #21 0x5c456f3c0dc3 in v8::internal::ValueSerializer::WriteObject(v8::internal::Handle<v8::internal::Object>) /git/nodejs/node/out/Debug/../../deps/v8/src/objects/value-serializer.cc:509:16
    #22 0x5c456de451cf in v8::ValueSerializer::WriteValue(v8::Local<v8::Context>, v8::Local<v8::Value>) /git/nodejs/node/out/Debug/../../deps/v8/src/api/api.cc:3527:45
    #23 0x5c456d829c28 in node::serdes::SerializerContext::WriteValue(v8::FunctionCallbackInfo<v8::Value> const&) /git/nodejs/node/out/Debug/../../src/node_serdes.cc:191:24
    #24 0x5c4570440aa1 in Builtins_CallApiCallbackGeneric snapshot.cc
    #25 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc
    #26 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc
    #27 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc
    #28 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc
    #29 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc
    #30 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc
    #31 0x5c457043ecdd in Builtins_InterpreterEntryTrampoline snapshot.cc

SUMMARY: AddressSanitizer: heap-buffer-overflow (/git/nodejs/node/out/Debug/node+0x6461246) (BuildId: 78039db21b075505da13c25549fe81d89b95ea50) in __asan_memmove
Shadow bytes around the buggy address:
  0x523000014b80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x523000014c00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x523000014c80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x523000014d00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x523000014d80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
=>0x523000014e00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00[01]fa
  0x523000014e80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x523000014f00: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x523000014f80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x523000015000: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x523000015080: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07 
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
==940543==ABORTING
```
</details>","ramidzkh",19631324,"2024-10-02 11:13:23","git bisect find faulty commit heap buffer overflow address read size 6449 thread realloc expand buffer reserve raw bytes writerawbytes write raw bytes call apicallbackgeneric interpreterentrytrampoline jsentrytrampoline js entry invoke call value serializer writevalue write host object write jsarraybufferview write jsreceiver writeobject write jsobject
"
434,121,"cc @ronag ","bnoordhuis",275871,"2024-10-02 13:25:17","ronag
"
435,121,"If I read this correctly it's `SlowCopy` that has the problem?","ronag",3065230,"2024-10-02 13:33:13","read correctly slowcopy problem
"
436,121,"Who exactly is calling `SlowCopy`? It seems to me that there is a invalid assumption made that the caller to `SlowCopy` validates the range. But I guess that only applies if called from JS?","ronag",3065230,"2024-10-02 13:35:00","call SlowCopy seem invalid assumption caller SlowCopy validate range guess apply call JS
"
437,121,"Can someone who can reproduce check if the following fixes the issue?

```
diff --git a/src/node_buffer.cc b/src/node_buffer.cc
index ad6b794cf5d..6b2551c72fe 100644
--- a/src/node_buffer.cc
+++ b/src/node_buffer.cc
@@ -568,6 +568,9 @@ void StringSlice(const FunctionCallbackInfo<Value>& args) {
 void SlowCopy(const FunctionCallbackInfo<Value>& args) {
   Environment* env = Environment::GetCurrent(args);
 
+  THROW_AND_RETURN_UNLESS_BUFFER(env, args[0]);
+  THROW_AND_RETURN_UNLESS_BUFFER(env, args[1]);
+
   ArrayBufferViewContents<char> source(args[0]);
   SPREAD_BUFFER_ARG(args[1].As<Object>(), target);
 
@@ -575,6 +578,11 @@ void SlowCopy(const FunctionCallbackInfo<Value>& args) {
   const auto source_start = args[3]->Uint32Value(env->context()).ToChecked();
   const auto to_copy = args[4]->Uint32Value(env->context()).ToChecked();
 
+  THROW_AND_RETURN_IF_OOB(ParseArrayIndex(env, args[2], 0, &target_start));
+  THROW_AND_RETURN_IF_OOB(ParseArrayIndex(env, args[3], 0, &source_start));
+  THROW_AND_RETURN_IF_OOB(ParseArrayIndex(env, args[4], source.length(),
+                                          &source_end));
+
   memmove(target_data + target_start, source.data() + source_start, to_copy);
   args.GetReturnValue().Set(to_copy);
 }

```","ronag",3065230,"2024-10-02 13:36:28","reproduce check fix issue
"
438,121,"I found this reproduction example interesting. Here are some other reproductions, any lower number than these work fine. Higher are crashes.
`v8.deserialize(v8.serialize({a: new Int32Array(1024)}))`
`v8.deserialize(v8.serialize({b: new Int16Array(8192)}))`
`v8.deserialize(v8.serialize({c: new Uint32Array(1024)}))`
`v8.deserialize(v8.serialize({d: new Uint16Array(8192)}))`

no bug with (Ui|I)nt8Arrays, only multibytes, from what I can tell.","yellows111",25440281,"2024-10-02 20:07:00","reproduction example interesting reproduction lower number work fine high crash deserialize serialize int array deserialize serialize int array deserialize serialize uint array deserialize serialize uint array bug uint array multibyte
"
439,121,"@ronag The changes in `SlowCopy` didn't compile (from current HEAD or that first failing commit). I've never coded in here before, but I tried changing the patch to:
```diff
diff --git a/src/node_buffer.cc b/src/node_buffer.cc
index cd51d9acf9..77fb90e0e3 100644
--- a/src/node_buffer.cc
+++ b/src/node_buffer.cc
@@ -569,12 +569,20 @@ void StringSlice(const FunctionCallbackInfo<Value>& args) {
 void SlowCopy(const FunctionCallbackInfo<Value>& args) {
   Environment* env = Environment::GetCurrent(args);
 
+  THROW_AND_RETURN_UNLESS_BUFFER(env, args[0]);
+  THROW_AND_RETURN_UNLESS_BUFFER(env, args[1]);
+
   ArrayBufferViewContents<char> source(args[0]);
   SPREAD_BUFFER_ARG(args[1].As<Object>(), target);
 
-  const auto target_start = args[2]->Uint32Value(env->context()).ToChecked();
-  const auto source_start = args[3]->Uint32Value(env->context()).ToChecked();
-  const auto to_copy = args[4]->Uint32Value(env->context()).ToChecked();
+  size_t target_start = args[2]->Uint32Value(env->context()).ToChecked();
+  size_t source_start = args[3]->Uint32Value(env->context()).ToChecked();
+  size_t to_copy = args[4]->Uint32Value(env->context()).ToChecked();
+
+  THROW_AND_RETURN_IF_OOB(ParseArrayIndex(env, args[2], 0, &target_start));
+  THROW_AND_RETURN_IF_OOB(ParseArrayIndex(env, args[3], 0, &source_start));
+  THROW_AND_RETURN_IF_OOB(ParseArrayIndex(env, args[4], source.length(),
+                                         &to_copy));
 
   memmove(target_data + target_start, source.data() + source_start, to_copy);
   args.GetReturnValue().Set(to_copy);
```
but it still causes a crash in the same place.","ramidzkh",19631324,"2024-10-02 23:07:26","change slowcopy compile code change patch cause crash
"
440,121,"@joyeecheung any insights? I don't understand how `Buffer` even comes into the picture here... e.g. `v8.deserialize(v8.serialize({a: new Int32Array(1024)}))`","ronag",3065230,"2024-10-03 13:15:23","insight understand buffer picture deserialize serialize int32array
"
441,121,"> but it still causes a crash in the same place. 

@ramidzkh the same crash?","ronag",3065230,"2024-10-03 13:16:39","cause crash place crash
"
442,121,"Yes. Maybe it's because memmove is being passed the end offset and not the length?","ramidzkh",19631324,"2024-10-03 13:24:27","memmove pass end offset length
"
443,121,"@ronag `v8.serialize({a: new Int32Array(1024)})` returns a Buffer instance","targos",2352663,"2024-10-03 14:06:00","ronag serialize int array buffer instance
"
444,121,"How? Buffer is not part of v8.","ronag",3065230,"2024-10-03 17:29:53","How buffer part v8
"
445,121,"Found it. `copy` comes from `internalBinding('buffer')`.
https://github.com/nodejs/node/blob/b2161d3a137e5a2582c71c798e140d2ba8f7c1d4/lib/v8.js#L370-L374","ramidzkh",19631324,"2024-10-03 23:42:59","copy come internalBinding buffer
"
500,125,"```console
$ node
Welcome to Node.js v22.7.0.
Type "".help"" for more information.
> ""\v"".notAFunction()
TypeError: ""
            "".notAFunction is not a function
```","avivkeller",38299977,"2024-08-22 19:01:10","node type information error function
"
448,122,"cc @ronag if you have any ideas.

found 3 commits related to encoding:
- https://github.com/nodejs/node/commit/f7f7b0c4988cf83044ff94e7efc8b0e3fdeaef94
- https://github.com/nodejs/node/commit/28ca678f81e3579800d7201fbdad498d16cc0995
- https://github.com/nodejs/node/commit/8ba53ae7b71899c0ba3fc6826a2eb27c88f9da2a
","nikhilro",22201788,"2024-08-24 16:59:29","encoding commit
"
449,122,"Hi! v22.7.0 has a few known buffer issues, so could you provide a minimal reproduction so the issue can be narrowed down?

Additionally, could you self-moderate your comment containing curse-words, as it may be offensive to some viewers?

Edit: Thanks!

---

Possibly a duplicate of: #54521","avivkeller",38299977,"2024-08-24 17:17:16","hi known buffer issue provide minimal reproduction issue narrow edit thanks possibly duplicate
"
450,122,"Can you check if this fixes it? https://github.com/nodejs/node/pull/54526","ronag",3065230,"2024-08-24 17:47:01","check fix
"
451,122,"@RedYetiDev

1. Ah gotcha, likely too hard to narrow down to minimal reproduction. If you wanna get on a call, I can show you a reproduction that happens within ~8 minutes. Happy to just test when the patch comes out though.
2. Done

@ronag 

1. Similarly, happy to test when the patch comes out. I can setup the build if you really want. 

Thanks for confirming both. I'll rollback to 22.6.0 for now.
","nikhilro",22201788,"2024-08-24 18:43:00","gotcha difícil reduzir reprodução mínima querer chamada mostrar reprodução minutos feliz testar patch sair feito similar feliz testar patch sair configurar construção querer obrigado confirmar rollback
"
452,122,"We also ran into this issue, took us forever to find the culprit 

We reproduced it by having a simple express http handler deployed on amazon app runner:
```
  res.status(200).json({
    umlaute: 'äöü',
  });
};
```

Further Info:
node 22.6 seems not to be affected, but 22.7 is","sharpner",574362,"2024-08-26 08:41:59","issue take forever find culprit reproduce simple express http handler deploy amazon app runner node affect
"
453,122,"I'm seeing this show up as failed PostgreSQL queries that contain an umlaut as a parameter, with a cryptic-looking error:
```
Unable to execute query: ""invalid byte sequence for encoding ""UTF8""
```
~~Further, I couldn't reproduce it on Apple silicon, but it fails reliably on Linux.~~

edit: the [test case](https://github.com/nodejs/node/pull/54526#issuecomment-2308173057) provided by @blexrob fails reliably in 22.7.0 on both Apple Silicon and Linux (22.6.0 works as expected)
```js
let i = 0;
const testStr = ""jürge"";
const expected = Buffer.from(testStr).toString(""hex"");
for(; i < 1_000_000; i++) {
  const buf = Buffer.from(testStr);
  const ashex = buf.toString(""hex"");
  if (ashex !== expected) {
    console.log(`Decoding changed in iteration ${i} when changing to FastWriteStringUTF8, got ${ashex}, expected ${expected}`);
    break;
  }
}

if(i<1_000_000) {
  console.error(""FAILED after %d iterations"",i);
} else
  console.log(""PASSED after %d iterations"",i);
```","eugene1g",147496,"2024-08-26 11:33:57","query falhar postgresql conter umlaut parametro erro executar query byte sequence encoding utf8 reproduzir apple silicon falhar linux caso teste falhar confiável apple silicon linux funcionar esperado iteração mudar fastwriteutf got esperar
"
454,122,"I'd like to remind everyone that ""me too"" comments only add noise to this already noisy topic. Please refrain from commenting until you have something to add to the conversation

Edit: this isn't directed at any comments. This is meant to deter future ""me too"" comments, as they occur often with issues like this.","avivkeller",38299977,"2024-08-26 13:05:57","remind everyone comment add noise noisy topic refrain comment add conversation direct comment deter future comment occur issue
"
455,122,"I feel like one of the patches in v22.8.0 (#54560), when it lands, will resolve this issue. Once that lands, please post a comment whether it resolves this issue. Given it's current state, that could be a few days.","avivkeller",38299977,"2024-08-26 22:03:15","patch land resolve issue land post comment resolve issue current state day
"
456,122,"I assume you have already tracked this down, but I believe the issue is basically:
1. After enough calls to some string to buffer writing API, V8 optimizes the call to use the Fast API path.
2. Node.js' [`FastWriteString`](https://github.com/nodejs/node/commit/8ba53ae7b71899c0ba3fc6826a2eb27c88f9da2a#diff-81f77f34c4f5b8cc35f1a506808b94e2a281f3341c0f1a38ef2b8a8ba730b22bR1472-R1476) (I'm only guessing this is the API in question, but it is likely the one) gets the call and incorrectly assumes that the `v8::FastOneByteString` it is given is ASCII: This is not the case, [`OneByteString` is Latin-1](https://v8.github.io/api/v6.2/classv8_1_1String.html#a8f14ab3aff52295d2d3245081a1b29eb) encoded.
3. The function then directly copies the data into the destination buffer [here](https://github.com/nodejs/node/commit/8ba53ae7b71899c0ba3fc6826a2eb27c88f9da2a#diff-81f77f34c4f5b8cc35f1a506808b94e2a281f3341c0f1a38ef2b8a8ba730b22bR1485). The buffer is now assumed to contain the string's data as UTF-8, but instead contains the data as Latin-1.","aapoalas",19621382,"2024-08-27 10:03:23","assume track believe issue basically call string buffer write api v8 optimize call use fast api path nodejs fastwritestring guess api question likely one get call incorrectly assume v8fastonestring ascii case onestring latin encoded function directly copy data destination buffer buffer assume contain string data utf instead contain data latin
"
457,122,"#54565 will fix this issue for the v22.8.0 release. Then, #54526 (and similar) will be evaluated for a future release.

When #54565 lands, I'll close this issue","avivkeller",38299977,"2024-08-27 15:06:12","fix issue release evaluate future release land close issue
"
458,122,"This kept us up a couple of nights. Thank you for fixing it!","devronhansen",20226404,"2024-08-28 07:15:41","keep night thank fix
"
459,122,"I am not familiar with the internals of node, but I just lost a few days because of this.
I could not replicate efficiently because it takes a while to happen.

What gave it away was that **the same** request lifecycle returned intact UTF-8 string to the browser and corrupted UTF-8 to the logger service, which spins up a new worker for log transport.","adriano-tirloni",6390605,"2024-08-28 16:20:09","lost day replicate efficiently happen request lifecycle return intact utf string browser corrupt utf logger service spin worker log transport
"
460,122,"> When #54565 lands, I'll close this issue

This PR has landed. Expect the release to follow shortly:","avivkeller",38299977,"2024-08-29 10:07:29","land close issue pr land expect release follow shortly
"
461,122,"I hope that the test coverage gets improved with the fix in 22.8","SimonX200",24841171,"2024-08-31 15:50:50","hope test coverage improve fix
"
462,122,"Did this land in 22.8.0? Could not find it in the release notes:

https://nodejs.org/en/blog/release/v22.8.0","cbratschi",3909121,"2024-09-04 16:47:05","land release note
"
463,122,"> [[`e071651bb2`](https://github.com/nodejs/node/commit/e071651bb2)] - src: disable fast methods for `buffer.write` (Michaël Zasso) [#54565](https://github.com/nodejs/node/pull/54565)","avivkeller",38299977,"2024-09-04 16:49:59","src disable fast method buffer write michael zasso
"
464,122,"if this broke your data when saving to mongo, here is a script to help fix it: https://github.com/nicholas-long/mongo-node-fix-54543","nicholas-long",19252698,"2024-11-05 17:38:25","broke data save mongo script fix
"
762,157,"Related to https://github.com/nodejs/node/pull/51289","kibertoad",1847934,"2024-03-28 11:36:26","relate node pull
"
465,123,"I managed to reproduce using your code snippet, and the slightly modified one below (for readability)
```js
let i = 0;

while (i < 1_000_000) {
  const asHex = Buffer.from(""\x80"").toString(""hex"");

  if (asHex === '80') {
    break;
  } else if (asHex !== 'c280') {
    console.log(""Unexpected return value:"", asHex);
  }

  i++;
}

if (i < 1_000_000) {
  console.log(""FAILED after %d iterations"", i);
  process.exit(1);
} else {
  console.log(""PASSED after %d iterations"", i);
}
```
```console
$ node repro.js
FAILED after 8827 iterations
$ node repro.js
FAILED after 5509 iterations
$ node repro.js
FAILED after 48741 iterations
$ node repro.js
FAILED after 7487 iterations
$ node repro.js
FAILED after 9189 iterations
```","avivkeller",38299977,"2024-08-23 11:19:21","reproduzir código trecho modificar legibilidade iteração falhar
"
466,123,"bisecting gives me, as first bad commit:

commit c9dabe2927374e15d970814af2f758d05c2f977c
Author: Robert Nagy <ronagy@icloud.com>
Date:   Thu Aug 15 03:01:05 2024 +0200

    buffer: use fast API for writing one-byte strings

however, that one's even worse and shows a lot of incorrect 'asHex' values:

```
Unexpected return value afdead0b
Unexpected return value 00dead0b
Unexpected return value 00000000
Unexpected return value 00dead0b
Unexpected return value 01dead0b
Unexpected return value 00000000
Unexpected return value 905e0150
Unexpected return value 00738148
```

so it looks like the more extreme bug got fixed (probably in 78008935b0d66fe61f7b507c6b529aac097c8560) but then issues still  remained for (eg)  \x80","unilynx",2772353,"2024-08-23 13:03:23","buffer usar rápido api escrever um byte string extremo erro corrigir problema permanecer  
"
467,123,"CC @ronag ","avivkeller",38299977,"2024-08-23 13:08:59","ronag retornar
"
468,123,"just to confirm the above - if I take the v22.x branch (5ae0260837ce72e97caca75568f6edabd414d905) but revert 78008935b0d66fe61f7b507c6b529aac097c8560 and a5a60e68232ae26615ff2c297bea49314354c42c, the issue is no longer present


","unilynx",2772353,"2024-08-23 13:15:06","confirm take branch revert issue present
"
469,123,"I'll have a look.","ronag",3065230,"2024-08-23 13:34:59","look
"
470,123,"```js
let i = 0;

while (i < 1_000_000) {
  const buf = Buffer.from(""\x80"")

  if (buf[0] !== 194 || buf[1] !== 128) {
    console.log(""Unexpected return value:"", buf, buf[0], buf[1]);
    break
  }

  i++;
}

if (i < 1_000_000) {
  console.log(""FAILED after %d iterations"", i);
  process.exit(1);
} else {
  console.log(""PASSED after %d iterations"", i);
}

```","ronag",3065230,"2024-08-23 13:51:03","PASSED iteration
FAILED iteration


Note:  The provided text is JavaScript code, not a typical text suitable for issue classification.  The pre-processing steps requested would remove almost all meaningful information.  The resulting text above only retains the words ""PASSED"", ""FAILED"", and ""iteration"" because they are not considered stop words and are not significantly altered by stemming/lemmatization.   A more meaningful pre-processing for this type of text would involve techniques specific to code analysis, such as extracting function names, variable names, and error messages.
"
471,123,"This seems to be something in V8.

In
```cpp
uint32_t FastWriteString(Local<Value> receiver,
                         const v8::FastApiTypedArray<uint8_t>& dst,
                         const v8::FastOneByteString& src,
                         uint32_t offset,
                         uint32_t max_length) {
}
```

`src.length === 1` i.e. `FastOneByteString` thinks that `Buffer.from(['\x80'])` has a length of 1.

@targos @joyeecheung @nodejs/buffer ","ronag",3065230,"2024-08-23 13:57:02","v8 fastwrite string buffer length
"
472,123,"Which is kind of correct...  is it the slow path that is broken?","ronag",3065230,"2024-08-23 13:57:47","kind correct slow path broken
"
473,123,"actually @anonrig @lemire might have ideas?","ronag",3065230,"2024-08-23 13:59:37","anonrig lemire idea
"
474,123,"Is the problem here that we are not handling incomplete utf8 sequences? ","ronag",3065230,"2024-08-23 14:00:53","problem handle incomplete utf8 sequence
"
475,123,"I'm not sure where the `c2` from the expected `c280` is coming from?","ronag",3065230,"2024-08-23 14:04:10","sure expected come
"
476,123,"If 0x80 was a valid Unicode position, 0xC2 0x80 woud be its UTF8 Encoding. At the very least, this is a regression compared to earlier node (or V8?) versions.

I'm not sure about correctness or what the spec says - JavaScript has always kind of tolerated invalid unicode in its string (otherwise Buffer.from(xxx, ""latin1"") wouldn't be useful either). I think https://github.com/nodejs/node/issues/54518#issuecomment-2306833198 is coming from the same direction (I'm also seeing issues other Invalid UTF-8 encoding issues pop up - 0x80 was just the cleanest example of the regression)

Anyway, if we ignore 0x80 for now... 0xA0 (non breaking space)is certainly a valid Unicode character and perhaps the most often occurring Unicode codepoint above 128. It should encode to 0xC2 0xA0 in utf8

```
let i = 0;
let prev = '';
for(; i < 1_000_000; i++) {
  const ashex = Buffer.from(""\xA0"").toString(""hex"");
  if(prev !== ashex) {
    console.log(""Got "", ashex);
    prev = ashex;
  }
}
```

returns

```
Got  c2a0
Got  a0
```

The encoding here also changes for the fast path

node 20 only returns `c2a0`
","unilynx",2772353,"2024-08-23 14:12:01","regression unicode utf encoding javascript string buffer valid character codepoint


"
477,123,"Looking at the slow implementation there is a `REPLACE_INVALID_UTF8` flag which I guess is what is causing the difference. 

@lemire does simdutf have a ""memcpy"" + replace invalid utf8 routine?","ronag",3065230,"2024-08-23 14:15:46","look slow implementation replace invalid utf8 flag cause difference simdutf memcpy replace invalid utf8 routine
"
478,123,"@ronag 

>  does simdutf have a ""memcpy"" + replace invalid utf8 routine?

It does not. The simdutf library does not do replacement. It only transcodes valid inputs.

","lemire",391987,"2024-08-23 14:17:04","simdutf memcpy replace invalid utf8 routine
"
479,123,"@ronag 

In simdutf, the expectation (currently) is that you assume that the input is valid. If it is not, then simdutf will tell you, and you can use a slow path. We expect most inputs to be valid strings... ","lemire",391987,"2024-08-23 14:21:23","simdutf expectativa assumir entrada válido. não, simdutf informar, usar caminho lento. esperar maioria entrada string válido.
"
480,123,"so is there a way I could do:

```js
if (!simd_utf8_copy(src, dst, size)) {
  // slow path
}
```","ronag",3065230,"2024-08-23 14:27:42","way simd_utf8_copy src dst size slow path
"
481,123,"> so is there a way I could do:

Let me have a look at the offending code.","lemire",391987,"2024-08-23 14:32:16","way could look offending code
"
482,123,"@ronag Let me create a PR (for discussion).","lemire",391987,"2024-08-23 14:34:58","create pr discussion
"
483,123,"@ronag I see you were faster (https://github.com/nodejs/node/pull/54526), so let me go to https://github.com/nodejs/node/pull/54526 instead of me creating a PR.","lemire",391987,"2024-08-23 14:36:56","see faster let go create pr
"
484,123,"Fixed by #54565 ","avivkeller",38299977,"2024-08-29 12:01:56","fixed
"
485,124,"Hi! Can you make a reproduction without using any dependencies?","avivkeller",38299977,"2024-08-23 09:49:23","make reproduction use dependency
"
528,127,"Can you strip your example to just the basics? Something very small that will reproduce this?","avivkeller",38299977,"2024-08-18 11:43:08","strip example basic reproduce
"
486,124,"Here is an example using purely Buffer.

```
let example = new Buffer(""1234567890"")
example.utf8Write(""abc"", 1)
```

Using 22.7.0
```
node:internal/buffer:1066
      throw new ERR_BUFFER_OUT_OF_BOUNDS('length');
      ^

RangeError [ERR_BUFFER_OUT_OF_BOUNDS]: ""length"" is outside of buffer bounds
    at proto.utf8Write (node:internal/buffer:1066:13)
    at Object.<anonymous> (/Users/sebastianscheibe/Code/XXX/test_github.js:4:9)
    at Module._compile (node:internal/modules/cjs/loader:1546:14)
    at Module._extensions..js (node:internal/modules/cjs/loader:1691:10)
    at Module.load (node:internal/modules/cjs/loader:1317:32)
    at Module._load (node:internal/modules/cjs/loader:1127:12)
    at TracingChannel.traceSync (node:diagnostics_channel:315:14)
    at wrapModuleLoad (node:internal/modules/cjs/loader:217:24)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:166:5)
    at node:internal/main/run_main_module:30:49 {
  code: 'ERR_BUFFER_OUT_OF_BOUNDS'
}

Node.js v22.7.0
```

Using 22.5
```
 node test_github.js                                                                                                                                                                   
(node:45481) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.
(Use `node --trace-deprecation ...` to show where the warning was created)
```","Ecostack",8505607,"2024-08-23 10:34:07","use buffer example alloc allocunsafe buffer from method instead deprecation warning rangeerror err buffer out bounds length outside buffer bound utf write
"
487,124,"There seems to be a change in the latest version which introduces this check regarding the offset.

22.5:
https://github.com/nodejs/node/blob/fd9233acbfdbff8f25dc7dec5e83c697e35b6de9/lib/internal/buffer.js#L1045

22.7:
https://github.com/nodejs/node/blob/65eff1eb19a6d8e17435bbc4147ac4535e81abb4/lib/internal/buffer.js#L1065","Ecostack",8505607,"2024-08-23 10:37:43","change latest version introduce check regard offset
"
488,124,"Thanks! @nodejs/buffer PTAL","avivkeller",38299977,"2024-08-23 10:43:01","thanks nodejs buffer ptal
"
489,124,"i dont know if my issue has something to do with this, but since 22.7 the encoding of buffers wont work anymore.

```
MongoError: text contains invalid UTF-8
```
even expressjs delivers garbage.

yesterday, i build my app on node:22-alpine and all works fine.
since: https://hub.docker.com/layers/library/node/22-alpine/images/sha256-3dbc5d17cf89e1d8ae6f4a8a562f8a5b5df52b4c7060bfb359de86de6a3ecc3c

all is broken. nothing changed in the code base!

btw. ""node:20-alpine"" works as expected (like node:22-alpine yesterday)","ericrange",1785416,"2024-08-23 10:52:11","encoding buffer work anymore mongoerror text contain invalid utf expressjs deliver garbage build app node work fine break nothing change code base node work expect
"
490,124,"I was able to reproduce using both your snippet, and the slightly modified one below:
```js
Buffer.from(""abc"").utf8Write(""abc"", 1)
```
```console
$ node repro.js
node:internal/buffer:1066
      throw new ERR_BUFFER_OUT_OF_BOUNDS('length');
      ^

RangeError [ERR_BUFFER_OUT_OF_BOUNDS]: ""length"" is outside of buffer bounds
    at proto.utf8Write (node:internal/buffer:1066:13)
    at Object.<anonymous> (/repro.js:1:20)
    at Module._compile (node:internal/modules/cjs/loader:1546:14)
    at Module._extensions..js (node:internal/modules/cjs/loader:1691:10)
    at Module.load (node:internal/modules/cjs/loader:1317:32)
    at Module._load (node:internal/modules/cjs/loader:1127:12)
    at TracingChannel.traceSync (node:diagnostics_channel:315:14)
    at wrapModuleLoad (node:internal/modules/cjs/loader:217:24)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:166:5)
    at node:internal/main/run_main_module:30:49 {
  code: 'ERR_BUFFER_OUT_OF_BOUNDS'
}

Node.js v22.7.0
```","avivkeller",38299977,"2024-08-23 11:20:49","reproduce snippet modify buffer utf write rangeerror err buffer out bound node internal buffer  module compile extension module load tracingchannel tracesync wrapmoduleload function executeuserentrypoint runmain code err buffer out bound node


**Explicação das etapas:**

1. **Remoção de ruídos:**  URLs, tags HTML (````js`, ````console`) e caracteres especiais foram removidos.  A numeração da versão do Node.js foi removida por ser irrelevante para a classificação. Os caminhos de arquivo ( `/repro.js`, `node:internal/buffer:1066`, etc.) foram também removidos pois não agregam informação relevante para a classificação de uma issue.

2. **Padronização de palavras:**  A redução para o singular e a remoção de conjugações foram feitas implicitamente ao remover as stop words e focar nas palavras-chave.  Por exemplo, ""reproduce"" e ""modified"" mantiveram seus significados sem precisar de ajustes explícitos de radical.

3. **Remoção de stop words:** Palavras como ""was"", ""able"", ""to"", ""using"", ""both"", ""your"", ""the"", ""slightly"", ""one"", ""below"", ""at"", ""is"", ""of"", ""in"", ""v"" foram removidas pois não contribuem significativamente para a classificação do tipo de problema.  Considerou-se também a remoção de nomes de funções e variáveis internas do Node.js, como ""proto.utf8Write"", ""Module._compile"", etc., já que estas não são úteis para a categorização de um erro genérico do usuário.  A mensagem de erro ""RangeError [ERR_BUFFER_OUT_OF_BOUNDS]"" foi reduzida para ""rangeerror err buffer out bound"" pois as palavras ""RangeError"" e ""[ERR_BUFFER_OUT_OF_BOUNDS]"" representam a mesma informação essencial.


O resultado final foca nas palavras-chave essenciais para a classificação da issue, indicando um problema relacionado a limites de buffer (""buffer"", ""out"", ""bound"") e a função `utf8Write`.
"
491,124,"Leaving this here as it may help someone, this also happens with OpenTelemetry:

```
Error: PeriodicExportingMetricReader: metrics export failed (error RangeError [ERR_BUFFER_OUT_OF_BOUNDS]: ""length"" is outside of buffer bounds)
at doExport (/app/node_modules/@opentelemetry/sdk-metrics/src/export/PeriodicExportingMetricReader.ts:133:15) |  
```","andreialecu",697707,"2024-08-23 12:53:40","export metric fail rangeerror err buffer out bound
"
492,124,"Fixed by #54524","avivkeller",38299977,"2024-08-23 14:19:07","fix
"
493,124,"We are getting the same thing with Firestore queries when we use the same version. We are downgrading node","elliottAtTreatment",139826482,"2024-08-23 16:17:11","get thing firestore query use version downgrade node
"
494,124,"In case helpful - still seeing the `RangeError [ERR_BUFFER_OUT_OF_BOUNDS]: ""length"" is outside of buffer bounds` error when using GCP Secret Manager - temporarily resolved by reverting to 22.5.0

```js
const { SecretManagerServiceClient } = require('@google-cloud/secret-manager');
...
const [response] = await (new SecretManagerServiceClient()).accessSecretVersion({
    name: secretPath,
});
```
","quinnspraut",110827227,"2024-08-23 19:16:22","case helpful see rangeerror err buffer out bound error use gcp secret manager temporarily resolve revert
"
495,124,"It should be fixed in next week's release (22.8.0) which includes: https://github.com/nodejs/node/pull/54524 as a patch. I will take care of it. ","RafaelGSS",26234614,"2024-08-23 19:26:07","fix next week release include patch take care
"
496,124,"Did we just witness an example of Hyrum's law?","nicolasnoble",7281574,"2024-08-25 00:56:12","witness example hyrum law
"
497,124,"> i dont know if my issue has something to do with this, but since 22.7 the encoding of buffers wont work anymore.
> 
> ```
> MongoError: text contains invalid UTF-8
> ```
> 
> even expressjs delivers garbage.
> 
> yesterday, i build my app on node:22-alpine and all works fine. since: https://hub.docker.com/layers/library/node/22-alpine/images/sha256-3dbc5d17cf89e1d8ae6f4a8a562f8a5b5df52b4c7060bfb359de86de6a3ecc3c
> 
> all is broken. nothing changed in the code base!
> 
> btw. ""node:20-alpine"" works as expected (like node:22-alpine yesterday)

https://github.com/nodejs/node/issues/54543","ericrange",1785416,"2024-08-25 15:23:28","buffer encoding work expressjs deliver garbage build app node work fine break code base node work expect
"
498,124,"So an emergent fix has to wait until next week's release (22.8.0) ?","nodegin",8536244,"2024-08-26 12:28:58","emergent fix wait week release
"
499,124,"The release is scheduled for today, see https://github.com/nodejs/node/pull/54560","avivkeller",38299977,"2024-08-26 13:05:02","release schedule today
"
763,157,"@IlyasShabi Maybe you have thoughts on this?","kibertoad",1847934,"2024-03-28 15:22:11","Maybe thought
"
501,126,"I'm unable to reproduce in v22.6.0, but I haven't tested in v20. @LoongZP can you reproduce in the *latest* version of v20? (v20.16.0)
```console
➜  ~ node
Welcome to Node.js v22.6.0.
Type "".help"" for more information.
> Array.prototype[1] = 2
2
> console.log(Array.prototype);
Object(2) [ <1 empty item>, 2 ]
undefined
>
```","avivkeller",38299977,"2024-08-21 12:09:08","unable reproduce v22.6.0 test v20 reproduce latest version v20 16.0 welcome node v22.6.0 type help information array prototype empty item
"
502,126,"@RedYetiDev 
The strange thing is that I also have no error when executing in interactive mode in node, it only occurs when node xx.js, which I also found in v22.3.0.","LoongZP",49547352,"2024-08-21 12:31:21","strange thing error execute interactive mode node occur node xx js v22.3.0
"
503,126,"I'll retest later, but for now could you try to reproduce in the latest version of those release lines?

v22.6.0
v20.16.0","avivkeller",38299977,"2024-08-21 12:38:09","retest later try reproduce latest version release line
"
504,126,"@RedYetiDev 
I also tried it in ubuntu (node v20.11.1.) and found this issue as well.","LoongZP",49547352,"2024-08-21 12:40:34","tried ubuntu node issue
"
505,126,"@RedYetiDev 
I've tried the following:
<html xmlns:o=""urn:schemas-microsoft-com:office:office""
xmlns:dt=""uuid:C2F41010-65B3-11d1-A29F-00AA00C14882""
xmlns=""http://www.w3.org/TR/REC-html40"">

<head>

<meta name=ProgId content=OneNote.File>
<meta name=Generator content=""Microsoft OneNote 15"">
</head>

<body lang=zh-CN style='font-family:微软雅黑;font-size:12.0pt'>
<!--StartFragment-->

<div style='direction:ltr'>


  | os | node  version | result
-- | -- | -- | --
my   coputer | Microsoft   Windows NT 10.0.22631.0   x64 | 22.6.0 | x
my   coputer | Microsoft   Windows NT 10.0.22631.0   x64 | 22.3.0 | x
my   coputer | Microsoft   Windows NT 10.0.22631.0   x64 | 20.14.0 | x
other's   coputer | Linux   version 5.15.0-118-generic (buildd@lcy02-amd64-103) (gcc (Ubuntu   9.4.0-1ubuntu1~20.04.2) 9.4.0, GNU ld (GNU Binutils for Ubuntu) 2.34)   #128~20.04.1-Ubuntu SMP Wed Jul 17 13:41:17 UTC 2024 | 20.11.1 | x
other's   coputer | Microsoft   Windows NT 10.0.22631.0   x64 | 20.9.9 | x



</div>

<!--EndFragment-->
</body>

</html>


**NOTE:**
It's strange that there is no problem with assigning a value to Array.prototype[0/2/3/4...].

","LoongZP",49547352,"2024-08-21 13:12:07","coputer microsoft windows nt x64 node version result computer windows nt x64 computer windows nt x64 computer linux version generic utc computer windows nt x64 strange problem assign value array prototype
"
506,126,"```js
Array.prototype[1] = 2;
console.log(Array.prototype);
```
```console
$ node repro.js
Object(2) [ <1 empty item>, 2 ]
node:internal/process/task_queues:77
          callback();
          ^

TypeError: callback is not a function
    at process.processTicksAndRejections (node:internal/process/task_queues:77:11)

Node.js v22.6.0
```

---

```js
Array.prototype[0] = 2;
console.log(Array.prototype);
```
```console
$ node repro.js
Object(1) [ 2 ]
```","avivkeller",38299977,"2024-08-21 14:48:15","array prototype elemento atribuir valor tipo erro callback funcao node js versao


**Explicação do pré-processamento:**

1. **Remoção de ruídos:**  URLs, tags HTML não estavam presentes no texto.  Números, nomes de variáveis (como `repro.js`), e informações de versão (`Node.js v22.6.0`) foram mantidos, pois podem ser relevantes para a classificação de um *issue*. Caracteres especiais foram removidos implicitamente durante a tokenização.  A saída do console foi resumida.

2. **Padronização de palavras:**  Palavras foram reduzidas à sua raiz (stemming). Por exemplo, ""elementos"" se tornou ""elemento"".  O processo de lematização não foi executado pois requer um analisador morfológico mais sofisticado.

3. **Remoção de stop words:** Palavras como ""o"", ""a"", ""em"", ""de"",  etc, foram removidas. A lista exata de stop words dependeria da linguagem e do contexto,  mas a lista acima representa um exemplo de stop words que provavelmente foram removidas.  A decisão de manter ""js"" e ""node"" depende do contexto do sistema de classificação de issues.  Se o sistema for especificamente para Node.js, mantê-los é importante.

**Observação:** O pré-processamento ideal pode variar dependendo do classificador utilizado e dos dados de treinamento. Este exemplo apresenta uma abordagem razoável, mas ajustes podem ser necessários para obter melhores resultados em um cenário real.
"
507,126,"@RedYetiDev 
So what is the reason, it's a very strange mistake.","LoongZP",49547352,"2024-08-21 15:20:46","reason strange mistake
"
508,126," I think leaving first index cause the issue 

Array.prototype[0]=2;
let problem = Array.prototype;
console.log(problem);

C:\Users\Moorthi\De
Object(1) [ 2 ]
","moorthid2023",122676740,"2024-08-21 16:03:30","leave first index cause issue array prototype problem object
"
509,126,"> I think leaving first index cause the issue
> 
> Array.prototype[0]=2; let problem = Array.prototype; console.log(problem);
> 
> C:\Users\Moorthi\De Object(1) [ 2 ]

**No, you  can try the code below:**

Array.prototype[2] = 2;
let problem = Array.prototype;
console.log(problem);","LoongZP",49547352,"2024-08-21 16:13:03","leave first index cause issue array prototype let problem console log array prototype let problem console log
"
510,126,"> Array.prototype[2] = 2;
> let problem = Array.prototype;
> console.log(problem);

The failing line is:
https://github.com/nodejs/node/blob/8b0c699f2aafdf81bc4834b9bd2a4923741d3a6f/lib/internal/process/task_queues.js#L85

So something is calling that line incorrectly when `Array.prototype[1]` isn't what it should be...

I've added the `console` label, as this isn't reproducible without calling `console.log`.

---

The following prefixes each behave differently:
```js
// Crashes
Array.prototype[1] = 1;
```
```js
// Hangs
Array.prototype[1] = null;
```
```js
// Works normally
Array.prototype[1] = undefined;
```

The error can be reproduced without console (but this function is called from the console.log call):
```js
process.nextTick(()=>{});
```","avivkeller",38299977,"2024-08-21 17:46:01","array prototype problema chamar linha incorretamente array prototype adicionar label console reproduzir chamar console prefixo comportar diferente travar funcionar normalmente erro reproduzir console funcao chamar console call
"
511,126,"@nodejs/process ","avivkeller",38299977,"2024-08-21 17:58:41","nodejs process
"
512,126,"It's just missing primordials but honestly I think it's fine? As long as the error message is outputted clearly and correctly I don't think Node makes (or should make) guarantees regarding operating correctly if builtins are modified like this.

","benjamingr",1315533,"2024-08-21 19:11:20","missing primordial error message output clearly correctly node make guarantee operate correctly builtin modify
"
513,126,"Parts of the Node.js runtime are implemented in JavaScript, and thus inherently susceptible to manipulations of built-in prototypes by user code. I don't think this is considered a bug by most collaborators.","tniessen",3109072,"2024-08-21 20:42:06","node runtime implement javascript inherently susceptible manipulation built prototype user code think consider bug collaborator
"
514,126,"I've added `wontfix` given the comments, feel free to adjust if needed.","avivkeller",38299977,"2024-08-21 20:58:22","add wontfix comment adjust need
"
595,138,"https://github.com/nodejs/node/pull/53627 seems like the likely culprit.","cjihrig",2512748,"2024-07-17 18:31:20","culprit likely
"
764,157,"> @IlyasShabi Maybe you have thoughts on this?

I have opened a pr aimed at solving this problem","mertcanaltin",37827216,"2024-03-29 19:45:58","Maybe thought solve problem
"
515,126,"Forgive me for not knowing much about the nodejs kernel, but I don't think it's a modification of the built-in function, Array.prototype is an object that I can add some functionality to. Although such code does not conform to the development specifications and is even somewhat stupid.
The problem now is that it gives an error message, but it doesn't help me locate the error in the code.
In the meantime, I gave Array.prototype[0/2/3....] There are no errors in the assignment, which I feel is not in line with the logic of the thinking and the consistency of the code.","LoongZP",49547352,"2024-08-21 23:59:45","forgive know nodejs kernel think modification built function array prototype object add functionality code conform development specification somewhat stupid problem give error message help locate error code meantime give array prototype error assignment feel line logic consistency code
"
516,126,"We should probably fix the following though:

```console
$ echo 'Array.prototype[1]={callback(){console.log(1)}};console.log()' > repro.js
$ node repro.js

1
Error: async hook stack has become corrupted (actual: nan, expected: nan)
----- Native stack trace -----

 1: 0x100c0b70c node::AsyncHooks::FailWithCorruptedAsyncStack(double) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 2: 0x100c0b6cc node::AsyncHooks::FailWithCorruptedAsyncStack(double) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 3: 0x100bda210 node::AsyncWrap::PopAsyncContext(v8::FunctionCallbackInfo<v8::Value> const&) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 4: 0x100eda884 v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, unsigned long*, int) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 5: 0x100eda030 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 6: 0x101834b24 Builtins_CEntry_Return1_ArgvOnStack_BuiltinExit [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 7: 0x1017ac3e4 Builtins_InterpreterEntryTrampoline [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 8: 0x1017ac3e4 Builtins_InterpreterEntryTrampoline [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
 9: 0x1017ac3e4 Builtins_InterpreterEntryTrampoline [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
10: 0x1017aa50c Builtins_JSEntryTrampoline [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
11: 0x1017aa1f4 Builtins_JSEntry [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
12: 0x100fe2830 v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
13: 0x100fe2088 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
14: 0x100e7e8dc v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
15: 0x100bcd08c node::InternalCallbackScope::Close() [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
16: 0x100bcca68 node::InternalCallbackScope::~InternalCallbackScope() [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
17: 0x100c69594 node::StartExecution(node::Environment*, std::__1::function<v8::MaybeLocal<v8::Value> (node::StartExecutionCallbackInfo const&)>) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
18: 0x100bd243c node::LoadEnvironment(node::Environment*, std::__1::function<v8::MaybeLocal<v8::Value> (node::StartExecutionCallbackInfo const&)>, std::__1::function<void (node::Environment*, v8::Local<v8::Value>, v8::Local<v8::Value>)>) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
19: 0x100cf6464 node::NodeMainInstance::Run(node::ExitCode*, node::Environment*) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
20: 0x100cf613c node::NodeMainInstance::Run() [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
21: 0x100c6ce94 node::Start(int, char**) [/nix/store/xr2x034ilq5g69n06hp7g54g0hawyl3n-nodejs-slim-20.15.1/bin/node]
22: 0x1849ae0e0 start [/usr/lib/dyld]

----- JavaScript stack trace -----

1: popAsyncContext (node:internal/async_hooks:559:12)
2: emitAfterScript (node:internal/async_hooks:521:3)
3: processTicksAndRejections (node:internal/process/task_queues:93:7)

```","aduh95",14309773,"2024-08-22 07:42:51","fix following error async hook stack become corrupt javascript stack trace processtickand rejections
"
517,126,"Maybe it's worth it to do a better error here for `async_hooks`? I don't think this can be completely prevented since userland can always pollute prototype.","jazelly",28685065,"2024-08-23 11:10:13","worth better error async_hooks think prevent userland pollute prototype
"
518,126,"The reason why only `Array.prototype[1]` fails is because [here](https://github.com/nodejs/node/blob/main/lib/internal/fixed_queue.js#L85), the first item (0 index) in the queue is a tick object which contains `async hook info`, so if you pollute the 0 index it will be overwritten, if you pollute index 2, because index 1 is `undefined` therefore it will just `return`, so the polluted item at index 2  never got retrieved.

Back to why this fails, because the polluted item does not have a async id, so it will crash when `undefined` is sent to binding layer through `popAsyncContext` function.","jakecastelli",38635403,"2024-08-23 12:31:10","reason fail item queue tick object contain async hook info pollute index overwrite pollute index undefined return pollute item retrieve

fail pollute item async id crash undefined send binding layer popAsyncContext function
"
519,126,"My thought for fix this inline with @jazelly - IMO if async id is not a number (`NaN`) we should throw an error instead.","jakecastelli",38635403,"2024-08-23 12:42:51","thought fix inline imo async id number error
"
520,126,"Like any other (expected?) behavior caused by prototype pollution, essentially as long as there is some JS code expecting ""querying a non-existent property leads to undefined"", it can always be affected. Guarding higher level code isn't enough, it's mostly about guarding any non-existent/out-of-bound access (expect on user-provided objects).

Also IMO this isn't a bug most of the time, it's just an UX issue. At least it is better to keep `console.log()` working in the prototype polluted with accessors/traps, as it's possible for people to try to use it to debug unexpected accesses. In that case it's the implementation of `console.log()` that should be hardened. But it's not really worth it/possible to make all the other APIs work with prototype pollution, unless we try to move everything to C++ whereever possible.","joyeecheung",4299420,"2024-08-23 13:01:07","behavior causa prototype pollution js code esperar consultar propriedade inexistente indefinido sempre afetado guardar código nível alto suficiente guardar acesso inexistente limite esperar objeto usuário imo bug tempo problema ux melhor manter console log funcionar prototype poluir acessors traps possível pessoa tentar usar depurar acesso inesperado caso implementação console log endurecer realmente valer possível fazer api funcionar prototype pollution menos tentar mover tudo c++ possível
"
521,126,"In the particular case of `FixedCircularBuffer`, it should just probably be guarded with a `this.bottom < this.list.length` bound check to avoid out-of-bound access.

https://github.com/nodejs/node/blob/d5dc540f10b597a3dfb23aa1e5391b6964aa2ed6/lib/internal/fixed_queue.js#L81-L83","joyeecheung",4299420,"2024-08-23 13:04:09","case particular fixedcircularbuffer should probably guard bound check avoid out bound access
"
522,126,"Just thought asking about the ""out of bound access issue here"" - the `this.list` will be `kSize` [here](https://github.com/nodejs/node/blob/d5dc540f10b597a3dfb23aa1e5391b6964aa2ed6/lib/internal/fixed_queue.js#L8) which is `2048` when [initialised](https://github.com/nodejs/node/blob/d5dc540f10b597a3dfb23aa1e5391b6964aa2ed6/lib/internal/fixed_queue.js#L63). And this line [here](https://github.com/nodejs/node/blob/d5dc540f10b597a3dfb23aa1e5391b6964aa2ed6/lib/internal/fixed_queue.js#L85) with bit mask should prevent the out of bound access issue.","jakecastelli",38635403,"2024-08-23 13:37:23","bound access issue list ksize line bit mask prevent bound access issue
"
523,126,"We totally should fix the one Antoine pointed out (where node core dumps). Even if we don't do primordials everywhere for readability/performance we totally still should in error paths so users can tell why their code failed.","benjamingr",1315533,"2024-08-23 16:08:38","fix antoine point node core dump  primordial readability performance error path user tell code fail
"
524,126,"`new Array()` doesn't actually initialize it, it'll need to be filled or otherwise it's still an out-of-bound access that leads to prototype lookup. ","joyeecheung",4299420,"2024-08-23 16:25:33","array initialize fill out bound access lead prototype lookup
"
525,126,"Actually, this rings a bell - we should probably just forbid `new Array` with the linter. I made a similar argument against holey arrays in https://github.com/nodejs/node/pull/52058#discussion_r1576280300 (it can also lead to worse performance in array accesses).","joyeecheung",4299420,"2024-08-23 16:32:08","ring bell probably forbid array similar argument holey array lead worse performance array access
"
526,126,"
> we should probably just forbid `new Array` with the linter.

I agree. https://github.com/nodejs/node/pull/54281 fixed a similar issue.
","targos",2352663,"2024-08-24 10:06:09","forbid array linter agree fix similar issue
"
527,126,"> it's still an out-of-bound access that leads to prototype lookup.

Much appreciated! Now I understood 🙏 ","jakecastelli",38635403,"2024-08-24 10:29:42","access lead prototype lookup
"
1419,248,"Will it be available in 18LTS **and** in 16LTS?","mudlee",1439334,"2023-01-12 14:17:37","available lts lts
"
529,127,"I've already done so. It's 30 lines with no external dependencies. The issue is specifically about class hierarchies, inherited methods, and subclassing so it's not like it can get any smaller. Maybe I could remove `enumerable: true, configurable: true` to save two lines if that'd help you out. Or rename the variables from descriptive names like `Window` and `EventTarget` into generic ones like `Subclass` and `Superclass`.","domenic",617481,"2024-08-19 01:58:47","issue class hierarchy inherit method subclass small remove line variable descriptive name generic name
"
530,127,"> I've already done so. It's 30 lines with no external dependencies. The issue is specifically about class hierarchies, inherited methods, and subclassing so it's not like it can get any smaller. Maybe I could remove `enumerable: true, configurable: true` to save two lines if that'd help you out. Or rename the variables from descriptive names like `Window` and `EventTarget` into generic ones like `Subclass` and `Superclass`.

You are correct, I was trying to oversimplify the code, but that's not needed. Sorry for the mistake. When I get a chance I'll check this for `repro-exists`.","avivkeller",38299977,"2024-08-19 02:01:18","já feito linha dependência externa problema hierarquia classe método herdado subclasse pequeno remover enumerable configurable linha ajudar renomear variável nome descritivo janela eventtarget genérico subclasse superclasse desculpa erro chance verificar repro exists
"
531,127,"FWIW the only vm subsystem PR for that version is https://github.com/nodejs/node/pull/53517","avivkeller",38299977,"2024-08-19 02:08:31","vm subsystem pr version
"
532,127,"Maybe https://github.com/nodejs/node/commit/c0962dc3bfd94409162fcb77a9da20bce98848c7 @legendecas ?","marco-ippolito",36735501,"2024-08-19 07:57:10","maybe legendecas
"
533,127,"I can confirm the issue. Will prepare a fix soon.","legendecas",8500303,"2024-08-19 09:19:43","confirm issue prepare fix
"
534,127,"I think the best course of this issue would be setting the prototype of the inner `globalThis` in the vm context. The issue is caused by the class hierarchy with the `globalThis`:

```
Outer Context    |    Vm Context
Object           |    Object
  ^              |      ^
  | prototype    |      | prototype
EventTarget      |    Global
  ^              |      ^
  | prototype    |      | prototype
Window           |      |
  ^              |      |
  | prototype    |      |
window (sandbox) <--- globalThis
		intercepts property access
```

If I understand correctly, the expected class hierarchy should be:

```
Outer Context    |    Vm Context
Object           |    Object
  ^              |      ^
  | prototype    |      | prototype
EventTarget      |    EventTarget
  ^              |      ^
  | prototype    |      | prototype
Window           |    Window
  ^              |      ^
  | prototype    |      | prototype
window (sandbox) <--- globalThis
		intercepts property access
```

With the fix in https://github.com/nodejs/node/pull/53517, the inner `globalThis` correctly queries the own properties of the sandbox object with `Object.hasOwn`, however, it can not distinguish `in` operator with `Object.hasOwn` with current V8 APIs.

To fix the issue and preserving the correct `Object.hasOwn` behavior, we have two solutions:
1. Delegate `prototype` lookup to the sandbox object, so that `in` operator will lookup the property on the outer prototype instead. However, this may unconditionally leaks vm outside `Object.prototype` properties to the inner vm context. I believe this may already be the case for `jsdom` since API objects like `EventTarget` are inherited from the outside `Object`.
2. Manually setting the inner `globalThis` prototype to be the `Window.prototype` in userland before (1) gets implemented. This works in Node.js versions before and after `v22.5.0`. Moreover, in `v22.5.0` and later, `Object.hasOwn` will return correct value.

Since `Object.hasOwn` behavior is not fixable in user land, I am wondering if it would make sense to you to set the inner global prototype like the following snippet:

```js
""use strict"";

const vm = require(""vm"");

class EventTarget {
  addEventListener() {}
}

const windowConstructor = function () {};
Object.setPrototypeOf(windowConstructor, EventTarget);
const windowPrototype = Object.create(EventTarget.prototype);

function Window() {
  vm.createContext(this);
  this._globalProxy = vm.runInContext(""this"", this);

  // Set up the inner global prototype
  Object.setPrototypeOf(this._globalProxy, windowPrototype);

  const window = this;
  Object.defineProperty(this, ""window"", {
    get() {
      return window._globalProxy;
    },
    enumerable: true,
    configurable: true
  });
}

const window = new Window();

console.log(vm.runInContext(`""addEventListener"" in window`, window));
```

In this way, the following snippet will output the expected results:

```js
const jsdom = require('jsdom');
const vm = require('vm');
const { JSDOM } = jsdom;
const dom = new JSDOM(``, {
  runScripts: 'outside-only',
});

const vmContext = dom.getInternalVMContext();
// Uncomment the following line to see the difference.
// vm.runInContext(`Object.setPrototypeOf(window, Window.prototype)`, vmContext); 
console.log(vm.runInContext(`window instanceof Object`, vmContext)); // => always `false` because the window was created outside the context
console.log(vm.runInContext(`window instanceof EventTarget`, vmContext));
console.log(vm.runInContext(`'addEventListener' in window`, vmContext));
console.log(vm.runInContext(`Object.hasOwn(window, 'addEventListener')`, vmContext));
console.log(vm.runInContext(`Object.getOwnPropertyDescriptor(window, 'addEventListener')`, vmContext));
```

The output should be in Node.js `v22.5.0`:
```
false
true
true
false
undefined
```
","legendecas",8500303,"2024-08-19 13:08:13","think best course issue set prototype inner globalThis vm context issue cause class hierarchy globalThis fix inner globalThis correctly query own property sandbox object object.hasOwn however distinguish operator object.hasOwn current v8 api fix issue preserve correct object.hasOwn behavior two solution delegate prototype lookup sandbox object operator lookup property outer prototype however may unconditionally leak vm outside object.prototype property inner vm context believe may already case jsdom api object eventtarget inherit outside object manually set inner globalThis prototype window.prototype userland get implement work node.js version v22.5.0 moreover v22.5.0 later object.hasOwn return correct value object.hasOwn behavior fixable user land wonder make sense set inner global prototype following snippet way following snippet output expected result output node.js v22.5.0 false true true false undefined
"
535,127,"I can try such things, but from past experience anything other than our current (admittedly convoluted) setup has caused lots of tests to break. I would expect that anything that causes a regression like this to be reverted...","domenic",617481,"2024-08-20 00:29:45","try thing past experience current setup cause lot test break expect regression revert
"
536,127,"Given how many other things this appears to fix, I'm happy to close this. In fact, I would wonder if it's possible to back-port https://github.com/nodejs/node/commit/c0962dc3bfd94409162fcb77a9da20bce98848c7 to v20, so that I could land https://github.com/jsdom/jsdom/pull/3765 without having to wait for v22 to become the earliest LTS...","domenic",617481,"2024-08-25 07:30:36","happy close wonder possible back port v20 land v22 earliest lts
"
537,127,"I removed https://github.com/nodejs/node/labels/dont-land-on-v20.x on the original PR and it can be backported in the next release.","legendecas",8500303,"2024-08-27 09:25:33","remove label original pr backport next release
"
538,128,"Thanks for the report! Seeing as you seem to know the cause, if you'd like, you can submit a patch PR.","avivkeller",38299977,"2024-08-09 14:37:31","report know cause submit patch pr
"
539,128,"I've opened a PR patching this in #54288. Thanks again :-)","avivkeller",38299977,"2024-08-09 20:28:38","open pr patch thank
"
540,128,"present in node v22.7.0

`PS C:\temp\drtest> node run.js
node:internal/fs/cp/cp-sync:56
  fsBinding.cpSyncCheckPaths(src, dest, opts.dereference, opts.recursive);
            ^

Error: Cannot copy \\?\C:\temp\drtest\foo to a subdirectory of self \\?\C:\temp\drtest\foobar
    at cpSyncFn (node:internal/fs/cp/cp-sync:56:13)
    at Object.cpSync (node:fs:3046:3)
    at Object.<anonymous> (C:\temp\drtest\run.js:2:4)
    at Module._compile (node:internal/modules/cjs/loader:1546:14)
    at Module._extensions..js (node:internal/modules/cjs/loader:1691:10)
    at Module.load (node:internal/modules/cjs/loader:1317:32)
    at Module._load (node:internal/modules/cjs/loader:1127:12)
    at TracingChannel.traceSync (node:diagnostics_channel:315:14)
    at wrapModuleLoad (node:internal/modules/cjs/loader:217:24)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:166:5) {
  code: 'ERR_FS_CP_EINVAL'
}

Node.js v22.7.0
PS C:\temp\drtest>
`


[drtest.zip](https://github.com/user-attachments/files/16812721/drtest.zip)
","blackram",374148,"2024-08-30 06:34:35","erro copiar subdiretorio node versão
"
541,129,"@nodejs/typescript ","targos",2352663,"2024-08-09 07:27:44","nodejs typescript
"
542,129,"This looks like a swc issue","himself65",14026360,"2024-08-09 07:39:08","look swc issue
"
543,129,"https://play.swc.rs/?version=1.7.6&code=H4sIAAAAAAAAA22MQQrDMAwE74H8YY%2F2JT%2FoqR%2FoF4wQxWDsIinJIfTvVSpKL1n2tDsMtaKKh9StGN9HV5OVbAiOeYLnFQ%2Fof6WM4x2vWrFKIGFnzj3mM8K2Skfn%2FcKecoCu8c7T147aFbcLevn5AxyNlzaeyfH8AbQti82%2FAAAA&config=H4sIAAAAAAAAA1VPOw7DIAzdOQXy3KFi6NA79BCIOhERAYQdqSjK3QsJpM1mv4%2Ff8yqkhIkMPOVaxrJEnQjTuReEsmf9KQhwjkgm2chw6yxTpQbtCHdoOxhgnUbk6kJSd6WaA1wIhN3RsNl6O%2BT%2FTBPmmJDoKqxS7UeH10TRUmEO72Un2y%2B179HgAT9RDzsPg6VXd3JaUGxfBMLf3xcBAAA%3D&strip-types=","himself65",14026360,"2024-08-09 07:39:56","Não há texto além de URLs e parâmetros no texto fornecido.  Após a remoção das URLs, não restam palavras para processar. Portanto, o resultado do pré-processamento é:

vazio
"
544,129,"Related PR: https://github.com/swc-project/swc/pull/9399","himself65",14026360,"2024-08-09 07:40:53","PR
"
545,129,"I will handle this issue and open PRs when swc landed their fix","himself65",14026360,"2024-08-09 07:49:55","handle issue open pr fix
"
546,129,"> I will handle this issue and open PRs when swc landed their fix

Great, I'll wait for swc to fix this before I try it again!👍
However, the nodejs changelog doesn't mention this issue, so I think this note should be added","mowtwo",41664636,"2024-08-09 07:56:38","handle issue open pr swc land fix wait swc fix try nodejs changelog mention issue note add
"
547,129,"Uhh the code provided doesn't work in vanilla JavaScript 

edit: I believe `--experimental-strip-types` doesn't cover this yet","alexsch01",5721147,"2024-08-09 10:09:05","code work vanilla javascript believe cover yet
"
548,129,"> Uhh the code provided doesn't work in vanilla JavaScript
> 
> edit: I believe `--experimental-strip-types` doesn't cover this yet

Theoretically, it should, because it doesn't generate external JS nor require transformations. But I this has already been taken care of in SWC","khaosdoctor",3200560,"2024-08-09 13:12:35","code work vanilla javascript believe cover generate external js require transformation take care swc
"
596,138,"Also, for reference, the erroring line is https://github.com/nodejs/node/blob/7b573d12a3a139fe4b076e080a275dadbc81a938/src/node_file.cc#L994","avivkeller",38299977,"2024-07-17 18:33:32","refer error line
"
765,157,"@mertcanaltin thanks for sending a PR I will review it asap ","IlyasShabi",33763729,"2024-03-29 20:22:35","review pr asap
"
1592,275,"Congrats 🎉 ","benjamingr",1315533,"2022-06-29 11:28:31",NULL
549,130,"Reproduction:
```console
$ node
Welcome to Node.js v22.5.1.
Type "".help"" for more information.
> require('url').pathToFileURL('\\\\?\\UNC\\server\\share\\folder\\file.txt', { windows: false }).href;
'file:///<path>/%5C%5C%3F%5CUNC%5Cserver%5Cshare%5Cfolder%5Cfile.txt'
> require('url').pathToFileURL('\\\\?\\UNC\\server\\share\\folder\\file.txt', { windows: true }).href;
'file:///UNC/server/share/folder/file.txt'
```","avivkeller",38299977,"2024-08-08 01:16:16","node informação  pathToFileURL  file  txt  windows  href  file  UNC server share folder file txt
"
550,131,"I saw it's only allowed on Linux, but I was using it on Github CI and it's ubuntu-latest, still error

<img width=""643"" alt=""image"" src=""https://github.com/user-attachments/assets/35bc8298-e15d-4be1-aeff-50c8b827d707"">
","himself65",14026360,"2024-08-07 23:19:58","allow linux use github ci ubuntu latest error
"
551,131,"working on this","juanarbol",17013303,"2024-08-07 23:36:21","work
"
552,131,"> working on this

You are so fast! Thanks a lot!","himself65",14026360,"2024-08-07 23:38:52","work fast thank lot
"
553,131,"I've assigned @juanarbol, as they have opened a PR to resolve this issue. Because this is a simple fix, I don't want newcomers to come accross this issue thinking they can solve it when it's already been solved. Feel free to unassign.","avivkeller",38299977,"2024-08-08 00:05:27","assign juanarbol open pr resolve issue simple fix want newcomer come accross issue think solve solve free unassign
"
554,133,"This seems to be working as intended.

While loops block the main thread, meaning no other execution can occur, hence the hanging.

I've optimisticly marked this as wontfix, but another member of the org can always change that. If members agree, please close the issue as ""Not planned"".","avivkeller",38299977,"2024-08-04 14:50:11","work intend loop block main thread mean execution occur hang optimistically mark wontfix member org always change member agree close issue plan
"
555,133,"I believe the issue is that the repl hangs when you type in `while(true);` **without pressing enter** (meaning the preview evaluation causes the hanging). It doesn't happen when running with TERM=dumb (which disables the preview) and also doesn't seem to happen on node 20. 

The preview evaluation works by sending a `Runtime.evaluate` command to the v8 inspector with a timeout of 333ms, but it looks like the timeout is ignored in this case. ","jfhr",31999724,"2024-08-04 15:27:40","issue repl hang type while press enter preview evaluation cause hang happen run TERM dumb disable preview seem happen node preview evaluation work send Runtime evaluate command v8 inspector timeout 333ms look like timeout ignore case
"
556,133,"Oh okay. I've adjusted the labels, thanks!","avivkeller",38299977,"2024-08-04 15:30:00","adjust label thank
"
557,133,"Yeah, exactly, the issue is with the preview, which simulates code
execution and relies on it completing to show you the preview; if the code
never finishes execution `theoretically` the response keeps waiting
indefinitely and the tty is rendered unresponsive.

On Sun, Aug 4, 2024 at 6:30 PM Aviv Keller ***@***.***> wrote:

> Oh okay. I've adjusted the labels, thanks!
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/nodejs/node/issues/54193#issuecomment-2267581307>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/BJ6CR56VXKRXVU6JYGUQ7HDZPZCI7AVCNFSM6AAAAABL6CU246VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDENRXGU4DCMZQG4>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
","dmand-commits",175909111,"2024-08-05 11:18:16","preview simular codigo execucao depender completar mostrar preview codigo nunca finalizar execucao resposta manter esperar indefinidamente tty tornar responsivo ajustar etiqueta
"
558,133,"The preview should be limited to 333ms. That's the hardcoded limit that is defined in the code. Could someone check if this is an issue with Node.js vs V8?","BridgeAR",8822573,"2024-08-05 11:32:09","preview limit hardcode limit define code check issue node v8
"
559,133,"Looking in to it @BridgeAR ","MrJithil",26359740,"2024-08-09 13:15:49","look
"
560,133,"Its an issue from v8. Reporting to v8 and will analyze there. ","MrJithil",26359740,"2024-08-12 08:57:39","issue report analyze
"
561,133,"Please close the ticket as known deps issue. ","MrJithil",26359740,"2024-08-12 08:58:06","close ticket known dep issue
"
562,133,"@MrJithil could you provide more information about why this is a known issue, what exactly goes wrong on V8?

Thanks!","avivkeller",38299977,"2024-08-12 22:16:31","provide information known issue go wrong v8
"
563,133,"I see. `Runtime.evaluate` is ignoring the timeout.","avivkeller",38299977,"2024-09-14 22:57:49","see runtime evaluate ignore timeout
"
564,133,"@nodejs/v8 the runtime inspector is not respecting the `timeout` parameter","avivkeller",38299977,"2024-09-19 22:47:40","runtime inspector respect timeout parameter
"
565,133,"Yes. This has to be fixed in v8. Thats why it's a known dep issue. ","MrJithil",26359740,"2024-10-06 10:09:57","fix known dep issue
"
566,133,"https://issues.chromium.org/issues/371768644","MrJithil",26359740,"2024-10-06 10:25:49","Não há texto para pré-processar além do URL fornecido.  Após remover o URL, não restará nenhum texto para as etapas de padronização e remoção de stop words.  Portanto, o resultado é:

```
```
"
567,133,"This was introduced in https://github.com/nodejs/node/pull/49639. V8 option `--no-use-osr` can be a workaround to fix the issue.

Running with `--trace-osr`, the log shows that there is an infinite loop around osr compilation:

```
[OSR - compilation started. function: , osr offset: 2, mode: ConcurrencyMode::kConcurrent]
[OSR - unavailable (failed or in progress). function: , osr offset: 2, mode: ConcurrencyMode::kConcurrent]
[OSR - compilation started. function: , osr offset: 2, mode: ConcurrencyMode::kConcurrent]
[OSR - unavailable (failed or in progress). function: , osr offset: 2, mode: ConcurrencyMode::kConcurrent]
[OSR - compilation started. function: , osr offset: 2, mode: ConcurrencyMode::kConcurrent]
```

V8 Issue: https://issues.chromium.org/issues/374013413","legendecas",8500303,"2024-10-17 10:23:36","introduce v8 option workaround fix issue run log show infinit loop osr compilation osr compilation start function osr offset mode concurrencymode concurrent osr unavail fail progress function osr offset mode concurrencymode concurrent osr compilation start function osr offset mode concurrencymode concurrent osr unavail fail progress function osr offset mode concurrencymode concurrent osr compilation start function osr offset mode concurrencymode concurrent v8 issu
"
568,134,"I also tested it on Mac OS, using the same node version, and I got the same FATAL ERROR. 
","vdata1",10380316,"2024-08-03 11:29:15","test mac os node version fatal error
"
569,134,"I'm able to reproduce on latest `main` as well as on 20.14.0.

/cc @nodejs/v8 ","aduh95",14309773,"2024-08-03 12:32:46","reproduce latest main
"
570,134,"Any reason to believe this is a V8 bug?

It looks like `FromJust` is used somewhere in core with an empty `Maybe` (which is the equivalent of ignoring errors and crashes the process).","targos",2352663,"2024-08-03 16:12:35","reason believe v8 bug look fromjust use core empty maybe equivalent ignore error crash process
"
597,138,"Similar issue showing up in Yarn (https://github.com/yarnpkg/berry/issues/6398), it either hangs or if run with `CI=true` then `node` stops mid execution without an error code.
Bisects to https://github.com/nodejs/node/pull/53627.","merceyz",3842800,"2024-07-17 18:42:50","issue yarn hang run ci true node stop mid execution error code bisect
"
571,134,"This is due to node creating holey arrays in some places. Then the setter is called when the first element is set.

In this case, it happens here:
https://github.com/nodejs/node/blob/67f713731ca8c978b873161513e0a72bb59053b1/lib/tty.js#L114-L115

That's easy to fix with an initialization like `const winSize = [0, 0];`, but then it crashes at another place, for the same reason:

https://github.com/nodejs/node/blob/67f713731ca8c978b873161513e0a72bb59053b1/src/node_http_parser.cc#L1306-L1325","targos",2352663,"2024-08-04 17:40:50","node create holey array setter call first element set case happen fix initialization winSize crash place reason
"
572,134,"I think using `CreateDataProperty` instead of `Set` would avoid the issue but there are countless places where we can do it, as it's not specific to array indices:

```js
Object.defineProperty(Object.prototype, 'methods', {   
  set() {
    throw new Error('boom')    
  }
});

const http = require('http');
```","targos",2352663,"2024-08-04 17:57:56","think use createdataproperty avoid issue countless place specific array indice
"
573,134,"We could use the alternative Array::New and Object::New variants that take arrays of keys and/or values and copies them directly to avoid it, but then this looks like another case of invalid modifications to prototypes that we don't explicitly support","joyeecheung",4299420,"2024-08-04 18:13:25","use alternative array new object new variant take array key value copy directly avoid look case invalid modification prototype explicitly support
"
574,134,"We don't support them, but we usually try to avoid hard crashes in these cases.","targos",2352663,"2024-08-05 05:52:36","support usually try avoid hard crash case
"
575,134,"I have a PR to get rid of the crashes https://github.com/nodejs/node/pull/54276 but I am hesitant to write a regression tests for these, because monkey patching prototypes are generally considered unsupported, there are also many other bindings where we don't care about this...well, it's worth the code cleanup anyway.","joyeecheung",4299420,"2024-08-08 22:23:38","PR rid crash code cleanup worth
"
576,134,"I don't think we should add tests.","targos",2352663,"2024-08-09 06:09:53","think add test
"
577,134,"This no longer crashes since awhile ago (22.9.0/20.18.0 I think?), closing.","joyeecheung",4299420,"2024-11-05 01:09:50","crash ago close
"
578,135,"So the problem happens only when pass the flag `--experimental-permission`? In previous versions is this happens normally? ","kevinuehara",20498649,"2024-07-29 13:56:44","problem happen flag experimental permission previous version happen normally
"
579,135,"Yes, only with `--experimental-permission`; that triggers the code path that checks the reference value.  I haven't tested older versions, but to be honest the code is pretty clear that it mandates a string argument, I guess it just wasn't tested with callers that provide the path as a Buffer.","alistairjevans",19165743,"2024-07-29 14:05:32","trigger code path check reference value test older version honest code clear mandate string argument guess test caller provide path buffer
"
580,135,"So a think this is an improvement... I can test and see if this error occurred in older versions. But anyway I will validate and see if I can improve and resolve with PR.","kevinuehara",20498649,"2024-07-29 14:23:41","think improvement test error occur older version validate improve resolve pr
"
581,135,"Ah, sorry, I wasn't trying to state that this is a regression, I think this is just a part of the still-in-development experimental permissions work, thought I'd flag it.","alistairjevans",19165743,"2024-07-29 14:30:01","sorry try state regression part still development experimental permission work flag
"
582,135,"Aah ok! But thank you to sinalize! Someone can answer this question and if it is already under development, otherwise I can help with the contribution ❤️ ","kevinuehara",20498649,"2024-07-29 14:48:54","ok thank sinalize someone answer question development help contribution
"
583,135,"I think @RafaelGSS is the man to talk to, based on the commit history.","alistairjevans",19165743,"2024-07-29 14:50:54","think rafaelgss man talk base commit history
"
584,135,"Apparently, this is caused by https://github.com/nodejs/node/pull/52135. I will work on that. ","RafaelGSS",26234614,"2024-07-29 17:45:41","cause work
"
585,136,"Introduced in `v22.3.0`. Points to this commit f88386561c72eb4d855822bf7c102114e23cf6a8 cc @H4ad 👀 ","jakecastelli",38635403,"2024-07-26 13:47:27","introduce point commit
"
586,136,"Thanks for the report, I will open a PR soon.","H4ad",12551007,"2024-07-26 14:26:12","report open pr
"
587,136,"thank you for the fix @H4ad !","jfhr",31999724,"2024-07-30 09:37:09","fix
"
588,137,"Reproducible:
```mjs
import fs from 'node:fs';

// await fs.writeFile('file.txt', '123456789')

const blob = await fs.openAsBlob('file.txt');
console.log(await blob.text());

console.log(await blob.slice(3).text());

console.log(await blob.slice(3).slice().text());
```
```
└─$ node index.mjs
123456789
456789
456
```
","avivkeller",38299977,"2024-07-17 20:36:36","reproducible código javascript ler arquivo texto trecho arquivo


"
589,137,"It however does not occur with non-fs blobs:
```mjs
import { Blob } from 'node:buffer';

const blob = new Blob(['123456789']);

console.log(await blob.text());
console.log(await blob.slice(3).text());
console.log(await blob.slice(3).slice().text());
```
```
└─$ node index.mjs
123456789
456789
456789
```","avivkeller",38299977,"2024-07-17 20:39:25","occur non fs blob


**Explicação das etapas:**

1. **Remoção de ruídos:**  Foram removidos o código `mjs`, os códigos HTML (que não existiam explicitamente mas a estrutura poderia sugerir isso),  o código javascript, a saída do terminal e o caractere `:`

2. **Padronização de palavras:**  A palavra ""blobs"" foi reduzida para ""blob"" (plural para singular).  A palavra ""does not"" foi implicitamente tratada ao se considerar apenas o contexto relevante.  A precisão desta etapa depende do lematizador ou stemmer usado.  Sem uma ferramenta específica, a padronização foi limitada ao caso mais óbvio.

3. **Remoção de stop words:** As palavras ""it"", ""however"", ""with"" foram removidas como stop words comuns.  Considerando um contexto de classificação de issue, estas palavras pouco contribuem para a classificação.


Observe que sem usar uma biblioteca de processamento de linguagem natural (NLP) com um lematizador e um dicionário de stop words bem definido, este pré-processamento é aproximado.  Para um resultado mais preciso, ferramentas como NLTK ou spaCy em Python seriam recomendadas.
"
590,137,"Hey @RedYetiDev, could you assign me this issue? I'd like to work on it, if that's alright.","HardikGoyal2003",135348086,"2024-07-17 22:30:23","assign issue work alright
"
591,137,"Feel free to work on it, but issues aren't typically assigned (except when they are self assigned).

If you have an improvement, feel free to submit a PR.","avivkeller",38299977,"2024-07-17 22:31:37","work issue typically assign except self assign improvement submit pr
"
592,137,"https://github.com/nodejs/node/blob/cf8e5356d9fbbdca40d9b9fe062b3c292b7e91e3/src/dataqueue/queue.cc#L854
Should be:
```c
 new_end = std::min(end.value() + start_, end_); 
```","jleedev",23022,"2024-07-20 06:20:35","new end std min end value start end
"
593,137,"Feel free to submit a PR with suggestions to the Conway.","avivkeller",38299977,"2024-07-20 07:58:56","submit pr suggestion conway
"
594,138,"Given the stack trace you've produced, I've optimistically applied the `fs` and `v8 engine` labels, but those can always be changed.","avivkeller",38299977,"2024-07-17 18:29:53","stack trace apply label change
"
599,138,"@joyeecheung Any idea how is this possible?

> v8::Object::GetCreationContextChecked No creation context available","anonrig",1935246,"2024-07-17 19:32:24","joyeecheung idea possible v8 object get creation context creation context available
"
600,138,"This needs a better repro than the following command which runs 10+ subprocesses.

> npm run r (that's cleaning + installing dependencies + npm test) just hangs on.
","anonrig",1935246,"2024-07-17 19:48:10","need better repro command run subprocess hang
"
601,138,"https://github.com/latin-1/berry-node-22.5.0-broken/ is slightly better, but not perfect.
```
STREAM 55954: do read
STREAM 55954: push null
STREAM 55954: onEofChunk
STREAM 55954: emitReadable_
STREAM 55954: flow
STREAM 55954: read undefined
STREAM 55954: endReadable
STREAM 55954: endReadableNT
Usage Error: Couldn't find the node_modules state file - running an install might help (findPackageLocation)
```","avivkeller",38299977,"2024-07-17 19:49:28","do read push null eofchunk emitreadable flow read undefined endreadable endreadablent usage error find node_modules state file run install might help findpackagelocation
"
602,138,"I can not test it locally, but technically this should fix the bug: https://github.com/nodejs/node/pull/53910","anonrig",1935246,"2024-07-17 20:01:19","test locally technically fix bug
"
603,138,"I think we should hold on landing future fast API pull requests until we have a way to guarantee that the added code paths are tested.","targos",2352663,"2024-07-17 20:01:23","think hold land future fast api pull request way guarantee added code path test
"
604,138,"OK I found a reproduction, and the fix I proposed works.

Here's the repro:

```
const fs = require('fs')

let failed;
for (let i = 0; i < 1_000_000; i++) {
  failed = fs.readFile('./configure.py', (err, done) => {
    // do nothing
    console.log(err, done)
  })
}
console.log(failed)
```

> I think we should hold on landing future fast API pull requests until we have a way to guarantee that the added code paths are tested.

Agreed.

","anonrig",1935246,"2024-07-17 20:09:58","reproduction fix propose work repro think hold land future fast api pull request way guarantee add code path test agree
"
605,138,"> https://github.com/latin-1/berry-node-22.5.0-broken/ is slightly better, but not perfect.

@RedYetiDev Note that the issue happens in the `yarn` step where the process exits early without an error, `yarn build` fails because `yarn` failed.","merceyz",3842800,"2024-07-17 20:21:18","issue happen yarn step process exit early error yarn build fail yarn fail
"
606,138,"> I can not test it locally, but technically this should fix the bug: https://github.com/nodejs/node/pull/53910

https://github.com/nodejs/node/pull/53910 doesn't fix https://github.com/nodejs/node/issues/53902#issuecomment-2234007874 but reverting https://github.com/nodejs/node/pull/53627 does.","merceyz",3842800,"2024-07-17 20:44:08","test locally technically fix bug revert
"
607,138,"we are seeing this in bunch of builds  in this build yarn cannot find the prettier this worked the nodejs version 22.4.1 

```
 time=2024-07-17T20:45:51.408Z level=INFO msg=""[git checkout] repo='https://github.com/replicatedhq/kots' dest='.' depth='1' branch='' tag='v1.112.1' expcommit='07dc36e669e3c33f6a70cb8d1efd1539a0b6a386' recurse='false'"" pkg=kots
  time=2024-07-17T20:45:51.414Z level=INFO msg=""[git checkout] execute: git config --global --add safe.directory /tmp/tmp.m9Ey9U"" pkg=kots
  time=2024-07-17T20:45:51.416Z level=INFO msg=""[git checkout] execute: git config --global --add safe.directory /home/build"" pkg=kots
  time=2024-07-17T20:45:51.418Z level=INFO msg=""[git checkout] execute: git clone --quiet --origin=origin --config=user.name=Melange Build --config=user.email=melange-build@cgr.dev --config=advice.detachedHead=false --branch=v1.112.1 --depth=1 https://github.com/replicatedhq/kots /tmp/tmp.m9Ey9U"" pkg=kots
  time=2024-07-17T20:45:52.837Z level=INFO msg=""[git checkout] execute: cd /tmp/tmp.m9Ey9U"" pkg=kots
  time=2024-07-17T20:45:52.837Z level=INFO msg=""[git checkout] tar -c . | tar -C \""/home/build\"" -x"" pkg=kots
  time=2024-07-17T20:45:53.542Z level=INFO msg=""[git checkout] execute: cd /home/build"" pkg=kots
  time=2024-07-17T20:45:53.542Z level=INFO msg=""[git checkout] execute: git config --global --add safe.directory /home/build"" pkg=kots
  time=2024-07-17T20:45:53.545Z level=INFO msg=""[git checkout] execute: git fetch --quiet origin --depth=1 --no-tags +refs/tags/v1.112.1:refs/origin/tags/v1.112.1"" pkg=kots
  time=2024-07-17T20:45:53.788Z level=INFO msg=""[git checkout] execute: git checkout --quiet origin/tags/v1.112.1"" pkg=kots
  time=2024-07-17T20:45:53.928Z level=INFO msg=""[git checkout] tag v1.112.1 is 07dc36e669e3c33f6a70cb8d1efd1539a0b6a386"" pkg=kots
  time=2024-07-17T20:45:53.938Z level=WARN msg=""+ mkdir -p /home/build/melange-out/kots/etc"" pkg=kots
  time=2024-07-17T20:45:53.939Z level=WARN msg=""+ mkdir -p /home/build/melange-out/kots/usr/bin"" pkg=kots
  time=2024-07-17T20:45:53.941Z level=WARN msg=""+ mv deploy/assets/backup.sh deploy/assets/fs-minio-check.sh deploy/assets/fs-minio-keys-sha.sh deploy/assets/fs-minio-reset.sh deploy/assets/kots-upgrade.sh deploy/assets/migrate-s3.sh deploy/assets/postgres deploy/assets/restore-db.sh deploy/assets/restore-s3.sh deploy/assets/restore.sh deploy/assets/s3-bucket-create.sh deploy/assets/s3-bucket-head.sh /home/build/melange-out/kots/etc/"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ export 'VERSION=1.112.1'"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ export 'GIT_TAG=1.112.1'"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ source .image.env"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ MINIO_TAG=0.20240713.014615-r0"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ RQLITE_TAG=8.26.7-r0"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ DEX_TAG=2.40.0-r3"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ SCHEMAHERO_TAG=0.17.9"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ LVP_TAG=v0.6.7"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ KOTS_KUSTOMIZE_BIN_DIR=/usr/bin"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ export 'PACT_SKIP_BINARY_INSTALL=true'"" pkg=kots
  time=2024-07-17T20:45:53.943Z level=WARN msg=""+ yarn install --pure-lockfile --network-concurrency 1"" pkg=kots
  time=2024-07-17T20:45:54.190Z level=INFO msg=""yarn install v1.22.22"" pkg=kots
  time=2024-07-17T20:45:54.203Z level=INFO msg=""info No lockfile found."" pkg=kots
  time=2024-07-17T20:45:54.207Z level=INFO msg=""[1/4] Resolving packages..."" pkg=kots
  time=2024-07-17T20:45:54.207Z level=INFO msg=""[2/4] Fetching packages..."" pkg=kots
  time=2024-07-17T20:45:54.208Z level=INFO msg=""[3/4] Linking dependencies..."" pkg=kots
  time=2024-07-17T20:45:54.212Z level=INFO msg=""[4/4] Building fresh packages..."" pkg=kots
  time=2024-07-17T20:45:54.216Z level=INFO msg=""Done in 0.03s."" pkg=kots
  time=2024-07-17T20:45:54.235Z level=WARN msg=""+ make -C web deps lint build-kotsadm"" pkg=kots
  time=2024-07-17T20:45:54.237Z level=INFO msg=""make: Entering directory '/home/build/web'"" pkg=kots
  time=2024-07-17T20:45:54.244Z level=INFO msg=""yarn --silent --frozen-lockfile"" pkg=kots
  time=2024-07-17T20:45:56.521Z level=INFO msg=""yarn prettier && yarn lint && yarn test:typecheck"" pkg=kots
  time=2024-07-17T20:45:56.723Z level=INFO msg=""yarn run v1.22.22"" pkg=kots
  time=2024-07-17T20:45:56.763Z level=INFO msg=""$ prettier src --check"" pkg=kots
  time=2024-07-17T20:45:56.775Z level=WARN msg=""/bin/sh: prettier: not found"" pkg=kots
  time=2024-07-17T20:45:56.785Z level=WARN msg=""error Command failed with exit code 127."" pkg=kots
  time=2024-07-17T20:45:56.785Z level=INFO msg=""info Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command."" pkg=kots
  time=2024-07-17T20:45:56.810Z level=INFO msg=""make: Leaving directory '/home/build/web'"" pkg=kots
  time=2024-07-17T20:45:56.810Z level=WARN msg=""make: *** [Makefile:55: lint] Error 127"" pkg=kots
  time=2024-07-17T20:45:56.811Z level=ERROR msg=""building package: unable to run package kots pipeline: unable to run pipeline: exit status 2"" pkg=kots
  ```","ajayk",1015125,"2024-07-17 21:17:19","yarn install prettier not found error command fail exit code build package unable run package kots pipeline unable run pipeline exit status make error  kotsadm
"
608,138,"> > I can not test it locally, but technically this should fix the bug: #53910
> 
> #53910 doesn't fix [#53902 (comment)](https://github.com/nodejs/node/issues/53902#issuecomment-2234007874) but reverting #53627 does.

#53904?","avivkeller",38299977,"2024-07-17 22:05:46","test locally technically fix bug revert
"
609,138,"> #53910 doesn't fix [#53902 (comment)](https://github.com/nodejs/node/issues/53902#issuecomment-2234007874) but reverting #53627 does.

https://github.com/nodejs/node/pull/53910 fixes the issue. What makes you think that it doesn't fix the issue?","anonrig",1935246,"2024-07-17 22:21:29","fix revert issue make think fix issue
"
610,138,"@anonrig They might be two different issues with `FastClose`, I guess? The yarn one does not crash; it hangs/exits without leaving any stack traces. ","latin-1",44946699,"2024-07-17 22:51:46","FastClose issue yarn hang exit stack trace
"
611,138,"> @anonrig They might be two different issues with `FastClose`, I guess? The yarn one does not crash; it hangs/exits without leaving any stack traces. 

If that's the issue, can you open a different/new issue with a reproducible test case?","anonrig",1935246,"2024-07-17 23:04:57","issue fastclose yarn hang exit stack trace reproducible test case
"
612,138,"> > #53910 doesn't fix [#53902 (comment)](https://github.com/nodejs/node/issues/53902#issuecomment-2234007874) but reverting #53627 does.
> 
> #53910 fixes the issue. What makes you think that it doesn't fix the issue?

Not the one I linked to in that comment.

> > > I can not test it locally, but technically this should fix the bug: #53910
> > 
> > 
> > #53910 doesn't fix [#53902 (comment)](https://github.com/nodejs/node/issues/53902#issuecomment-2234007874) but reverting #53627 does.
> 
> #53904?

Yeah, with that PR (or when I git revert #53627 on v22.5.0) the `yarn` command completes successfully.","merceyz",3842800,"2024-07-17 23:07:31","fix issue revert bug pr comando completar sucesso
"
613,138,"@zloirock you have a lot of good information about the crashing, do you have any other information about the hanging?","avivkeller",38299977,"2024-07-18 01:10:03","crash hang information
"
614,138,"@RedYetiDev at the moment, nothing fundamentally new / interesting. It's enough to clone `core-js` repo and run `npm install` to reproduce it. Now it’s morning for me, I’ll only be able to dig into this closer to night.","zloirock",2213682,"2024-07-18 01:24:17","moment nothing fundamentally new interesting enough clone core js repo run npm install reproduce morning able dig closer night
"
615,138,"In that case, good morning, and have a nice day :-). Because npm install isn't failing elsewhere (AFAIK) it might be a preinstall script, but I can't back that up so take it with a large grain of salt","avivkeller",38299977,"2024-07-18 01:25:56","case good morning nice day npm install fail preinstall script take large grain salt
"
616,138,"@RedYetiDev it's not related to `core-js` own lifecycle scripts, since even after disabling all of them `npm install` still fails, so maybe it's something from dependencies. Also, one time from some dozens `npm install` was successful -)","zloirock",2213682,"2024-07-18 01:37:30","install fail dependency
"
617,138,"This is all very strange indeed 🤔 ","avivkeller",38299977,"2024-07-18 01:38:58","strange
"
618,138,"> it might be a preinstall script

`--ignore-scripts` or manual disabling all the rest scripts also does not help.","zloirock",2213682,"2024-07-18 03:52:15","preinstall script ignore script manual disable script
"
619,138,"I have same issue with `yarn 1.22.22` in monorepo repository

```
macOS 14.5 (23F79), M1
```

```
$ yarn install
[######--------------------------------------------------------------------] 5806/107123
---> and Node 22.5.0 just stops installing and nothing is installed. Exit code is 0 and it looks like everything has been installed correctly, but it is not
```","ihmpavel",42217494,"2024-07-18 07:03:26","yarn instalacao monorepo node macos
"
620,138,"@ihmpavel Similar problem yesterday with clean node 22.5.0 on windows x64 (7zip download), trying npm install of several packages and it began to move cursor like a rotating clock, but it didn't stop neither print anything else. (I thought it was a npm problem).","nassau-t",56589513,"2024-07-18 09:58:39","problem yesterday clean node windows x64 npm install package move cursor rotate clock stop print npm problem
"
1593,275,"Thank you @benjamingr and thank you all! ","daeyeon",6630703,"2022-06-29 12:05:31",NULL
621,138,"In [HyperFormula ](https://github.com/handsontable/hyperformula)project Node 22.5.0 fails to install dependencies with message:
```
npm error Exit handler never called!
npm error This is an error with npm itself. Please report this error at:
npm error   <https://github.com/npm/cli/issues>
npm error A complete log of this run can be found in: (...)
```

Environment: `ubuntu-latest`
Command: `npm ci`

Version 22.4.1 [worked](https://github.com/handsontable/hyperformula/actions/runs/9975612666/job/27565800165).

GH workflow run: https://github.com/handsontable/hyperformula/actions/runs/9989988926/job/27610940453","sequba",2480086,"2024-07-18 11:14:34","node instal dependencia mensagem npm erro exit handler never call npm erro erro npm report erro npm completo log run encontrar ambiente ubuntu comando npm ci versao work workflow run
"
622,138,"**Hey everyone, I'd like to remind you that the project is aware of this issue, so no need to comment that you are also affected.**

Commenting that you are also affected only adds more noise to the already noisy issue. Instead of commenting, consider :+1:ing a comment that you agree with / affects you.

> ""This issue is highly active. Reconsider commenting unless you have read all the comments and have something to add.""","avivkeller",38299977,"2024-07-18 11:23:27","project aware issue need comment affected add noise noisy issue comment consider agree affect issue highly active reconsider comment read comment add
"
623,138,"> `--ignore-scripts` or manual disabling all the rest scripts also does not help.

I've looked at some npm issues, and something that changed is preventing the exit handler from ever being called, causing the hang. (CC @nodejs/npm)

One step closer to resolving the issue 😀","avivkeller",38299977,"2024-07-18 11:26:07","ignore script manual disable rest script help look npm issue something change prevent exit handler call cause hang step close resolve issue
"
624,139,"cc @MeowShe ","mcollina",52195,"2024-07-16 13:25:11","MeowShe
"
625,139,"> cc @MeowShe 

Maybe you are calling @MoLow ?
(I'm meowshe, he is moshe 😆)","MeowShe",106762153,"2024-07-16 13:29:53","call moshe
"
626,139,"ouch, sorry!","mcollina",52195,"2024-07-16 13:40:17","ouch sorry
"
627,139,"If anyone wants to pick this up, there is already an `exitHandler()` function in `node/lib/internal/test_runner/harness.js` that performs the cleanup. That same function is also exposed throughout the rest of the test runner as `root.harness.teardown()`. We probably just need a call to that somewhere.

Right now, `root.harness.teardown()` only removes the `uncaughtException` and `unhandledRejection` handlers. It should probably clean up the other event handlers as well.","cjihrig",2512748,"2024-07-16 13:55:10","call function cleanup event handler remove
"
628,140,"I'm able to reproduce with the snippet you provided.","avivkeller",38299977,"2024-07-12 13:52:44","able reproduce snippet
"
629,140,"Fixed by #53823","avivkeller",38299977,"2024-07-12 14:02:11","fix
"
630,140,"> Fixed by #53823

Closing, as the PR has landed","avivkeller",38299977,"2024-07-17 13:56:41","fix pr land
"
631,141,"@nodejs/crypto PTAL","avivkeller",38299977,"2024-07-06 12:53:28","nodejs crypto ptal
"
632,142,"\+ `repro-exists`:
```console
└─$ node
Welcome to Node.js v22.3.0.
Type "".help"" for more information.
> util.stripVTControlCharacters('\x1b]8;;http://example.com\x1b\\This is a link\x1b]8;;\x1b\\ hello')
ttp://example.comThis is a link;; hello
````","avivkeller",38299977,"2024-07-02 17:20:48","repro exist node welcome nodejs version type information util stripvtcontrolcharacters link hello
"
633,142,"The current RegEx used is:
```regex
/[\u001B\u009B][[\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\d\/#&.:=?%@~_]+)*|[a-zA-Z\d]+(?:;[-a-zA-Z\d\/#&.:=?%@~_]*)*)?\u0007)|(?:(?:\d{1,4}(?:;\d{0,4})*)?[\dA-PR-TZcf-ntqry=><~]))/g
```","avivkeller",38299977,"2024-07-02 17:22:25","current regex use
"
634,142,"I'm currently building and testing @isaacs suggested regex.","avivkeller",38299977,"2024-07-02 17:35:24","build test suggest regex
"
635,142,"Oh, hey, looks like you _can_ put other parameters between the `;` in OCS 8 codes, so this regexp would probably be a bit more complete:

```
/\u001b\]8;[^;]*?;(.*?)(?:\u001b\\|\u0007)(.*?)\u001b]8;[^;]*?;(?:\u001b\\|\u0007)/g
```

Note the addition of `[^;]*?` between the `;;` chars.

(I don't know of any terminal emulators or programs that _do_ put parameters there, as it's just ""reserved for future use"", but that's what the spec says it can be.)","isaacs",9287,"2024-07-02 17:40:18","hey look parameter code regexp complete  addition char  know terminal emulator program parameter reserve use spec say
"
636,142,"I was wrong, the `id` parameter is used in some cases to control link hover behavior, so yes, would need to strip that.","isaacs",9287,"2024-07-02 17:43:02","wrong parameter use case control link hover behavior need strip
"
637,142,"I'm seeing a number of failures with your RegEx, but I do agree the current one may have a bug. (I would CC a util team but there isn't one :/)","avivkeller",38299977,"2024-07-02 17:47:24","see number failure regex agree current bug
"
638,142,"The regex at https://github.com/chalk/ansi-regex/blob/main/index.js supports links. You could maybe find some inspiration there.","sindresorhus",170270,"2024-07-08 11:56:40","regex support link inspiration
"
639,142,"Hi @sindresorhus,

IIRC, the regex used is from ansi-regex, but an older version. 

Later today, I'll test if a newer version of the regex fixes the issue.","avivkeller",38299977,"2024-07-08 12:16:42","test newer version regex fix issue
"
640,142,"@sindresorhus 
```js
// From https://github.com/chalk/strip-ansi/blob/main/index.js
function ansiRegex({onlyFirst = false} = {}) {
	const pattern = [
		'[\\u001B\\u009B][[\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\d\\/#&.:=?%@~_]+)*|[a-zA-Z\\d]+(?:;[-a-zA-Z\\d\\/#&.:=?%@~_]*)*)?\\u0007)',
		'(?:(?:\\d{1,4}(?:;\\d{0,4})*)?[\\dA-PR-TZcf-nq-uy=><~]))'
	].join('|');

	return new RegExp(pattern, onlyFirst ? undefined : 'g');
}

console.log('\x1b]8;;http://example.com\x1b\\This is a link\x1b]8;;\x1b\\ hello'.replace(ansiRegex(), ''));
```

Outputs:
```
""ttp://example.com\u001b\\This is a link;;\u001b\\ hello""
```

https://runkit.com/6689b91eebd0a700080cd8b3/668c3336e85de300088f3f39","avivkeller",38299977,"2024-07-08 18:45:41","Para realizar o pré-processamento, precisaremos de bibliotecas de processamento de linguagem natural.  Usarei Python com as bibliotecas `re` (para expressões regulares), `nltk` (para stemming e remoção de stop words) e `unicodedata` (para normalizar caracteres).

Primeiro, instale as bibliotecas necessárias: `pip install nltk`

Depois, execute o código abaixo:

```python
import re
import nltk
import unicodedata
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

nltk.download('punkt')
nltk.download('stopwords')

text = """"""@sindresorhus 
```js
// From https://github.com/chalk/strip-ansi/blob/main/index.js
function ansiRegex({onlyFirst = false} = {}) {
	const pattern = [
		'[\\u001B\\u009B][[\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\d\\/#&.:=?%@~_]+)*|[a-zA-Z\\d]+(?:;[-a-zA-Z\\d\\/#&.:=?%@~_]*)*)?\\u0007)',
		'(?:(?:\\d{1,4}(?:;\\d{0,4})*)?[\\dA-PR-TZcf-nq-uy=><~]))'
	].join('|');

	return new RegExp(pattern, onlyFirst ? undefined : 'g');
}

console.log('\x1b]8;;http://example.com\x1b\\This is a link\x1b]8;;\x1b\\ hello'.replace(ansiRegex(), ''));
```

Outputs:
```
""ttp://example.com\u001b\\This is a link;;\u001b\\ hello""
```

https://runkit.com/6689b91eebd0a700080cd8b3/668c3336e85de300088f3f39""""""

# 1. Remover ruídos (URLs, tags HTML e caracteres especiais)
text = re.sub(r'http\S+', '', text) # Remove URLs
text = re.sub(r'<.*?>', '', text) # Remove tags HTML (se houver)
text = re.sub(r'[^a-zA-Z0-9\s]', '', text) # Remove caracteres especiais
text = unicodedata.normalize(""NFKD"", text).encode(""ascii"", ""ignore"").decode(""ascii"") # Normaliza caracteres

# 2. Tokenização
tokens = nltk.word_tokenize(text.lower())

# 3. Stemming (padronização de palavras)
stemmer = PorterStemmer()
stemmed_tokens = [stemmer.stem(token) for token in tokens]

# 4. Remoção de Stop Words
stop_words = set(stopwords.words('english'))
filtered_tokens = [token for token in stemmed_tokens if token not in stop_words and len(token) > 1] # remove palavras com apenas 1 caracter


# 5. Juntar os tokens
result = ' '.join(filtered_tokens)
print(result)
```

Este código irá:

1. **Remover ruídos:**  Usando expressões regulares para remover URLs e caracteres especiais.  A normalização remove caracteres acentuados.
2. **Tokenizar:**  Divide o texto em palavras individuais.
3. **Stemming:**  Reduz as palavras a sua forma raiz (ex: ""running"" para ""run"").
4. **Remover Stop Words:** Remove palavras comuns que geralmente não contribuem para a classificação (ex: ""the"", ""a"", ""is""). Remove também tokens com menos de 2 caracteres.
5. **Juntar:** Junta os tokens restantes em uma única string separada por espaços.


O resultado será uma string pré-processada, pronta para ser usada em um classificador de issues.  Lembre-se que a qualidade do pré-processamento pode influenciar significativamente a performance do classificador.  Pode ser necessário ajustar o código, adicionando ou removendo etapas, dependendo das características específicas dos seus dados.
"
641,142,"I've opened an issue in https://github.com/chalk/ansi-regex/issues/56, which is the source for the RegEx used by Node.js. Once resolved, I'll update the RegEx.","avivkeller",38299977,"2024-07-08 19:06:54","open issue source regex use node resolve update regex
"
642,142,"Fixed by https://github.com/nodejs/node/compare/5b3f3c5a3b9dc688c7afcb97b398a5969ae9455c...941635473d107af6848ea0812694680c46c41935","avivkeller",38299977,"2024-10-15 20:07:27","Fixed
"
643,143,"Thanks for the bug report! Feel free to submit a PR with your requested changes, and someone will review it.","avivkeller",38299977,"2024-06-15 01:38:43","bug report submit pr request change someone review
"
653,143,"I found yet another edge case where my (and the NodeJS) implementation behaved differently than the JavaScript implementation and fixed it in my code. Would you like to use that code in NodeJS? I didn't submit it as a pull request because I assume building a huge project like NodeJS might be a hassle and that's just some fun thing I did in my spare time. Maybe I'll do that anyway at some point, but only if there is interest in this.","panzi",134175,"2024-06-26 15:57:49","edge case implementation behave differently javascript implementation fix code use code nodejs submit pull request assume build huge project hassle fun thing spare time point interest
"
644,143,"Sorry, I'm not interested in contributing C++ code to NodeJS at the moment. I just noticed a lot of quirks with... well basically almost all dotenv parsers out there and am currently comparing them for fun. There are many more quirks in NodeJS's dotenv parser, but the others are for a bit more unusual situations. Having a space before the quote isn't that unusual though, I think. The other quirks that I'm just now writing down (copied form that document) are (in case you're interested):

This dialect supports strings quoited in double quotes (`""`), single quotes (`'`)
and back ticks (`` ` ``). These strings can be multi-line, but only in double quoted
strings `\n` will be translated to newlines.

If the second quote is missing only the current line is used as the value for
the variable. Parsing of more variables continues in the next line!

Quotes start with `#`. There doesn't need to be a space before the `#`.

Keys may contain *anything* except spaces (` `), including tabs and newlines.
Meaning this:

```dotenv
FOO#=1
BAR
=2
```

Is equivalent with this JSON:

```JSON
{ ""FOO#"": ""1"", ""BAR\n"": ""2"" }
```

Lines with syntax errors (i.e. no `=`) are silently ignored, but they will trip
up the parser so that the following correct line is also ignored.

Leading `export ` will be ignored. Yes, the `export` needs to be followed by a
space. If its a tab its used as part of the key.","panzi",134175,"2024-06-15 02:00:11","interesse contribuir código c++ nodejs momento notar muitas peculiaridade basicamente quase todo analisador dotenv comparar diversão muitos peculiaridade analisador dotenv nodejs outro situação incomum espaço antes aspas incomum pensar peculiaridade escrever copiar documento caso interesse dialecto suportar corda aspas dupla aspas simples crase corda multi linha somente aspas dupla será traduzir nova linha segunda aspa faltar somente linha atual usar valor variável análise variável continuar próxima linha aspas iniciar precisar espaço chave conter qualquer coisa exceto espaço incluir tabulação nova linha significar equivalente json linha erro sintaxe silenciosamente ignorar tropeçar analisador linha correta também ignorar líder export ignorar export precisar seguir espaço tabulação usar parte chave
"
645,143,"No problem! The parser specification hasn't been done yet, but it's being discussed at https://github.com/nodejs/node/issues/49148.

@IlyasShabi i know you worked on writing a specification, any insight? (Thanks!)","avivkeller",38299977,"2024-06-15 02:24:20","parser specification discuss work write specification insight
"
646,143,"@panzi There is no proper spec for this feature, the only reference is ""whatever [dotenv](https://www.npmjs.com/package/dotenv) does."" Do you happen to know what the expected behavior is, based on that?","tniessen",3109072,"2024-06-15 11:41:17","feature proper spec reference expect behavior
"
647,143,"Dotenv skips the white space

```js
var dotenv = require(""dotenv"")
console.log(dotenv.parse(""a= 'b'""))
// {a: ""b""}
```

For the other case:
```js

var dotenv = require(""dotenv"")
console.log(dotenv.parse(`
FOO#=1
BAR
=2
`))
// {BAR: ""2""}
```","avivkeller",38299977,"2024-06-15 11:45:07","dotenv pular espaço branco caso outro barra espaço foo igual um bar igual dois
"
648,143,"IIUC, this is your list of quirks:

1. This dialect supports strings quoted in double quotes (`""`), single quotes (`'`), and backticks (\`\`). 
   - These strings can be multi-line, but only in double-quoted strings `\n` will be translated to newlines.
2. If the second quote is missing, only the current line is used as the value for the variable.
   - Parsing of more variables continues in the next line.
3. Quotes start with `#`.
   - There doesn't need to be a space before the `#`.
4. Keys may contain anything except spaces, including tabs and newlines.
5. Lines with syntax errors (e.g., no `=`) are silently ignored.
   - They will cause the parser to ignore the following correct line as well.
6. Leading `export` will be ignored.
   - The `export` needs to be followed by a space. If it is a tab, it is used as part of the key.","avivkeller",38299977,"2024-06-15 11:51:19","dialect support string quote double quote single quote backtick string multi line double quote newline second quote miss current line use value variable parse variable continue line quote start key contain space tab newline line syntax error silently ignore parser ignore follow correct line lead export ignore export need space tab part key
"
649,143,"Nice bug report. I'll fix it. ","anonrig",1935246,"2024-06-15 12:17:44","nice bug report fix
"
650,143,"> @panzi There is no proper spec for this feature, the only reference is ""whatever [dotenv](https://www.npmjs.com/package/dotenv) does."" Do you happen to know what the expected behavior is, based on that?

While this implementation is not behaving quite like the npm dotenv package I'm not sure if emulating that behavior 100% is even a good idea. That package parses this:
```dotenv
FOO
=BAR
```
As:
```JSON
{ ""FOO"": ""BAR"" }
```
Is that a good idea?

Just for fun I'm looking at different dotenv implementations, write down how they work and try to implement a compatible parser in Rust (except for deliberate differences where e.g. I won't import a Unicode database to resolve named Unicode escape sequences (Python dotenv-cli), don't emulate obvious mangled encoding handling (Python dotenv-cli), and don't implement what I consider arbitrary code execution vulnerabilities (Ruby dotenv)). Here is what I have written down so far, in case you are interested in maybe comparing the sections about NodeJS and JavaScript dotenv: <https://github.com/panzi/punktum#nodejs-dialect>
I'm sure I have lots of English spelling mistakes and the document could be structured better. It's not finished in any case.

Looking at all the dotenv implementations I don't know what I'd expect anymore, except that white space around keys and values isn't significant.","panzi",134175,"2024-06-16 01:07:10","proprio spec feature referencia dotenv comportamento esperado comportamento npm dotenv emular ideia pacote analisar foo bar foo bar ideia implementacao dotenv trabalho parser rust diferenca importar banco dados unicode resolver sequencia escape unicode emular tratamento codificacao implementar vulnerabilidade execucao codigo nodejs javascript spelling mistake documento estruturado finished implementacao dotenv esperar espaco branco chave valor significativo
"
651,143,"> While this implementation is not behaving quite like the npm dotenv package I'm not sure if emulating that behavior 100% is even a good idea.

I am not claiming that it's a good idea, but as far as I can tell, it is what's been happening thus far. And deviating from that convention ad-hoc, without a proper specification, IMO doesn't seem like a good idea either.","tniessen",3109072,"2024-06-16 12:16:44","implementation behave npm dotenv package emulate behavior good idea claim good idea far happen deviate convention ad hoc proper specification good idea
"
652,143,"Just for fun I wrote my own implementation of the JavaScript dotenv parser in C++, trying to be 100% compatible. I haven't found an edge case where it produces the any different output to the original. I've licensed it under MIT, if you want you can just copy-paste it into NodeJS. If you prefer any other open source license I can do that, too. See: <https://github.com/panzi/cpp-dotenv>

I'm not a C++ pro, so things might not be 100% ideal. Also I write the environment into an `std::unordered_map<std::string, std::string>` and use some C++20 features (`std::string_view::find_first_not_of()` and `std::string_view::find_last_not_of()`). See also all the comments that say ""SYNTAX ERROR"". While the original just ignores these, and I also ignore them the same way the original does, you might want to log errors there. The original supports `DOTENV_CONFIG_DEBUG=true`, but it only logs things like that it couldn't read the `.env` file, that there where encoding errors (this C++ version ignores encodings, it will work with ASCII, ISO-8859-1, and UTF-8, since it only compares with ASCII characters), or that it did/didn't overwrite an pre-existing environment variable (depending on `DOTENV_CONFIG_OVERRIDE=ture` - yes, override, not overwrite). Instead maybe you could make it so it logs these syntax errors when that environment variable is ste to `true`? In my (also just for fun) Rust implementation I did just that.

DOS line ending support needs testing. And might be possible to somehow implement without always allocating a new string.","panzi",134175,"2024-06-17 01:09:00","fun write implementation javascript dotenv parser c++ try 100 compatible find edge case produce different output original license mit want copy paste nodejs prefer open source license  see comment say syntax error original ignore ignore way original might want log error original support dotenv config debug true log thing couldnt read env file encoding error c++ version ignore encoding work ascii iso utf compare ascii character might make log syntax error environment variable set true also fun rust implementation  dos line ending support need test might possible implement always allocate new string
"
654,143," I would like to work on it if it is still up for grabs","thisalihassan",24819103,"2024-07-07 22:53:39","work like grab
"
655,143,">  I would like to work on it if it is still up for grabs

IIRC @anonrig said he'd work on it, so you'd have to ask him.","avivkeller",38299977,"2024-07-07 23:01:37","work like grab ask
"
680,146,"So, it's specific to x64. I can reproduce with `node-v22.0.0-darwin-x64` on Rosetta.","targos",2352663,"2024-05-02 15:14:20","specific x64 reproduce node darwin x64 rosetta
"
656,143,"If you don't just use my code you can still look at the source comments about correctly emulating the behavior of the regular expression of the original (without using regular expressions in C++).","panzi",134175,"2024-07-07 23:21:52","use code look source comment correctly emulate behavior regular expression original use regular expression c
"
657,143,"Fixed by #53786","avivkeller",38299977,"2024-07-09 16:57:53","fix
"
658,144,"I have verified that the issue does not occur with Node 18 and yet it occurs systematically with Node 20 and up.","lemire",391987,"2024-06-12 14:17:16","verify issue occur node 18 occur systematically node 20
"
659,144,"@chharvey Please review https://github.com/nodejs/node/pull/53431","lemire",391987,"2024-06-12 15:04:57","review
"
660,144,"it seems like it has somthing to do with x being an array saved in constant. example: 

```
const x = [""x""];

const a = new Set([x, [""y""]]);
const b = new Set([x, [""y""]]);

assert.deepStrictEqual(a, b); // AssertionError
```

but:

```
const a = new Set([[""x""], [""y""]]);
const b = new Set([[""x""], [""y""]]);

assert.deepStrictEqual(a, b); // null
```

can i work on this?

","DanielBelz1997",128147522,"2024-06-12 20:53:42","work issue array constant set assertion deepstrict equal
"
661,144,"> can i work on this?

Yes!!! Have a look at https://github.com/nodejs/node/pull/53431","lemire",391987,"2024-06-12 21:10:52","work
"
662,144,"@DanielBelz1997  Yup, your analysis is correct. Take a look at the [`setEquiv` function here](https://github.com/BridgeAR/node/blob/575784b4cff6eb7fbb16e41cdd2b576563756a09/lib/internal/util/comparisons.js#L443).

Starting on line 447, a new ""SafeSet"" is created that contains all the values in `a` that are *not* in `b` (as determined by `b.has()`, whch checks by reference). When you create a reference `const x = ['x']`, it doesn’t get put into that SafeSet since it’s in both sets. Whereas a newly constructed object would be put in since it can’t be in both sets.

The bug lies on line 468, where we loop over the values in `b`. Since the reference `x` is in `b` but not in the SafeSet, the call on line 471, `setHasEqualElement(‹SafeSet›, ‹x›, ...)`, fails. In your second example you have no references, so all the values in `a` get put into that SafeSet when it’s created. Then when we loop over `b`, the call `setHasEqualElement(...)` passes for all those values.","chharvey",1362083,"2024-06-13 03:55:10","setEquiv function line new safeset create value not determine reference create reference put safeset set newly construct object put set bug line loop value reference safeset call line sethasequalelement fail second example reference value safeset create loop call sethasequalelement pass value
"
663,144,"@chharvey thank you for the direction! I will get on that as soon as possible.","DanielBelz1997",128147522,"2024-06-13 05:24:46","direction get soon possible
"
664,144,"This is a great catch! The bug seems to only occur for sets where both contain a reference identical object and another non-reference identical object.

To fix it, it should be enough to add a check here to verify the reference identical one does not exist in the other set https://github.com/nodejs/node/blob/1839eb203afc6dba75b602504649a475319fdeae/lib/internal/util/comparisons.js#L505

```js
        if (!a.has(val) && !setHasEqualElement(set, val, strict, memo))
```

An alternative would be to undo some of the set changes from https://github.com/nodejs/node/pull/46593. It was not an issue before due to always adding all objects to the intermediate set.

I would just run the benchmark on both options and see what has less impact.","BridgeAR",8822573,"2024-06-13 09:59:01","great catch bug seem occur set contain reference identical object non reference identical object fix enough add check verify reference identical one exist set undo set change issue add object intermediate set run benchmark option see less impact
"
665,144,"@BridgeAR I have added your simple fix to https://github.com/nodejs/node/pull/53431","lemire",391987,"2024-06-13 15:45:43","add simple fix
"
666,145,"I've been able to reproduce.

```js
const worker_threads = require('worker_threads');

if (worker_threads.isMainThread) {
    new worker_threads.Worker(__filename, { env: process.env });
} else {
    console.log('Hello, world!');
}
```

`node --cpu-prof index.js`","avivkeller",38299977,"2024-05-04 00:02:08","reproduce
"
667,145,"The issue occurs when the `env` is set to *any* value. I'll look into it.","avivkeller",38299977,"2024-05-04 00:07:34","issue occur env set value look
"
668,145,"I've determined the issue is not on the JS side of things but on the C++ side instead. I'm no CPP expert, so I haven't looked into it much, but I'd assume it is has something to do with the `node_worker.cc` file: <https://github.com/nodejs/node/blob/71a1fa3043d495dfaa2105d07cd090c51bcd8eed/src/node_worker.cc>

(I determined this by fiddling around with the `/lib/internal/worker.js` file, and seeing that no matter the value set, the issue has to do with the `WorkerImpl`, implemented in CPP)","avivkeller",38299977,"2024-05-04 01:04:26","determine issue c++ side cpp expert look assume something node_worker file worker js file value set issue workerimpl implement cpp
"
669,145,"CC @nodejs/workers","avivkeller",38299977,"2024-05-04 01:04:40","nodejs worker
"
670,145,"I think the relevant code is [here](https://github.com/nodejs/node/blob/71a1fa3043d495dfaa2105d07cd090c51bcd8eed/src/node_worker.cc#L536) . I debug into the C++ code and found the `cpu_prof` in `env->options_` is `false`.","theanarkh",21155906,"2024-05-04 04:52:49","think relevant code debug c++ code find cpu_prof env option false
"
671,146,"Hi! Could you possibly provide some example code to reproduce this? Preferably code that has been compiled into plain JS.","avivkeller",38299977,"2024-05-02 13:04:07","provide example code reproduce preferably code compile plain js
"
672,146,"I would absolutely love to. Unfortunately the bug is reproduced by running `tsc`. Neither I nor the TypeScript team have been able to make a small reproduction.

It was caused by https://github.com/microsoft/TypeScript/pull/53081 and fixed by https://github.com/microsoft/TypeScript/pull/58339 (unreleased yet).","remcohaszing",779047,"2024-05-02 13:14:52","love bug reproduce run tsc typescript team able make small reproduction cause fix unreleased
"
673,146,"AFAICT this doesn't *seem* like an issue with Node.js itself, but rather a compiler (such as `tsc`), but I'm no expert, and I'd love to get a second opinion.","avivkeller",38299977,"2024-05-02 13:18:32","seem issue node compiler expert second opinion
"
674,146,"Sorry, I now see I forgot to provide a critical piece of information. This is a regression in Node.js 22.0.0. It wasn’t a problem before.","remcohaszing",779047,"2024-05-02 13:20:39","regression node.js problem
"
675,146,"Ahh, okay, thank you.","avivkeller",38299977,"2024-05-02 13:22:01","okay thank
"
676,146,"@targos I have a feel we rushed the V8 upgrades.

cc @nodejs/v8 @RafaelGSS","mcollina",52195,"2024-05-02 13:42:12","rush v8 upgrade
"
677,146,"It's probably related to V8, but I'm not sure waiting would have changed anything? We released v22.0.0 with the version of V8 that's in current Chrome.","targos",2352663,"2024-05-02 15:05:22","relate v8 release v22.0.0 version v8 current chrome
"
678,146,"Seems specific to Linux or x64 as I cannot reproduce on ARM64 macOS.","targos",2352663,"2024-05-02 15:08:28","linux x64 reproduce arm64 macos
"
679,146,"We also don't know which version of V8 introduced the bug (assuming it's in V8).","targos",2352663,"2024-05-02 15:10:03","know version v8 introduce bug assume v8
"
684,146,"> It's probably related to V8,

The code that started/stopped crashing in TS had do to with indexing into strings.
The string that TS was looking into starts/stops crashing when there is/isn’t an emoji.

One TS maintainer potentially saw the crash appear/disappear when adding a `console.log` somewhere. So it may be related to some optimization routine
","wooorm",944406,"2024-05-02 15:29:46","v8 code crash ts index string string ts crash emoji ts maintainer crash add console log optimization routine
"
685,146,"I’m on an 2.6 GHz 6-Core Intel Core i7, Sonoma 14.4.1 (23E224).
I have a bunch of the GNU utils tho. So perhaps there could be something that doesn’t happen on mac normally, but my machine looks more like Linux.","wooorm",944406,"2024-05-02 15:31:23","core intel ghz core linux mac
"
686,146,"
Ignore the repro-exists tag, I didn't mean to add it, and it won't effect anything.","avivkeller",38299977,"2024-05-02 15:57:57","ignore repro exist tag mean add effect
"
687,146,"Just to give a side by side using https://github.com/remcohaszing/typescript-bug-58369:

```console
$ grep -A8 'function scanJSDocCommentTextToken' ./node_modules/typescript/lib/tsc.js
  function scanJSDocCommentTextToken(inBackticks) {
    fullStartPos = tokenStart = pos;
    tokenFlags = 0 /* None */;
    if (pos >= end) {
      return token = 1 /* EndOfFileToken */;
    }
    for (let ch = text.charCodeAt(pos); pos < end && (!isLineBreak(ch) && ch !== 96 /* backtick */); ch = codePointAt(text, ++pos)) {
      if (!inBackticks) {
        if (ch === 123 /* openBrace */) {
$ node ./node_modules/typescript/lib/tsc.js
[1]    1090384 segmentation fault  node ./node_modules/typescript/lib/tsc.js
```

Now, add `debugger` to the loop (console.log works too but is loud):

```console
$ grep -A8 'function scanJSDocCommentTextToken' ./node_modules/typescript/lib/tsc.js
  function scanJSDocCommentTextToken(inBackticks) {
    fullStartPos = tokenStart = pos;
    tokenFlags = 0 /* None */;
    if (pos >= end) {
      return token = 1 /* EndOfFileToken */;
    }
    for (let ch = text.charCodeAt(pos); pos < end && (!isLineBreak(ch) && ch !== 96 /* backtick */); ch = codePointAt(text, ++pos)) {
      debugger; // ADDED
      if (!inBackticks) {
$ node ./node_modules/typescript/lib/tsc.js
```

I have not been able to extract out a test which just calls the parser via the public API, nor by extracting this code and giving it the same inputs.","jakebailey",5341706,"2024-05-02 16:04:01","add debugger loop console log work loud extract test call parser via public api extract code give input
"
688,146,"Weird, thanks for the information!","avivkeller",38299977,"2024-05-02 16:11:24","weird thanks information
"
689,146,"```
(gdb) run node_modules/typescript/lib/tsc.js
Starting program: /home/iojs/tmp-targos/node/out/Debug/node node_modules/typescript/lib/tsc.js
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7ffff7a4f640 (LWP 18826)]
[New Thread 0x7ffff724e640 (LWP 18827)]
[New Thread 0x7ffff6a4d640 (LWP 18828)]
[New Thread 0x7ffff624c640 (LWP 18829)]
[New Thread 0x7ffff5a4b640 (LWP 18830)]
[New Thread 0x7ffff51a9640 (LWP 18831)]

Thread 1 ""node"" received signal SIGSEGV, Segmentation fault.
0x00005554d878345d in ?? ()
(gdb) bt
#0  0x00005554d878345d in ?? ()
#1  0x00001967bd580c69 in ?? ()
#2  0x000000000000200e in ?? ()
#3  0x0000200e00000000 in ?? ()
#4  0x0000000000000000 in ?? ()
```

Perfect 🙃 ","targos",2352663,"2024-05-02 16:31:26","node module typescript lib tsc js program home iojs tmp targos node out debug node node module typescript lib tsc js thread debug libthread db enable host libthread db library lib x86 linux gnu libthread db so thread thread thread thread thread thread thread node receive signal sigsegv segmentation fault bt
"
690,146,"Just to note it, you can also add `noop();` instead of `debugger;` if you want a debugger-statement free crasher.","jakebailey",5341706,"2024-05-02 16:47:04","add noop debugger statement free crasher
"
691,146,"This is due to the Maglev compiler. I confirm that `./configure --v8-disable-maglev` fixes it.

Maglev was enabled in https://github.com/nodejs/node/pull/51360

/cc @kvakil","targos",2352663,"2024-05-02 18:24:28","confirm maglev compiler fix configure v8 disable maglev enable
"
692,146,"/cc @victorgomes","targos",2352663,"2024-05-02 18:29:52","victorgomes retorne texto
"
693,146,"I'm rebuilding with ASan and GCC stack protection flags to see if it helps to pinpoint the issue","targos",2352663,"2024-05-03 08:21:51","rebuild ASan GCC stack protection flag pinpoint issue
"
694,146,"GCC failed to build so I switched to clang.
Here's a bit more information:

<details>

```
(lldb) run node_modules/typescript/lib/tsc.js
Process 107011 launched: '/home/iojs/tmp-targos/node/out/Debug/node' (x86_64)
Process 107011 stopped
* thread #1, name = 'node', stop reason = signal SIGSEGV: invalid address (fault address: 0xd848)
    frame #0: 0x00005554dd0c345d
->  0x5554dd0c345d: movl   0xb(%rbx), %r14d
    0x5554dd0c3461: incl   %r12d
    0x5554dd0c3464: cmpl   %r14d, %r12d
    0x5554dd0c3467: jge    0x5554dd0c3497
(lldb) bt
* thread #1, name = 'node', stop reason = signal SIGSEGV: invalid address (fault address: 0xd848)
  * frame #0: 0x00005554dd0c345d
    frame #1: 0x00005554dd07990f
    frame #2: 0x00005554dd078120
    frame #3: 0x00005554dd08f431
    frame #4: 0x00005554dd08ede4
    frame #5: 0x00005554dd08ff1a
    frame #6: 0x00005554dd090015
    frame #7: 0x00005554dd090236
    frame #8: 0x00005554dd0905bf
    frame #9: 0x00005554dd08c36a
    frame #10: 0x00005554dd08538e
    frame #11: 0x00005554fcdd0d5e
    frame #12: 0x00005554dd08fa47
    frame #13: 0x00005554dd0860d4
    frame #14: 0x00005554dd087c7b
    frame #15: 0x00005554dd0670dd
    frame #16: 0x00005554dd08569f
    frame #17: 0x00005554fcdd0d5e
    frame #18: 0x00005554fcdd0d5e
    frame #19: 0x00005554fcdd0d5e
    frame #20: 0x00005554fcdd0d5e
    frame #21: 0x00005554fcdd0d5e
    frame #22: 0x00005554fcdd0d5e
    frame #23: 0x00005554fcdd0d5e
    frame #24: 0x00005554fcdd0d5e
    frame #25: 0x00005554fcdd0d5e
    frame #26: 0x00005554fcdd0d5e
    frame #27: 0x00005554fcdd0d5e
    frame #28: 0x00005554fcdd0d5e
    frame #29: 0x00005554fcdd0d5e
    frame #30: 0x00005554fcdd0d5e
    frame #31: 0x00005554dd04b3d3
    frame #32: 0x00005554fcdd0d5e
    frame #33: 0x00005554fcdd0d5e
    frame #34: 0x00005554fcdd0d5e
    frame #35: 0x00005554fcdd0d5e
    frame #36: 0x00005554fcdd0d5e
    frame #37: 0x00005554fcdd0d5e
    frame #38: 0x00005554fcdd0d5e
    frame #39: 0x00005554fcdd0d5e
    frame #40: 0x00005554fcdd0d5e
    frame #41: 0x00005554fcdd0d5e
    frame #42: 0x00005554fcdd0d5e
    frame #43: 0x00005554fcdce05c
    frame #44: 0x00005554fcdcdd83
    frame #45: 0x0000555559b6a5dc node`v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) [inlined] v8::internal::GeneratedCode<unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, unsigned long**>::Call(this=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>) at simulator.h:178:12
    frame #46: 0x0000555559b6a5d9 node`v8::internal::(anonymous namespace)::Invoke(isolate=<unavailable>, params=<unavailable>)::InvokeParams const&) at execution.cc:418:22
    frame #47: 0x0000555559b68766 node`v8::internal::Execution::Call(isolate=<unavailable>, callable=<unavailable>, receiver=<unavailable>, argc=<unavailable>, argv=<unavailable>) at execution.cc:504:10
    frame #48: 0x00005555593dc7d7 node`v8::Function::Call(this=<unavailable>, context=<unavailable>, recv=<unavailable>, argc=<unavailable>, argv=<unavailable>) at api.cc:5485:7
    frame #49: 0x000055555857e144 node`node::builtins::BuiltinLoader::CompileAndCall(this=0x000061f0000027a0, context=Local<v8::Context> @ 0x00007fffffffc360, id=""internal/main/run_main_module"", argc=4, argv=0x0000603000060d30, optional_realm=0x0000618000000080) at node_builtins.cc:490:14
    frame #50: 0x000055555857db08 node`node::builtins::BuiltinLoader::CompileAndCall(this=0x000061f0000027a0, context=Local<v8::Context> @ 0x00007fffffffc620, id=""internal/main/run_main_module"", realm=0x0000618000000080) at node_builtins.cc:474:10
    frame #51: 0x0000555558a1d04a node`node::Realm::ExecuteBootstrapper(this=0x0000618000000080, id=""internal/main/run_main_module"") at node_realm.cc:161:32
    frame #52: 0x00005555584af033 node`node::StartExecution(env=0x000061f000001c80, main_script_id=""internal/main/run_main_module"") at node.cc:237:35
    frame #53: 0x00005555584aeb92 node`node::StartExecution(env=0x000061f000001c80, cb=node::StartExecutionCallback @ 0x00007fffffffd900)>) at node.cc:365:12
    frame #54: 0x0000555558083dd6 node`node::LoadEnvironment(env=0x000061f000001c80, cb=node::StartExecutionCallback @ 0x00007fffffffdb80, preload=node::EmbedderPreloadCallback @ 0x00007fffffffdbc0)>, std::function<void (node::Environment*, v8::Local<v8::Value>, v8::Local<v8::Value>)>) at environment.cc:551:10
    frame #55: 0x000055555886bd56 node`node::NodeMainInstance::Run(this=0x00007fffffffe170, exit_code=0x00007fffffffde80, env=0x000061f000001c80) at node_main_instance.cc:120:7
    frame #56: 0x000055555886adc0 node`node::NodeMainInstance::Run(this=0x00007fffffffe170) at node_main_instance.cc:100:3
    frame #57: 0x00005555584b60a9 node`node::StartInternal(argc=2, argv=0x000060b000002da0) at node.cc:1445:24
    frame #58: 0x00005555584b5766 node`node::Start(argc=2, argv=0x00007fffffffe608) at node.cc:1452:27
    frame #59: 0x000055555d969352 node`main(argc=2, argv=0x00007fffffffe608) at node_main.cc:97:10
    frame #60: 0x00007ffff7a75d90 libc.so.6`__libc_start_call_main(main=(node`main at node_main.cc:96), argc=2, argv=0x00007fffffffe608) at libc_start_call_main.h:58:16
    frame #61: 0x00007ffff7a75e40 libc.so.6`__libc_start_main_impl(main=(node`main at node_main.cc:96), argc=2, argv=0x00007fffffffe608, init=0x00007ffff7ffd040, fini=<unavailable>, rtld_fini=<unavailable>, stack_end=0x00007fffffffe5f8) at libc-start.c:392:3
    frame #62: 0x0000555557ed2a35 node`_start + 37
(lldb) register read
General Purpose Registers:
       rax = 0x00007ea6937000d9
       rbx = 0x000000000000d83d
       rcx = 0x000000000000000a
       rdx = 0x000000000000000d
       rdi = 0x00007ee68b891811
       rsi = 0x0000000000002028
       rbp = 0x00007fffffff94f0
       rsp = 0x00007fffffff94a8
        r8 = 0x0000000000000060
        r9 = 0x000000000000007b
       r10 = 0x0000000000000000
       r11 = 0x0000000000000040
       r12 = 0x000000000000200f
       r13 = 0x0000631000015080
       r14 = 0x000000000000d800
       r15 = 0x0000200e00000000
       rip = 0x00005554dd0c345d
    rflags = 0x0000000000010246
        cs = 0x0000000000000033
        fs = 0x0000000000000000
        gs = 0x0000000000000000
        ss = 0x000000000000002b
        ds = 0x0000000000000000
        es = 0x0000000000000000
```

</details>

I don't know what else to do at this point. Happy to run more commands if you have any idea.","targos",2352663,"2024-05-03 09:31:55","gcc build switch clang information process launch stop reason signal sigsegv invalid address address frame
"
695,146,"`--no-maglev-inlining` also fixes it.","targos",2352663,"2024-05-03 09:35:18","fix
"
696,146,"I also tried the repro with:
- https://nodejs.org/download/v8-canary/v23.0.0-v8-canary202405011e593b294c/ (V8 12.6.144)
- https://nodejs.org/download/nightly/v22.0.0-nightly2024042244f81a1b7d/ (V8 12.3.219.16)
- https://nodejs.org/download/nightly/v22.0.0-nightly2024041907f481cfcf/ (V8 12.2.281.27)
- https://nodejs.org/download/nightly/v22.0.0-nightly20240331021cf91208/ (V8 11.9.169.7)

They all segfault so I don't think it's a V8 regression, but really a Maglev inlining bug.","targos",2352663,"2024-05-03 09:59:29","repro segfault think maglev inlining bug
"
697,146,"I submitted a V8 bug report: https://issues.chromium.org/issues/338535750","targos",2352663,"2024-05-03 10:24:45","submit v8 bug report
"
698,146,"It looks very similar to https://issues.chromium.org/issues/42204637","targos",2352663,"2024-05-03 11:54:43","look similar issue
"
699,146,"Well, there is a v8 option called `--print-opt-source` which can print source code of optimized and inlined functions.
The problem occurs when v8 optimizes the `isLineBreak` js function in tsc.js. 
I changed the function to this and the problem is gone.
```ts
// tsc.js
function isLineBreak(ch) {
  return ch === 10 /* lineFeed */ || ch === 13 /* carriageReturn */ ;
}
```

```
gdb --args ~/tannalwork/projects/node/node_g --print-opt-source ./node_modules/typescript/lib/tsc.js

--- FUNCTION SOURCE (/home/tannal/tannalwork/projects/node/out/typescript-bug-58369/node_modules/.pnpm/typescript@5.4.5/node_modules/typescript/lib/tsc.js:isLineBreak) id{16,-1} start{744101} ---
(ch) {
  return ch === 10 /* lineFeed */ || ch === 13 /* carriageReturn */ || ch === 8232 /* lineSeparator */ || ch === 8233 /* paragraphSeparator */;
}
--- END ---

Thread 1 ""node_g"" received signal SIGSEGV, Segmentation fault.
0x00005554dbb1115d in ?? ()
```","tannal",149947508,"2024-05-05 04:17:03","v8 option print source code optimize inline function problem occur v8 optimize isLineBreak js function tsc js change function problem gone tsc js function isLineBreak ch return ch lineFeed ch carriageReturn gdb args node g print source node module typescript lib tsc js function source home tannal tannalwork project node out typescript bug node module typescript lib tsc js isLineBreak ch return ch lineFeed ch carriageReturn ch lineSeparator ch paragraphSeparator thread node g receive signal sigsegv segmentation fault
"
700,146,"@targos Could you try to run the test with maglev _and_ with pointer compression enabled?","victorgomes",548275,"2024-05-06 14:32:14","try run test maglev pointer compression enable
"
701,147,"thanks for the great reproduction. I have opened a PR with a fix","MoLow",8221854,"2024-05-02 09:07:49","fix reproduction
"
702,147,"thx for the quick fix","ert78gb",496775,"2024-05-02 09:14:06","thx fix
"
703,148,"/cc @anonrig ","aduh95",14309773,"2024-04-28 23:20:52","anonrig retorne
"
705,148,"Windows 10.0.19045.4170, Node.js v22.0.0
(same results on Command Prompt, Windows PowerShell, and Git Bash)

```sh
PATH>node --run test -- A B
[
  'NODE_22_PATH_TO_EXE',
  'PATH\\script.js',
  ""'A"",
  ""B'""
]
(node:21628) ExperimentalWarning: Task runner is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
```

```sh
PATH>npm run test -- A B

> test
> node script.js A B

[
  'NODE_22_PATH_TO_EXE',
  'PATH\\script.js',
  'A',
  'B'
]
```","alexsch01",5721147,"2024-04-30 10:59:13","node run test a b node script js a b experimental warning task runner experimental feature change time
"
706,149,"I'm opening a PR","nicolo-ribaudo",7000710,"2024-04-26 13:33:09","open pr
"
707,149,"Is there a workaround for this with Gulp? I would ask over in 

- https://github.com/gulpjs/vinyl-fs/issues/350

but GitHub blocks me from commenting there (permissions of that repo allow certain people to comment only?).","trusktr",297678,"2024-04-26 23:55:53","workaround gulp ask github block comment permission repo allow person comment
"
708,149,"I found a workaround for my case (but its common case, so maybe it helps someone):

I didn't realize new versions of Node.js include `recursive` and `filter` options in various `fs` functions including `cp`. So I was able to delete gulp and rewrite this `gulpfile.js`,

```js
const {src, dest, series} = require('gulp')
const {promises} = require('fs')

async function mkDist() {
	try { await promises.mkdir('./dist') } catch (e) { if (e.code !== 'EEXIST') throw e }
}

function copy() {
	return src([ './src/**', '!./src/**/*.{ts,tsx}', './src/**/*.d.ts', ]).pipe(dest('./dist/'))
}

exports.copyAssets = series(mkDist, copy)
```

to a plain Node.js script using the relatively new `cp` function with `recursive` and `filter` options:

```js
import fs from 'fs'

async function mkDist() {
	try { await fs.promises.mkdir('./dist') } catch (e) { if (e.code !== 'EEXIST') throw e }
}

await fs.promises.cp('./src', './dist', {
	recursive: true,
	filter: (src) => src.endsWith('.tsx') || (src.endsWith('.ts') && !src.endsWith('.d.ts')) ? false : true
})
```

Not bad! It used to be tedious to this sort of thing with plain Node prior to cp+recursive+filter, which I'm sure is why libraries like gulp/vinyl came to exist.","trusktr",297678,"2024-04-28 06:23:40","node js include recursive filter option various fs function include cp delete gulp rewrite gulpfile js plain node js script use relatively new cp function recursive filter option bad tedious sort thing plain node prior cp recursive filter sure library gulp vinyl exist
"
709,150,"Another potential bug is that the property is now read-only (even after you access it once to trigger the getter).","targos",2352663,"2024-04-26 13:26:56","potential bug property read only access trigger getter
"
710,150,"I'm opening a PR","nicolo-ribaudo",7000710,"2024-04-26 13:32:43","open PR
"
711,150,"I'm seeing the same issue with mtime as well.","mojavelinux",79351,"2024-04-26 18:13:10","see issue mtime
"
712,150,"Yes, the linked PR will fix both","avivkeller",38299977,"2024-04-26 18:19:52","fix
"
713,151,"For your information, I have the same problem on my Windows machine, so it's not just a problem with Github actions
```
PS C:\Users\me> node --version
v22.0.0
PS C:\Users\me> npm --version
node:internal/modules/cjs/loader:1205
  throw err;
  ^

Error: Cannot find module 'C:\Users\me\AppData\Roaming\npm\node_modules\npm\bin\npm-cli.js'
    at Module._resolveFilename (node:internal/modules/cjs/loader:1202:15)
    at Module._load (node:internal/modules/cjs/loader:1027:27)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:187:14)
    at node:internal/main/run_main_module:28:49 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}
```","Thanaen",16762369,"2024-04-25 08:39:42","information problem windows machine problem github action node version error find module appdata roaming npm node modules npm bin npm cli js code module not found
"
714,151,"I am also experiencing this.","danieljameswilliams",4445229,"2024-04-25 08:50:25","experience
"
715,151,"@Thanaen

- How did you install/update Node.js?
- Does `C:\Users\me\AppData\Roaming\npm\node_modules\npm\bin\npm-cli.js` exist on your system?

I'm currently not able to reproduce on my Windows machine. I tried:
- With `Volta` version manager (my usual setup)
- With the offitial `.msi` installer (in a Windows Sandbox)

```
C:\Users\WDAGUtilityAccount>node -v
v22.0.0

C:\Users\WDAGUtilityAccount>npm -v
10.5.1
```
","targos",2352663,"2024-04-25 09:00:00","install update node js exist system reproduce windows machine volta version manager offitial msi installer node v npm v
"
716,151,"@targos 
I updated Node via the node-v22.0.0-x64 installer, downloaded directly from the Node website.

When I saw that it didn't work, I uninstalled Node, then did a clean install, with the same installer file. (after cleaning up all the cache files etc)

I then tried activating corepack and installing npm via corepack (`corepack enable` then `corepack prepare npm@latest --activate`)

After checking, it seems that the `C:\Users\me\AppData\Roaming\npm` folder doesn't exist 😅

Also, I've changed the `npm_config_cache` environment variable to point to my Dev Drive, so maybe that's a factor?
PS: I've tried removing my environment variable, but it doesn't fix the problem","Thanaen",16762369,"2024-04-25 09:25:45","atualizar node instalador limpar instalar ativar corepack instalar npm corepack verificar pasta existir mudar variavel ambiente remover variavel ambiente problema
"
717,151,"@targos I've just tried installation via Volta, and npm works correctly.
Maybe a problem with the MSI installer and Windows 11?","Thanaen",16762369,"2024-04-25 09:36:05","tried installation volta npm work correctly problem msi installer windows
"
718,151,"I don't know how to reproduce on my Windows system but it seems indeed to be a general issue on GitHub actions (which download the binary from https://nodejs.org/dist/v22.0.0/node-v22.0.0-win-x64.7z): https://github.com/nodejs/citgm/actions/runs/8831148407/job/24245743480?pr=1056","targos",2352663,"2024-04-25 10:42:35","know reproduce windows system seem general issue github action download binary nodejs org dist v22 node v22 win x64
"
719,151,"have the same issue","alvicode",105916663,"2024-04-25 10:46:14","issue
"
720,151,"The main difference I see between v20/v21 and v22 is the presence of `npm.ps1` and `npx.ps1` in the distribution.
This is from https://github.com/nodejs/node/pull/52009

/cc @nodejs/npm @lukekarrys 
","targos",2352663,"2024-04-25 10:50:11","difference presence npm ps1 distribution
"
732,151,"As for signing, Node.js signs assets it produces (the `node.exe` file, and msi installer). The logic for that is in `vcbuild.bat`. However, I'd be a little wary of using Node.js' signing certificate to sign something originating from outside of Node.js.","richardlau",5445507,"2024-04-25 16:27:37","sign nodejs sign asset produzir file msi installer logic vcbuild bat wary usar nodejs sign certificate sign algo originar fora nodejs
"
733,151,"This is the expected error if the image just didn't set the path","StoneCypher",77482,"2024-04-25 17:58:31","expected error image set path
"
766,157,"@mertcanaltin @kibertoad Have you tried to reproduce it on a mac os? I'm unable to reproduce it on my end 🤔  it might be related to Windows maybe","IlyasShabi",33763729,"2024-03-29 21:26:21","reproduce mac os unable reproduce end relate window
"
995,196,"Anyone with a Quick fix, or which version is stable?
My version: `v20.6.0`","Qodestackr",55054375,"2023-09-18 18:42:05","quick fix stable version
"
721,151,"Also /cc @StefanStojanovic.

I'm trying to find a simple reproduction but I hit another problem. Here are the steps I took:
- Download v22 from https://nodejs.org/download/release/v22.0.0/ (I used the `-arm64.zip` one)
- Extract it and cd into it.
- Run:

```
PowerShell 7.4.2
PS C:\Users\mzasso\Documents\node-v22.0.0-win-arm64\node-v22.0.0-win-arm64> .\node.exe -v
v22.0.0
PS C:\Users\mzasso\Documents\node-v22.0.0-win-arm64\node-v22.0.0-win-arm64> .\npm.cmd -v
10.5.1
PS C:\Users\mzasso\Documents\node-v22.0.0-win-arm64\node-v22.0.0-win-arm64> .\npm.ps1 -v
node.exe not found.

Suggestion [3,General]: The command ""node.exe"" was not found, but does exist in the current location.
PowerShell does not load commands from the current location by default (see ''Get-Help about_Command_Precedence'').

If you trust this command, run the following command instead:
PS C:\Users\mzasso\Documents\node-v22.0.0-win-arm64\node-v22.0.0-win-arm64>
```","targos",2352663,"2024-04-25 11:23:37","problema encontrar reproducao simples passo baixar extrair executar node exe v npm cmd v npm ps1 v comando node exe encontrar existir local padrao confia comando
"
722,151,"Then I installed a global node.exe with Volta and hit another (still different, but similar) issue:

```
PS C:\Users\mzasso\Documents\node-v22.0.0-win-arm64\node-v22.0.0-win-arm64> .\npm.ps1 -v
node:internal/modules/cjs/loader:1205
  throw err;
  ^

Error: Cannot find module 'C:\Program Files\Volta\node_modules\npm\bin\npm-prefix.js'
    at Module._resolveFilename (node:internal/modules/cjs/loader:1202:15)
    at Module._load (node:internal/modules/cjs/loader:1027:27)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:187:14)
    at node:internal/main/run_main_module:28:49 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}

Node.js v22.0.0
Could not determine Node.js install directory
```

Maybe the problem is that the `npm.ps1` script tries to determine where npm is installed based on where the global node.exe is installed? This seems wrong.","targos",2352663,"2024-04-25 11:32:14","instal global nodeexe volta encontrar problema npm script determinar npm instalar base global nodeexe instalar problema
"
723,151,"This appears to be a problem w/ the base node installation in windows itself.

A related issue is https://github.com/npm/cli/issues/6971

It seems that in some installations npm does not end up where it belongs? Or is missing directories?","wraithgar",36607,"2024-04-25 14:40:46","problem base node installation windows installation npm end directory
"
724,151,"> Maybe the problem is that the npm.ps1 script tries to determine where npm is installed based on where the global node.exe is installed?

No, it tries to ask windows where node.exe is

```
$nodebin = $(Get-Command $nodeexe -ErrorAction SilentlyContinue -ErrorVariable F).Source
```

It then looks to the parent folder of the node executable and starts looking for npm there

```
$nodedir = $(New-Object -ComObject Scripting.FileSystemObject).GetFile(""$nodebin"").ParentFolder.Path
```

That's why this is happening

> Suggestion [3,General]: The command ""node.exe"" was not found, but does exist in the current location.
PowerShell does not load commands from the current location by default (see ''Get-Help about_Command_Precedence'')

There is no `node` executable that is in a valid path. Windows is refusing to consider the one in the cwd as valid when npm asks for it because of command precedence.","wraithgar",36607,"2024-04-25 14:46:37","problem npm script try determine npm install base global nodeexe install ask windows nodeexe nodebin get command nodeexe erroraction silentlycontinue errorvariable source look parent folder node executable start look npm happen suggestion command nodeexe find exist current location powershell load command current location default see get help about command precedence node executable valid path windows refuse consider one cwd valid npm ask command precedence
"
725,151,"`npm.cmd` looks for node using `%~dp0\node.exe`.  Is it getting a different answer for this than `Get-Command`?","wraithgar",36607,"2024-04-25 14:53:33","look node use get command different answer
"
726,151,"> `npm.cmd` looks for node using `%~dp0\node.exe`. Is it getting a different answer for this than `Get-Command`?

Yes. `%~dp0` is the directory that contains `npm.cmd`","targos",2352663,"2024-04-25 15:09:27","npm look node get different answer get command directory contain npm
"
727,151,"npm has to make an assumption that `npm` and `node` are in the same place, and based on that can go find itself.  `npm.cmd` and `corepack` do this by evaluating `%~dp0\node.exe`.  `npm.ps1` does this by calling `Get-Command node.exe`.

Is there another node.exe that is in the path?  How do these strings materially differ, shouldn't they be the same?

It looks like that difference is the root cause here.  We'll keep this issue open to track the work instead of making duplicates.

While we're on the subject however, it appears that this `npm.ps1` file is not properly digitally signed in the node installation.  cf https://github.com/npm/cli/issues/7280.","wraithgar",36607,"2024-04-25 15:43:14","npm assumir npm node mesmo lugar base encontrar npm cmd corepack avaliar node exe npm ps1 chamar get command node exe outro node exe caminho string materialmente diferenciar mesmo diferença causa raiz manter issue aberto rastrear trabalho fazer duplicata assunto npm ps1 arquivo digitalmente assinar node instalação
"
728,151,"This may represent a larger issue that has to date gone unnoticed.  What npm is trying to make sure of is that `node` and `npm` are both reached by the same method.   If there is some other node installation that is called when a person runs `node` that differs than the one npm shipped with that could cause problems.  There is no guarantee that other version of node even works with this version of npm.

If `Get-Command node.exe` is not returning the same node.exe that is alongside the file that runs when `npm.ps1` is called, that is an issue.  It seems like it's an issue w/ the installer in that it's not putting the version of node that was installed properly in the user's PATH.","wraithgar",36607,"2024-04-25 16:05:19","issue installer node npm version path problem guarantee method installation
"
729,151,"In the short term, we'll update the `.ps1` script to use `%dp0`, @lukekarrys is working on this.","wraithgar",36607,"2024-04-25 16:16:27","update script use work
"
730,151,"> > `npm.cmd` looks for node using `%~dp0\node.exe`. Is it getting a different answer for this than `Get-Command`?
> 
> Yes. `%~dp0` is the directory that contains `npm.cmd`

I think this is a mistake in the ps1 scripts that `npm` ships with then. They should be using `%~dp0` instead of `Get-Command`. I'll make a PR to npm fixing this in `npm.ps1` and `npx.ps1`.

> It appears that this npm.ps1 file is not properly digitally signed in the node installation. cf https://github.com/npm/cli/issues/7280.

I would be curious if anyone knows how to fix the issue with digitally signing the ps1 scripts. I don't think it's directly related to this issue, but v22 is the first time these scripts are included in the Node installer. I'm not sure if this is something that should be fixed on the npm or node side.","lukekarrys",542108,"2024-04-25 16:17:26","npm look node usar diretorio conter npm erro script ps1 npm usar get command pr npm corrigir npm ps1 npx ps1 arquivo npm ps1 assinar digitalmente instalacao node problema assinar digitalmente script ps1 diretamente relacionado problema v script incluir instalador node npm node lado
"
731,151,"`%~dp0` is a .cmd/batch file thing. Powershell equivalents (depending on the version being targetted): https://stackoverflow.com/a/36417541","richardlau",5445507,"2024-04-25 16:19:24","cmd batch file powershell equivalent version
"
734,151,"> As for signing, Node.js signs assets it produces (the `node.exe` file, and msi installer). The logic for that is in `vcbuild.bat`. However, I'd be a little wary of using Node.js' signing certificate to sign something originating from outside of Node.js.

Thanks, that's good to know. I don't love the idea either of Node signing a file that lives in the npm repo. Maybe a dumb question, but what would it take for Node to own this Powershell script? I don't have any of the historical context here, but AFAIK npm doesn't do anything special with those files beyond ensuring they exist. If those files were moved to Node we would just shift the implicit contract to ensuring the files referenced within the Powershell script existed.

This is off topic for this discussion but I'd like to continue it (in a new issue probably).","lukekarrys",542108,"2024-04-25 21:52:36","node sign asset produzir logic wary usar node sign certificado sign algo originar fora node ideia node sign arquivo viver npm repo pergunta node possuir powershell script contexto npm fazer algo especial arquivo garantir arquivo mover node mudar contrato implícito garantir arquivo referenciar dentro powershell script existir tópico discussão gostaria continuar issue novo
"
735,151,"I have a PR open that should fix this issue: https://github.com/npm/cli/pull/7422

I'm no Powershell expert but I think I was able to match the behavior in the `bin/npm` bash script.

We do have tests for these scripts that ensure they run, but they assume a fixed location of `node.exe`. If anyone would like to review the PR from the perspective of how this file will be run from a user's machine after being placed by the Node installer, that would be greatly appreciated.","lukekarrys",542108,"2024-04-25 23:09:30","fix issue match behavior bash script test script assume fix location node anyone like review perspective file run user machine place node installer appreciate
"
736,151,"> I have a PR open that should fix this issue: [npm/cli#7422](https://github.com/npm/cli/pull/7422)
> 
> I'm no Powershell expert but I think I was able to match the behavior in the `bin/npm` bash script.
> 
> We do have tests for these scripts that ensure they run, but they assume a fixed location of `node.exe`. If anyone would like to review the PR from the perspective of how this file will be run from a user's machine after being placed by the Node installer, that would be greatly appreciated.

@nodejs/platform-windows ","richardlau",5445507,"2024-04-25 23:42:05","fix issue match behavior bash script test script assume fix location node exe review perspective file run user machine place node installer appreciate platform windows
"
737,151,"I tried the script from https://github.com/npm/cli/pull/7422 with my repro steps and it works.","targos",2352663,"2024-04-26 07:07:38","tried script repro step work
"
738,151,"```shell
$ npm -v

node:internal/modules/cjs/loader:1205
  throw err;
  ^

Error: Cannot find module 'C:\Users\<username>\AppData\Roaming\npm\node_modules\npm\bin\npm-cli.js'
    at Module._resolveFilename (node:internal/modules/cjs/loader:1202:15)
    at Module._load (node:internal/modules/cjs/loader:1027:27)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:187:14)
    at node:internal/main/run_main_module:28:49 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}

Node.js v22.0.0
```

You have to copy `C:\Program Files\nodejs\node_modules\npm` to `%AppData%\Roaming\npm\node_modules` temporarily.

I think this issue only occurs on:
- Fresh installation of Node v22
- Upgraded to Node v22 but never installed npm globally (`npm i -g npm`) before

The new npm script seems to only check global installation by default and will not use the version bundled in the Node installation directory.

","bamf2077",37755859,"2024-04-28 01:26:28","instalacao node v22 npm global novo script npm verificar instalacao global versao pacote node instalacao diretorio
"
739,151,"https://github.com/actions/node-versions/releases/tag/22.0.0-8879734543
* Still generates the same error in GitHub Actions.","cclauss",3709715,"2024-04-29 18:54:11","generate error github action
"
740,151,"@cclauss that build is from 5 hours ago but the fix was only merged 2 hours ago. ","westy92",290167,"2024-04-29 19:04:39","build hour ago fix merge hour ago
"
741,151,"The fix was merged in npm but has not been released yet. Our goal is to release it today. After that happens we will make a new PR to Node which should then fix this issue.","lukekarrys",542108,"2024-04-29 19:35:44","fix merge npm release goal release today happen make new pr node fix issue
"
742,151,"For visibility, I wanted to surface another bug found in the new npm Powershell scripts that shipped with v22, since folks watching this issue might hit this one as well.

The full details are here (https://github.com/npm/cli/issues/7375#issuecomment-2083924657) but the gist is argument parsing is different between batch/cmd files and powershell, so attempting to call a run script like `npm run echo -- arg1 --arg2` will not pass the `--arg2` along due to the leading dashes.

To get the same behavior in Powershell you need to run `npm run echo --% arg1 --arg2`. *Edit: this is not fully equivalent. See the linked issue fore more details.*

So far I have not been able to fix this in npm's Powershell shim to get parity with the batch file. If this is not possible, then npm might chose to remove the PS1 shims and send a PR to remove them from the Node installer as well.
","lukekarrys",542108,"2024-04-30 20:31:26","bug npm powershell script ship folk watch issue detail argument parse different batch cmd file attempt call run script pass leading dash behavior powershell need run edit fully equivalent link issue detail fix npm powershell shim parity batch file possible npm chose remove ps1 shim send pr remove node installer
"
743,152,"Thanks for the issue! If you'd like to open a PR to fix it, the team would be happy to review! (Plus you'll get a shiny ""contributor"" badge if merged 😀 )

I think it is worth it to fix it, as even the little things can cause issues down the line","avivkeller",38299977,"2024-04-21 12:44:35","fix issue happy review contributor merge worth fix little thing caus issue line
"
744,152,"I've opened a PR to resolve this issue. You have been marked as the Co-Author. If you'd prefer *not* be mentioned in the PR, please let me know.","avivkeller",38299977,"2024-04-21 19:53:59","open pr resolve issue mark co author prefer mention pr let know
"
756,155,"Thank you @targos ! 

","Malikrehman00107",111962911,"2024-04-01 07:40:11","thank
"
757,156,"I think this feature is not supported in `spawnSync`(or `execSync`) currently. 
See: https://github.com/nodejs/node/pull/29412.","theanarkh",21155906,"2024-03-30 08:54:45","feature support spawnSync execSync
"
758,156,"Then it should throw an error, not crash.","targos",2352663,"2024-03-30 09:07:46","throw error crash
"
759,156,"Let me work on this one","juanarbol",17013303,"2024-05-28 14:52:46","work one
"
760,156,"Oh, never-mind, it must be fixed by https://github.com/nodejs/node/pull/48479

So I will mark this as a dupe of https://github.com/nodejs/node/issues/48476","juanarbol",17013303,"2024-05-29 05:05:37","fix dupe
"
789,161,"I spent some time playing with your demo and it's leaking memory in Node v20.11.1 but not v20.10.0.
I did not bisect Node.js core yet.

Moreover, I haven't identified the cause of the leak yet and why it's showing up in the convoluted example. More importantly, several  EventEmitter leaks are showing up in both.

Can you simplify your example only using Node.js core?","mcollina",52195,"2024-03-30 08:44:20","memory leak nodejs example simplify core emitter
"
1610,277,"> Alright☺

Spam comment, user blocked.","Trott",718899,"2022-06-20 19:34:41",NULL
745,153,"Hi @LiST-GIT, according to the document, the rl.close() method closes the Interface instance and relinquishes control over the input and output streams. When called, the 'close' event will be emitted. Calling rl.close() does not immediately stop other events (including 'line') from being emitted by the Interface instance. IMO, rl.close() does not exit the process.

In the test code, `var r = repl.start({});` opens stdin and stdout and wait for users input so closing the REPL server does not exit the stdin and stdout unless users send EXIT event.

I wrote 2 samples to make the test code work smoothly:

```
const repl = require('repl');
const path = require('path');

// Start the REPL session
const r = repl.start();


r.setupHistory(path.join(__dirname, '/history'), () => {});

r.close();

r.on('exit', () => {
    console.log('REPL session closed.');
    process.exit();
  });
```

It quits the node process very soon without giving users chance to input and save into history.
Below modifications let users input and save history and exit by inputing "".exit"" in the repl. 
```
const repl = require('repl');
const path = require('path');

// Start the REPL session
const r = repl.start({
  prompt: '> '  
});

// Setup the history for the REPL session
r.setupHistory(path.join(__dirname, '/history'), (err) => {
  if (err) {
    console.log('Error setting up history:', err);
  } else {
    console.log('History setup completed.');
  }
});

// Define the exit event handling
r.on('exit', () => {
  console.log('REPL session closed.');
  process.exit();
});
```



","lucshi",50089527,"2024-04-17 08:29:05","close method close interface instance relinquish control input output stream call close event emit call close immediately stop event include line emit interface instance imo close exit process test code open stdin stdout wait user input close repl server exit stdin stdout unless user send exit event write sample make test code work smoothly quit node process soon give user chance input save history modification let user input save history exit input exit repl session close repl session close error setup history history setup complete
"
746,153,"If agreed, would I submit a PR to explain the repl.close() behavior more clearly especially for stdin and stdou cases instead of file stream cases?","lucshi",50089527,"2024-04-17 08:31:18","agreed submit pr explain repl close behavior clearly stdin stdout case file stream case
"
747,153,"Thank you for your response @lucshi . I've updated the code again. In the callback of setupHistory, calling r.pause can now properly exit the program. I think it might be because r.close already calls r.pause, but in setupHistory, due to the asynchronous fd executing the open callback, r.resume is called again, which is why it continues to wait on stdin. Is this by design?
```js
const repl = require('repl');

var r = repl.start({});
r.setupHistory(__dirname + '/history', () => {
    r.pause();
});
r.close();

```","LiST-GIT",523889,"2024-04-17 09:43:46","thank response update code callback setupHistory call properly exit program think design asynchronous fd execute open callback resume call continue wait stdin design
"
748,153,"According to the REPL implementation , setupHistory resumes the REPL again even if it has been closed. IMHO, in real pracise, users (programmers) ought to know the callback of setupHistory occurs after r.close() so the original code snippet does not make great sense although it is a great corner test case. Usually users are supposed to do some evaluations to well use REPL after history setup. A common code snippet found on web be like : 


```
const repl = require('repl');
const fs = require('fs');

// Start the REPL
const myRepl = repl.start({
  prompt: '> '
});

// Setup history file
const historyFilePath = __dirname + '/history.txt';
myRepl.setupHistory(historyFilePath, () => {
  console.log('History setup complete.');

  // Execute some commands after history setup
  myRepl.eval('console.log(""Executing command 1"")', myRepl.context, 'history_callback', (err, result) => {
    if (err) {
      console.error('Error executing command 1:', err);
    } else {
      console.log('Command 1 executed successfully.');
    }
  });

  myRepl.eval('console.log(""Executing command 2"")', myRepl.context, 'history_callback', (err, result) => {
    if (err) {
      console.error('Error executing command 2:', err);
    } else {
      console.log('Command 2 executed successfully.');
    }
  });

  // Close the REPL after executing commands
  setTimeout(() => {
    console.log('Closing the REPL...');
    myRepl.close();
  }, 2000); // Close the REPL after 2 seconds
});

// Event handler for when REPL is closed
myRepl.on('close', () => {
  console.log('REPL closed.');
});
```
As the REPL API manuals does not give such a clear sample to demostrate how to close the REPL gracefully. I think complementing the document could be a quick solution. What's your advice here?","lucshi",50089527,"2024-04-17 14:17:01","repl implementation setuphistory resume repl close real pracise user programmer know callback setuphistory occur r close original code snippet make great sense great corner test case user suppose evaluation well use repl history setup common code snippet web repl api manual give clear sample demostrate close repl gracefully think complement document quick solution advice
"
749,153,"I think you're right, the programmer should determine the order of setupHistory and close themselves.","LiST-GIT",523889,"2024-04-18 11:53:32","programmer determine order setup history close
"
750,153,"I think I can submit a PR to resolve this issue even if the close is done ahead of setupHistory. 
Feel free to reopen this issue @LiST-GIT ","lucshi",50089527,"2024-04-19 06:37:01","submit pr resolve issue close ahead setupHistory reopen issue
"
751,154,"Duplicate https://github.com/nodejs/node/issues/52084","anonrig",1935246,"2024-04-05 16:01:09","duplicate issue
"
752,155,"The issue you're encountering is due to JavaScript's handling of integers beyond Number.MAX_SAFE_INTEGER (which is 2^53 - 1), resulting in the values being interpreted as negative when passed to Buffer.toString().

make sure  that the start and end parameters passed to Buffer.toString() are within the range of safe integers. You can achieve this by performing bounds checking before calling Buffer.toString().","Malikrehman00107",111962911,"2024-04-01 06:50:38","issue encounter due javascript handle integer beyond number max safe integer result value interpret negative pass buffer tostring make sure start end parameter pass buffer tostring range safe integer achieve perform bound check call buffer tostring
"
753,155,"> The issue you're encountering is due to JavaScript's handling of integers beyond Number.MAX_SAFE_INTEGER (which is 2^53 - 1), resulting in the values being interpreted as negative when passed to Buffer.toString().
> 
> make sure that the start and end parameters passed to Buffer.toString() are within the range of safe integers. You can achieve this by performing bounds checking before calling Buffer.toString().

Sorry for being made an unclear comment on example code. I wrote INT_MAX < start but I think it would be correct to express it as 2^32-1.
This problem occurs when using a value greater than 2^31-1 as offsets(start or end). And this is smaller than the kMaxLength constant, which is the maximum size of buffer allowed by Buffer.js (in 64-bit architecture, 2^32). so I think this case should be handled by Buffer.toString().","imyp92",26646765,"2024-04-01 07:23:42","issue encounter due javascript handle integer beyond number max safe integer result value interpret negative pass buffer to string make sure start end parameter pass buffer to string range safe integer achieve perform bound check call buffer to string sorry make unclear comment example code write int max think correct express problem occur use value great offset start end small kmaxlength constant maximum size buffer allow buffer js bit architecture think case handle buffer to string
"
754,155,"I see ! 

you may need to perform bounds checking before calling Buffer.toString() to ensure that the offsets are within the range of safe integers. This will help prevent the index out of range errors until a fix or enhancement is made to Buffer.toString().

Rest i think Node Js internal need to have a look on this.","Malikrehman00107",111962911,"2024-04-01 07:29:35","need perform bound check call Buffer toString ensure offset range safe integer help prevent index range error fix enhancement make Buffer toString Node Js internal need look
"
755,155,"This should fix it in a non-breaking way:

```diff
diff --git a/lib/buffer.js b/lib/buffer.js
index a8d07342e15..904f1fff6b3 100644
--- a/lib/buffer.js
+++ b/lib/buffer.js
@@ -820,12 +820,12 @@ Buffer.prototype.toString = function toString(encoding, start, end) {
   else if (start >= len)
     return '';
   else
-    start |= 0;
+    start = MathTrunc(start) || 0;

   if (end === undefined || end > len)
     end = len;
   else
-    end |= 0;
+    end = MathTrunc(end) || 0;

   if (end <= start)
     return '';
```","targos",2352663,"2024-04-01 07:39:02","fix non break way
"
767,157,"I couldn't reproduce it. Also, you don't need to call `node:process` since `process` is a global variable:

```text
node on  main via ⬢ v21.7.1
❯ cat .env
JWT_PUBLIC_KEY=""-----BEGIN PUBLIC KEY-----
MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAzi4k4ful8Q65RWbHvZwD
jKNfspb89typkUATf8KXlYcWp6ibUG9nKpYrig3jmlCdMvCm+S7kZedACshFyRmm
1ocaWjRIt/jJyzntxnMIgWetTedZXXzlFbparDMrdEMmsPbM7LrByCU57iKloZEl
BhOSQZk/JbJK1YpozTCxcs28YlpnTuMBaXvXddrQuNHo+HYhK53XlFXyiOBzmEFY
cBrVqptdjA3z7uNNd6A4IAfEkRYp4lZxZgwTPyjYZ1oXmhalvbr6OAs9ujLIZPSM
QoP1VoHLdOqrs7QTmi2rrNCfIcFkFp02N39TovMm9zZQJjQvFEJqIKe4db2457vr
uJ5qxkWmbBu+/tf6ytKfbiA433neLSvpfquPXbq3OLGzJ4H2YHiHa0ddfUCqdN49
t5nCPEMp6OTa5kXuwObf8yvHyoP8HgQQD+/sftHUIE/1sdQ6fzB/9L+smzp5SW/X
nI8NY0k1SH9MLlweGuXi6M1jS62kPWk4HTDQmiqUTImcG0XYRrVd5ISXPdfnVgnq
KKht+SUmkPrfaWMDc21FsXXmmVSRTjvBhA6Cy6PLPzGZaeA4TVkOZUkp1OvcyfiI
HixuZca1OASxGeUM8lcPi9my8TJCtw5ZR0M/uqVV/1o3U0nx+U5z54ulWN9leMLY
vgv+lGrqfFWRemajGXSm8L0CAwEAAQ==
-----END PUBLIC KEY-----""

node on  main via ⬢ v21.7.1
❯ cat hello.js
process.loadEnvFile('./.env');
console.log(process.env.JWT_PUBLIC_KEY);

node on  main via ⬢ v21.7.1
❯ node hello.js
-----BEGIN PUBLIC KEY-----
MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAzi4k4ful8Q65RWbHvZwD
jKNfspb89typkUATf8KXlYcWp6ibUG9nKpYrig3jmlCdMvCm+S7kZedACshFyRmm
1ocaWjRIt/jJyzntxnMIgWetTedZXXzlFbparDMrdEMmsPbM7LrByCU57iKloZEl
BhOSQZk/JbJK1YpozTCxcs28YlpnTuMBaXvXddrQuNHo+HYhK53XlFXyiOBzmEFY
cBrVqptdjA3z7uNNd6A4IAfEkRYp4lZxZgwTPyjYZ1oXmhalvbr6OAs9ujLIZPSM
QoP1VoHLdOqrs7QTmi2rrNCfIcFkFp02N39TovMm9zZQJjQvFEJqIKe4db2457vr
uJ5qxkWmbBu+/tf6ytKfbiA433neLSvpfquPXbq3OLGzJ4H2YHiHa0ddfUCqdN49
t5nCPEMp6OTa5kXuwObf8yvHyoP8HgQQD+/sftHUIE/1sdQ6fzB/9L+smzp5SW/X
nI8NY0k1SH9MLlweGuXi6M1jS62kPWk4HTDQmiqUTImcG0XYRrVd5ISXPdfnVgnq
KKht+SUmkPrfaWMDc21FsXXmmVSRTjvBhA6Cy6PLPzGZaeA4TVkOZUkp1OvcyfiI
HixuZca1OASxGeUM8lcPi9my8TJCtw5ZR0M/uqVV/1o3U0nx+U5z54ulWN9leMLY
vgv+lGrqfFWRemajGXSm8L0CAwEAAQ==
-----END PUBLIC KEY-----
```","anonrig",1935246,"2024-03-30 00:56:43","reproduce need call node process process global variable
"
768,157,"I couldn't reproduce it on `main` branch as well.","anonrig",1935246,"2024-03-30 00:58:03","reproduce main branch
"
769,157,"@anonrig @IlyasShabi I can confirm that this only happens in Windows. E. g. https://github.com/lokalise/node-service-template/actions/runs/8491928125/job/23264398029?pr=536 is green, but same tests are failing locally for me.","kibertoad",1847934,"2024-03-30 16:17:20","confirm happen windows test fail local
"
770,157,"I reproduced this on Node.js Windows CI","anonrig",1935246,"2024-03-30 16:18:11","reproduce node windows ci
"
771,157,"Would it be a good idea to process the values by chunking them?","mertcanaltin",37827216,"2024-04-06 16:41:04","good idea process value chunk
"
772,157,"@IlyasShabi Was the fix included in 22.0.0? I've tried running it, and it's still crashing with the same error when trying to load this value:

```
JWT_PUBLIC_KEY=""-----BEGIN PUBLIC KEY-----
MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAzi4k4ful8Q65RWbHvZwD
jKNfspb89typkUATf8KXlYcWp6ibUG9nKpYrig3jmlCdMvCm+S7kZedACshFyRmm
1ocaWjRIt/jJyzntxnMIgWetTedZXXzlFbparDMrdEMmsPbM7LrByCU57iKloZEl
BhOSQZk/JbJK1YpozTCxcs28YlpnTuMBaXvXddrQuNHo+HYhK53XlFXyiOBzmEFY
cBrVqptdjA3z7uNNd6A4IAfEkRYp4lZxZgwTPyjYZ1oXmhalvbr6OAs9ujLIZPSM
QoP1VoHLdOqrs7QTmi2rrNCfIcFkFp02N39TovMm9zZQJjQvFEJqIKe4db2457vr
uJ5qxkWmbBu+/tf6ytKfbiA433neLSvpfquPXbq3OLGzJ4H2YHiHa0ddfUCqdN49
t5nCPEMp6OTa5kXuwObf8yvHyoP8HgQQD+/sftHUIE/1sdQ6fzB/9L+smzp5SW/X
nI8NY0k1SH9MLlweGuXi6M1jS62kPWk4HTDQmiqUTImcG0XYRrVd5ISXPdfnVgnq
KKht+SUmkPrfaWMDc21FsXXmmVSRTjvBhA6Cy6PLPzGZaeA4TVkOZUkp1OvcyfiI
HixuZca1OASxGeUM8lcPi9my8TJCtw5ZR0M/uqVV/1o3U0nx+U5z54ulWN9leMLY
vgv+lGrqfFWRemajGXSm8L0CAwEAAQ==
-----END PUBLIC KEY-----""
```","kibertoad",1847934,"2024-04-27 12:59:20","fix include tried running still crashing error load value begin public key end public key
"
773,157,"@kibertoad According to this https://github.com/nodejs/node/releases/tag/v22.0.0 I think it was not released","IlyasShabi",33763729,"2024-04-27 13:04:32","accord think release
"
774,157,"Gotcha, thanks! Here's hoping it will be included into subsequent releases. As it wasn't a semver major, it should be possible to include it at any point.","kibertoad",1847934,"2024-04-27 13:06:02","hope include subsequent release semver major possible include point
"
775,158,"Thanks for the report. See https://github.com/nodejs/node/pull/52115","cjihrig",2512748,"2024-03-16 16:14:10","report
"
776,159,"This seems like a bug. Ed25519 and Ed448 should only be available via the oneshot apis in the first place. ","panva",241506,"2024-03-17 19:28:17","bug available oneshot api
"
777,159,"Yes, there is indeed an error here, so an error should be thrown here instead of returning a zero-filled Buffer.","xicilion",26833060,"2024-03-18 17:05:03","error throw return zero fill buffer
"
778,159,"cc @nodejs/crypto ","panva",241506,"2024-03-19 11:22:22","nodejs crypto
"
779,159,"I would like to work on this if nobody else is. ","medic-code",60046611,"2024-03-22 19:37:58","work nobody else
"
780,160,"@mcollina @ronag","benjamingr",1315533,"2024-03-07 13:09:38","mcollina ronag
"
781,160,"I'm sorry it caused a regression this far down. Will patch it. Hopefully we can backport the fix to v18.","mcollina",52195,"2024-03-07 13:20:54","patch hope backport fix
"
782,160,"I can confirm the issue has been fixed in the following node.js versions:
- [v18.20.0](https://nodejs.org/en/blog/release/v18.20.0)
- [v20.12.0](https://nodejs.org/en/blog/release/v20.12.0)
- [v21.7.1](https://nodejs.org/en/blog/release/v21.7.1)","dy-dx",1074881,"2024-03-26 18:45:17","confirm issue fix nodejs version
"
783,161,"Did you run on `v20.11.0` at all? I've noticed what I believe to be same thing on a very similar service I work on (fastify server + pino logger with file transports configured, also processes very high log volume). I only see issues on `v20.11.1` though and not on `v20.11.0`, which seems odd to me, since the commit you linked landed in `v20.11.0`.

`v20.10.0` performs as expected, like you mentioned.","bienzaaron",18443246,"2024-03-01 22:51:49","run v20.11.0 notice thing similar service work fastify server pino logger file transport configure process high log volume issue v20.11.1 v20.11.0 seem odd commit link land v20.11.0 v20.10.0 perform expect mention
"
784,161,"Thanks for reporting. Can you include a script to reproduce?","mcollina",52195,"2024-03-03 16:37:34","report include script reproduce
"
785,161,"@bienzaaron In my case, the memory leak can also be observed in `v20.11.0`, it really seems like the aforementioned commit from `v20.11.0` might be at fault. Here's a screenshot from my memory graphs in Grafana: first part is `v20.11.1` with the commit in question reverted, second part is stock `v20.11.0` - memory leak present still.
![Screenshot from 2024-03-04 09-09-34](https://github.com/nodejs/node/assets/13771292/842d6e05-4829-44b2-9b30-256e09b3826b)
","kshaa",13771292,"2024-03-04 07:09:11","memory leak observe v20.11.0 seem commit v20.11.0 fault screenshot memory graph grafana part v20.11.1 commit question revert part stock v20.11.0 memory leak present
"
786,161,"Does it crash for an OOM? We really need a script to reproduce.

It can be that the optimization in question unveiled a bug somewhere in Winston.","mcollina",52195,"2024-03-04 09:17:55","crash oom need script reproduce optimization unveil bug winston
"
787,161,"@mcollina

> Does it crash for an OOM?

Yes, it does, I let the code run its course this time and it ends up crashing as follows:  
```
# ./memleak.sh
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 unpipe listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(Use `node20 --trace-warnings ...` to show where the warning was created)
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 error listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 unpipe listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 error listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 drain listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 close listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 finish listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 drain listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 close listeners added to [File]. Use emitter.setMaxListeners() to increase limit
(node:373378) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 finish listeners added to [File]. Use emitter.setMaxListeners() to increase limit

<--- Last few GCs --->

[373378:0x308ebee0]  1331902 ms: Scavenge 4061.9 (4140.6) -> 4060.6 (4140.8) MB, 5.90 / 0.00 ms  (average mu = 0.703, current mu = 0.013) task; 
[373378:0x308ebee0]  1331959 ms: Scavenge 4062.1 (4140.8) -> 4060.7 (4140.8) MB, 5.48 / 0.00 ms  (average mu = 0.703, current mu = 0.013) task; 
[373378:0x308ebee0]  1332002 ms: Scavenge 4062.2 (4140.8) -> 4060.9 (4145.1) MB, 6.06 / 0.00 ms  (average mu = 0.703, current mu = 0.013) task; 


<--- JS stacktrace --->

FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory
----- Native stack trace -----

 1: 0xc8640c node::Abort() [node20]
 2: 0xb755c8 void node::FPrintF<>(_IO_FILE*, char const*) [node20]
 3: 0xe8450c v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, v8::OOMDetails const&) [node20]
 4: 0xe846dc v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, v8::OOMDetails const&) [node20]
 5: 0x108c3ec  [node20]
 6: 0x10a28c4 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node20]
 7: 0x10f36b0 v8::internal::MinorGCJob::Task::RunInternal() [node20]
 8: 0xcf47f8  [node20]
 9: 0xcf72ec node::PerIsolatePlatformData::FlushForegroundTasksInternal() [node20]
10: 0x17c1ad0  [node20]
11: 0x17d5414  [node20]
12: 0x17c288c uv_run [node20]
13: 0xbaeb58 node::SpinEventLoopInternal(node::Environment*) [node20]
14: 0xccc3d0  [node20]
15: 0xcccd00 node::NodeMainInstance::Run() [node20]
16: 0xc4615c node::Start(int, char**) [node20]
17: 0xffff82c20e10 __libc_start_main [/lib/aarch64-linux-gnu/libc.so.6]
18: 0xbacfa0  [node20]
./memleak.sh: line 3: 373378 Aborted                 node20 dist/index.js
```
  
For reference `memleak.sh` is just:  
```  
#!/usr/bin/env bash

node20 dist/index.js
```
  
where `node20 --version` is `v20.11.1`.    
  
And afterwards I ran it with the revert patch applied and here are the two memory/cpu usage graphs again:   
![Screenshot from 2024-03-04 13-42-41](https://github.com/nodejs/node/assets/13771292/0b1b57fd-38d8-44de-a28f-7bc5b1a7a783)  
     
> We really need a script to reproduce.
  
The following snippets of code seem to be enough to reproduce the problem - [link](https://github.com/kshaa/node-memory-leak).   
  
On one hand - perhaps this code just produces so many logs that winston can't manage to process them quickly enough so they accrue in-memory and eventually crash with OOM.    
On the other hand - I wonder why this memory leak happens only in `v20.11.1` and it does not leak when I revert that commit.   
  ","kshaa",13771292,"2024-03-04 11:48:01","crash oom code run crash maxlistenersexceededwarning possible event emitter memory leak detect unpipe listener add file use emitter setmaxlisteners increase limit error listener drain listener close listener finish listener garbage collect scavenge mb task fatal error reach heap limit allocation fail javascript heap memory node abort print v8 utils reportoomfailure v8 internal v8 heap collectgarbage v8 internal minor gc job task runinternal node perisolatplatformdata flushforegroundtasksinternal uv run node spin eventloopinternal node nodemaininstance run node start libc start main abort reproduce script reproduce problem code produce log winston manage process accrue memory crash oom memory leak happen revert commit
"
788,161,"@mcollina Could you please provide any updates? Thank you.","yannis-tseng",48202988,"2024-03-26 05:01:01","provide update thank
"
996,196,"[v20.6.1](https://github.com/nodejs/node/releases/tag/v20.6.1) is stable.","meyfa",3982806,"2023-09-18 18:44:40","stable
"
997,197,"unfortunately, I am not able to reproduce this ","MoLow",8221854,"2023-08-30 04:38:35","able reproduce
"
790,161,"Unfortunately don't have a more concrete example without using `winston`. However it seems that the memory leak is not present anymore in node `v20.12.1`.  
  
Tested on my staging environment:  
![Screenshot from 2024-04-04 13-18-50](https://github.com/nodejs/node/assets/13771292/a2fa7d96-e5cb-43fb-945f-f35d22ed2ae5)  
  
Also tested with the [simplified test case](https://github.com/kshaa/node-memory-leak) which only uses `node` and `winston`:  
![Screenshot from 2024-04-04 13-22-12](https://github.com/nodejs/node/assets/13771292/840e6a4b-2440-4b6b-8be7-23af929147d9)

","kshaa",13771292,"2024-04-04 10:40:39","unfortunately concrete example use winston seem memory leak present node test staging environment also test simplify test case use node winston
"
791,161,"Then... closing.","mcollina",52195,"2024-04-04 11:16:46",NULL
792,162,"/cc @nodejs/whatwg-stream ","aduh95",14309773,"2024-02-12 17:36:46","nodejs whatwg stream
"
793,162,"Good finding! Are you planning to send a PR to fix?","mcollina",52195,"2024-02-13 06:45:23","good find plan send pr fix
"
794,162,"@mcollina Sure, I can do that. I'll wait for the spec change to land first.","MattiasBuelens",649348,"2024-02-13 06:57:13","sure wait spec change land
"
795,163,"I agree subtest `after` and `afterEach` should be called before parent @nodejs/test_runner.
I couldnt reproduce with `test`though.

This works fine:
```js
'use strict';
require('../common');
const assert = require('node:assert');
const { test, afterEach, after } = require('node:test');


let afterEachRacing = true;
let afterRacing = true;

test('parent', () => {
    afterEach(() => afterEachRacing = false);
    after(() => afterRacing = false);

    test('child', () => {
        afterEach(() => assert.ok(afterEachRacing));
        after(() => assert.ok(afterRacing));
        test(() => { });
    });
});

```
this fails:
```js
'use strict';
require('../common');
const assert = require('node:assert');
const { describe, it,  afterEach, after } = require('node:test');


let afterEachRacing = true;
let afterRacing = true;

describe('parent', () => {
    afterEach(() => afterEachRacing = false);
    after(() => afterRacing = false);

    describe('child', () => {
        afterEach(() => assert.ok(afterEachRacing));
        after(() => assert.ok(afterRacing));
        it(() => { });
    });
});
```","marco-ippolito",36735501,"2024-02-07 10:55:30","agree subtest call parent nodejs test_runner reproduce test work fine fail
"
796,163,"I meant that

```js
test('parent', async (t) => {
  t.afterEach((c) => console.log('parent after each', c.name));
  t.after((c) => console.log('parent after', c.name));

  await t.test('child', async (t) => {
    t.afterEach((c) => console.log('child after each', c.name));
    t.after((c) => console.log('child after', c.name));
  
    await t.test('works', () => {});
  });
});
```

produces

```
parent after each works
child after each works
parent after each child
child after child
parent after parent
```

instead of

```
child after each works
parent after each works
parent after each child
child after child
parent after parent
```

so the parent's afterEach for `works` runs before the child's.","bendemboski",559001,"2024-02-07 16:32:00","parent after each work child after each work parent after each child child after child parent after parent child after each work parent after each work
"
797,164,"@nodejs/url","targos",2352663,"2024-01-29 12:28:37","nodejs url
"
798,164,"@anonrig it seems like an issue with ada parse
```c++
  auto out = ada::parse<ada::url_aggregator>(input.ToStringView());
  ```","marco-ippolito",36735501,"2024-01-29 15:44:57","issue ada parse
"
799,164,"I am checking it.","lemire",391987,"2024-01-29 15:48:44","check
"
800,164,"It is a bug in ada. See https://github.com/ada-url/ada/pull/583

@anonrig will need to review.","lemire",391987,"2024-01-29 16:57:09","bug ada review
"
801,164,"For people who are curious, we did not have any test with an IPv4 address containing ignorable Unicode characters. This was just an untested code path.","lemire",391987,"2024-01-29 16:58:31","test ipv4 address contain unicode character untested code path
"
802,164,"@anonrig has approved my fix and the fix is merged. A new release of ada will be necessary to fix this issue in node.","lemire",391987,"2024-01-29 17:36:17","approve fix merge new release ada necessary fix issue node
"
803,164,"Fixed on main with https://github.com/nodejs/node/pull/51542, should be included in the next release and backported","marco-ippolito",36735501,"2024-02-04 17:15:55","fix main include next release backport
"
804,165,"@nodejs/url ","aduh95",14309773,"2024-01-18 21:40:28","nodejs url
"
805,165,"It seems to be a bug of `ada-url/ada` that not doing well with boundary case.

see https://github.com/ada-url/ada/pull/581.","ChenKS12138",42082890,"2024-01-21 10:29:11","bug ada url boundary case
"
806,165,"Fixed on main by https://github.com/nodejs/node/pull/51542, should be included in the next release and backported","marco-ippolito",36735501,"2024-02-04 17:13:01","fix main include next release backport
"
807,166,"This is also fixed in this PR https://github.com/nodejs/node/pull/51289
cc: @anonrig @marco-ippolito ","IlyasShabi",33763729,"2024-01-18 18:01:11","fix pr
"
808,167,"You can just remove `done` and it will work as expected.
```javascript
  test(""callback test"", () => {
    setTimeout(() => {
      assert.ok(false, ""oh no an assert failed"");
    });
  });
```
AFAIK `done` is useful when you have function thats take a callback and you want to check that it is called or when for some reason can't use assertions:

```javascript
const { describe, it } = require(""node:test"");
const assert = require(""node:assert"");
const fs = require('node:fs');

describe(""describe wrapper"", async () => {
    it(""callback test"", (t, done) => {
        fs.readFile('package.json', (err, data) => {
            if (err) done(err); // will fail with [Error: ENOENT: no such file or directory
            else assert.ok(data);
        });
    }, 0);
});
```
PRs to improve the documentation are always welcomed","marco-ippolito",36735501,"2024-01-05 13:24:18","remove work expect callback test assert fail use assertion describe wrapper callback test read file error fail error assert ok improve documentation welcome
"
822,169,"I suspect eventNames() is called a lot less frequently than the benefits of that pre-allocation PR, so I would suggest changing eventNames to do a more rigorous check that the keys are not only _there_ but also are non-empty arrays.","Qard",205482,"2024-01-01 07:23:33","suspect eventName call lot less frequently benefit pre allocation pr suggest change eventName rigorous check key non empty array
"
823,169,"Hey @Qard can you pls tell me a instance where we are using the `eventNames()`, it will be a lot easier for me if you can do so!!","Medhansh404",139563645,"2024-01-01 11:50:24","Hey Qard tell instance use eventNames easier
"
824,169,"@juanarbol I was looking into the issue, and I found myself creating a PR. I'm not sure if it's the right way to do it, but I would like to know how you will fix it.","IlyasShabi",33763729,"2024-01-01 12:45:13","look issue find create pr sure right way like know fix
"
825,170,"@nodejs/loaders ","targos",2352663,"2023-12-21 08:25:01","nodejs loader
"
860,179,"Could you please provide a very minimal reproduction steps? A tiny code snippet will be helpful for us to debug the issue. ","MrJithil",26359740,"2023-11-16 13:00:10","provide minimal reproduction step tiny code snippet helpful debug issue
"
1441,251,"> Fix in #45495

That was quick! Great stuff 👍 ","tkarls",5672845,"2022-11-17 15:03:29","fix quick great stuff
"
809,167,"That doesn't quite work as expected. In that case, the error gets thrown  disconnected from any test, so it looks like all tests are passing, but then there's a mysterious `'test failed'` (again, in green?) and a discussion about generating async activity.

<details>
<summary>Modified script</summary>

```js
""use strict"";
const { describe, test } = require(""node:test"");
const assert = require(""node:assert"");

describe(""describe wrapper"", () => {
  test(""callback test"", () => {
    setTimeout(() => {
      assert.ok(false, ""oh no an assert failed"");
    });
  });

  test(""promise test"", async () => {
    assert.ok(true, ""this assert will pass"");
  });
});

describe(""another describe block"", () => {
  test(""sync test"", () => {
    assert.ok(true, ""this assert will pass 2"");
  });
});
```
</details>

Output:

```
$ node --test test.js
▶ describe wrapper
  ✔ callback test (0.3599ms)
  ✔ promise test (0.1025ms)
▶ describe wrapper (1.6332ms)

▶ another describe block
  ✔ sync test (0.0629ms)
▶ another describe block (0.193ms)

ℹ Warning: Test ""callback test"" generated asynchronous activity after the test ended. This activity created the error ""AssertionError [ERR_ASSERTION]: oh no an
assert failed"" and would have caused the test to fail, but instead triggered an uncaughtException event.
✖ test.js (41.915ms)
  'test failed'

ℹ tests 4
ℹ suites 2
ℹ pass 3
ℹ fail 1
ℹ cancelled 0
ℹ skipped 0
ℹ todo 0
ℹ duration_ms 47.6652

✖ failing tests:

test at test.js:1:1
✖ test.js (41.915ms)
  'test failed'
```

My expectation is that callback tests wait on the callback to be called, or an error to be thrown, in order to tie any thrown errors to the in-progress test. That's how they work in other test frameworks.","domenic",617481,"2024-01-05 13:51:59","work expect case error throw disconnect test look test pass mysterious test fail green discussion generate async activity
"
810,167,"@nodejs/test_runner @MoLow I think in any case the callback test failing shouldn't interfere with any of the other tests.

Re: the second example - The ""fail the test file for an uncaught error"" behavior actually seems reasonable to me.","benjamingr",1315533,"2024-01-05 15:14:21","think case callback test fail interfere test file uncaught error behavior seem reasonable
"
811,167,"> @nodejs/test_runner @MoLow I think in any case the callback test failing shouldn't interfere with any of the other tests.
> 
> Re: the second example - The ""fail the test file for an uncaught error"" behavior actually seems reasonable to me.

I agree with both these statments","MoLow",8221854,"2024-01-06 21:33:08","test runner think case callback test fail interfere test example fail test file uncaught error behavior seem reasonable agree statement
"
812,167,"If the test goes in 'uncaughtException' it's not possible to recover, so it will interfere with other test.
```
The correct use of 'uncaughtException' is to perform synchronous cleanup of allocated resources
(e.g. file descriptors, handles, etc) before shutting down the process.
It is not safe to resume normal operation after 'uncaughtException'.
```

I agree with the second statement","marco-ippolito",36735501,"2024-02-04 17:31:24","test go uncaughtException possible recover interfere test correct use uncaughtException perform synchronous cleanup allocate resource file descriptor handle shut process safe resume normal operation uncaughtException agree statement
"
813,167,"In other test frameworks, the framework is responsible for catching the exception, so it never reaches uncaughtException.","domenic",617481,"2024-02-04 23:43:54","test framework responsible catch exception reach uncaughtException
"
814,167,"This seems to fix the issue. The problem is that [this never finishes](https://github.com/nodejs/node/blob/8a41d9b636be86350cd32847c3f89d327c4f6ff7/lib/internal/test_runner/test.js#L637).

```diff
diff --git a/lib/internal/test_runner/harness.js b/lib/internal/test_runner/harness.js
index 469ca903c7..b62d4dded6 100644
--- a/lib/internal/test_runner/harness.js
+++ b/lib/internal/test_runner/harness.js
@@ -74,7 +74,7 @@ function createProcessEventHandler(eventName, rootTest) {
     }
 
     test.fail(new ERR_TEST_FAILURE(err, eventName));
-    test.postRun();
+    test.abortController.abort();
   };
 }
```

It might also be worth considering [`ref()'ing` this timer](https://github.com/nodejs/node/blob/8a41d9b636be86350cd32847c3f89d327c4f6ff7/lib/internal/test_runner/test.js#L91) or implementing another waiting technique, because currently, the following code does not honor its timeout.

```js
const { test } = require('node:test');

test({ timeout: 3000 }, (t, done) => {
  // done() is not called but there are no ref()'ed handles so we exit.
});
```

It might also be worth considering setting a reasonable default test timeout instead of Infinity for the same reason.

Speaking of test timeouts, the new `--test-timeout` CLI flag behaves surprisingly. Consider the following code run with `--test-timeout=2000`. It correctly times out when used with `--test`, but passes without `--test`. I believe that's because it is not incorporated into [`parseCommandLine()`](https://github.com/nodejs/node/blob/8a41d9b636be86350cd32847c3f89d327c4f6ff7/lib/internal/test_runner/utils.js#L189) and the logic that uses it.

```js
const { test } = require('node:test');

test((t, done) => {
  setTimeout(done, 3000);
});
```","cjihrig",2512748,"2024-02-09 04:37:58","fix issue problem never finish consider implement wait technique currently code honor timeout consider set reasonable default test timeout infinity reason speak test timeout new cli flag behave surprisingly consider code run correctly time use pass believe incorporate logic use
"
815,167,"I find a similar bug that Node.js test runner works well in Codespaces and throw errors just like this issue in GitHub actions, they are all running in latest Linux + Node.js 20:
- Source codes: idea2app/GitHub-RESTful-middleware@ea82b92
- CI logs: https://github.com/idea2app/GitHub-RESTful-middleware/actions/runs/10534720786","TechQuery",19969570,"2024-08-24 02:07:15","bug node.js test runner work codespace throw error github action run latest linux node.js source code ci log
"
816,167,"Hey, this issue has been resolved for several months. If you're experiencing an issue, please open a new issue or visit nodejs/help.","avivkeller",38299977,"2024-08-24 02:22:15","resolve issue experience issue open new issue
"
817,168,"in this case 
```
import { test, before, after } from 'node:test';
import { open } from 'node:fs/promises';

let filehandle;

before(async () => {
  console.log('before');
  filehandle = await open('./index.mjs', 'r');
});

after(async () => {
  console.log('after');
  await filehandle.close();
});


// test('test', async (t) => {
// //   await t.test(() => {});
// });
```
The after hook is called AFTER the end of the root test","marco-ippolito",36735501,"2024-01-05 20:10:06","case hook call end root test
"
818,168,"Reopening due to https://github.com/nodejs/node/issues/51997","mcollina",52195,"2024-03-07 08:58:18","reopen due
"
819,169,"I will _try_ to fix this one","juanarbol",17013303,"2023-12-31 06:43:31","try fix one
"
820,169,"@juanarbol do you mind if you share how are you planning to approach this issue, do you paln to make changes on the default undefined values or add something/ enhacement that caters to them the undefined listeners so that it won't cause events to be as one? i'm just curious 
 ","Medhansh404",139563645,"2023-12-31 15:17:05","approach issue plan change default undefined value add enhancement cater undefined listener cause event one curious
"
821,169,"> @juanarbol do you mind if you share how are you planning to approach this issue, do you paln to make changes on the default undefined values or add something/ enhacement that caters to them the undefined listeners so that it won't cause events to be as one? i'm just curious

I don't know yet, I will figure that out later.
I will reference the issue once I have something","juanarbol",17013303,"2023-12-31 21:41:45","plan approach issue plan change default undefined value add enhancement cater undefined listener cause event curious figure later reference issue something
"
826,171,"cc @nodejs/url ","anonrig",1935246,"2023-12-17 18:28:10","nodejs url
"
947,190,"Created PR. ","MrJithil",26359740,"2023-09-25 12:02:26","PR
"
827,171,"Hello,
I am interested in contributing to Node.js and would like to work on my first issue. However, I am a bit confused because I thought that most file systems and operating systems do not allow null characters in file names. I have configured that this issue still occurs in Node.js version 22.5.1. If this is indeed a problem that needs to be addressed, may I work on it?","injunchoi98",80089617,"2024-07-20 08:43:00","contribute node js work first issue confuse file system operating system allow null character file name configure issue occur node js version problem address work
"
828,171,"You can work on any issue you'd like. If you have a suggested improvement to any part of the code base, feel free to submit a PR.","avivkeller",38299977,"2024-07-20 21:50:29","work issue suggest improvement part code base submit pr
"
829,171,"It looks like this issue got resolved in v22.12, as you can see here:

![screenshot showing that the error can get reproduced in v22.11 but not v22.12](https://github.com/user-attachments/assets/ea782302-4a83-4714-bf3a-b3fb228b9782)

(and it still works as intended in v23) So I think that it is fine to close this issue","dario-piotrowicz",61631103,"2025-01-25 17:52:31","look issue resolve v22 work intend v23 fine close issue
"
830,173,"Thanks for the report and the repro case!
I'm gonna work on a fix for this <3","juanarbol",17013303,"2023-12-06 03:16:50","report repro case work fix
"
831,173,"I'm sorry to say that this is a race condition. The code itself is a bit confusing, and the problem is that you are setting the handlers for an event at the same time that you are unsettling them.

When you listen to the new handler, the events for `SIGINT` in `process` is `fallbackHandler`, __not__ `[fallbackHandler, realHandler]` (is not an array containing both handlers), at that point you have that state and you scheduled a `removeHandler` that which will reach this point https://github.com/nodejs/node/blob/99f6084ef04dd868c7b894ca0fdbb5088773ca6c/lib/events.js#L700 who will __schedule a  delete__ to all the handlers (no matter what cuz' that was the state when you schedule that task, having just one handler, not both), then it will append the `realHandler` but the scheduled task will delete all the listeners associated to `SIGINT`, to avoid that, you schedule the delete of the `fallbackListener` on the next tick, that's why the `setInmediate` makes that work as expected, it has the `events` handler list object ready to be modified again.

I don't think Node.js needs to change the behavior for this specific case, it could break a lot of things over there; this behavior has been since Node.js v1.2.0 see https://github.com/nodejs/node/pull/601, especially if your case can be easily fixed. Another working ""equivalent"" snippet is:

```js
const fallbackHandler = () => console.debug(""in fallback handler"");

process.on(""SIGINT"", fallbackHandler);
process.on(""newListener"", (event) => event === ""SIGINT"" && process.nextTick(() => process.off(""SIGINT"", fallbackHandler)));

process.on(""SIGINT"", function realHandler () { console.debug(""in real handler"")});
process.stdin.resume();

```","juanarbol",17013303,"2023-12-13 22:34:47","sorry say race condition code bit confusing problem set handler event time unsettl listen new handler event sigint process fallbackhandler not array contain handler point state schedule removehandler reach point schedule delete handler matter state schedule task one handler append realhandler schedule task delete listener associate sigint avoid schedule delete fallbacklistener next tick setinmediate make work expect event handler list object ready modify think nodejs need change behavior specific case could break lot thing behavior nodejs v120 see case easily fix another work equivalent snippet fallbackhandler consoledebug fallback handler process sigint fallbackhandler process newlistener event event sigint process nexttick process sigint fallbackhandler process sigint realhandler consoledebug real handler process stdin resume
"
832,173,"Thanks for opening this issue, I had a bit of fun!","juanarbol",17013303,"2023-12-13 22:35:35","Thanks open issue bit fun
"
833,173,"That implementation is a bit weird in how it switches between a list and a single value; I assume that's for efficiency? Anyway, I'm not sure that's what's happening here. Unless I'm missing something, the sequence seems to be (and the code looks perfectly sequential, with no race possible that I can see):

- `addListener()`
  - [`emit('newListener')`](https://github.com/nodejs/node/blob/99f6084ef04dd868c7b894ca0fdbb5088773ca6c/lib/events.js#L562)
    - `removeListener()`
      - [`delete events[""SIGINT""]`](https://github.com/nodejs/node/blob/99f6084ef04dd868c7b894ca0fdbb5088773ca6c/lib/events.js#L700)
  - [`events[""SIGINT""] = realHandler`](https://github.com/nodejs/node/blob/99f6084ef04dd868c7b894ca0fdbb5088773ca6c/lib/events.js#L574)

Which should work as expected. The fact that I can't replicate the same issue with a plain `EventEmitter` seems to confirm it:

```javascript
// evtest.js
const { EventEmitter } = require(""node:events"");

const ee = new EventEmitter();
const fallbackHandler = () => console.debug(""in fallback handler"");

ee.on(""SIGINT"", fallbackHandler);
ee.on(""newListener"", (event) => event === ""SIGINT"" && ee.off(""SIGINT"", fallbackHandler));

ee.on(""SIGINT"", () => console.debug(""in real handler""));

process.on(""SIGINT"", () => ee.emit(""SIGINT""));

process.stdin.resume();
```

```console
$ node evtest.js
^Cin real handler
```

Something else seems to be going on here.","dividedmind",823636,"2023-12-18 11:22:20","implementation bit weird switches list single value assume efficiency sure happening missing something sequence seems code looks perfectly sequential race possible addListener emit newListener removeListener delete events sigint events sigint realhandler work expected fact replicate issue plain EventEmitter seems confirm evtest js const eventemitter require node events const ee new eventemitter const fallbackhandler console debug fallback handler ee sigint fallbackhandler ee newlistener event event sigint ee sigint fallbackhandler ee sigint console debug real handler process sigint ee emit sigint process stdin resume node evtest js cin real handler something else
"
834,174,"According to the spec, this is a bug in node.js

Spec:
- https://console.spec.whatwg.org/#logger
- https://console.spec.whatwg.org/#formatter
- https://tc39.es/ecma262/#sec-tostring","himself65",14026360,"2023-11-25 22:57:30","accord spec bug node


**Explicação do Pré-processamento:**

1. **Remoção de ruídos:** As URLs foram removidas.  Não há tags HTML neste texto. Caracteres especiais não estavam presentes.

2. **Padronização de palavras:**  ""According"" foi reduzido para ""accord"".  ""is"" é uma palavra pequena o suficiente para ser mantida (a remoção de verbos auxiliares como ""is"" dependendo do contexto, às vezes é recomendada em NLP mas não é obrigatória para todas as aplicações). O plural ""specs"" foi reduzido para ""spec"" (embora a concisão da frase pudesse resultar em uma perda de informação neste caso).

3. **Remoção de stop words:** ""The"", ""a"", ""in"" foram removidas, pois são stop words comuns em inglês.

A saída é uma representação simplificada do texto original, ideal para uso em um classificador de issues, pois mantém as palavras-chave mais relevantes (""accord"", ""spec"", ""bug"", ""node"").  Note que a decisão de manter ou remover palavras como ""is"" pode variar dependendo da técnica e do modelo de classificação utilizados.
"
835,174,"Looking into it.","MrJithil",26359740,"2023-11-27 05:10:22","look
"
836,174,"I believe this is because `console.log(""%s"", o) `calls `inspect` to obtain the object.

https://github.com/nodejs/node/blob/2f4065250e453da2de2ee9cbb8aaae28cbdb4df5/lib/internal/util/inspect.js#L2197-L2216","Ch3nYuY",110093775,"2023-12-01 08:46:05","believe call inspect obtain object
"
837,175,"Let me know if you need more details on how to reproduce, I could perhaps create a small repo to show the issue if it helps.","KidkArolis",324440,"2023-11-23 15:21:58","need detail reproduce create small repo show issue
"
838,175,"Could you produce a repro that doesn't include downloading any external code? If not, you should report it to the dependency you are using.","aduh95",14309773,"2023-11-23 16:00:05","produce repro include download external code report dependency use
"
839,175,"Working on reproducing it in a standalone file, but this behaviour change happens strictly if running this with Node.js 20.10.0:

```
# Node 20.9.0 - works
NODE_OPTIONS=""--abort-on-uncaught-exception"" ./node_modules/.bin/knex migrate:make test

# Node 20.10.0 - does not work
NODE_OPTIONS=""--abort-on-uncaught-exception"" ./node_modules/.bin/knex migrate:make test

# Node 20.10.0 - works when no flag passed
./node_modules/.bin/knex migrate:make test
```","KidkArolis",324440,"2023-11-23 16:17:02","work reproduce standalone file behaviour change happen strictly run node js 20 10 0 node 20 9 0 work node 20 10 0 work flag pass
"
1506,261,"Thank you for reporting! I can reproduce this issue on v18.8.0.","cola119",22386678,"2022-08-27 13:29:18",NULL
840,175,"I've put together a repo here: https://github.com/tjenkinson/node-20.10.0-ERR_REQUIRE_ESM-crash

It seems instead of the `ERR_REQUIRE_ESM` error being thrown now when esm is `require`'d it crashes.

From the debugger it looks like it might be a crash happening in the internal `containsModuleSyntax` module?","tjenkinson",3259993,"2023-11-23 16:29:36","put repo seem instead err require esm error throw crash debugger look like crash happen internal containsmodule syntax module
"
841,175,"Just pushed a new commit to that repro that changes it slightly. It seems to be when it's a module in `node_modules` that it trips up.","tjenkinson",3259993,"2023-11-23 16:44:15","push commit repo change slight module node_module trip
"
842,175,"Looks like the crash is here: https://github.com/nodejs/node/blob/4e713a3930b0758231ebaf6debbf30bb18eec920/lib/internal/modules/cjs/loader.js#L1406

And this was added in https://github.com/nodejs/node/commit/a9b25356c0d651965b71ccd7802dfa373304deb8","tjenkinson",3259993,"2023-11-23 17:04:15","crash add
"
843,175,"Here's a C++ backtrace:

```
  * frame #0: 0x0000000102254f78 node`v8::base::OS::Abort() [inlined] v8::base::OS::Abort()::$_0::operator()(this=<unavailable>) const at platform-posix.cc:698:5 [opt]
    frame #1: 0x0000000102254f78 node`v8::base::OS::Abort() at platform-posix.cc:698:5 [opt]
    frame #2: 0x000000010095ef6c node`v8::internal::Isolate::CreateMessageOrAbort(this=<unavailable>, exception=<unavailable>, location=<unavailable>) at isolate.cc:1799:7 [opt]
    frame #3: 0x000000010095e0e4 node`v8::internal::Isolate::ThrowInternal(this=0x0000000128008000, raw_exception=Tagged<v8::internal::Object> @ x24, location=0x000000016fdfc390) at isolate.cc:1888:36 [opt]
    frame #4: 0x000000010095d9ac node`v8::internal::Isolate::ThrowAt(this=0x0000000128008000, exception=Handle<v8::internal::JSObject> @ x21, location=0x000000016fdfc390) at isolate.cc:1655:10 [opt]
    frame #5: 0x0000000101049728 node`v8::internal::PendingCompilationErrorHandler::ThrowPendingError(this=<unavailable>, isolate=0x0000000128008000, script=Handle<v8::internal::Script> @ x21) const at pending-compilation-error-handler.cc:200:12 [opt]
    frame #6: 0x00000001007e018c node`v8::internal::(anonymous namespace)::CompileToplevel(v8::internal::ParseInfo*, v8::internal::Handle<v8::internal::Script>, v8::internal::MaybeHandle<v8::internal::ScopeInfo>, v8::internal::Isolate*, v8::internal::IsCompiledScope*) [inlined] v8::internal::(anonymous namespace)::FailWithPreparedPendingException(isolate=0x0000000128008000, script=Handle<v8::internal::Script> @ x20, pending_error_handler=0x000000016fdfc750, flag=KEEP_EXCEPTION) at compiler.cc:1437:30 [opt]
    frame #7: 0x00000001007e0174 node`v8::internal::(anonymous namespace)::CompileToplevel(v8::internal::ParseInfo*, v8::internal::Handle<v8::internal::Script>, v8::internal::MaybeHandle<v8::internal::ScopeInfo>, v8::internal::Isolate*, v8::internal::IsCompiledScope*) [inlined] v8::internal::(anonymous namespace)::FailWithPendingException(isolate=0x0000000128008000, script=Handle<v8::internal::Script> @ x20, parse_info=0x000000016fdfc5b8, flag=KEEP_EXCEPTION) at compiler.cc:1449:10 [opt]
    frame #8: 0x00000001007e0174 node`v8::internal::(anonymous namespace)::CompileToplevel(parse_info=0x000000016fdfc5b8, script=Handle<v8::internal::Script> @ x20, maybe_outer_scope_info=MaybeHandle<v8::internal::ScopeInfo> @ x23, isolate=0x0000000128008000, is_compiled_scope=<unavailable>) at compiler.cc:1571:5 [opt]
    frame #9: 0x00000001007e3e30 node`v8::internal::Compiler::GetWrappedFunction(source=<unavailable>, arguments=<unavailable>, context=<unavailable>, script_details=0x000000016fdfc858, cached_data=<unavailable>, compile_options=<unavailable>, no_cache_reason=<unavailable>) at compiler.cc:3810:20 [opt]
    frame #10: 0x000000010061521c node`v8::ScriptCompiler::CompileFunctionInternal(v8_context=<unavailable>, source=0x000000016fdfcda0, arguments_count=<unavailable>, arguments=0x00006000009650e0, context_extension_count=<unavailable>, context_extensions=<unavailable>, options=kNoCompileOptions, no_cache_reason=kNoCacheNoReason, script_or_module_out=0x0000000000000000) at api.cc:2724:10 [opt]
    frame #11: 0x0000000100614bc4 node`v8::ScriptCompiler::CompileFunction(context=Local<v8::Context> @ x0, source=<unavailable>, arguments_count=<unavailable>, arguments=0x00006000009650e0, context_extension_count=<unavailable>, context_extensions=<unavailable>, options=kNoCompileOptions, no_cache_reason=<unavailable>) at api.cc:2646:10 [opt]
    frame #12: 0x000000010024a030 node`node::contextify::ContextifyContext::CompileFunctionAndCacheResult(env=0x0000000121834000, parsing_context=Local<v8::Context> @ 0x000000016fdfcb50, source=0x000000016fdfcda0, params=size=5, context_extensions=size=0, options=kNoCompileOptions, produce_cached_data=true, id_symbol=Local<v8::Symbol> @ 0x000000016fdfcb48, try_catch=0x000000016fdfccf0) at node_contextify.cc:1345:35
    frame #13: 0x000000010024695c node`node::contextify::ContextifyContext::ContainsModuleSyntax(args=0x000000016fdfd788) at node_contextify.cc:1472:3
```","targos",2352663,"2023-11-23 17:30:21","v8 base os abort inline v8 base os abort platform posix cc opt v8 base os abort platform posix cc opt v8 internal isolate createmessageorabort exception location isolate cc opt v8 internal isolate throwinternal raw exception isolate cc opt v8 internal isolate throwat exception isolate cc opt v8 internal pendingcompilationerrorhandler throwpendingerror pending compilation error handler cc opt v8 internal anonymous namespace compiletoplevel inline v8 internal anonymous namespace failwithpreparedpendingexception compiler cc opt v8 internal anonymous namespace compiletoplevel inline v8 internal anonymous namespace failwithpendingexception compiler cc opt v8 internal anonymous namespace compiletoplevel compiler cc opt v8 internal compiler getwrappedfunction compiler cc opt v8 scriptcompiler compilefunctioninternal api cc opt v8 scriptcompiler compilefunction api cc opt node contextify contextifycontext compilefunctionandcacheresult node contextify cc node contextify contextifycontext containsmodulesyntax node contextify cc
"
844,175,"The crash happens within a TryCatch scope, so it seems like a V8 bug. It shouldn't abort in this case.","targos",2352663,"2023-11-23 17:32:38","crash happen trycatch scope seem v8 bug abort case
"
845,175,"I added some logs to the `PredictExceptionCatcher` and it returns here:

https://github.com/nodejs/node/blob/4e713a3930b0758231ebaf6debbf30bb18eec920/deps/v8/src/execution/isolate.cc#L2437-L2438

/cc @nodejs/cpp-reviewers ","targos",2352663,"2023-11-23 17:58:16","add log `Predictexceptioncatcher` return
"
846,175,"This looks like a negligence from our side of not disabling aborting temporarily for the syntax check in our ShouldAbortOnUncaughtException  callback.","joyeecheung",4299420,"2023-11-30 17:31:36","look negligence side disable abort temporarily syntax check callback
"
847,175,"cc @nodejs/loaders ","joyeecheung",4299420,"2023-11-30 22:15:17","nodejs loader
"
848,175,"@KidkArolis I opened a PR that fixes this issue.","anonrig",1935246,"2023-12-01 01:10:39","open pr fix issue
"
849,175,"@joyeecheung how do you explain that `PredictExceptionCatcher` doesn't find the TryCatch scope?","targos",2352663,"2023-12-01 11:15:43","explain predictExceptionCatcher find tryCatch scope
"
850,175,"> how do you explain that PredictExceptionCatcher doesn't find the TryCatch scope?

I think that's for JavaScript `try {} catch {}`, not `v8::TryCatch`.","joyeecheung",4299420,"2023-12-01 12:44:32","explain PredictExceptionCatcher find TryCatch scope think JavaScript try catch v8 TryCatch
"
851,176,"Actually, I just found out, that there is the same problem with read operations.
`shared_folder/read-file.js`
``` javascript
const fs = require(""fs"");

fs.readFile(""helloWorld.txt"", 'utf8', (err, data)=>{
		if (err) {
			console.error(err);
			return;
		}
		console.log(data);
	}
)
```
running `node read-file.js` outputs
```
[Error: ENOTSUP: operation not supported on socket, read] {
  errno: -95,
  code: 'ENOTSUP',
  syscall: 'read'
}
```","ig-onoffice-de",85568061,"2023-11-23 12:10:23","operation support socket read error
"
852,176,"I can confirm the issue happens when writing to a `vboxsf` filesystem using io_uring. Possible fix here: https://github.com/libuv/libuv/pull/4268","santigimeno",1084056,"2023-12-28 19:18:06","confirm issue happen write vboxsf filesystem use io_uring possible fix
"
853,178,"it has been fixed in node 20, you are using node 18 in the example
```
13:55:23 ~/Documents/projects/test $ nvm use 20
Now using node v20.9.0 (npm v10.1.0)
13:56:03 ~/Documents/projects/test $ node index.js
```","marco-ippolito",36735501,"2023-11-21 12:56:15","fix node 20 use node 18 example
"
854,178,"The two URLs are different.

- With Node v18, `assert.deepEqual` shows that there is a difference.
- With Node v20, `assert.deepEqual` doesn't return an error, although the URLs aren't equal.

It works in v18 and the bug is in v20.","regseb",1262990,"2023-11-21 13:08:55","node assert deepEqual url difference bug
"
855,178,"cc @anonrig ","marco-ippolito",36735501,"2023-11-21 13:12:19","anonrig retorno
"
856,178,"The difference is not about assert. It's about URL changing the properties of the object. In Node.js 18 the symbol was enumerable and therefore it was compared by assert. But the URL object changed in the meanwhile.","BridgeAR",8822573,"2023-11-21 13:36:40","difference url change property object node symbol enumerable compare assert url object change meanwhile
"
857,178,"I believe it is closely related to https://github.com/nodejs/node/pull/46904 which changing the `symbol` to `private property`.
`assert.deepEqual` only compare the enumerable properties, so it no longer able to check that `symbol` property.

Will it be acceptable to check like `Date` in here, and create an dedicated checking for `URL` object?
https://github.com/nodejs/node/blob/f425710f13d6e1b2a9664248434f6ba6df60e861/lib/internal/util/comparisons.js#L184-L204","climba03003",23028015,"2023-11-21 13:44:12","closely relate change symbol private property assert deepEqual compare enumerable property longer able check symbol property acceptable check date create dedicate check url object
"
858,178,"The [`util.isDeepStrictEqual(val1, val2)`](https://nodejs.org/dist/latest-v20.x/docs/api/util.html#utilisdeepstrictequalval1-val2) method has the same problem (probably because it uses the same code).

```JavaScript
const util = require(""node:util"");

const url1 = new URL(""http://foo1.com/"");
const url2 = new URL(""http://foo2.com/"");
console.log(util.isDeepStrictEqual(url1, url2));
// true
```","regseb",1262990,"2024-03-07 14:11:27","method problem code
"
859,178,"FYI There's the same problem with `Promise`. https://github.com/nodejs/node/issues/55198#issuecomment-2384180276

```javascript
import assert from 'node:assert/strict';

const promise1 = Promise.resolve(""foo"");
const promise2 = Promise.resolve(""bar"");
assert.deepEqual(promise1, promise2);
```","regseb",1262990,"2024-10-01 06:31:30","problem promise
"
861,179,"It is not possible to recreate. The error occurs randomly, when data is being fetched from the DB. This issue appears quite often because fetching happens a lot as well.","SanderKok01",58295226,"2023-11-21 11:29:31","recreate error occur randomly datum fetch db issue appear often fetch happen
"
862,179,"Is this issue comparable to #47644 ?
There is not a solution for me in this issue.","SanderKok01",58295226,"2023-11-21 11:34:35","issue comparable solution
"
863,179,"This is most likely due to #44731. cc @ShogunPanda","tniessen",3109072,"2023-11-21 22:18:11","likely due
"
864,179,"@SanderKok01 I'm sorry about the other issue. I'm catching up at work and then I'll finally able to address this.

Even tho is hard for you to reproduce the issue, can you please at least tell us if it happens when connecting to some specific hosts (even local, it doesn't matter) and eventually give us how the connecting host(s) DNS resolve such hosts?","ShogunPanda",201101,"2023-11-22 16:28:17","sorry issue catch work address hard reproduce issue tell happen connect specific host local matter eventually give connect host dns resolve host
"
865,179,"@ShogunPanda The command I'm using is `npm run dev`, which starts the local development environment at `localhost:1337`. But after some time, at random, the local server crashes and I have to restart. It always gives off the same error.

The connection to the local server itself is stable. Starting and using goes smoothly, until it just crashes. Sometimes without even doing anything, it just stops.

Please let me know if you have any other questions for me. Happy to help!","SanderKok01",58295226,"2023-11-23 08:00:35","crash local server restart error connection stable smooth stop
"
866,179,"Ok, that makes sense. I'll look into, it. Thanks for your informations.","ShogunPanda",201101,"2023-11-23 11:12:52","make sense look thanks information
"
867,179,"I am going to close this as a duplicate of https://github.com/nodejs/node/issues/48763, which is due to https://github.com/nodejs/node/pull/44731.","tniessen",3109072,"2023-12-02 18:32:32","close duplicate due
"
868,179,"This should have been fixed in #51045. Once it gets in 21.x or 20.x please let me know if you have additional problems.","ShogunPanda",201101,"2023-12-22 10:13:56","fix problem
"
869,180,"I thought this would be easy to fix when I saw

https://github.com/nodejs/node/blob/0304da22d35822dd4d9ee8e0b0b364979a3476e2/src/module_wrap.cc#L256

But this is not just an off-by-one issue.

For `import(jsModuleDataUrl, { with: { type: 'json', other: 'unsupported' } })` (test I added), the `raw_attributes` array contains 4 elements.

For ``import(`data:text/javascript,import${JSON.stringify(jsModuleDataUrl)}with{type:""json""}`)`` (existing test), it contains 3 elements.
","targos",2352663,"2023-11-13 10:20:12","issue off one array element contain element
"
870,180,"I don't understand how it's possible. The array is guaranteed to have a size that's a multiple of two:

https://github.com/nodejs/node/blob/0304da22d35822dd4d9ee8e0b0b364979a3476e2/deps/v8/src/execution/isolate.cc#L5446-L5448","targos",2352663,"2023-11-13 10:31:17","understand possible array guarantee size multiple two
"
871,180,"Debug build makes it a bit more understandable:

```
$ ./node_g test/es-module/test-esm-import-attributes-errors.mjs
FATAL ERROR: v8::String::Cast Value is not a String
----- Native stack trace -----

 1: 0x100645944 node::DumpNativeBacktrace(__sFILE*) [/Users/mzasso/git/nodejs/node/out/Debug/node]
 2: 0x100784638 node::Abort() [/Users/mzasso/git/nodejs/node/out/Debug/node]
 3: 0x100784798 node::OOMErrorHandler(char const*, v8::OOMDetails const&) [/Users/mzasso/git/nodejs/node/out/Debug/node]
 4: 0x100b344fc v8::String::CheckCast(v8::Data*) [/Users/mzasso/git/nodejs/node/out/Debug/node]
 5: 0x1005fd248 v8::String::Cast(v8::Data*) [/Users/mzasso/git/nodejs/node/out/Debug/node]
 6: 0x1006ed5e8 v8::Local<v8::String> v8::Local<v8::String>::Cast<v8::Data>(v8::Local<v8::Data>) [/Users/mzasso/git/nodejs/node/out/Debug/node]
 7: 0x1006ed590 v8::Local<v8::String> v8::Local<v8::Data>::As<v8::String>() const [/Users/mzasso/git/nodejs/node/out/Debug/node]
 8: 0x1006ea2dc node::loader::createImportAttributesContainer(node::Environment*, v8::Isolate*, v8::Local<v8::FixedArray>) [/Users/mzasso/git/nodejs/node/out/Debug/node]

```","targos",2352663,"2023-11-13 10:45:50","debug build make bit understandable fatal error v8 string cast value string native stack trace node abort oomerrorhandler v8 string checkcast v8 string cast v8 local string v8 local string cast v8 local data as v8 local string node loader createimportattributescontainer environment isolate local fixedarray
"
872,180,"Found the issue: https://github.com/nodejs/node/pull/50703","targos",2352663,"2023-11-13 11:05:17","issue
"
873,181,"Can confirm. The bug here is that the promise-based version allocates a 64k buffer and thinks it's done when it reads less than that. That optimization is valid for regular files but not for files under /proc. It should keep reading until EOF (zero read.)","bnoordhuis",275871,"2023-10-28 09:58:42","confirm bug promise base version allocate 64k buffer think read optimization valid regular file file proc keep read eof zero read
"
874,181,"(rookie question) Is there a way to way to check whether the file we are reading is one of these special files? other than maybe checking the path?","debadree25",20257253,"2023-10-28 12:44:37","rookie question way check file read special file path
"
875,181,"Checking the path isn't enough because a procfs can be mounted anywhere; /proc is just the most common.

Checking `fs.statfsSync(path).type === 0x9FA0` (PROC_SUPER_MAGIC) works but isn't race-free.

I'm not 100% sure if it's okay to assume that `fs.fstatSync(fd).dev === 22` means the file is on procfs.","bnoordhuis",275871,"2023-10-28 13:27:04","check path enough procfs mount common check fs statfsSync path type proc super magic work race free sure okay assume fs fstatSync fd dev file procfs
"
876,181,"Forgot to mention, linux has a `fstatfs(fd)` syscall but that isn't exposed by libuv. Would IMO be okay to use in a linux-only code path though.

edit: having said that... it's easier all around to simply read until EOF. Zero-sized files are rare enough that they aren't worth optimizing for. You're making at least two system calls either way.","bnoordhuis",275871,"2023-10-28 13:29:43","fstatfs syscall libuv okay linux code path easy read eof zero size file rare worth optimize system call
"
877,181,"@nodejs/fs ","benjamingr",1315533,"2023-10-28 14:58:39","nodejs fs
"
878,181,"Hi! It's been a few months since any activity on this issue. I just attempted to reproduce in v22.6.0, and I was unable to do:
```javascript
require(""fs/promises"").readFile(""/proc/net/unix"", ""utf-8"").then(x => console.log(x.length))
require(""fs"").readFile(""/proc/net/unix"", ""utf-8"", (_, x) => console.log(x.length))
```
```console
$ node index.js
75897
75897
```

For that reason, I'm optimistically closing this issue, but feel free to reopen.","avivkeller",38299977,"2024-08-08 22:00:47","reproduzir v22.6.0 incapaz fechar issue reabrir
"
879,182,"@nodejs/loaders ","benjamingr",1315533,"2023-10-27 14:12:58","nodejs loader
"
880,182,"It's probably because these imports are executed in order, but not in a forced sequence.
I guess currently we have the equivalent of `Promise.all(specifiers.map(s => import(s)))`, but I haven't looked at the code that handles this CLI option.","targos",2352663,"2023-10-27 14:28:56","probably import execute order forced sequence guess currently equivalent promise all specifier map import look code handle cli option
"
1532,265,"Filed in https://bugs.chromium.org/p/chromium/issues/detail?id=1350842","connor4312",2230985,"2022-08-07 19:17:16",NULL
881,182,"The relevant code is here:

https://github.com/nodejs/node/blob/0a0b8dfd0d3684d6602599e1f0d9d935b3758700/lib/internal/process/esm_loader.js#L24-L30

So it’s essentially as if you had written a single import file with:

```js
import './a.mjs'
import './b.mjs'
```

Instead of:

```js
await import('./a.mjs')
await import('./b.mjs')
```

We could change the current behavior from the first option to the second, but I think it would be a breaking change.","GeoffreyBooth",456802,"2023-10-27 15:53:31","code essentially single import file import a mjs import b mjs instead await import a mjs await import b mjs could change current behavior first option second think would break change
"
882,182,"I did not find this by accident. I wrestled with figuring out why my loaders were loading in a different order than I specified with --import.

This will people hard. Definitely goes against the principle of least surprise.

I think this must be changed.","giltayar",403268,"2023-10-27 16:02:07","find accident wrestle figure loader load order specify import people hard definitely go principle least surprise think change
"
883,182,"It also differs from how `--require` works, because by the nature of CommonJS everything in the first `--require` is loaded before the second one starts (though async activity kicked off by the first is not necessarily resolved before the second begins). I guess we could consider this a bug and therefore not a breaking change? @targos what do you think?","GeoffreyBooth",456802,"2023-10-27 16:48:18","differ nature commonjs everything require load second start async activity kick necessarily resolve second begin guess consider bug breaking change think
"
884,182,"In the static import case, b isn’t evaluated until all of a is finished, so it would be in serial i think?","ljharb",45469,"2023-10-27 17:14:45","static import case b evaluate finish serial
"
885,182,"> We could change the current behavior from the first option to the second, but I think it would be a breaking change.

But we need it to emulate loader chaining without extra hacks & wrappers. @arcanis, what do you think about Yarn PnP and possible `--loader`-> `--import` transition?","koshic",20106607,"2023-10-27 18:01:20","change current behavior first option second break change need emulate loader chain extra hack wrapper think yarn pnp possible loader import transition
"
886,182,"Definitely sounds to me like a bug, not a major change. It would be entirely reasonable for a user to _expect_ that the imports happen in serial as they _are_ serial to the app entrypoint, just not serial amongst each other.","Qard",205482,"2023-10-27 18:01:26","bug reasonable user expect import happen serial app entrypoint serial
"
887,182,"> But we need it to emulate loader chaining without extra hacks & wrappers. @arcanis, what do you think about Yarn PnP and possible `--loader`-> `--import` transition?

I didn't check yet but I'd also expect the `--import` flags to be executed sequentially - I'm also not sure why it'd prevent loader chaining if it was the case, do you have an example in mind?
","arcanis",1037931,"2023-10-27 22:28:33","need emulate loader chain extra hack wrapper think yarn pnp possibl loader import transition check expect import flag execute sequentiali sure prevent loader chain example mind
"
888,182,"> I’m also not sure why it’d prevent loader chaining if it was the case, do you have an example in mind?

Because `import` statements are async, even if that async-ness is obscured. Consider:

```js
// a.js
import { register } from 'node:module'
import typescript from 'typescript'

register('./hooks-a.js', import.meta.url)
typescript.doSomethingWithThis()

// b.js
import { register } from 'node:module'

register('./hooks-b.js', import.meta.url)
```

When run via `--import ./a.js --import ./b.js`, Node evaluates this as if you had written a root file of:

```js
import './a.js'
import './b.js'
```

The way ESM is specified, modules are evaluated from the leaves of the tree back up to the root. So the first code to get evaluated here is whatever is in `typescript`, then back up to `a.js` and `b.js` (not necessarily in that order). Others understand this better than I do; see https://stackoverflow.com/questions/35551366/what-is-the-defined-execution-order-of-es6-imports

Anyway I agree that this is surprising and that Node should evaluate `--import`s sequentially rather than in parallel. My only concern is whether changing this would break anyone.","GeoffreyBooth",456802,"2023-10-27 22:48:07","sure prevent loader chaining example mind import statement async async ness obscure consider register node module typescript dosomethingwith register hook node module run import import node evaluate write root file import import way esm specify module evaluate leaf tree root code evaluate typescript back js necessarily order understand see agree surprising node evaluate import sequentially parallel concern break anyone
"
889,182,"> why it'd prevent loader chaining if it was the case, do you have an example in mind?

Sure. Let's assume that yarn use `--import` instead of `--experimental-loader` for .pnp.loader.mjs (with `register` call inside)  and set `NODE_OPTIONS='--import /project-path/.pnp.loader.mjs'`. The following scenarios will fail:

1. `yarn node --import any-package app.js` - can't resolve `any-package`, there is no node_modules on disk

2. The same as 1 - can't resolve `cool-hooks`:
```js
// ts-transpiler.mjs
import { register } from 'node:module';
register('cool-hooks'); // failed
```
`yarn node --import ./ts-transpiler.mjs app.ts`

3. Depends on whether `register` in .pnp.loader.mjs was executed or not:
```js
// ts-transpiler.mjs
import { register } from 'node:module';
register('./local-hook.mjs');

// local-hook.mjs
const esbuild = await import('esbuild'); // random crashes
```
`yarn node --import ./ts-transpiler.mjs app.ts`
","koshic",20106607,"2023-10-27 23:48:58","prevent loader chain example yarn use import experimental loader pnp loader mjs register call set node option import project path pnp loader mjs scenario fail yarn node import any package app js resolve any package node module disk resolve cool hook register node module register cool hook fail yarn node import ts transpiler mjs app ts depend register pnp loader mjs execute register node module register local hook mjs local hook mjs esbuild import esbuild random crash yarn node import ts transpiler mjs app ts
"
890,182,"> `yarn node --import any-package app.js` - can't resolve any-package, there is no `node_modules` on disk

If it's made sequential, I'd expect the `--import` calls from the NODE_OPTIONS to be evaluated prior to the ones from the command line (same as for `--requure`), so it should work 🤔

One thing to be careful about is that the resolution for `any-package` won't be able to start until after the precedent imports have finished executing, but that's already the case for `--loader`, so as long as we keep that it sounds ok.","arcanis",1037931,"2023-10-28 07:34:58","yarn node import package app js resolve package node module disk sequential expect import call node option evaluate prior command line require work resolucao package able start precedent import finish execute loader keep sound ok
"
891,182,"
> When run via `--import ./a.js --import ./b.js`, Node evaluates this as if you had written a root file of:

> ```js
> import './a.js'
> import './b.js'
> ```

I'm pretty sure it's not the case.
The implementation you linked in https://github.com/nodejs/node/issues/50427#issuecomment-1783146723 literally does a (primordial-based) `Promise.all`. That's not what successive `import` statements do.

I agree that we should consider this a bug and change it to evaluate in a sequence.","targos",2352663,"2023-10-28 08:45:10","consider bug change evaluate sequence
"
892,182,"There are three way of supporting several `--import`:

1. Concurrently (the current way):
   ```js
   await Promise.all(imports.map(moduleReferrer => import(moduleReferrer)));
   ```
2. Using static imports (the linking is done concurrently, but execution order is guaranteed):
   ```js
   await import(`data:text/javascript,${encodeURIComponent(imports.map(
     moduleReferrer => `import ${JSON.stringify(moduleReferrer)}`
   ).join(';'))}`);
   ```
3. Sequentially:
   ```js
   for (const moduleReferrer of imports) {
     await import(moduleReferrer);
   }
   ```

It seems that only the latter would allow chaining of loaders, the tradeoff being that if one of the module has a long-running TLA task, work will start later on other `--import`ed modules, but it's probably the only way for `--import` to compete with `--require`.","aduh95",14309773,"2023-10-28 13:26:46","way support import concurrently current way use static import link concurrently execution order guarantee sequentially module referrer allow chain loader tradeoff module long run task work start later import module probably way import compete require
"
893,182,"> It seems that only the latter would allow chaining of loaders, the tradeoff being that if one of the module has a long-running TLA task, work will start later on other `--import`ed modules, but it’s probably the only way for `--import` to compete with `--require`.

Number 3 was what I was envisioning as well. It would also allow hooks registered in the first `--import` to affect subsequent imports, which is a feature of `--loader` that should be present in `--import` as well. The following should work:

```shell
node --import ts-node/register --import my-script.ts app.ts
```

@aduh95 are you already working on this?","GeoffreyBooth",456802,"2023-10-28 16:15:42","allow chain loader tradeoff module long run task work start late import module probably way import compete require envision allow hook register import affect subsequent import feature loader present import work node import register import script app work
"
894,182,"To clarify - (2) very much does permit chaining here since evaluation of each successive module will only happen after the previous has fully completed including with TLA support, with that benefit over (3) of continuing to parallelize the loading pipeline.","guybedford",598730,"2023-10-28 17:28:21","clarify permit chain evaluation successive module happen previous fully complete tla support benefit parallelize load pipeline
"
895,182,"> To clarify - (2) very much does permit chaining here since evaluation of each successive module will only happen after the previous has fully completed including with TLA support, with that benefit over (3) of continuing to parallelize the loading pipeline.

It doesn't, because the modules will still get _resolved_ in parallel, meaning that a loader registered in the first `--import` wouldn't be able to drive the resolution of subsequent `--import` calls (ie something like `--import import-map --import other-loader`, where `other-loader` is a package registered in the import map).","arcanis",1037931,"2023-10-28 17:38:32","clarify permit chaining evaluation successive module happen previous fully complete tla support benefit parallelize load pipeline module resolve parallel loader register import drive resolution subsequent import call ie import import map import loader loader register import map
"
896,182,"> It doesn't, because the modules will still get resolved in parallel, meaning that a loader registered in the first --import wouldn't be able to drive the resolution of subsequent --import calls (ie something like --import import-map --import other-loader, where other-loader is a package registered in the import map).

That is not what the reported bug is in this issue, the bug reported and replication provided only refer to the import ordering bug.

I appreciate the loader chaining use case though in widening the fix to also support that case, in which case that seems a worthy justification for (3).","guybedford",598730,"2023-10-28 18:21:10","module still get resolve parallel mean loader register first import able drive resolution subsequent import call ie something like import import map import loader loader package register import map report bug issue bug report replication provide refer import order bug appreciate loader chain use case widen fix also support case seem worthy justification
"
897,182,"> I appreciate the loader chaining use case though in widening the fix to also support that case, in which case that seems a worthy justification for (3).

Yes, I think the example I posted, where the second `--import` is written in TypeScript, is only possible in 3?","GeoffreyBooth",456802,"2023-10-28 18:22:04","appreciate loader chain use case widen fix also support case seem worthy justification example post second import write typescript possible
"
898,182,"Can I take it?","MrJithil",26359740,"2023-10-30 07:36:05","Can take
"
899,183,"For setTimeoutPromisified:

To ensure that the specified value is returned, even if it's falsy, we can modify the line to check if result is 'undefined':
`return resolve(result !== undefined ? result : id);`

For setIntervalPromisified:

`startTime += interval;`
This increments the startTime by the interval, causing the value to change. To maintain the original value passed to setInterval, we can store it and return it instead of the incremented startTime.

So, first we can store the original value like:
`const originalValue = startTime;`

Then, in the callback, emit the originalValue instead of the incremented startTime:
`emitter.emit('data', originalValue);`

@mika-fischer ","Onyx2406",32770175,"2023-10-22 11:41:53","ensure specified value return even falsy modify line check result undefined return resolve result undefined id increment starttime interval cause value change maintain original value pass setinterval store return incremented starttime store original value callback emit originalvalue incremented starttime
"
900,183,"> For setTimeoutPromisified:
> 
> To ensure that the specified value is returned, even if it's falsy, we can modify the line to check if result is 'undefined': `return resolve(result !== undefined ? result : id);`

Disagree. It should *always* return the same value the the original `setTimeout` returns. So for `undefined`, it should also return `undefined`.

> For setIntervalPromisified:
> 
> `startTime += interval;` This increments the startTime by the interval, causing the value to change. To maintain the original value passed to setInterval, we can store it and return it instead of the incremented startTime.
> 
> So, first we can store the original value like: `const originalValue = startTime;`
> 
> Then, in the callback, emit the originalValue instead of the incremented startTime: `emitter.emit('data', originalValue);`

That would work.

I don't know what the original intention behind returning these other values was. If they are not needed, I'd just remove them completely. If they are needed for some reason, they need to be communicated in some other way...","mika-fischer",426158,"2023-10-22 11:54:07","ensure specified value return even falsy modify line check result undefined return resolve result undefined id disagree always return value original settimeout return undefined increment starttime interval cause value change maintain original value pass setinterval store return increment starttime store original value callback emit originalvalue increment starttime work know original intention return value need remove need communicate way
"
1265,232,"Out of curiosity, can you test with node v19.6.1 and see if the same problem exists?","mscdex",54666,"2023-04-07 01:45:37","curiosity test node v19 see problem exist
"
1540,267,"Upstream issue: https://github.com/aklomp/base64/issues/96","mscdex",54666,"2022-07-18 22:18:17",NULL
901,183,"This seems like a pretty straightforward bug @nodejs/test_runner @ErickWendel where we should check if result is passed instead of using `||`.

Your report and diagnosis seems correct @mika-fischer thank you for opening a good report.

Would you be interested in opening a PR to align `setTimeout` promisified with the non faked version?","benjamingr",1315533,"2023-10-22 13:57:02","check result pass use open pr align settimeout promisify version
"
902,183,"> For setTimeoutPromisified:
> 
> To ensure that the specified value is returned, even if it's falsy, we can modify the line to check if result is 'undefined': `return resolve(result !== undefined ? result : id);`
> 
> For setIntervalPromisified:
> 
> `startTime += interval;` This increments the startTime by the interval, causing the value to change. To maintain the original value passed to setInterval, we can store it and return it instead of the incremented startTime.
> 
> So, first we can store the original value like: `const originalValue = startTime;`
> 
> Then, in the callback, emit the originalValue instead of the incremented startTime: `emitter.emit('data', originalValue);`
> 
> @mika-fischer

Should we use `return resolve(result);` and what do you think about setIntervalPromisified ? @benjamingr 
","Onyx2406",32770175,"2023-10-22 14:16:34","ensure specified value return even falsy modify line check result undefined return resolve result undefined id maintain original value pass setinterval store return incremented starttime store original value originalvalue callback emit originalvalue incremented starttime use resolve think setintervalpromisified
"
903,183,"That the fakes should all return the same types of results as the originals (even though I personally don't like these overloads) - the whole point of fake timers is that they match the originals.","benjamingr",1315533,"2023-10-22 14:22:55","fake return type result original point fake timer match original
"
904,183,"> Would you be interested in opening a PR to align `setTimeout` promisified with the non faked version?

Yes, I can do a PR tomorrow. ","mika-fischer",426158,"2023-10-22 14:34:10","interested open pr align settimeout promisified fake version  yes pr tomorrow
"
905,183,"See https://github.com/nodejs/node/pull/50331

Turns out setTimeout was already fixed in main","mika-fischer",426158,"2023-10-22 20:12:59","turn settimeout fix main
"
906,183,"For completeness, the setTimeout issue was already fixed [here](https://github.com/nodejs/node/commit/c750049318be98e3883c9d557d8cc6e8d81a6787#diff-f55a12a3f70eb028a92d8d076db8456c693b72bf669c9c6856bdaec496a3896aL181)","mika-fischer",426158,"2023-10-23 13:24:17","completeness settimeout issue fix
"
907,184,"cc @nodejs/url ","debadree25",20257253,"2023-10-18 07:28:31","nodejs url
"
908,184,"I can reproduce on the latest `main`.","aduh95",14309773,"2023-10-18 15:02:37","reproduce latest main
"
909,184,"cc @lemire","anonrig",1935246,"2023-10-18 15:03:51","lemire retornar
"
910,184,"Great. I can write a fix. ","MrJithil",26359740,"2023-10-18 23:15:58","write fix
"
911,184,"It is indeed a bug in ada-url/ada. I have a verification and a potential fix upstream.

Thank you for the clear report with reproducible cases.","lemire",391987,"2023-10-19 00:30:39","bug ada url verification potential fix upstream report case
"
912,184,"@lemire @anonrig Thanks for the very quick fix! 

Could you give a rough estimate when this fix will reach v18 bugfix releases?
","rlindner81",9608015,"2023-10-19 07:58:39","quick fix rough estimate fix reach v18 bugfix release
"
913,184,"@anonrig Should be able to tell you.","lemire",391987,"2023-10-19 15:06:25","able tell
"
914,184,"When will it appear in the 20th node?","baymer",5292544,"2023-11-17 17:15:58","appear node
"
915,184,"The fix is included in Ada v2.7.3 (Ref commit : https://github.com/ada-url/ada/commit/d4ab1a6ba82a173452b000eeb446112f892e601e). It is not yet merged into Node.js core.","anonrig",1935246,"2023-11-17 17:36:00","fix include ada v2.7.3 merge node.js core
"
916,184,"I retriggered the update script: https://github.com/nodejs/node/pull/50771","anonrig",1935246,"2023-11-17 17:38:19","retrigger update script
"
917,184,"@nodejs/releasers I added `lts-watch-v18` and `lts-watch-v20` to the version update pull request.","anonrig",1935246,"2023-11-17 17:39:08","add lts watch v18 lts watch v20 version update pull request
"
918,185,"Paging @ShogunPanda.","bnoordhuis",275871,"2023-10-18 08:04:43","ShogunPanda
"
919,185,"But @james-rms, can you try with the latest v20.x release? This may have been fixed already.","bnoordhuis",275871,"2023-10-18 08:05:24","try latest v20 release may fix
"
920,185,"I have reproduced on v20.8.1, which is latest at time of posting.","james-rms",18162835,"2023-10-18 19:00:40","reproduce v20 latest time post
"
921,185,"I also fail to reproduce with `NODE_OPTIONS=--no-network-family-autoselection`, which was given as a workaround in the similar https://github.com/nodejs/node/issues/47644","james-rms",18162835,"2023-10-18 19:05:43","fail reproduce workaround similar issue
"
922,185,"I'm having this exact error too in production on an application running on node:20-alpine, in an API that uses grpc-js. I'm really not sure how to reproduce it, so I'm downgrading the docker image to node:18-alpine to see if it keeps happening. If it is the case I'll downgrade again to node:16-alpine","Farenheith",5713887,"2023-11-14 00:34:58","error production application run node alpine api use grpc downgrade docker image node alpine case downgrade node alpine
"
923,185,"Can you please provide which hosts were you connecting to and how are they resolved from the connecting machine?

anyway, rather than downgrading you can temporary disable the feature with `--no-network-family-autoselection` (or similar. I'm typing from the phone so I can't check the exact spelling)","ShogunPanda",201101,"2023-11-14 07:15:34","provide host connect resolve connect machine disable feature network family autoselection
"
924,185,"The application provides a GRPC server and connects to another one, also, it connects to about 4 REST servers, 1 redis and 1 mongo. All APIS are on AWS ECS and are accessible internally through separate load balancers with designated DNS. I hope that answers your question.

I'll take a look if I can try it on the parameter you suggested, but I'd rather try to simulate it locally if the application shows up to be stable with node 18, if I figure out how to.

Edit:
Unfortunately, I think I'll have to downgrade for other reasons: I have not only this problem with this API, but some really strange timeouts with a redis instance here that is used even by other more demanding APIs, with no timeouts at all, and I'm suspecting the library ""@grpc/grpc-js"" is messing up the network, as other GRPC Services here are using an old legacy lib ""grpc"", and I couldn't find any other difference between them. The problem with all of this is that the legacy lib only works up to node 16, so, at least I need to exclude this variable first to keep investigating.


The error on this thread didn't happen on node 18 for me, though.
Also, the difference between @grpc/grpc-js and grpc is that the newer is a pure javascript implementation of the gRPC protocol, using node internal http2 to do it, while grpc implements the protocol in C++, I think, and link it to NodeJs","Farenheith",5713887,"2023-11-14 10:38:33","application provide grpc server connect another connect rest server redis mongo api aws ecs accessible internally separate load balancer designate dns answer question look try parameter suggest rather try simulate locally application show stable node figure downgrade reason problem api really strange timeout redis instance use demanding api timeout suspect library grpc mess network grpc service use old legacy lib grpc find difference legacy lib work node least need exclude variable keep investigate error thread happen node though difference grpc grpc newer pure javascript implementation grpc protocol use node internal http2 grpc implement protocol c link node
"
925,185,"I see. At least you gave me a little more context, which will help.
I hope we can have you update soon!","ShogunPanda",201101,"2023-11-22 16:14:42","see give little context help hope update soon
"
926,185,"This should have been fixed in #51045. Once it gets in 21.x or 20.x please let me know if you have additional problems.","ShogunPanda",201101,"2023-12-22 10:15:08","fix problem
"
927,185,"Hello, in my case the problem was that I was issuing too many requests with my free Cloudinary plan and the server was blocking certain requests. to get around this I used the VPN (proton VPN) and I no longer have a problem","levialkalidamat",105973580,"2024-03-07 11:37:48","case problem issue many request free cloudinary plan server block request get around use vpn problem
"
1266,232,"No error.

```
Welcome to Node.js v19.6.1.
Type "".help"" for more information.
> new Date()
2023-04-07T14:00:29.886Z
```","danpeixoto",29102315,"2023-04-07 14:01:33","error
date
"
928,186,"Hello, I have a question.
Should both work(`new spec`, `spec`)? Or should only `spec` work?
Currently, `new spec` and `spec()` work, but `spec` does not work.
I would like to ask if it should work the same way as `tap` and `dot`.

While looking for related content, I found that there was an issue that the behavior was different before. (https://github.com/nodejs/node/issues/48112)
","pluris",10344797,"2023-10-13 17:26:28","question work new spec spec work spec work new spec spec work spec work like ask work way tap dot look relate content find issue behavior different
"
929,186,"I'd like to work on this","himself65",14026360,"2023-10-13 18:51:38","like work
"
930,186,"I think the reason is spec is a class, but others are *function","himself65",14026360,"2023-10-13 19:02:09","reason spec class function
"
931,186,"I'm not sure this is a bug, you need to call the function, i.e. `.compose(spec())`. FWIW when using the `new` keyboard, you are calling the function as a constructor, which is supported but it's no longer necessary since https://github.com/nodejs/node/pull/49184 has landed.","aduh95",14309773,"2023-10-13 21:33:38","call function compose spec use new keyboard call function constructor support longer necessary
"
932,186,"> I'm not sure this is a bug, you need to call the function, i.e. `.compose(spec())`. FWIW when using the `new` keyboard, you are calling the function as a constructor, which is supported but it's no longer necessary since https://github.com/nodejs/node/pull/49184 has landed.

It's a bug in the form of anything you said is not documented. The only documented thing is `.compose(tap)`, which is incorrect.","mcollina",52195,"2023-10-14 07:01:38","bug document correct compose tap
"
933,186,"https://github.com/nodejs/node/blob/3a648af0f0e5315086c6b5d2bfa90c3804656ca0/lib/internal/streams/duplexify.js#L86

The error starts from here, body is class SpecReporter, but nodejs treats it as a async generator","himself65",14026360,"2023-10-14 21:49:11","error start body class specreporter nodejs treat async generator
"
934,187,"cc @lemire @nodejs/url ","anonrig",1935246,"2023-09-29 19:14:51","lemire nodejs url
"
935,187,"It appears that the bug is caused with this trace:

```
0   node                          	       0x1016ba17c ada::unicode::has_tabs_or_newline(std::__1::basic_string_view<char, std::__1::char_traits<char>>) + 80 (ada.cpp:9841) [inlined]
```

I've talked to @isaacs and appears that they're using M1 (NEON). We might have a bug in our SIMD solution @lemire 

Ref: https://github.com/ada-url/ada/blob/main/src/unicode.cpp#L49","anonrig",1935246,"2023-09-29 21:28:01","bug cause trace node ada unicode has tab newline ada cpp inline talk isaacs use m1 neon bug simd solution lemire
"
936,187,"> If it only crashes when you have a large number of processes, then it is likely not a bug in the C++ code. It is likely ressource exhaustion, and it has likely to do with Node.js/v8 stability.

If it's a segfault that would have to do with invalid memory access, not running out of memory.","mscdex",54666,"2023-09-29 23:44:13","crash large number process likely bug c++ code likely ressource exhaustion likely node.js v8 stability segfault invalid memory access run memory
"
937,187,"> If it's a segfault that would have to do with invalid memory access, not running out of memory.

If you try to allocate memory and it fails, and you have disabled exceptions in C++, you get back a null pointer. Dereferencing a null pointer is a segmentation fault.


I am not claiming that's the mechanism at play here, but we don't have a reproducible test case so one can only speculate. The only information that we have is that it only occurs if the system is highly stressed. Other possibilities include data races (outside of `ada::can_parse` since `ada` is single-threaded). Without a reproducible test case, it is difficult to do anything productive.","lemire",391987,"2023-09-29 23:58:36","segfault invalid memory access run memory allocate memory fail disable exception c++ null pointer dereference null pointer segmentation fault claim mechanism play reproducible test case speculate information occur system highly stress possibility data race ada can_parse ada single_threaded reproducible test case difficult productive
"
938,187,"Fixed upstream in https://github.com/ada-url/ada/pull/519

Thanks @isaacs for the report.","lemire",391987,"2023-09-30 01:18:04","fix upstream report
"
939,187,"Both node.js and ada need to get ARM-based sanitized testing. For ada, I opened an issue at https://github.com/ada-url/ada/issues/520

For node.js, someone should check. I know it runs sanitizers, but possibly only on x64 builds.","lemire",391987,"2023-09-30 01:31:04","node js ada need get arm base sanitize test ada open issue node js someone check know run sanitizer possibly x64 build
"
940,187,"cc @nodejs/build ","anonrig",1935246,"2023-09-30 01:31:46","nodejs build
"
941,187,"Thanks!","isaacs",9287,"2023-10-01 01:46:04","Thanks
"
942,188,"related to #49926 ","rluvaton",16746759,"2023-09-28 16:38:26","relate
"
943,189,"I believe the fix for this issue and issue #49927 is:

```diff
diff --git a/lib/internal/test_runner/runner.js b/lib/internal/test_runner/runner.js
index 08f9b48dda..6e6faf5000 100644
--- a/lib/internal/test_runner/runner.js
+++ b/lib/internal/test_runner/runner.js
@@ -139,6 +139,17 @@ class FileTest extends Test {
   #rawBufferSize = 0;
   #reportedChildren = 0;
   failedSubtests = false;
+
+  constructor(options) {
+    super(options);
+    this.loc ??= {
+      __proto__: null,
+      line: 1,
+      column: 1,
+      file: this.name,
+    };
+  }
+
   #skipReporting() {
     return this.#reportedChildren > 0 && (!this.error || this.error.failureType === kSubtestsFailed);
   }
```

We should probably add `path.resolve()` around the location's file. In a semver major change, I think we should call `path.resolve()` on the input before calling `super(options)`.","cjihrig",2512748,"2023-09-29 01:16:35","fix issue path resolve input super option  call semver major change add
"
944,189,"@razvanbh @cjihrig will one of you open a PR?","MoLow",8221854,"2023-10-01 16:46:48","open pr
"
945,189,"I didn't have time to write a test the other day when I posted that comment and hoped someone would have by now :smile:. I can do it today.","cjihrig",2512748,"2023-10-01 16:50:17","time write test day post comment hope someone today
"
946,190,"(1) is a validation bug and probably also responsible for (2), see diff and PR welcome. Other parts of node do seem to be validating it correctly as an int32, just not lib/internal/vm.js.
<details>

```diff
diff --git a/lib/internal/vm.js b/lib/internal/vm.js
index ba5e232466..111bab8621 100644
--- a/lib/internal/vm.js
+++ b/lib/internal/vm.js
@@ -13,10 +13,10 @@ const {
   validateBoolean,
   validateBuffer,
   validateFunction,
+  validateInt32,
   validateObject,
   validateString,
   validateStringArray,
-  validateUint32,
 } = require('internal/validators');
 const {
   ERR_INVALID_ARG_TYPE,
@@ -46,8 +46,8 @@ function internalCompileFunction(code, params, options) {
   } = options;
 
   validateString(filename, 'options.filename');
-  validateUint32(columnOffset, 'options.columnOffset');
-  validateUint32(lineOffset, 'options.lineOffset');
+  validateInt32(columnOffset, 'options.columnOffset');
+  validateInt32(lineOffset, 'options.lineOffset');
   if (cachedData !== undefined)
     validateBuffer(cachedData, 'options.cachedData');
   validateBoolean(produceCachedData, 'options.produceCachedData');
```

</details>","bnoordhuis",275871,"2023-09-25 07:13:13","bug responsável diff pr bem parte nó validar corretamente int32 lib internal vm js validar string filename columnoffset lineoffset validar int32 buffer cacheddata validar boolean producecacheddata
"
948,191,"Currently, you can only have ""one absolute URL <=> one module""; it's a limitation we inherit from the HTML spec IIRC. You need to make changes in your resolve loader so it produces a different URL every time you want a different module to be loaded – otherwise it will return the one that's already on the LoadCache.","aduh95",14309773,"2023-09-22 07:57:16","limitation inherit html spec need make change resolve loader produce different url time want different module load otherwise return one loadcache
"
949,191,"> You need to make changes in your resolve loader so it produces a different URL every time you want a different module to be loaded

The loader is doing this: `resolved.url = resolved.url + match` [link](https://github.com/iambumblehead/nodejs-import-attributes-repro/blob/main/loader.js#L7C40-L7C40)

The json file alone is always returned from LoadCache regardless of url or query params

The reproduction repo seeks to demonstrate 1) the url is modified by the loader 2) json returned to the main thread is cached. What other corrections to the demo loader would return un-cached json to the unit-test?

My own numerous attempts mutating the url at the loader failed to break the cache","iambumblehead",2058705,"2023-09-22 09:24:00","need make change resolve loader produce different url time want different module load loader resolved url resolved url match json file always return loadcache regardless url query param reproduction repo seek demonstrate url modify loader json return main thread cache correction demo loader return un cache json unit test own numerous attempt mutate url loader fail break cache
"
950,191,"I created a minimal repro:

```js
import { register } from 'node:module';
import assert from 'node:assert';

async function resolve(referrer, context, next) {
  const result = await next(referrer, context);
  const url = new URL(result.url)
  url.searchParams.set('randomSeed', Math.random());
  result.url = url.href;
  return result;
}

function load(url, context, next) {
  if (context.importAssertions.type === 'json') {
    return {
      shortCircuit: true,
      format: 'json',
      source: JSON.stringify({ data: Math.random() }),
     };
  }
  return next(url, context);
}

register(`data:text/javascript,export ${encodeURIComponent(resolve)};export ${encodeURIComponent(load)}`);

assert.notDeepStrictEqual(
  await import('./file.json', { assert: { type: 'json' } }),
  await import('./file.json', { assert: { type: 'json' } }),
);
```

/cc @nodejs/loaders ","aduh95",14309773,"2023-09-22 09:54:57","create minimal repro  register node module assert resolve referrer context next result await next referrer context url new URL result url url searchParams set randomSeed Math random result url href result load url context next context importAssertions type json shortCircuit true format json source JSON stringify data Math random next url context register data text javascript export encodeURIComponent resolve export encodeURIComponent load assert notDeepStrictEqual await import file json assert type json await import file json
"
951,191,"Is there a minimal repro that doesn’t involve customization hooks? In particular, I want some code that can be run either in Node or in browsers, to see how browsers behave (so that we can copy their behavior).","GeoffreyBooth",456802,"2023-09-24 22:38:26","minimal repro involve customization hook want code run node browser see browser behave copy behavior
"
952,191,"Respectfully, the issue reported here is a ""loader issue"" and reproducing the issue requires a loader. Browsers do not provide loader hooks to reproduce this issue, how can they be related to this issue?","iambumblehead",2058705,"2023-09-25 17:06:25","issue report loader reproduce browser provide hook relate
"
953,191,"> Respectfully, the issue reported here is a “loader issue” and reproducing the issue requires a loader.

Sorry, I thought it was a bug regardless and loaders were just providing the way to reproduce it. So you’re saying that the default, no hooks registered scenario is fine and matches browsers? It’s only when hooks are registered that the issue appears, and it’s unrelated to the content of the hooks themselves (as in, the hooks in question aren’t caching when they shouldn’t)?","GeoffreyBooth",456802,"2023-09-25 22:48:20","issue report loader issue reproduce loader bug loader reproduce default hook register scenario fine match browser hook register issue appear unrelated content hook hook cache
"
954,191,"I think this is actually a bug regardless, even when loaders are not used.

Minimal repro:

```js
import { writeFileSync } from 'fs'
import assert from 'assert'
import test from 'node:test'

test('json', async () => {
  writeFileSync('foo.json', JSON.stringify({ firstJson: true }))
  const firstJson = await import('./foo.json?a=1', {
    assert: { type: 'json' },
  })
  writeFileSync('foo.json', JSON.stringify({ firstJson: false }))
  const secondJson = await import('./foo.json?a=2', {
    assert: { type: 'json' },
  })

  assert.notDeepEqual(firstJson, secondJson)
})

test('js', async () => {
  writeFileSync('foo.mjs', `
  export const firstJS = true
  `)
  const firstJS = await import('./foo.mjs?a=1')
  writeFileSync('foo.mjs', `
  export const firstJS = false
  `)
  const secondJS = await import('./foo.mjs?a=2')
  assert.notDeepEqual(firstJS, secondJS)
})
```

It seems to be caching based on the filename, not the import url. When loading JavaScript (or anything that doesn't use `assert`, I guess?) it caches based on the URL, so the js test passes.","isaacs",9287,"2023-09-25 23:41:43","think bug regardless loader use minimal repro writefile json stringify firstjson true firstjson import foo json assert type json writefile json stringify firstjson false secondjson import foo json assert type json deep equal js writefile foo mjs export firstjs true firstjs import foo mjs writefile foo mjs export firstjs false secondjs import foo mjs deep equal seem cache base filename import url load javascript use assert cache base url js test pass
"
955,191,"> So you’re saying that the default, no hooks registered scenario is fine and matches browsers? 

Yes, the default, no hooks registered scenario is fine and matches browsers afaik.

When a hook returns a ""json"" modified source it is not returned to the importing module and instead a cached source is returned.

This is different from ""module"" and ""commonjs"" sources. When a hook returns ""module"" or ""commonjs""  modified sources, those modified sources are returned to the importing module.","iambumblehead",2058705,"2023-09-25 23:42:50","hook retorno json modificado fonte retornar importar modulo invés fonte cache retornar diferente modulo commonjs fonte hook retorno modulo commonjs fonte modificado fonte retornar importar modulo
"
964,193,"> Personally, I would consider switching away from using `node:fs` if Deno, Bun, and Node.js could reach a consensus on implementing the WHATWG/fs and File System Access API.

Sure, do you want to open an issue on https://github.com/wintercg/proposal-common-minimum-api/ to propose something? Or to just start a discussion.","GeoffreyBooth",456802,"2023-09-19 22:24:39","consider switch use node fs deno bun node js reach consensus implement whatwg file system access api propose something start discussion
"
965,193,"> Sure, do you want to open an issue on https://github.com/wintercg/proposal-common-minimum-api/ to propose something? Or to just start a discussion.

Already did: https://github.com/wintercg/proposal-common-minimum-api/issues/5","jimmywarting",1148376,"2023-09-20 16:10:05","abrir issue propor algo discutir
"
966,193,"Looking good on nightly!

```shell
> ./node /tmp/test.mjs
21.0.0-nightly202309229718a9465c
file:///private/tmp/rel
```","lgarron",248078,"2023-09-22 16:30:38","good nightly
"
956,191,"> Yes, the default, no hooks registered scenario is fine and matches browsers afaik.

No it doesn't:

```js
/// index.mjs
const assert = {type:'json'};
const importWithoutQuery = await import(""./package.json"", {assert});
const importWithQuery = await import(""./package.json?key=value"", {assert});
console.log(
  JSON.stringify(importWithQuery.default) !== JSON.stringify(importWithoutQuery.default)
);
```

```js
/// server.js
import http from 'node:http';
import {createReadStream} from 'node:fs';

http.createServer((req, res) => {
  switch(req.url) {
    case '/':
      res.setHeader('Content-Type', 'text/html');
      res.end('<script type=module>import ""/index.mjs""</script>');
      return;
    case '/index.mjs':
      res.setHeader('Content-Type', 'text/javascript');
      createReadStream(new URL('./index.mjs', import.meta.url)).pipe(res);
      return;
    default:
        res.setHeader('Content-Type', 'application/json');
        res.end(JSON.stringify({ data: Math.random() }))
        return;
  }
}).listen(8080);
```

```js
/// node.mjs
import { register } from 'node:module';

function load(url, context, next) {
  if (context.importAssertions.type === 'json') {
    return {
      shortCircuit: true,
      format: 'json',
      source: JSON.stringify({ data: Math.random() }),
     };
  }
  return next(url, context);
}

register(`data:text/javascript,export ${encodeURIComponent(load)}`);
```

```json
/// package.json
{}
```

Node.js will print `false` when browsers (Safari and Chromium, and `node --experimental-network-imports`) print `true`.

```console
$ node --import ./node.mjs index.mjs
(node:66937) ExperimentalWarning: Importing JSON modules is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
false
$ node server.mjs &
$ node --experimental-network-imports --input-type=module -e 'import ""http://localhost:8080/index.mjs""'
(node:67034) ExperimentalWarning: Network Imports is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:67034) ExperimentalWarning: Import assertions are not a stable feature of the JavaScript language. Avoid relying on their current behavior and syntax as those might change in a future version of Node.js.
(node:67034) ExperimentalWarning: Importing JSON modules is an experimental feature and might change at any time
true
```

The reason is that the Node.js ESM loader, when loading a JSON file from a file: URL, checks the CJS cache first; the reason for this choice was that in case CJS and ESM code try to load the same JSON file, they get the same data. Maybe we should restrict that behavior to when there's no query string in the loaded URL.","aduh95",14309773,"2023-09-26 14:10:08","yes default hook register scenario fine match browser node print false browser safari chromium node experimental network import print true reason node js esm loader load json file file url check cjs cache first reason choice case cjs esm code try load json file get data maybe restrict behavior query string load url
"
957,191,"> Maybe we should restrict that behavior to when there's no query string in the loaded URL.

(Or hash.)

I think that would be the most expected outcome. `./package.json` and `./package.json?x#y` are completely different things from a require() point of view. They ought to be from an import point of view as well (and indeed, they are, except in this instance).

Another (more complicated, probably worse, maybe more performant) approach would be to only look to the require cache if the file is loaded from disk, and cache the stat (which I believe it does already), and only return the cached value if the mtime, dev, and ino all match what it saw the last time it loaded. Would save a file read and prevent the surprise, but the reason I'm guessing it's ""probably worse"" is that it might be quite a bit more complexity for not much performance benefit.","isaacs",9287,"2023-09-26 15:46:53","restrict behavior query string url hash expect outcome package json different require import point view load file disk cache stat mtime dev ino match save file read prevent surprise complexity performance benefit
"
958,191,"> No it doesn't

Sorry everyone, I submitted my comment just after @isaacs' comment and probably should have deleted or edited that. At that time, I wasn't aware of the general issue and believed the problem was loader-specific. I agree with things @aduh95 and @isaacs are messaging and have no additional input now.","iambumblehead",2058705,"2023-09-26 18:33:48","no doesnt sorry submit comment isaacs comment probably delete edit time aware general issue believe problem loader specific agree thing ad uh isaacs message additional input
"
959,192,"This is the result of node trying to make the `ciphers` option work for both TLSv1.2 and 1.3 because openssl has different APIs for them (SSL_CTX_set_cipher_list vs. SSL_CTX_set_ciphersuites.)

Node parses the string but it doesn't understand bang syntax and treats it as a TLSv1.2 cipher. PR welcome. Untested, but I think the fix looks something like this:
```diff
diff --git a/lib/internal/tls/secure-context.js b/lib/internal/tls/secure-context.js
index 36d33e6ac8..0fa3098ffa 100644
--- a/lib/internal/tls/secure-context.js
+++ b/lib/internal/tls/secure-context.js
@@ -99,21 +99,25 @@ function processCiphers(ciphers, name) {
   const cipherList =
     ArrayPrototypeJoin(
       ArrayPrototypeFilter(
         ciphers,
         (cipher) => {
-          return cipher.length > 0 &&
-            !StringPrototypeStartsWith(cipher, 'TLS_');
+          if (cipher.length === 0) return false;
+          if (StringPrototypeStartsWith(cipher, 'TLS_')) return false;
+          if (StringPrototypeStartsWith(cipher, '!TLS_')) return false;
+          return true;
         }), ':');
 
   const cipherSuites =
     ArrayPrototypeJoin(
       ArrayPrototypeFilter(
         ciphers,
         (cipher) => {
-          return cipher.length > 0 &&
-            StringPrototypeStartsWith(cipher, 'TLS_');
+          if (cipher.length === 0) return false;
+          if (StringPrototypeStartsWith(cipher, 'TLS_')) return true;
+          if (StringPrototypeStartsWith(cipher, '!TLS_')) return true;
+          return false;
         }), ':');
 
   // Specifying empty cipher suites for both TLS1.2 and TLS1.3 is invalid, its
   // not possible to handshake with no suites.
   if (cipherSuites === '' && cipherList === '')
```","bnoordhuis",275871,"2023-09-18 19:59:21","node parse string understand bang syntax treat tlsv12 cipher pr welcome fix look like node try make cipher option work tlsv12 because openssl different api ssl_ctx_set_cipher_list ssl_ctx_set_ciphersuites
"
960,193,"Yes, this is a bug, thank you for flagging it. `import.meta.resolve` should return an URL string, similar to `import.meta.url`. cc @guybedford @aduh95 @nodejs/loaders ","GeoffreyBooth",456802,"2023-09-18 02:52:37","bug flag import.meta.resolve return url string similar import.meta.url
"
961,193,"I think it should match deno / browsers behavior and return a url string.

","jimmywarting",1148376,"2023-09-19 21:32:31","match deno browser behavior return url string
"
962,193,"Ugh much as it pains me, it _is_ spec'ed to return a url string. Not what anybody wanted, but it is what it is. Maaaybe something else coming.","JakobJingleheimer",3012099,"2023-09-19 21:41:09","pain spec return url string anybody want may something else come
"
963,193,"all the fuzz in #48994 is really only about `node:fs` only supporting URL instances. and /paths (no fileUrl string path)
that is what they are bothered about. 
if we did not have `node:fs`, or if the filesystem was so inherity bad that it allowed folks to create files and directory with bad names, then nobody would have created #48994 and nobody would complain about it. so imo i think there is nothing wrong with it returning a string. perhaps maybe, just maybe we could improve `node:fs` to work with fileUrl strings instead somehow?

Personally, I would consider switching away from using `node:fs` if Deno, Bun, and Node.js could reach a consensus on implementing the WHATWG/fs and File System Access API. This would promote more cross-compatibility in code, eliminate the complexity of having to deal with paths, URLs, or URL strings, and ensure consistent functionality across different environments, including the browser, without relying on additional dependencies. While it might not be as developer-friendly, it would provide a consistent and dependency-free solution.","jimmywarting",1148376,"2023-09-19 22:04:52","consider switch usar node fs deno bun node js alcançar consenso implementar whatwg fs file system access api promover compatibilidade cruzada eliminar complexidade lidar caminho url string garantir funcionalidade consistente ambiente diferente incluir navegador sem depender dependência adicional talvez amigável desenvolvedor fornecer solução consistente livre dependência
"
1267,232,"/cc @anonrig This seems to be related to simdutf.","mscdex",54666,"2023-04-07 14:24:04","seem relate simdutf
"
967,193,"> Looking good on nightly!

Also looking good in`v20.8.0`!

```shell
> echo ""console.log(process.versions.node); console.log(import.meta.resolve('./rel'));"" > /tmp/test.mjs
> node /tmp/test.mjs
20.8.0
file:///private/tmp/rel
```","lgarron",248078,"2023-10-03 23:26:06","look good nightly look good v20 8 0 echo console log process version node console log import meta resolve rel node test mjs
"
968,194,"It's because the current working directory is cached (introduced in https://github.com/nodejs/node/pull/27224 FWIW, before snapshots were a thing.)

Should be easy to fix by clearing `cachedCwd` in lib/internal/bootstrap/switches/does_own_process_state.js. PR welcome.","bnoordhuis",275871,"2023-09-17 09:14:47","fix clear cachedcwd lib internal bootstrap switch own process state pr welcome
"
969,195,"cc @nodejs/url ","anonrig",1935246,"2023-09-16 03:08:50","nodejs url
"
970,195,"I think it is a minor issue.

Line:
https://github.com/nodejs/node/blob/e9ff81016dfcf183f4fcc2640497cb8b3365fdd7/src/node_url.cc#L279

aborts when the parsing failed (it is deliberate).

Might I suggest:

```C++
  if (!out) {
    return args.GetReturnValue().Set(false);
  }
```

","lemire",391987,"2023-09-16 23:24:47","think minor issue abort parse deliberate suggest
"
971,195,"This issue is fixed in ada's `main`, but unfortunately due to old GCC version of CI, Ada's next version is blocked. Ref: https://github.com/nodejs/node/pull/49340

cc @nodejs/build ","anonrig",1935246,"2023-09-19 00:33:09","issue fix ada main unfortunately old gcc version ci ada next version block
"
972,196,"Note that this is breaking`@babel/core`, and thus all the frameworks/project that use it. It would be great to prioritize it 🙏 ","nicolo-ribaudo",7000710,"2023-09-05 08:48:30","break babel core framework project use prioritize
"
973,196,"Can someone give a reproducible example? The code from https://github.com/liuxingbaoyu/node-v20.6-bug doesn't show the problem (it throws an error in `mod/index.js`).","targos",2352663,"2023-09-05 08:57:23","example code show problem throw error
"
974,196,"Sorry, I forgot to push the second commit.
But the initial error is also different due to the regression.","liuxingbaoyu",30521560,"2023-09-05 08:59:47","sorry forget push second commit initial error different regression
"
975,196,"Please try again, thanks!","liuxingbaoyu",30521560,"2023-09-05 09:00:01","try thanks
"
976,196,"Right, that error happens because it runs twice. You can replace `index.js` with the following to not see the error:
```js
console.log(""RUNNING"");
exports.File = 2;
require(""./1"");


```","nicolo-ribaudo",7000710,"2023-09-05 09:00:08","run twice replace index js see error log run export file require
"
977,196,"A minimal reproduction:

```js
// index.mjs
import ""./dep.cjs"";
```
```js
// dep.cjs
require(""./dep.cjs"");
console.log(""RUNNING"");
```

Running `node index.mjs` logs twice but it should log once.","nicolo-ribaudo",7000710,"2023-09-05 09:07:12","reproduction minimal index mjs import dep cjs dep cjs require dep cjs console log run node index mjs log twice log once
"
978,196,"I have a repro. Starting to bisect.","targos",2352663,"2023-09-05 09:09:36","repro bisect
"
979,196,"@targos If it helps, it looks like the problem is that ESM's CJS loader doesn't set [this `loaded = true`](https://github.com/nodejs/node/blob/5b31ff112783f97d12763a6516fcdadb7fa046ec/lib/internal/modules/cjs/loader.js#L909) before evaluating the CJS module.

Here probably: https://github.com/nodejs/node/blob/5b31ff112783f97d12763a6516fcdadb7fa046ec/lib/internal/modules/esm/translators.js#L326","nicolo-ribaudo",7000710,"2023-09-05 09:25:33","problema cjs loader definir loaded true avaliar modulo cjs
"
980,196,"Bug is introduced by https://github.com/nodejs/node/pull/47999","targos",2352663,"2023-09-05 09:26:12","bug introduce
"
981,196,"In case there is no easy fix, would it be possible to revert that PR?

(cc @aduh95)","nicolo-ribaudo",7000710,"2023-09-05 13:15:33","easy fix possible revert pr
"
982,196,"Thanks for the ping, I'll have a look","aduh95",14309773,"2023-09-05 13:23:10","Thanks ping look
"
983,196,"To help with search, this is the issue for the error ""TypeError: Cannot redefine property: File"" generated in `@babel/core`. See https://github.com/babel/babel/issues/15927","demurgos",2262218,"2023-09-05 23:03:59","help search issue error typeerror redefine property file generate babel core
"
984,196,"Assuming angular tests would have  caught this, Should we add it to citgm? (The failure seem to break angular)

https://github.com/angular/angular-cli/issues/25782","rluvaton",16746759,"2023-09-06 05:37:23","assume angular test catch add citgm failure seem break angular
"
985,196,"> In case there is no easy fix, would it be possible to revert that PR?
> 
> (cc @aduh95)

The change from https://github.com/nodejs/node/pull/47999 is opt-in. Why not just stop opting in?","JakobJingleheimer",3012099,"2023-09-06 08:02:00","case easy fix possible revert pr change opt in opt
"
986,196,"@rluvaton We are also working on https://github.com/nodejs/citgm/pull/628 (angular was broken through Babel)","nicolo-ribaudo",7000710,"2023-09-06 08:54:09","work angular break babel
"
987,196,"> angular was broken through Babel

Same thing with astro: [withastro/astro #8411](https://github.com/withastro/astro/issues/8411)","kacperwyczawski",97523625,"2023-09-06 08:55:37","angular break babel astro
"
988,196,"> @rluvaton We are also working on [nodejs/citgm#628](https://github.com/nodejs/citgm/pull/628) (angular was broken through Babel)

Jest (which is in CITGM already) also uses Babel, I'm surprised that wasn't discovered...

","SimenB",1404810,"2023-09-06 11:04:36","work nodejs citgm angular break babel jest citgm use babel surprise discover
"
989,196,"@SimenB This bug is only triggered when the ESM package uses a CJS package. :)","liuxingbaoyu",30521560,"2023-09-06 11:19:48","bug trigger esm package usar cjs package
"
990,196,"Jest's CI is failing now, I'd have thought those would have been caught.

EDIT: right, it's the build script (which is in ESM): https://github.com/jestjs/jest/actions/runs/6094016439/job/16535303696","SimenB",1404810,"2023-09-06 11:21:18","jest ci fail thought catch build script esm
"
991,196,"CITGM result from v20.6.0 release: https://github.com/nodejs/node/pull/49185#issuecomment-1698005213. Apparently, `jest` broke but no one looked at these failures (that's why I suggested: https://github.com/nodejs/citgm/issues/955)

Stack: https://ci.nodejs.org/job/citgm-smoker/3212/nodes=fedora-last-latest-x64/testReport/junit/(root)/citgm/jest_v29_6_4/","RafaelGSS",26234614,"2023-09-06 11:27:11","release jest broke suggest failure
"
992,196,"Right, so there at least the error reported in this bug can be seen.

If Jest is known to be flaky on CITGM, I'd be happy to take a look. I don't think I've been pinged on any CITGM stuff since v19 release (https://github.com/nodejs/node/pull/44626#issuecomment-1282191258)","SimenB",1404810,"2023-09-06 11:30:37","error report bug see jest flaky citgm happy look think ping citgm stuff v19 release
"
993,196,"When could we expect a release for the [fix](https://github.com/nodejs/node/pull/49500) that was merged ? 🙏 ","camcamd",22561207,"2023-09-06 15:38:08","expect release fix merge
"
994,196,"For people watching issue this for the error with Babel: we added a workaround in `@babel/core`, `@babel/traverse` and `@babel/types` 7.22.17. Please make sure to upgrade and they should be compatible with Node.js 20.6.0.","nicolo-ribaudo",7000710,"2023-09-08 14:28:15","add workaround babel core babel traverse babel type compatible node js
"
998,197,"You can see that it's not just my local machine; the GitHub Actions CI also timed out:

https://github.com/jaydenseric/graphql-upload/actions/runs/5989368434/job/16245479185#step:4:105

So I've experienced this issue on 3 seperate machines now; work laptop, personal laptop, and in CI.","jaydenseric",1754873,"2023-08-30 04:41:34","machine github action ci time issue machine laptop laptop ci
"
999,197,"I am able to reproduce this with https://github.com/jaydenseric/graphql-upload/commit/3b7f034e1c2d084f314734377c4351c171b87a42 on macOS. It does not reproduce 100% of the time (possibly a race condition?) so I used a small bash script:

```
while :
do
  NODE_V8_COVERAGE=./coverage ~/iojs/node/node processRequest.test.mjs
done
```

I believe this is only related to `NODE_V8_COVERAGE` and not the test runner. Also note that the bash script does not use `--test`. I've also heard from other folks that this can be reproduced without the test runner (ie, using node-tap on a different codebase).

When [`NODE_V8_COVERAGE` is present, the inspector is enabled at startup](https://github.com/nodejs/node/blob/51f4ff245018153abbb918b0d4a3cce65510d762/src/inspector_profiler.cc#L422-L430). When the process is getting ready to exit, we call [`EndStartedProfilers()`](https://github.com/nodejs/node/blob/51f4ff245018153abbb918b0d4a3cce65510d762/src/inspector_profiler.cc#L395-L414).

I'm not yet sure if we are missing some cleanup step, but when the process hangs, we enter an infinite loop of flushing and adding new tasks:

```
(lldb) bt
* thread #1, queue = 'com.apple.main-thread', stop reason = signal SIGSTOP
  * frame #0: 0x000000018886a1e0 libsystem_malloc.dylib`nanov2_pointer_size + 312
    frame #1: 0x000000018886a06c libsystem_malloc.dylib`nanov2_size + 32
    frame #2: 0x0000000188869e48 libsystem_malloc.dylib`free + 148
    frame #3: 0x000000010295f52c node`node::PerIsolatePlatformData::FlushForegroundTasksInternal() [inlined] std::__1::default_delete<v8::Task>::operator()(this=<unavailable>, __ptr=0x00006000013c8720) const at memory:1428:5 [opt]
    frame #4: 0x000000010295f51c node`node::PerIsolatePlatformData::FlushForegroundTasksInternal() [inlined] std::__1::unique_ptr<v8::Task, std::__1::default_delete<v8::Task>>::reset(this=<unavailable>, __p=0x0000000000000000) at memory:1689:7 [opt]
    frame #5: 0x000000010295f514 node`node::PerIsolatePlatformData::FlushForegroundTasksInternal() [inlined] std::__1::unique_ptr<v8::Task, std::__1::default_delete<v8::Task>>::~unique_ptr(this=<unavailable>) at memory:1643:19 [opt]
    frame #6: 0x000000010295f514 node`node::PerIsolatePlatformData::FlushForegroundTasksInternal() [inlined] std::__1::unique_ptr<v8::Task, std::__1::default_delete<v8::Task>>::~unique_ptr(this=<unavailable>) at memory:1643:17 [opt]
    frame #7: 0x000000010295f514 node`node::PerIsolatePlatformData::FlushForegroundTasksInternal(this=0x000000014ae073f8) at node_platform.cc:494:5 [opt]
    frame #8: 0x0000000102960b34 node`node::NodePlatform::DrainTasks(this=0x0000600002ce4000, isolate=<unavailable>) at node_platform.cc:457:25 [opt]
    frame #9: 0x00000001028311b0 node`node::FreeEnvironment(env=<unavailable>) at environment.cc:513:15 [opt]
    frame #10: 0x000000010293ead8 node`node::NodeMainInstance::Run() [inlined] node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>::operator()(this=<unavailable>, pointer=0x000000014b033800) const at util.h:675:39 [opt]
    frame #11: 0x000000010293ead0 node`node::NodeMainInstance::Run() [inlined] std::__1::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>>::reset(this=<unavailable>, __p=0x0000000000000000) at memory:1689:7 [opt]
    frame #12: 0x000000010293ead0 node`node::NodeMainInstance::Run() [inlined] std::__1::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>>::~unique_ptr(this=<unavailable>) at memory:1643:19 [opt]
    frame #13: 0x000000010293ead0 node`node::NodeMainInstance::Run() [inlined] std::__1::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>>::~unique_ptr(this=<unavailable>) at memory:1643:17 [opt]
    frame #14: 0x000000010293ead0 node`node::NodeMainInstance::Run(this=<unavailable>) at node_main_instance.cc:90:1 [opt]
    frame #15: 0x00000001028c76c8 node`node::Start(int, char**) [inlined] node::StartInternal(argc=<unavailable>, argv=<unavailable>) at node.cc:1374:24 [opt]
    frame #16: 0x00000001028c762c node`node::Start(argc=<unavailable>, argv=<unavailable>) at node.cc:1381:27 [opt]
    frame #17: 0x00000001083f50f4 dyld`start + 520
```

At least some of the new tasks are coming from `v8::internal::Heap::PostFinalizationRegistryCleanupTaskIfNeeded()` (note that I added a `printf()` if you're curious about the top couple frames):

```
(lldb) bt
* thread #1, queue = 'com.apple.main-thread', stop reason = signal SIGSTOP
  * frame #0: 0x0000000188a1d8d4 libsystem_kernel.dylib`__write_nocancel + 8
    frame #1: 0x000000018894ce14 libsystem_c.dylib`__swrite + 24
    frame #2: 0x000000018892c1ac libsystem_c.dylib`_swrite + 108
    frame #3: 0x000000018891e564 libsystem_c.dylib`__sfvwrite + 492
    frame #4: 0x0000000188948df8 libsystem_c.dylib`puts + 152
    frame #5: 0x000000010256389c node`non-virtual thunk to node::PerIsolatePlatformData::PostNonNestableTask(std::__1::unique_ptr<v8::Task, std::__1::default_delete<v8::Task>>) [inlined] node::PerIsolatePlatformData::PostNonNestableTask(this=<unavailable>, task=v8::Task @ 0x00006000010abb90) at node_platform.cc:281:3 [opt]
    frame #6: 0x0000000102563890 node`non-virtual thunk to node::PerIsolatePlatformData::PostNonNestableTask(std::__1::unique_ptr<v8::Task, std::__1::default_delete<v8::Task>>) at node_platform.cc:0 [opt]
    frame #7: 0x0000000102884418 node`v8::internal::Heap::PostFinalizationRegistryCleanupTaskIfNeeded(this=0x00000001280152b8) at heap.cc:6559:15 [opt]
    frame #8: 0x0000000102863874 node`v8::internal::FinalizationRegistryCleanupTask::RunInternal(this=0x00006000010abbd0) at finalization-registry-cleanup-task.cc:98:10 [opt]
    frame #9: 0x0000000102564880 node`node::PerIsolatePlatformData::RunForegroundTask(this=0x00000001216051e8, task=v8::Task @ 0x00006000010abbf0) at node_platform.cc:435:11 [opt]
    frame #10: 0x0000000102563504 node`node::PerIsolatePlatformData::FlushForegroundTasksInternal(this=0x00000001216051e8) at node_platform.cc:504:5 [opt]
    frame #11: 0x0000000102564b88 node`node::NodePlatform::DrainTasks(this=0x0000600002f98000, isolate=<unavailable>) at node_platform.cc:462:25 [opt]
    frame #12: 0x00000001024351b0 node`node::FreeEnvironment(env=<unavailable>) at environment.cc:513:15 [opt]
    frame #13: 0x0000000102542ad8 node`node::NodeMainInstance::Run() [inlined] node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>::operator()(this=<unavailable>, pointer=0x0000000121822c00) const at util.h:675:39 [opt]
    frame #14: 0x0000000102542ad0 node`node::NodeMainInstance::Run() [inlined] std::__1::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>>::reset(this=<unavailable>, __p=0x0000000000000000) at memory:1689:7 [opt]
    frame #15: 0x0000000102542ad0 node`node::NodeMainInstance::Run() [inlined] std::__1::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>>::~unique_ptr(this=<unavailable>) at memory:1643:19 [opt]
    frame #16: 0x0000000102542ad0 node`node::NodeMainInstance::Run() [inlined] std::__1::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment(node::Environment*)>>::~unique_ptr(this=<unavailable>) at memory:1643:17 [opt]
    frame #17: 0x0000000102542ad0 node`node::NodeMainInstance::Run(this=<unavailable>) at node_main_instance.cc:90:1 [opt]
    frame #18: 0x00000001024cb6c8 node`node::Start(int, char**) [inlined] node::StartInternal(argc=<unavailable>, argv=<unavailable>) at node.cc:1374:24 [opt]
    frame #19: 0x00000001024cb62c node`node::Start(argc=<unavailable>, argv=<unavailable>) at node.cc:1381:27 [opt]
    frame #20: 0x0000000107e090f4 dyld`start + 520
```

@nodejs/v8 does anything immediately stand out to you?","cjihrig",2512748,"2023-09-30 14:17:56","able reproduce macos reproduce time possibly race condition use small bash script node v8 coverage test runner also hear folk reproduce without test runner ie use node tap different codebase node v8 coverage present inspector enable startup process get ready exit call endstartedprofilers sure miss cleanup step process hang enter infinite loop flush add new task thread queue com apple main thread stop reason signal sigstop frame libsystem malloc dylib nanov2 pointer size frame libsystem malloc dylib nanov2 size frame libsystem malloc dylib free frame node node perisolatplatformdata flushforegroundtasksinternal inline std default delete v8 task operator this unavailable ptr const memory frame node node perisolatplatformdata flushforegroundtasksinternal inline std unique ptr v8 task std default delete v8 task reset this unavailable frame node node perisolatplatformdata flushforegroundtasksinternal inline std unique ptr v8 task std default delete v8 task unique ptr this unavailable frame node node perisolatplatformdata flushforegroundtasksinternal inline std unique ptr v8 task std default delete v8 task unique ptr this unavailable frame node node perisolatplatformdata flushforegroundtasksinternal this node platform frame node node nodeplatform draintasks this isolate node platform frame node node freeenvironment env environment frame node node nodemaininstance run inline node functiondeleter node environment node freeenvironment node environment operator this unavailable pointer const util frame node node nodemaininstance run inline std unique ptr node environment node functiondeleter node environment node freeenvironment node environment reset this unavailable frame node node nodemaininstance run inline std unique ptr node environment node functiondeleter node environment node freeenvironment node environment unique ptr this unavailable frame node node nodemaininstance run inline std unique ptr node environment node functiondeleter node environment node freeenvironment node environment unique ptr this unavailable frame node node nodemaininstance run this node main instance frame node node start inline node startinternal argc argv node frame node node start argc argv node frame dyld start new task come v8 internal heap postfinalizationregistrycleanuptaskifneeded note add printf curious top couple frame thread queue com apple main thread stop reason signal sigstop frame libsystem kernel dylib write nocancel frame libsystem c dylib swrite frame libsystem c dylib swrite frame libsystem c dylib sfvwrite frame libsystem c dylib puts frame node non virtual thunk node perisolatplatformdata postnonnestabletask inline node perisolatplatformdata postnonnestabletask this unavailable task v8 task frame node non virtual thunk node perisolatplatformdata postnonnestabletask node platform frame node v8 internal heap postfinalizationregistrycleanuptaskifneeded heap frame node v8 internal finalizationregistrycleanuptask runinternal this finalization registry cleanup task frame node node perisolatplatformdata runforegroundtask this task v8 task node platform frame node node perisolatplatformdata flushforegroundtasksinternal this node platform frame node node nodeplatform draintasks this isolate node platform frame node node freeenvironment env environment frame node node nodemaininstance run inline node functiondeleter node environment node freeenvironment node environment operator this unavailable pointer const util frame node node nodemaininstance run inline std unique ptr node environment node functiondeleter node environment node freeenvironment node environment reset this unavailable frame node node nodemaininstance run inline std unique ptr node environment node functiondeleter node environment node freeenvironment node environment unique ptr this unavailable frame node node nodemaininstance run inline std unique ptr node environment node functiondeleter node environment node freeenvironment node environment unique ptr this unavailable frame node node nodemaininstance run this node main instance frame node node start inline node startinternal argc argv node frame node node start argc argv node frame dyld start nodejs v8 anything immediately stand
"
1000,197,"Both codebases that I've seen this observed on are using `FinalizationRegistry`. Adding the following code to my reproduction seems to have fixed the hang (although it's obviously not a proper solution):

```js
globalThis.FinalizationRegistry = function(){};
globalThis.FinalizationRegistry.prototype.register = function(){};
```

There seems to be an issue with Node's use of the inspector interacting with `FinalizationRegistry`.","cjihrig",2512748,"2023-09-30 15:55:00","codebase observe use finalizationregistry add code reproduction fix hang proper solution issue node use inspector interact finalizationregistry
"
1001,197,"Possibly related issue with D8: https://bugs.chromium.org/p/v8/issues/detail?id=14281.","cjihrig",2512748,"2023-10-03 18:07:11","issue d8
"
1002,197,"Possibly related: https://github.com/nodejs/node/pull/47452 maybe we can try to see if the bug goes away with that PR?","joyeecheung",4299420,"2023-10-04 15:47:03","bug go away PR
"
1003,197,"I just tried that patch. Unfortunately, I still observed the process hang.","cjihrig",2512748,"2023-10-04 15:54:39","tried patch unfortunately still observe process hang
"
1004,197,"Can this be bisected to a particular commit? (I would expect it to be one of those V8 upgrades, perhaps we can just test the ones around V8 upgrades with the repro)","joyeecheung",4299420,"2023-10-04 16:05:25","bisect particular commit expect v8 upgrade test v8 upgrade repro
"
1005,197,"Was it introduced in 20.0.0 or a later update?","targos",2352663,"2023-10-04 16:05:46","introduce late update
"
1006,197,"There was (sadly) no V8 upgrade since v20.0.0","targos",2352663,"2023-10-04 16:06:07","v8 upgrade v20.0.0
"
1007,197,"It has been tricky to bisect because it doesn't reproduce all the time. For the reproduction in this issue, I'm only seeing it on Node 20 (which would be convenient because of the V8 update in 20.0.0). However, in an unrelated codebase, I first witnessed what I believe to be the same bug on Node 18 back in February - at the time I thought it was just a bug in c8 as it went away with Node 19.

I believe @mcollina has observed the bug on versions other than 20. @isaacs has seen an issue in node-tap related to source maps that seems very similar to this one as well. Unfortunately, we don't know if we are all seeing the same bug, or if there are multiple bugs that all result in a hang.","cjihrig",2512748,"2023-10-04 16:30:09","bisect tricky reproduce time reproduction issue node convenient v8 update unrelated codebase witness bug node february bug c8 node believe observe bug version issue node tap relate source map similar unfortunately know bug result hang
"
1008,197,"From the [discussions](https://github.com/nodejs/TSC/pull/1450/files) at the TSC meeting it seemed like there was consensus to document in release notes and the release announcement as a known limitation versus delaying the LTS promotion. The exception might be if we had a confirmed fix, but needed a few more days to get it landed. As @richardlau mentioned, the decision is up to the Release team to make one way or the other.


","mhdawson",9373002,"2023-10-04 19:18:46","document release note release announcement known limitation delay lts promotion exception confirm fix day land decision release team
"
1009,197,"If we are not even sure this is a regression in v20.x, is this still relevant for the v20.x LTS promotion? It seems there are reports that this could go back to v18.x https://github.com/nodejs/node/issues/49344#issuecomment-1747256117","joyeecheung",4299420,"2023-10-05 16:47:03","regression relevant promotion report go back
"
1010,197,"We have been experiencing this issue with ava as far back as Node 16 I believe: https://github.com/Agoric/agoric-sdk/pull/7619

Others have been experiencing the same issue with other environments: https://github.com/pact-foundation/pact-js/issues/1074

At some point we had a half consistent repro, at least on some environments. Since then I've successfully worked around the issue by [having ava call `takeCoverage()`](https://github.com/Agoric/agoric-sdk/pull/7619/files#diff-532e79ef9219d38160660c96d08d34bc4cebeb10be918073d7b3e83818b2c5fdR144-R146) before exiting. We have not experienced a hang since.","mhofman",86499,"2023-10-06 13:22:16","experiencing issue ava far node believe point half consistent repro least environment successfully work around issue ava call takecoverage exit experience hang since
"
1011,197,"Small update: I can no longer reproduce this on v20.8.1 or v21.0.0. However, the bug is not really fixed. Those versions include a version of undici with workarounds for `NODE_V8_COVERAGE`. If I undo those workarounds, the hang returns.

> Since then I've successfully worked around the issue by [having ava call takeCoverage()](https://github.com/Agoric/agoric-sdk/pull/7619/files#diff-532e79ef9219d38160660c96d08d34bc4cebeb10be918073d7b3e83818b2c5fdR144-R146) before exiting.

Worth noting that I tried that in Node core with no luck.","cjihrig",2512748,"2023-10-21 18:58:34","update reproduzir v20.8.1 v21.0.0 bug corrigir versão undici workaround node_v8_coverage undo workaround hang retornar sucesso workaround issue ava call takecoverage sair notar tentar node core sorte
"
1012,197,"node:internal/errors:497
    ErrorCaptureStackTrace(err);
    ^

Error: querySrv ETIMEOUT _mongodb._tcp.cluster0.femsvtn.mongodb.net
    at QueryReqWrap.onresolve [as oncomplete] (node:internal/dns/promises:251:17) {
  errno: undefined,
  code: 'ETIMEOUT',
  syscall: 'querySrv',
  hostname: '_mongodb._tcp.cluster0.femsvtn.mongodb.net'
}

Node.js v20.9.0
[nodemon] app crashed - waiting for file changes before starting...



i have face this error for node   V-20.9.1 LTS  ","Pratik4412",121230559,"2023-11-09 09:17:30","error querySrv ETIMEOUT node mongodb net errno code ETIMEOUT syscall querySrv hostname mongodb net nodemon app crashed wait file change face error node LTS
"
1013,197,"@bcoe do you think you can take a look at this?","mcollina",52195,"2023-11-20 19:17:32","think take look
"
1268,232,"cc @lemire","anonrig",1935246,"2023-04-07 15:23:19","lemire retornar
"
1374,243,"this is the pr where `res.strictContentLength` the https://github.com/nodejs/node/pull/44378 but it has not been documented in http.md. I'll add it","marco-ippolito",36735501,"2023-02-12 11:55:00","add document res strictcontentlength
"
1014,197,"> @bcoe do you think you can take a look at this?

@mcollina I might potentially have some time over the holidays to look, but I do not have any time prior.

@cjihrig how convinced are you that this is related to https://bugs.chromium.org/p/v8/issues/detail?id=14281? I could try to find someone from Chromium to take a look.","bcoe",194609,"2023-11-20 19:43:30","think take look might potentially time holiday look time prior convinced relate try find someone chromium take look
"
1015,197,"@bcoe https://bugs.chromium.org/p/v8/issues/detail?id=14281 does seem extremely close to what's going on in node. The generation of the `source-map-cache` (which node does when `NODE_V8_COVERAGE` is set) makes use of the FinalizationRegistry. If you look up a lot of source maps (150-200 or so) right as the isolate is about to quit, it'll trigger a hang pretty reliably, especially if some of those source map files can't be found. I was able to avoid it in node-tap by looking them up proactively, so that I only ever have 0 or 1 at process exit.","isaacs",9287,"2023-11-21 08:32:03","node generation source map cache make use finalizationregistry look source map isolate quit trigger hang reliably source map file avoid node tap look proactively process exit
"
1016,197,"Linking https://github.com/nodejs/node/issues/47748 here as they look similar.","richardlau",5445507,"2023-11-29 13:26:53","link similar
"
1017,197,"@bcoe did you have any luck with the V8 team?","mcollina",52195,"2023-12-13 09:59:44","luck v8 team
"
1018,197,"@cjihrig out of curiosity, what happens if you add ` fg.cleanupSome();` after the call to `unregister` in the iterable weakmap?

My guess is this helper cleans up resources immediately, rather than waiting until exit? I wonder if it happens to break the deadlock behavior. I haven't dug any real digging, I was just reading that the v8 bug, which says all the test262 test cases use cleanupSome.
","bcoe",194609,"2023-12-13 14:29:08","curiosity happen add fg cleanup call unregister iterable weakmap guess helper clean resource immediately wait exit wonder happen break deadlock behavior dig real dig read v8 bug say test262 test case use cleanupSome
"
1019,197,"> @bcoe did you have any luck with the V8 team?

@mcollina yes, and I have an offer of help in the new year...

However, looking at @paulrutter's analysis with gdb in #47748, I think there's a chance this isn't a bug with v8, but an issue with JavaScript callbacks being registered with FinalizationRegistry, and then causing an exception when they execute late. 

Thoughts on this line of thinking?

","bcoe",194609,"2023-12-18 16:41:25","luck v8 team offer help year look analysis chance bug v8 issue javascript callback register finalizationregistry cause exception execute thought line thinking
"
1020,197,"I think the analysis in https://github.com/nodejs/node/issues/47748#issuecomment-1846037987 might actually be correct. It's something we should fix on our end before digging deep on the V8 side.","mcollina",52195,"2023-12-18 18:04:26","analysis correct fix end dig v8 side
"
1021,197,"A minimal script https://github.com/nodejs/node/issues/47748#issuecomment-1862079963 to reliably reproduce the problem and generate the same call stacks mentioned above.","legendecas",8500303,"2023-12-19 06:16:56","script reproduzir problema gerar pilha chamadas
"
1022,198,"Hey! Thanks for the report, and the repro case is really good, I'm gonna work on this one :-)","juanarbol",17013303,"2023-08-09 01:06:37","report repro case good work
"
1023,198,"The problem seems to be the `moveMessagePortToContext` call, the crash is gone by doing this:

```js
context.messagePort = workerData.crash ? workerData.messagePort : messageChannel.port2
```

I'm investigating a bit more, and send a possible fix for this one","juanarbol",17013303,"2023-08-13 17:09:12","problem seem moveMessagePortToContext call crash gone investigate send possible fix
"
1024,199,"I'm guessing this is because the test runner uses the `beforeExit` event, and the ref'ed handle prevents that from being emitted. We'll need to move to a different mechanism for detecting when all of the tests have run.","cjihrig",2512748,"2023-08-07 18:03:29","guess test runner use beforeexit event ref handle prevent emit need move different mechanism detect test run
"
1025,199,"I guessed as much, however the above pattern is really good.","mcollina",52195,"2023-08-07 18:36:45","guessed pattern good
"
1026,199,"I looked at this really quickly. The good news is that it's pretty simple to fix this case:

```diff
diff --git a/lib/internal/test_runner/harness.js b/lib/internal/test_runner/harness.js
index 36c36f2de1..e9076eb378 100644
--- a/lib/internal/test_runner/harness.js
+++ b/lib/internal/test_runner/harness.js
@@ -158,7 +158,6 @@ function setup(root) {
 
   process.on('uncaughtException', exceptionHandler);
   process.on('unhandledRejection', rejectionHandler);
-  process.on('beforeExit', exitHandler);
   // TODO(MoLow): Make it configurable to hook when isTestRunner === false.
   if (globalOptions.isTestRunner) {
     process.on('SIGINT', terminationHandler);
@@ -180,6 +179,7 @@ function setup(root) {
       topLevel: 0,
       suites: 0,
     },
+    exitHandler,
     shouldColorizeTestFiles: false,
   };
   root.startTime = hrtime();
diff --git a/lib/internal/test_runner/test.js b/lib/internal/test_runner/test.js
index cc7c81cad8..fd22433a3d 100644
--- a/lib/internal/test_runner/test.js
+++ b/lib/internal/test_runner/test.js
@@ -687,6 +687,13 @@ class Test extends AsyncResource {
       this.parent.addReadySubtest(this);
       this.parent.processReadySubtestRange(false);
       this.parent.processPendingSubtests();
+
+      if (this.parent === this.root &&
+          this.root.activeSubtests === 0 &&
+          this.root.pendingSubtests.length === 0 &&
+          this.root.readySubtests.size === 0) {
+        this.root.harness.exitHandler();
+      }
     } else if (!this.reported) {
       if (!this.passed && failed === 0 && this.error) {
         this.reporter.fail(0, kFilename, this.subtests.length + 1, kFilename, {
```

The bad news is that a couple tests are failing. I think it's just related to handling asynchronous activity after the tests finish running like:

```js
test('extraneous async activity test', () => {
  setTimeout(() => { throw new Error(); }, 100);
});
```

This is kind of expected since the test runner finishes ASAP now instead of once the process is getting ready to exit. I'll have to keep looking into how to best handle this case.","cjihrig",2512748,"2023-08-07 19:10:55","test fail relate handle asynchronous activity test finish run expect test runner finish asap process get ready exit look handle case
"
1027,199,"CC @giltayar we might have discussed this use-case or a similar one in Node.TLV","MoLow",8221854,"2023-08-11 06:26:27","discuss use case similar node tlv
"
1028,200,"I can reproduce on macOS. `Buffer.from()` and `Buffer.allocUnsafe()` use the internal `Buffer` pool so it might be related to that.","lpinca",1443911,"2023-08-03 19:19:00","reproduce macOS Buffer use internal Buffer pool relate
"
1029,200,"The culprit seems to be this commit https://github.com/nodejs/node/commit/2ef13b8fb638d9d7b815296dfbf6a631868ce001.

cc: @anonrig ","lpinca",1443911,"2023-08-03 19:28:38","culprit seem commit
"
1030,200,"FWIW this seems to fix the issue:

```diff
diff --git a/src/encoding_binding.cc b/src/encoding_binding.cc
index b65a4f868e..747df2c40c 100644
--- a/src/encoding_binding.cc
+++ b/src/encoding_binding.cc
@@ -164,9 +164,9 @@ void BindingData::DecodeUTF8(const FunctionCallbackInfo<Value>& args) {
   size_t length = buffer.length();
 
   if (has_fatal) {
-    auto result = simdutf::validate_utf8_with_errors(data, length);
+    bool is_valid = simdutf::validate_utf8(data, length);
 
-    if (result.error) {
+    if (!is_valid) {
       return node::THROW_ERR_ENCODING_INVALID_ENCODED_DATA(
           env->isolate(), ""The encoded data was not valid for encoding utf-8"");
     }

```

cc: @lemire ","lpinca",1443911,"2023-08-03 19:41:33","fix issue validate utf
"
1176,224,"I think the `idna.js` is flawed. `icu.toASCII` does not equal to `domainToASCII`. I think our approach is correct, but the previous code was flawed, and our pull request on removing the ICU from `idna.js` exposed the bug.","anonrig",1935246,"2023-04-26 16:49:44","idna flaw icu.toascii equal domaintoascii approach correct previous code flaw pull request remove icu idna expose bug
"
1410,247,"> 

OMG 😂 

I'd like to help working on it. Do you know where to look at?","ErickWendel",8060102,"2023-01-09 14:40:55","like help work know look
"
1031,200,"No string that begins with the byte value 0x80 can be valid (does not matter what comes after).

I have added tests for this upstream, specifically

```C++
  const char bad[1] = {(char)0x80};
  size_t length = 1;
  simdutf::result res = implementation.validate_utf8_with_errors(bad, length);
  ASSERT_TRUE(res.error);
```

We run tests with sanitizers, so an out-of-bound access or an undefined behavior would be detected.

https://github.com/simdutf/simdutf/pull/265


What is the expectation in this routine...?

```C++
if (has_fatal) {
     auto result = simdutf::validate_utf8_with_errors(data, length);

     if (result.error) {
       return node::THROW_ERR_ENCODING_INVALID_ENCODED_DATA(
           env->isolate(), ""The encoded data was not valid for encoding utf-8"");
     }
   }
```

Is the expectation that the data is incorrect? If so, I would encourage `validate_utf8_with_errors` as it is likely more performant.","lemire",391987,"2023-08-03 23:36:24","byte value valid matter add test upstream run test sanitizer out bound access undefined behavior expectation routine data incorrect encourage validate utf performant
"
1032,200,"I think the expectation is that data is correct. Anyway the reproduction script calls `validate_utf8_with_errors` 20000 times and it fails only a few times on my machine. Sometimes it does not fail. `validate_utf8` never fails.

```
luigi@imac:Desktop$ cat repro.js 
let error1Count = 0;
let error2Count = 0;
for (let index = 0; index < 20000; index++) {
  try {
    const buffer = Buffer.from([0x80]); // this is unstable
    // const buffer = Buffer.allocUnsafe(1) // this is unstable
    // const buffer = Buffer.alloc(1)       // this is stable
    buffer[0] = 0x80;
    const data = new TextDecoder('utf-8', { fatal: true }).decode(buffer);
    error1Count++; // then data is the '\uFFFD' replacement character
  } catch {}
  try {
    // this is stable
    const data = new TextDecoder('utf-8', { fatal: true }).decode(
      new Uint8Array([0x80])
    );
    error2Count++;
  } catch {}
}
console.log(error1Count, error2Count);
luigi@imac:Desktop$ node repro.js 
5 0
luigi@imac:Desktop$ node repro.js 
0 0
luigi@imac:Desktop$ node repro.js 
4 0
luigi@imac:Desktop$ node repro.js 
108 0
luigi@imac:Desktop$ node repro.js 
73 0
luigi@imac:Desktop$ node repro.js 
2 0
```","lpinca",1443911,"2023-08-04 14:43:52","expect data correct reproduction script call validate_utf8_with_errors time fail time machine sometimes fail validate_utf8 never fail  error count error count try buffer unstable buffer unstable buffer stable buffer data textdecoder utf fatal true decode buffer error count data textdecoder utf fatal true decode uint8array error count console log
"
1033,200,"I am going to be adding tests upstream today. Give me 24 hours to research this, to see whether there is an issue.","lemire",391987,"2023-08-04 14:53:44","add test upstream research issue
"
1034,200,"Sure, no hurries.","lpinca",1443911,"2023-08-04 14:56:00","Sure no hurries
"
1035,200,"I am going to be issue a patch release.","lemire",391987,"2023-08-04 16:25:18","go issue patch release
"
1036,200,"The issue is upstream in simdutf. I have a patch release for it https://github.com/simdutf/simdutf/releases/tag/v3.2.15

I recommend upgrading to v3.2.15. It is nearly identical to v3.2.14 except for this one issue.

cc @anonrig ","lemire",391987,"2023-08-04 17:32:08","issue upstream simdutf patch release recommend upgrade nearly identical issue
"
1037,200,"Thanks @lpinca and @anonrig for updating.

Thanks @JoakimCh  for reporting the issue.","lemire",391987,"2023-08-16 19:10:00","update report issue
"
1038,201,"Good catch. FYI if you paste a ""Permalink URL"", it will show the line(s) of code: https://github.com/nodejs/node/blob/fe514bf960ca1243b71657af662e7df29f5b57cf/lib/internal/modules/esm/formats.js#L29

Would you like to send a PR to fix this?","aduh95",14309773,"2023-07-29 13:22:02","good catch paste permalink url show line code would like send pr fix
"
1039,201,"No thanks, I won't be able to get to this.","ghost",10137,"2023-07-29 14:17:53","get
"
1040,201,"@aduh95 i will be happy  to help with this bug","ntedgi",31243793,"2023-07-29 20:19:40","happy help bug
"
1041,201,"> @aduh95 i will be happy to help with this bug

I would be glad helping with this, too. Feel free to reach me if you want to.","lzcampos",56274028,"2023-08-01 01:53:41","happy help bug glad help free reach
"
1042,201,"I started working on it, but I'm figuring out that the MIME type may be wrong overall.

The current regexp also allow `application/javascript` while the doc clearly indicate that only `text/javascript` is valid: https://nodejs.org/api/esm.html#data-imports

As https://datatracker.ietf.org/doc/html/rfc9239 stands that `text/javascript` is now common and `application/javascript` is obsolete and the PR was made when it wasn't the case, I'll submit a PR changing that to get comment about this specific point.","Xstoudi",2575182,"2023-08-09 23:13:32","mime type wrong regexp allow application javascript doc indicate text javascript valid submit pr change get comment specific point
"
1043,201,"As the previous PR got closed and it seems that nobody is currently working on this issue I would like to submit a PR :)

Edit: The change is pretty simple, I'm now creating a test case.","andremralves",71379045,"2023-08-11 03:31:38","pr fechar ninguém trabalhar issue submeter pr mudar simples criar caso teste
"
1044,203,"Closing. I was using v18.16.1 and in v18.17.0 is fixed.","mcollina",52195,"2023-07-27 15:13:45","close use v18.16.1 v18.17.0 fix
"
1045,203,"Actually it's a problem, updating the report.","mcollina",52195,"2023-07-27 15:17:07","problem update report
"
1046,203,"This appears to be a bug with the TAP reporter.","cjihrig",2512748,"2023-07-27 15:21:21","bug tap reporter
"
1047,203,"This seems to fix it:

```diff
diff --git a/lib/internal/test_runner/reporter/tap.js b/lib/internal/test_runner/reporter/tap.js
index 4aec4ba072..e22c647669 100644
--- a/lib/internal/test_runner/reporter/tap.js
+++ b/lib/internal/test_runner/reporter/tap.js
@@ -198,15 +198,14 @@ function jsToYaml(indent, name, value, seen) {
       errStack = cause?.stack ?? errStack;
       errCode = cause?.code ?? errCode;
       errName = cause?.name ?? errName;
+      errMsg = cause?.message ?? errMsg;
+
       if (isAssertionLike(cause)) {
         errExpected = cause.expected;
         errActual = cause.actual;
         errOperator = cause.operator ?? errOperator;
         errIsAssertion = true;
       }
-      if (failureType === kTestCodeFailure) {
-        errMsg = cause?.message ?? errMsg;
-      }
     }
 
     result += jsToYaml(indent, 'error', errMsg, seen);
```","cjihrig",2512748,"2023-07-27 15:39:21","fix error message assertion expected actual operator assertionlike
"
1048,203,"Proposed fix in https://github.com/nodejs/node/pull/48942","cjihrig",2512748,"2023-07-27 16:07:33","fix
pull
"
1049,204,"Can you please provide a reproduction so it will be easier for us to fix the issue? 😄 ","rluvaton",16746759,"2023-07-30 18:46:03","provide reproduction easy fix issue
"
1050,204,"I would like to work on this one. Please assign","ocodista",19851187,"2023-07-30 18:55:18","work one assign
"
1051,204,"You can't assign in GitHub issues as far as I know, you can just start working on this

don't forget to add a test that fails on main and pass with your fix :)","rluvaton",16746759,"2023-07-30 18:57:38","assign github issue work add test fail main pass fix
"
1052,204,"Created a minimum reproduction for this issue
https://github.com/ocodista/node-issue-48937","ocodista",19851187,"2023-07-30 19:16:44","reproduction issue
"
1053,204,"> Created a minimum reproduction for this issue
> [ocodista/node-issue-48937](https://github.com/ocodista/node-issue-48937)

This is not exactly the same as the issue I'm facing... I'm using an Async Iterator, meanwhile at https://github.com/ocodista/node-issue-48937/blob/main/customReporter.js, you are using Stream API and throwing an exception. That would be a different unhandled exception, I think the similar one would be to pass the exception to the callback (I'm not fully sure how exceptions handling should work with async iterators...).","piranna",532414,"2023-07-30 19:26:00","criado mínimo reprodução issue usar iterator assíncrono entretanto usar stream api lançar exceção diferente exceção não tratada penso similar passar exceção callback certo exceções funcionar iteradores assíncronos
"
1054,204,"> > Created a minimum reproduction for this issue
> > [ocodista/node-issue-48937](https://github.com/ocodista/node-issue-48937)
> 
> This is not exactly the same as the issue I'm facing... I'm using an Async Iterator, meanwhile at https://github.com/ocodista/node-issue-48937/blob/main/customReporter.js, you are using Stream API and throwing an exception. That would be a different unhandled exception, I think the similar one would be to pass the exception to the callback (I'm not fully sure how exceptions handling should work with async iterators...).

I just updated the repo and replaced the customReporter implementation with one that uses a generator function.","ocodista",19851187,"2023-07-30 19:28:38","use async iterator generator function exception handle
"
1055,204,"> Can you please provide a reproduction so it will be easier for us to fix the issue?

I found this issue with https://github.com/Mafalda-SFU/node-test-reporter-json/blob/main/index.js, it seems Node.js recently added `test:enqueue` and `test:dequeue` events, and since I was not handling them, the switch when to the default branch, throwing the exception.

OffTopic: by the way, this is a JSON reporter, we can talk about including it in Node.js core if interested :-)","piranna",532414,"2023-07-30 19:30:21","provide reproduction easy fix issue find issue seem node recently add test enqueue test dequeue event handle switch default branch throw exception
"
1056,204,"> I just updated the repo and replaced the customReporter implementation with one that uses a generator function.

Cool, thank you :-)","piranna",532414,"2023-07-30 19:30:38","update repo replace customReporter implementation generator function thank
"
1057,204,"I think this is going to be somewhat involved to fix properly. The problem is that the error from the reporter ends up in the `uncaughtException` handler. Inside of the handler, we process errors and send them to... the reporter. This is the right thing to do in most cases since we want to control how the errors are logged.

We currently re-throw the error in the case where the test runner has not finished bootstrapping itself yet. I think that's what we should do in this case as well. The problem is distinguishing errors originating from the reporter from other errors. I don't think we can get away with only adding a `try...catch` or `'error'` event handler somewhere because the reporter could technically do something like `setImmediate(() => { throw new Error('boom'); });`.

I think to properly identify reporter errors, we need to run the `TestsStream.prototype[kEmitMessage]()` code in a new async context and leverage the existing async hook in `harness.js`. Essentially, we would track reporter errors like we track errors from the tests themselves.

Of course, we could also let the test runner break when it encounters an error that originates from somewhere other than a test. It's simpler, but less nice IMO (also technically a breaking change since we test this behavior).","cjihrig",2512748,"2023-07-31 22:27:40","think involved fix properly problem error reporter end uncaughtException handler handler process error send reporter right thing case want control error log currently re throw error case test runner finish bootstrap think case well problem distinguish error originate reporter error think get away add try catch error event handler somewhere reporter technically something setImmediate throw new error boom think properly identify reporter error need run TestsStream prototype kEmitMessage code new async context leverage exist async hook harness essentially would track reporter error track error test course could also let test runner break encounter error originate somewhere test simple nice imo technically break change since test behavior
"
1058,204,"> I think this is going to be somewhat involved to fix properly. The problem is that the error from the reporter ends up in the `uncaughtException` handler. Inside of the handler, we process errors and send them to... the reporter.

Difficult to find a more appropriate situation to give here the most obvious intended pun... who watches the watchmen? 🤡 


> We currently re-throw the error in the case where the test runner has not finished bootstrapping itself yet. I think that's what we should do in this case as well.

I think the same too.


> Of course, we could also let the test runner break when it encounters an error that originates from somewhere other than a test. It's simpler, but less nice IMO (also technically a breaking change since we test this behavior).

As a short term solution, I agree with this idea, it can help us to better understand the problem and find a more correct solution. As far as the errors are not being swallowed and silenced as it's currently happening, it's fine for me.","piranna",532414,"2023-07-31 22:45:40","think somewhat involv fix proper problem error reporter end uncaughtException handler handler process error send reporter difficult find appropriat situation give obvious intend pun watch watchmen currently re throw error case test runner finish bootstrapp yet think case also think also cours could also let test runner break encounter error origin somewher test simpler nice imo technic breaking chang short term solution agre idea help better understand problem find correct solution far error swallow silen happen fine
"
1059,204,"> As a short term solution, I agree with this idea

I don't think we should look at it like a short term solution. I think we should look at it as ""what is the desired behavior forever if we had to pick."" Either solution could be implemented before the next release. However, the proper fix could ship in the next release, while the change to let the test runner break would likely need to wait until October to ship.","cjihrig",2512748,"2023-07-31 23:04:14","solução curto prazo concordar ideia pensar olhar solução curto prazo pensar olhar comportamento desejado para sempre escolher solução implementar lançamento próximo no entanto correção adequada enviar lançamento próximo mudança permitir testador interromper provavelmente precisar esperar outubro enviar
"
1070,206,"> > the REPL can create a new V8 isolate and bypass any permission in several ways
> 
> Can you elaborate?

Basically, the same as https://github.com/nodejs/node/commit/34d92ed88c814e05b4b619705c67b3df3999c52d fixes. I don't have a reproducible example because I'm not sure if that's possible. I'm just wondering if REPL can create a new V8 isolate, it means it could create without the experimental permission rules, right?

Anyway, I created the #48920.","RafaelGSS",26234614,"2023-07-25 12:29:00","repl create new v8 isolate bypass permission way elaborate basically fix reproducible example sure possible wonder repl create new v8 isolate mean create experimental permission rule create
"
1177,224,"No need to revert, I'll add a new C++ function that directly calls `ada::idna::to_ascii` and expose them through internalBinding.","anonrig",1935246,"2023-04-26 16:50:42","need add new c++ function directly call ada idna ascii expose internalbinding
"
1178,226,"I'll take a stab at this one. Open to hearing any ideas anyone may have before I dig in.","GethosTheWalrus",7661715,"2023-06-16 00:52:03","take stab hear idea dig
"
1179,226,"hi @GethosTheWalrus If ur not working on it right now can i look into this issue
","Prateek462003",90177794,"2023-07-25 16:46:59","work issue
"
1060,204,"> > As a short term solution, I agree with this idea
> 
> I don't think we should look at it like a short term solution. I think we should look at it as ""what is the desired behavior forever if we had to pick."" Either solution could be implemented before the next release. However, the proper fix could ship in the next release, while the change to let the test runner break would likely need to wait until October to ship.

I would have expected that since I didn't have any error handling, the error would have buble up until it got to be an unhandled exception and crash the test runner. How should be the API to handled it? I don't know.

An alternative although more obscure would have been that the error would be redirected to the reporter as a failing test, but if a new exception is thrown that would lead to an infinite loop, but also we could add a field to the error to know if we have already processed it.","piranna",532414,"2023-07-31 23:11:53","solucao curto prazo concord ideia pensar curto prazo pensar comportamento desejado sempre solucao implementar proxima versao correcao proxima versao mudanca permitir testador quebrar outubro esperar esperar erro tratamento erro excecao nao tratada travar testador api tratar alternativa obscuro erro redirecionar relatar teste falha nova excecao lancada loop infinito campo erro processar
"
1061,204,"Couldn't new wrap the event calls to the reporter with a try-catch and log the error as something like ""ReporterError: ...""?

I think that would be the best output IMO","ocodista",19851187,"2023-07-31 23:54:19","wrap event call reporter try catch log error reportererror
"
1062,204,"> Couldn't new wrap the event calls to the reporter with a try-catch and log the error as something like ""ReporterError: ...""?
> 
> I think that would be the best output IMO

I don't fully understand your proposal, can you elaborate it?","piranna",532414,"2023-08-01 09:08:30","wrap event call reporter try catch log error reportererror best output proposal elaborate
"
1063,204,"> > Couldn't new wrap the event calls to the reporter with a try-catch and log the error as something like ""ReporterError: ...""?
> 
> > 
> 
> > I think that would be the best output IMO
> 
> 
> 
> I don't fully understand your proposal, can you elaborate it?

For example:

From the test_runner we need to call the events of the custom reporter.

My idea is that, whenever we call the event ""start"" (and others), we add a try-catch where, whenever the error happens, we write to output of the test_runner a new type of error, like `CustomReportError: ${error}`","ocodista",19851187,"2023-08-01 10:27:34","call event reporter try catch log error reportererror propose best output understand proposal elaborate example test runner call event custom reporter idea call event start add try catch error write output test runner type error customreporterror error
"
1064,204,"I just don't think a `try...catch` alone is going to be enough because errors can be asynchronous, but you're welcome to try that approach. I had something like this in mind:

```diff
diff --git a/lib/internal/test_runner/harness.js b/lib/internal/test_runner/harness.js
index 36c36f2de1..86e614ae4d 100644
--- a/lib/internal/test_runner/harness.js
+++ b/lib/internal/test_runner/harness.js
@@ -20,12 +20,15 @@ const { kEmptyObject } = require('internal/util');
 const { kCancelledByParent, Test, Suite } = require('internal/test_runner/test');
 const {
   parseCommandLine,
+  reporterScope,
   setupTestReporters,
 } = require('internal/test_runner/utils');
 const { bigint: hrtime } = process.hrtime;
 
 const testResources = new SafeMap();
 
+testResources.set(reporterScope.asyncId(), reporterScope);
+
 function createTestTree(options = kEmptyObject) {
   return setup(new Test({ __proto__: null, ...options, name: '<root>' }));
 }
@@ -42,6 +45,10 @@ function createProcessEventHandler(eventName, rootTest) {
     // Check if this error is coming from a test. If it is, fail the test.
     const test = testResources.get(executionAsyncId());
 
+    if (test === reporterScope) {
+      throw err;
+    }
+
     if (!test || test.finished) {
       // If the test is already finished or the resource that created the error
       // is not mapped to a Test, report this as a top level diagnostic.
diff --git a/lib/internal/test_runner/utils.js b/lib/internal/test_runner/utils.js
index fba2c31323..04647e9232 100644
--- a/lib/internal/test_runner/utils.js
+++ b/lib/internal/test_runner/utils.js
@@ -19,6 +19,7 @@ const {
   StringPrototypeSlice,
 } = primordials;
 
+const { AsyncResource } = require('async_hooks');
 const { relative } = require('path');
 const { createWriteStream } = require('fs');
 const { pathToFileURL } = require('internal/url');
@@ -35,6 +36,7 @@ const {
 } = require('internal/errors');
 const { compose } = require('stream');
 
+const reporterScope = new AsyncResource('TestReporterScope');
 const coverageColors = {
   __proto__: null,
   high: green,
@@ -162,14 +164,14 @@ async function getReportersMap(reporters, destinations, rootTest) {
 }
 
 
-async function setupTestReporters(rootTest) {
+const setupTestReporters = reporterScope.bind(async (rootTest) => {
   const { reporters, destinations } = parseCommandLine();
   const reportersMap = await getReportersMap(reporters, destinations, rootTest);
   for (let i = 0; i < reportersMap.length; i++) {
     const { reporter, destination } = reportersMap[i];
     compose(rootTest.reporter, reporter).pipe(destination);
   }
-}
+});
 
 let globalTestOptions;
 
@@ -411,6 +413,7 @@ module.exports = {
   isTestFailureError,
   kDefaultPattern,
   parseCommandLine,
+  reporterScope,
   setupTestReporters,
   getCoverageReport,
 };
```

That solution is not fully tested though, and unfortunately, it makes the test runner take extra ticks to fully bootstrap itself.","cjihrig",2512748,"2023-08-01 13:11:02","think try catch alone enough error asynchronous welcome try approach mind
"
1065,205,"This code is OK on node-v20.3.1-darwin-arm64.tar.gz, and failed on node-v20.4.0-darwin-arm64.tar.gz

other case:

```js:blob.mjs
// blob.mjs
import {describe, it, before, after} from ""node:test"";
import {strict as assert} from ""node:assert"";

describe(""blob"", async () => {
  it(""stream"", async () => {
    const bufs = [];
    const blob = new Blob([""A"", ""B"", ""C""]);
    await blob.stream().pipeTo(new WritableStream({
      write(chunk) {
        bufs.push(new TextDecoder().decode(chunk));
      }
    }));
    assert.equal(bufs.join(""""), ""ABC"");
    //assert.deepEqual(bufs, [""A"", ""B"", ""C""]); //node-20.3.1
    //assert.deepEqual(bufs, [""ABC""]); //chrome and firefox
  });
});
```

```shell
$ asdf global nodejs 20.3.1
$ node blob.mjs
▶ blob
  ✔ stream (6.642917ms)
▶ blob (7.957ms)

ℹ tests 1
ℹ suites 1
ℹ pass 1
ℹ fail 0
ℹ cancelled 0
ℹ skipped 0
ℹ todo 0
ℹ duration_ms 0.057125
```

```shell
$ asdf global nodejs 20.4.0
$ node blob.mjs
▶ blob
  ✖ stream (6.048208ms)
    'Promise resolution is still pending but the event loop has already resolved'

▶ blob (6.810833ms)

ℹ tests 1
ℹ suites 1
ℹ pass 0
ℹ fail 0
ℹ cancelled 1
ℹ skipped 0
ℹ todo 0
ℹ duration_ms 1.912083

✖ failing tests:

✖ stream (6.048208ms)
  'Promise resolution is still pending but the event loop has already resolved'

✖ blob (6.810833ms)
  'Promise resolution is still pending but the event loop has already resolved'
```

----

I encountered  the problem  when using Blob with helia:

```js
import {describe, it} from ""node:test"";
import {strict as assert} from ""node:assert"";

import {createHelia} from ""helia"";
import {unixfs} from ""@helia/unixfs"";

describe(""helia"", async () => {
  it(""unixfs.addByteStream"", async () => {
    const node = await createHelia();
    const nodefs = unixfs(node);

    const blob = new Blob([""Hello World!""], {type: ""text/plain""});
    const cid = await nodefs.addByteStream(blob.stream()); //never finished from nodejs>=20.4.0
    console.log(cid);

    await node.stop();
  });
});
```

----

From the blame list of [lib/internal/blob.js](https://github.com/nodejs/node/blame/main/lib/internal/blob.js),  the bug spawned by the change of  8cc14387a2e77d7a2b411e7edaed690d43ea3809 .

This issue may be same as #48668
","bellbind",69621,"2023-07-25 12:16:40","code work node version darwin arm tar gz fail node version darwin arm tar gz case import describe it before after node test import strict assert node assert describe async it async bufs blob new blob abc blob stream pipeto new writestream write chunk bufs push new textdecoder decode chunk assert equal bufs join abc assert deep equal bufs abc node version assert deep equal bufs abc chrome firefox test suite pass fail cancel skip todo duration test suite pass fail cancel skip todo duration problem use blob helia import describe it node test import strict assert node assert import createhelia helia import unixfs helia unixfs describe async it async node await createhelia nodefs unixfs blob new blob hello world type text plain cid await nodefs addbytestream blob stream node stop blame lib internal blob js github nodejs node blame main lib internal blob js bug spawn change issue may same
"
1066,206,"Hi, thanks for reporting it. I'm aware of this behaviour.","RafaelGSS",26234614,"2023-07-24 14:20:42","aware behaviour
"
1067,206,"Question is: should we make the internal calls to the inspector possible/privileged, or do like when the inspector is unavailable (this would just be a new condition in https://github.com/nodejs/node/blob/a0f3ed8ac40e7af441250ad8c2db0ed20b394adc/lib/internal/util/inspector.js#L48-L49)","targos",2352663,"2023-07-24 14:24:36",NULL
1068,206,"I believe REPL shouldn't be available when the permission model is enabled. Please let me know if I'm wrong, but the REPL can create a new V8 isolate and bypass any permission in several ways. If we start supporting REPL, it would mean that we need to cover all those cases.","RafaelGSS",26234614,"2023-07-24 14:31:49","believe repl available permission model enable wrong repl create new v8 isolate bypass permission way start support repl need cover case
"
1069,206,"> the REPL can create a new V8 isolate and bypass any permission in several ways

Can you elaborate?","targos",2352663,"2023-07-25 05:42:19","repl create new v8 isolate bypass permission way elaborate
"
1122,214,"Can I take on this issue?","winedarkmoon",127571479,"2023-06-17 17:53:42","take issue
"
1252,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51163/","nodejs-github-bot",18269663,"2023-04-12 16:40:07","CI
"
1071,207,"another test in my end doing a 100ms wait wil not have the same beharviour in that case return true always:

```js
import { setTimeout } from 'timers/promises';
while (true) {
  await setTimeout(100);
  const test = URL.canParse('/ ', 'http://n');
  console.log(test);
}

```

this will also fail at some point so maybe the 100 ms will aso fail just didnt get the point were it will fail


```js
import { setTimeout } from 'timers/promises';
while (true) {
  await setTimeout(1);
  const test = URL.canParse('/ ', 'http://n');
  console.log(test);
}
```","joacub",2091228,"2023-07-17 16:36:13","test end 100ms wait behaviour case return true fail point 100 ms fail point fail
"
1072,207,"@anonrig  i think you are following this changes so you may have all the details about this","joacub",2091228,"2023-07-17 16:39:20","think follow change detail
"
1073,207,"Thanks for the bug report. I confirm this is indeed a really awkward bug. cc @nodejs/url ","anonrig",1935246,"2023-07-17 16:45:55","bug report confirm awkward bug
"
1074,207,"This is probably due to v8 Fast API. When you call it multiple times, it triggers v8 fast api.","anonrig",1935246,"2023-07-17 16:46:27","due v8 fast api call multiple time trigger v8 fast api
"
1075,207,"@KhafraDev disabling/commenting out V8 Fast API fixes the bug","anonrig",1935246,"2023-07-17 16:48:18","disable comment v8 fast api fix bug
"
1076,207,"@joacub I opened a PR to fix this: https://github.com/nodejs/node/pull/48817","anonrig",1935246,"2023-07-17 17:43:19","abrir pr corrigir
"
1077,207,"> @joacub I opened a PR to fix this: #48817

Thank you so much sir, we are facing many many issues due to this and our websites goes down very often, thank you so much for your work ","joacub",2091228,"2023-07-17 18:48:13","fix issue website go often thank work
"
1078,208,"Thanks for reporting. I changed this in 4e3bc06e6547c1d640111b73e80e198ba03f7e45, but this is a bug.  I have removed the doc label because this should be fixed in the code. We should not expose any test objects to userland code.","cjihrig",2512748,"2023-08-02 22:10:50","bug fix code expose test object userland
"
1079,209,"I'm able to reproduce with `node --experimental-loader 'data:text/javascript,export function globalPreload(){return""throw null""}'` /cc @nodejs/loaders ","aduh95",14309773,"2023-07-15 07:55:35","reproduce node experimental loader export function global preload throw null
"
1080,210,"Could you provide any sample code to reproduce? preferably without any dependencies!","debadree25",20257253,"2023-07-14 07:22:44","provide sample code reproduce preferably dependency
"
1081,210,"Possibly related to https://github.com/nodejs/node/issues/47644? It might not be a duplicate because https://github.com/nodejs/node/issues/47644 was allegedly fixed (more than once). cc @ShogunPanda","tniessen",3109072,"2023-07-14 13:00:29","relate issue allegedly fix
"
1082,210,"I can't really do anything without at least a repro code. Will standby this.","ShogunPanda",201101,"2023-07-18 09:47:45","repro code standby
"
1083,210,"According to @Rand0mF's https://github.com/nodejs/node/issues/47644#issuecomment-1698909900, this also happens without using worker threads or web sockets.","tniessen",3109072,"2023-08-30 10:45:15","according random happen use worker thread web socket
"
1084,210,"If the bug is related to my changes (which most likely is), it's unrelated to either worker threads or websocket as we're talking about a bug in the connection handling. But I need the exact scenario to reproduce it, unfortunately.","ShogunPanda",201101,"2023-09-11 07:03:33","bug relate change worker thread websocket bug connection handle need exact scenario reproduce
"
1085,210,"@hp8wvvvgnj6asjm7 Has the issue been resolved?","tniessen",3109072,"2023-11-22 14:26:51","issue resolve
"
1086,210,"> @hp8wvvvgnj6asjm7 Has the issue been resolved?

no, but I can't make a small reproducible example and its so random that it's hard to tell what is going on.","hp8wvvvgnj6asjm7",45887282,"2023-11-22 17:02:26","issue resolve can not make small reproducible example random hard tell
"
1087,210,"This should have been fixed in #51045. Once it gets in 21.x or 20.x please let me know if you have additional problems.","ShogunPanda",201101,"2023-12-22 10:12:14","fix problem
"
1088,211,"cc @Ethan-Arrowood","anonrig",1935246,"2023-07-04 02:51:42","Ethan Arrowood
"
1089,211,"can i work on this?","pernelkanic",110184468,"2023-07-04 10:04:57","work
"
1090,211,"Can you share the case where it doesn't work with `withFileTypes`? I added a multitude of tests when I landed the option so I wanna know what I missed ","Ethan-Arrowood",16144158,"2023-07-04 15:12:11","case work filetype add multitude test land option wanna know miss
"
1091,211,"Btw it looks more like a bug than a documentation issue.","targos",2352663,"2023-07-04 15:21:40","bug documentation issue
"
1092,211,"> Btw it looks more like a bug than a documentation issue.

No documentation is provided for `recursive` regardless, so I think it's still an issue. Maybe I should have filed the lack of documentation and the bug separately.","That-Guy977",72870724,"2023-07-05 04:08:49","bug documentation issue documentation provide think issue file lack documentation bug separately
"
1093,211,"Can I work on this, it will be my first issue. 
","ghost",10137,"2023-07-05 04:47:37","work first issue
"
1094,211,"@Ethan-Arrowood From further testing, I've found some behavior that varies between the promise, callback, and synchronous versions.

- The promise version appears to not have any issues.

- The callback and synchronous versions can generate a entry `Dirent { name: undefined, path: '...', [Symbol(type)]: undefined }`, when `withFileTypes` is supplied, replacing a valid entry.

- The callback and synchronous versions fail to list certain files and directories when both `withFileTypes` and `recursive` are provided. I noticed this as several entries under `.git` missing, I'm unsure what the cause is. <details>Note: *Since nested directories themselves are not listed, these issues are likely not related to the recursion step as I had previously assumed, however this behavior is only present when `recursive` is also supplied and is not present in previous versions (Tested on Node v18.16.1.). I will update the original message to reflect this.*</details>

A minor inconsistency I found is that when providing the results the promise version appears to act as depth-first, while the callback and synchronous versions act as breath-first in their resulting arrays.

These tests have been on a limited filetree which I've uploaded to ~~[fs-readdir-recursive](https://github.com/That-Guy977/fs-readdir-recursive ""deadlink"")~~.","That-Guy977",72870724,"2023-07-05 05:14:24","teste comportamento variar promessa callback versão sincrona

promessa versão aparecer problema

callback versão sincrona gerar entrada dirent name undefined path symbol type undefined withfiletypes fornecer substituir entrada valido

callback versão sincrona falhar listar arquivo diretorio withfiletypes recursive fornecer notar entrada git faltar incerto causa nota diretorio aninhar listar problema provavelmente relacionado passo recursao assumir comportamento presente recursive presente versão anterior testar node v18.16.1 atualizar mensagem original refletir

pequeno inconsistencia encontrar fornecer resultado promessa versão aparecer agir profundidade primeiro callback versão sincrona agir largura primeiro array resultante

teste arquivo limit upload
"
1123,214,"> Can I take on this issue?

Please do. Happy to help if you get stuck on something. ","anonrig",1935246,"2023-06-17 19:21:18","take issue help get stuck
"
1180,227,"Based on the stack trace, it looks similar to https://github.com/nodejs/node/issues/46669 and https://github.com/nodejs/node/issues/46670, so possibly related to https://github.com/nodejs/node/pull/44731, https://github.com/nodejs/node/pull/46587. cc @ShogunPanda","tniessen",3109072,"2023-04-24 14:48:49","base stack trace look similar possibly relate
"
1181,227,"@tniessen It seems so. I'll take a look soon","ShogunPanda",201101,"2023-04-24 20:28:37","seem take look
"
1095,211,"Okay I can confirm there are two issues here. 

First, missing documentation for the `recursive` option for the `callback` and `sync` versions.

Second, I am seeing the `undefined` behavior in the `callback` and `sync` versions; I think your latest message @That-Guy977 explains it well. What I'm most intrigued by is how the tests aren't catching this. We definitely need to fix this. I'm going to start investigating this problem now. 

Finally, I do not believe the difference in search behavior matters. We make no guarantees in how Node recursively searches a directory. In a long historical thread I commented the possibility of specifying which algorithm could be used, but that is a feature not a bug in this case. 

Some users here expressed interest in contributing, @pernelkanic you commented first. Would you like to work on the documentation fix? ","Ethan-Arrowood",16144158,"2023-07-07 18:02:33","issue documentacao falta versao recursivo callback sync comportamento indefinido callback sync teste falha investigar problema diferenca busca importar garantia node busca recursivamente diretorio algoritmo funcionalidade usuario contribuir documentacao
"
1096,211,"> First, missing documentation for the `recursive` option for the `callback` and `sync` versions.

I believe the promise version has the same lack of documentation, as it and the other versions are lacking a similar description as `opendir` or `rm`, or even an explanation in the method description as is present in `mkdir`.","That-Guy977",72870724,"2023-07-07 18:26:06","missing documentation recursive option callback sync version believe promise version lack documentation similar description opendir rm explanation method description present mkdir
"
1097,211,"Oh good point 👍 that should be fixed too then","Ethan-Arrowood",16144158,"2023-07-07 18:27:11","good point fix
"
1098,211,"I'm happy to leave the documentation changes for a new contributor, but can also add those in if we get no response in a couple days.","Ethan-Arrowood",16144158,"2023-07-07 19:16:58","happy leave documentation change new contributor also add get response couple day
"
1099,211,"@RamdohokarAngha would you be interested in contributing docs for this? ","Ethan-Arrowood",16144158,"2023-07-19 16:37:12","interested contribute doc
"
1100,211,"@Ethan-Arrowood - Yes, I'm interested in contributing docs for this issue.
","ghost",10137,"2023-07-20 08:41:42","interested contribute doc issue
"
1101,211,"Thank you! Go for it! ","Ethan-Arrowood",16144158,"2023-07-20 15:34:13","go
"
1102,212,"The patch is a relatively simple find&replace but I wasn't sure if that's an acceptable patch in `deps/` (especially since it's a generated file). The fix only landed in 2.x of ada afaict.","jkrems",567540,"2023-07-01 15:29:28","patch relatively simple find replace acceptable patch deps generated file fix land ada
"
1103,212,"This will likely be fixed in https://github.com/nodejs/node/pull/48345 but the fact that we ended up with undefined behavior (which yes, didn't appear to break anything, maybe) in an LTS release make me question the recent pace of adding new C++ deps. It's a _lot_ of new, non-trivial, and non-hardened C++ code entering core.","jkrems",567540,"2023-07-01 15:36:02","fix likely end undefined behavior appear break anything lts release question recent pace add new c++ dep lot new non trivial non hardened c++ code enter core
"
1104,212,"Thanks for the report. I'm one of the authors of Ada. As you said, this is fixed in Ada v2.x, and is pending to be merged into the v18-x staging branch. (cc @nodejs/releasers)

> The patch is a relatively simple find&replace but I wasn't sure if that's an acceptable patch in deps/ (especially since it's a generated file). The fix only landed in 2.x of ada afaict.

Any changes to deps are prohibited and it's recommended for contributors to upstream any issues & fixes.

> release make me question the recent pace of adding new C++ deps

Unfortunately, Ada was the default URL parser for Node 19 and Node 20, and because most people prefer to stay in LTS, it is impossible to have the same amount of user feedback as a package would receive from a Node.js LTS release. Practically speaking, I believe it's inevitable to catch bugs like these without a certain users trying/using it.

> in an LTS release make me question the recent pace of adding new C++ deps

Here's the timeframe:

- January 29 - Ada v1.0 landed in main branch.
- April 4 - Ada backport to v18 open.
- April 12 - v18 first release including Ada parser.

To summarize: it took 74 days to land a new dependency to LTS release.

> It's a lot of new, non-trivial, and non-hardened C++ code entering core.

I disagree with your **non-trivial** classification. URL is one of the most important and used components in the Node.js runtime. If you have any specific recommendations about how to classify Ada as a **hardened** dependency, please open an issue to Ada's repository, and I'll be happy personally to follow up with them.

Regarding the status of Ada, let me give you some insight:

Ada has more tests than Web platform tests (which influenced URL parsers like curl and [boost/url](https://github.com/boostorg/url/pull/714) with finding bugs in their implementation, and has a significant test coverage & fuzzing coverage in Google's OSS Fuzz. 

But sometimes, it is not sufficient to catch bugs like these due to specific constraints, and despite how much code you write, and how much test you have in your project from time to time some significant bugs like these pass through.

cc @nodejs/url","anonrig",1935246,"2023-07-02 04:09:22","report author ada fix ada v2 x pending merge v18 x staging branch patch relatively simple find replace acceptable patch deps generated file fix land 2 x ada afaict change dep prohibit recommend contributor upstream issue fix release question recent pace add new c++ dep unfortunately ada default url parser node node people prefer stay lts impossible amount user feedback package would receive node js lts release practically believe inevitable catch bug user try use lts release question recent pace add new c++ dep timeframe january ada v1 0 land main branch april ada backport v18 open april v18 first release include ada parser summarize take 74 day land new dependency lts release lot new non trivial non hardened c++ code enter core disagree non trivial classification url important use component node js runtime specific recommendation classify ada hardened dependency please open issue ada repository happy personally follow status ada let give insight ada test web platform test influence url parser curl boost url find bug implementation significant test coverage fuzzing coverage google oss fuzz sometimes sufficient catch bug specific constraint despite much code write much test project time time significant bug pass through cc nodejs url
"
1105,212,"[This PR](https://github.com/nodejs/node/pull/46297) should help too","RafaelGSS",26234614,"2023-07-02 13:26:11","PR help
"
1106,212,"I think that @RafaelGSS’s answer is the right one. I expect that the community does not want to discourage fast paced contributions that improve the performance of Node. However, they also want high reliability. The two values are not in opposition: you can get more quality by improving testing as part of CI, improving tooling etc. In turn, this can make you more confident and able to receive contributions.

Regarding the URL parsing…

> Since Node.js 18, a new URL parser dependency was added to Node.js — Ada. This addition bumped the Node.js performance when parsing URLs to a new level. Some results could reach up to an improvement of 400%. ([State of Node.js Performance 2023](https://blog.rafaelgss.dev/state-of-nodejs-performance-2023))


Generally, my impression is Node should ramp up both the testing and the benchmarking… It seems that’s what Rafael is doing. 
","lemire",391987,"2023-07-02 16:46:00","think answer right expect community want discourage fast pace contribution improve performance node however want high reliability two value opposition get quality improve test part ci improve tool turn make confident able receive contribution regard url parse nodejs new url parser dependency add nodejs ada addition bump nodejs performance parse url new level result reach improvement state nodejs performance generally impression node ramp test benchmark seem rafael
"
1124,214,"> > Can I take on this issue?
> 
> Please do. Happy to help if you get stuck on something.

So the traverse function doesn't complete its execution before the files start to be watched, thus causing a race condition? Would introducing a mechanism to 'await' the initialization of the watcher could resolve this issue?","winedarkmoon",127571479,"2023-06-19 18:36:55","take issue please happy help get stuck traverse function complete execution file start watch cause race condition introduce mechanism await initialization watcher resolve issue
"
1125,214,"> So the traverse function doesn't complete its execution before the files start to be watched, thus causing a race condition? Would introducing a mechanism to 'await' the initialization of the watcher could resolve this issue?

That would be a breaking change since it will cause the function to behave differently in different operating systems.","anonrig",1935246,"2023-06-19 19:43:44","traverse function complete execution file start watch cause race condition introduce mechanism await initialization watcher resolve issue break change cause function behave differently operating system
"
1253,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51168/","nodejs-github-bot",18269663,"2023-04-12 17:55:28","CI
"
1254,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51171/","nodejs-github-bot",18269663,"2023-04-12 18:30:27","CI
"
1255,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51172/","nodejs-github-bot",18269663,"2023-04-12 19:35:46","CI
"
1107,212,"Thanks for the detailed response and for your work making URL parsing faster in node!

> Any changes to deps are prohibited and it's recommended for contributors to upstream any issues & fixes.

I'm generally aware of that but I wasn't sure how that policy deals with cases like this where node is using a major version that seemingly is no longer maintained upstream. If this was a more critical issue - would fixing it be blocked on doing a major version upgrade of the dependency? Or would we hope that upstream would create a new release line with a backport of the fix?

> I disagree with your non-trivial classification. URL is one of the most important and used components in the Node.js runtime.

By ""non-trivial"" I meant ""not just a few lines of obviously-correct code"". I didn't meant to imply anything about how important or heavily used the code is. We can definitely disagree on whether 2.5k LOC is ""trivial"" or not. I personally couldn't skim it and say ""yep, that's all correct"" which is roughly the bar I'd set for ""trivial code"". I'd be surprised if many developers could and that is the important part to me here, not the term ""trivial"".

> Practically speaking, I believe it's inevitable to catch bugs like these without a certain users trying/using it.

I definitely can understand that there's a tricky chicken&egg thing going on here. But in practice, this will likely mean that we're stuck on an older 18.x and can't upgrade to the latest version and the security fixes that brings. Which means that we get neither the faster URL parsing (which would have been a neat but non-critical win) nor all the other fixes (which we'd _actually_ care about).

So ada is getting real world exposure but at the expense of at least one (group of a few thousand) real world users not being able to upgrade within an LTS line. I'll readily admit that our little world is ""special"" since a typical nodejs setup doesn't require that ~all test suites pass with a bunch of sanitizers enabled. But I also can't tell teams to disable sanitizers on CI for a bit because node is incompatible.

> If you have any specific recommendations about how to classify Ada as a hardened dependency, please open an issue to Ada's repository, and I'll be happy personally to follow up with them.

To me, by definition, hardening only happens over time and with real usage. Which is a frustrating answer because it's not ""actionable"" but that cost of new code is very hard to ""solve"". New code will always be unstable (see also the very quick major bump).

But I want to be a bit more clear here: When I pointed out the pace of new native deps, I wasn't talking about ada in particular. Of all the new deps, ada is likely the one I have the least concerns about. Within the lifetime of node 18, multiple new native deps were added:

* First `aklomp/base64`. Around the time this was added, the author was already talking in issues about making breaking changes to the library. It had (afaik) a single author/maintainer, no other larger production uses, and no sanitizers or comparable checks (which required https://github.com/aklomp/base64/pull/105 since it had an out-of-bounds read in its tests).
* Then simdutf, postject, and ada. This time, there were 2 sanitizer violations/failed assertions and they made it into the LTS release itself, not just tests of those libraries. Ada had already made breaking changes, so getting the upstream fixes directly wasn't easy.

The issue in the OP is the one that I could easily identify and already have a workaround for. There's a second one in ada that I still can't easily reproduce that causes a failed assertion in the `string_view` constructor in one of our tests (length violation). But knowing that the 1.x version has known bugs that are fixed in 2.x makes debugging this further seem like wasted effort. At this point it seems like a better use of time to give up on 18.16.1, wait for the ada 2.x backport to make it into a nodejs 18.x release, and then try again.

Which is totally fine, btw! This isn't really blocking anything and because of the way we're running nodejs, we can safely skip 18.16.1. The only fallout is a couple of days of wasted time on my end which I'll survive. ;)","jkrems",567540,"2023-07-05 14:58:35","thanks detailed response work make url parsing faster node change dep prohibit recommend contributor upstream issue fix generally aware sure policy deal case node use major version seemingly longer maintain upstream more critical issue fix block major version upgrade dependency hope upstream create new release line backport fix disagree non trivial classification url one important use component node runtime non trivial mean few line obviously correct code mean imply anything important heavily use code definitely disagree k loc trivial personally skim say yep correct roughly bar set trivial code surprised many developer could important part term trivial practically speak believe inevitable catch bug like certain user try use definitely understand tricky chicken egg thing go practice likely mean stuck older x upgrade latest version security fix mean get neither faster url parsing neat non critical win other fix actually care ada get real world exposure expense least group thousand real world user able upgrade within lts line readily admit little world special typical nodejs setup require test suite pass bunch sanitizer enable tell team disable sanitizer ci bit node incompatible specific recommendation classify ada harden dependency please open issue ada repository happy personally follow definition harden happen time real usage frustrating answer actionable cost new code hard solve new code always unstable see also quick major bump want bit clear point pace new native dep talk ada particular new dep ada likely one least concern lifetime node multiple new native dep add first aklomp base around time add author already talk issue make breaking change library afaik single author maintainer larger production use sanitizer comparable check require since out bound read test then simdutf postject ada time sanitizer violation fail assertion make lts release test ada already make breaking change get upstream fix directly easy issue op one easily identify already workaround second ada still easily reproduce cause fail assertion string view constructor one test length violation know x version know bug fix x make debugging seem like waste effort point seem like better use time give x wait ada x backport make nodejs x release try totally fine btw really block anything way run nodejs safely skip fallout couple day waste time end survive
"
1108,212,"@jkrems 

You ran Node with ubsan, but  ubsan is *not* used as part of continuous integration tests of Node. In fact, it appears that it is not used because Node is not generally ubsan clean, at least as far as the comments on this issue are concerned: https://github.com/nodejs/node/pull/46297

> small-icu isn't ubsan-clean, I'm finding a way to skip it for now. @RafaelGSS  

> Example of an error that comes up a lot: SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior ../deps/v8/src/api/api-arguments-inl.h:332:3 @targos

And these problems predate the recent changes you allude to.

It is perfectly reasonable to demand the Node be ubsan clean, and I think it is reasonable to expect new dependencies to be ubsan clean... but it seems that it is not a goal that has been reached yet, generally.

","lemire",391987,"2023-07-05 16:03:42","node ubsan usar parte integração contínua teste fato parecer usar node geralmente ubsan limpo comentário issue small icu ubsan limpo encontrar forma pular exemplo erro aparecer muito undefinedbehavior sanitizer undefined behavior problema preceder mudança aludir perfeitamente razoável exigir node ubsan limpo razoável esperar nova dependência ubsan limpo parecer meta alcançar ainda geralmente
"
1109,212,"@lemire Our nodejs binaries are special™ in many ways. They link against BoringSSL, have dedicated V8 imports, are built using bazel, etc.. So I don't have any expectations of them being officially supported. The good news is that they've been ubsan clean for many years now, so code within nodejs core itself is _usually_ already clean and I'm always happy to upstream fixes if there's any sanitizer errors.

The reason I opened this issue and made the comment above is that these kinds of failures are actually very rare and hadn't happened in multiple years. So node _used_ to be fairly asan/ubsan clean but has stopped being reliably clean in the more recent past. And the majority (admittedly, small sample size) of issues came from the new deps with only one coming from node core itself (https://github.com/nodejs/node/pull/48566).","jkrems",567540,"2023-07-05 16:19:12","nodejs binário especial link boringssl dedicar v8 importar construir bazel expectativa oficialmente suportar notícia ubsan limpo ano código núcleo geralmente limpo feliz upstream correção sanitizer erro

razão abrir issue comentário tipo falha raro acontecer ano node asan ubsan limpo parar confiável limpo recente maioria pequeno amostra issue vir novo dep único vir núcleo
"
1110,213,"To be honest I don't think this is a bug. It's like opening sockets and never closing them.","lpinca",1443911,"2023-06-29 19:52:06","honest think bug like open socket close
"
1111,213,"Sorry, my bad, I did not notice that there is no `server.listen()` in the example, but anyway I think that the ""leak"" is expected with that sync loop.","lpinca",1443911,"2023-06-29 20:00:11","sorry bad notice server listen example think leak expect sync loop
"
1112,213,"I can reproduce even with an async loop so it's not that.","lpinca",1443911,"2023-06-29 20:17:02","reproduce async loop
"
1113,213,"This seems to fix the issue

```diff
diff --git a/lib/_http_server.js b/lib/_http_server.js
index 0242e7a089..571ed15c6d 100644
--- a/lib/_http_server.js
+++ b/lib/_http_server.js
@@ -549,7 +549,7 @@ function Server(options, requestListener) {
   this.timeout = 0;
   this.maxHeadersCount = null;
   this.maxRequestsPerSocket = 0;
-  setupConnectionsTracking(this);
+  // setupConnectionsTracking(this);
   this[kUniqueHeaders] = parseUniqueHeadersOption(options.uniqueHeaders);
 }
 ObjectSetPrototypeOf(Server.prototype, net.Server.prototype);

```

cc: @ShogunPanda ","lpinca",1443911,"2023-06-29 20:23:58","fix issue
"
1114,213,"Maybe we should call `setupConnectionsTracking` on `listen`  event ?","theanarkh",21155906,"2023-06-30 13:24:57","call setupConnectionsTracking listen event
"
1115,213,"It makes sense to me, there is no connection to track if the server is not listening.","lpinca",1443911,"2023-06-30 13:26:31","make sense connection track server listen
"
1116,213,"That is fine, but it does not explain the leak. I'll try to dig into this in the next few days.","ShogunPanda",201101,"2023-06-30 13:30:14","explain leak dig day
"
1117,213,"I think because the anonymous function hold the server object.
```js
setInterval(checkConnections.bind(server), server.connectionsCheckingInterval).unref();
```","theanarkh",21155906,"2023-06-30 13:36:27","think anonymous function hold server object
"
1118,213,"Yes, I confirm that is the issue. I'll move that call in a listen even as suggested.","ShogunPanda",201101,"2023-06-30 13:41:03","confirm issue move call listen even suggest
"
1119,214,"Does the issue resolve if you add a small timeout before writing file and after creating the watcher? I suspect the async nature of fs which does polling causes this issue. ","anonrig",1935246,"2023-06-12 18:13:21","issue resolve add small timeout write file create watcher suspect async nature fs poll cause issue
"
1120,214,"Looks like that did help - https://github.com/cjihrig/recursive-watcher-bug/actions/runs/5247088842/jobs/9476792611.

I don't think we can realistically ask every user of recursive file watching to add that to their code though.","cjihrig",2512748,"2023-06-12 18:18:59","help user file watch add code
"
1121,214,"> Looks like that did help - https://github.com/cjihrig/recursive-watcher-bug/actions/runs/5247088842/jobs/9476792611.
> 
> I don't think we can realistically ask every user of recursive file watching to add that to their code though.

@cjihrig I agree. It seems the issue is within this lines: https://github.com/nodejs/node/blob/main/lib/internal/fs/recursive_watch.js#L222

We can avoid using promisify, but I'm suspicious towards blocking the main thread while this is resolving. Unfortunately, I'm on parental leave and have limited access. If this task is not urgent, I can take a look at it in a week and a half.","anonrig",1935246,"2023-06-12 18:42:37","issue seem line avoid use promisify suspicious block main thread resolve unfortunately parental leave limit access task urgent look week half
"
1126,214,"> > So the traverse function doesn't complete its execution before the files start to be watched, thus causing a race condition? Would introducing a mechanism to 'await' the initialization of the watcher could resolve this issue?
> 
> That would be a breaking change since it will cause the function to behave differently in different operating systems.

Understood. Would it be feasible to implement a flag/event that is set once the traverse function has completed? This way, we could delay file watching until after the initial traversal?","winedarkmoon",127571479,"2023-06-19 20:09:17","traverse function complete execution file start watch cause race condition introduce mechanism await initialization watcher resolve issue breaking change cause function behave differently operating system feasible implement flag event set traverse function complete way delay file watch initial traversal
"
1127,214,"> > Looks like that did help - https://github.com/cjihrig/recursive-watcher-bug/actions/runs/5247088842/jobs/9476792611.
> > I don't think we can realistically ask every user of recursive file watching to add that to their code though.
> 
> @cjihrig I agree. It seems the issue is within this lines: https://github.com/nodejs/node/blob/main/lib/internal/fs/recursive_watch.js#L222
> 
> We can avoid using promisify, but I'm suspicious towards blocking the main thread while this is resolving. Unfortunately, I'm on parental leave and have limited access. If this task is not urgent, I can take a look at it in a week and a half.



> > Looks like that did help - https://github.com/cjihrig/recursive-watcher-bug/actions/runs/5247088842/jobs/9476792611.
> > I don't think we can realistically ask every user of recursive file watching to add that to their code though.
> 
> @cjihrig I agree. It seems the issue is within this lines: https://github.com/nodejs/node/blob/main/lib/internal/fs/recursive_watch.js#L222
> 
> We can avoid using promisify, but I'm suspicious towards blocking the main thread while this is resolving. Unfortunately, I'm on parental leave and have limited access. If this task is not urgent, I can take a look at it in a week and a half.



> > So the traverse function doesn't complete its execution before the files start to be watched, thus causing a race condition? Would introducing a mechanism to 'await' the initialization of the watcher could resolve this issue?
> 
> That would be a breaking change since it will cause the function to behave differently in different operating systems.

Regarding the race condition issue in the code you shared, I've analyzed it and come up with a  solution. The problem arises from the `traverse` function not completing its execution before the files start being watched, causing a race condition.

I propose the following solution to address this issue:

`async function traverse(dir, files = new SafeMap(), symbolicLinks = new SafeSet()) {
  const { opendir } = lazyLoadFsPromises();

  const filenames = await opendir(dir);
  const subdirectories = [];

  for await (const file of filenames) {
    const f = pathJoin(dir, file.name);

    files.set(f, file);

    // Do not follow symbolic links
    if (file.isSymbolicLink()) {
      symbolicLinks.add(f);
    } else if (file.isDirectory()) {
      subdirectories.push(traverse(f, files)); // Store the promise for each subdirectory
    }
  }

  await Promise.all(subdirectories); // Wait for all subdirectory promises to resolve

  return files;
}

// ...

async [kFSWatchStart](filename) {
  filename = pathResolve(getValidatedPath(filename));

  try {
    const file = lazyLoadFsSync().statSync(filename);

    this.#rootPath = filename;
    this.#closed = false;
    this.#watchingFile = file.isFile();

    if (file.isDirectory()) {
      this.#files.set(filename, file);

      await traverse(filename, this.#files, this.#symbolicFiles); // Await the completion of the traverse function

      for (const f of this.#files.keys()) {
        this.#watchFile(f);
      }
    } else {
      this.#watchFile(filename);
    }
  } catch (error) {
    if (error.code === 'ENOENT') {
      error.filename = filename;
      throw error;
    }
  }
}`

Here are the changes made and their explanations:

1.Modified the traverse function to be an async function and added the await keyword before the recursive call to traverse for subdirectories. This ensures that the function waits for the subdirectory traversal to complete before moving on, resolving the race condition.

2.In the [kFSWatchStart] method, added the await keyword before calling traverse for the initial directory. This ensures that the function waits for the traversal to complete before proceeding with watching the files.
","spacesugam",105580575,"2023-06-23 19:14:58","agree issue line avoid use promisify suspicious block main thread resolve unfortunately parental leave limit access task urgent look week half traverse function complete execution file start watch cause race condition introduce mechanism await initialization watcher resolve issue breaking change cause function behave differently different operat system race condition issue code share analyze come solution problem arise traverse function complete execution file start watch cause race condition propose solution address issue modify traverse function async function add await keyword recursive call traverse subdirectory ensure function wait subdirectory traversal complete move resolve race condition kFSWatchStart method add await keyword call traverse initial directory ensure function wait traversal complete proceed watch file
"
1128,214,"@spacesugam are you still interested in sending a PR?

I would go for the first option.","mcollina",52195,"2023-07-26 16:56:27","interested send pr go option
"
1129,214,"@anonrig @cjihrig I took another look at this issue, and there is a race condition between traversing the file system asynchronously and `watch`. Ultimately we are missing an event, i.e. ""the watch has been successfully set up"". The alternative is to make traversing the tree synchronous on Linux, so that it can all be set up correctly.

This is not a problem on Windows or Mac because they have different low-level primitives for watching","mcollina",52195,"2023-10-18 12:53:12","race condition traverse file system asynchronous watch miss event watch successfully set alternative make traverse tree synchronous linux set correctly problem windows mac different low level primitive watch
"
1130,214,"The only solution to this bug is to move the exploration of the directory tree to _synchronous_ on Linux. @anonrig do you see any specific issue with that?","mcollina",52195,"2023-12-26 09:03:42","solution bug move exploration directory tree synchronous linux issue
"
1131,214,"Quite possibly related, calling `fs.watch()` in recursive mode with an already aborted signal does not prevent StatWatchers from being created and referenced. Same with synchronously closing the returned watcher.","novemberborn",33538,"2024-01-02 21:09:32","relate call fs watch recursive mode abort signal prevent StatWatcher create reference synchronously close return watcher
"
1132,214,"> The only solution to this bug is to move the exploration of the directory tree to _synchronous_ on Linux. @anonrig do you see any specific issue with that?

Looks good to me!

> Quite possibly related, calling fs.watch() in recursive mode with an already aborted signal does not prevent StatWatchers from being created and referenced. Same with synchronously closing the returned watcher.

@novemberborn Can you create a different issue on this, with a possible reproduction please?","anonrig",1935246,"2024-01-02 21:14:38","solution bug move exploration directory tree synchronous linux specific issue good possibly relate call fs watch recursive mode abort signal prevent statwatcher create reference synchronously close return watcher create different issue possible reproduction
"
1133,216,"it seems like the header starting each message is being split in between two chunks on stdout.
","MoLow",8221854,"2023-05-21 11:52:01","header message split chunk stdout
"
1134,217,"`console.error` doesn't seem to have this problem. I'll use `console.error` as a workaround.","strager",48666,"2023-05-11 02:06:13","console error seem problem use console error workaround
"
1135,217,"It seems that if a line starts with a space character, only the first word in the line is printed.

This code, for example:
```js
import test from 'node:test'

test('bug', () => {
  console.log('hello world')
  console.log(' hello world')
})
```

outputs the following:
```
ℹ hello world
ℹ hello
```
","cronosmain",105239888,"2023-05-11 02:34:38","line start space character first word print code example import test node test bug console log hello world console log hello world hello world hello
"
1136,217,"I found the issue in the TapParse, can I work on this issue?","jakecastelli",38635403,"2023-05-11 09:33:02","found issue tap parse work issue
"
1137,217,"this will be fixed by https://github.com/nodejs/node/pull/47867 so no need to fix `TapParse`","MoLow",8221854,"2023-05-11 09:55:45","fix need fix tap parse
"
1138,217,"Thanks @MoLow! For the sake of the coding exercise, was the issue because of tap laxer (`tap_lexer.js`)?

By the way the fix PR you linked seems not the correct one ^ 47867 instead of 47955 (which is this issue itself)","jakecastelli",38635403,"2023-05-11 10:42:44","coding exercise issue tap laxer fix pr correct issue
"
1139,217,"> For the sake of the coding exercise, was the issue because of tap laxer (tap_lexer.js)?

don't know :)","MoLow",8221854,"2023-05-11 11:02:10","coding exercise issue tap laxer
"
1140,218,"also reported [here](https://github.com/nodejs/node/issues/47614#issuecomment-1526523755) - with a minimal repro

```js
// file.js
process.on('beforeExit', () => {
  console.log('beforeExit')
})
import('./anyfile.js')
console.log('THIS CONSOLE LOG IS PREINTED')
```

```shell
./node  file.js                                                                                              ✔
THIS CONSOLE LOG IS PREINTED
beforeExit
```

```shell
./node --experimental-loader=""data:text/javascript,export default true""  file.js                             ✔
(node:62415) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
THIS CONSOLE LOG IS PREINTED
beforeExit
beforeExit
beforeExit
```
","MoLow",8221854,"2023-05-09 09:02:17","reported minimal repro file process beforeexit console log print node experimental loader custom esm loader experimental feature change time console log print beforeexit beforeexit beforeexit
"
1141,218,"This is probably because the ESM loader uses `process.on('beforeExit')` in a way that asynchronous work is scheduled in the callback. We should probably refactor that part anyway, I don't like that the internals use a public API that can be tampered with (for example with `process.removeAllListeners('beforeExit');`)

Refs: https://nodejs.org/dist/latest-v20.x/docs/api/process.html#event-beforeexit

/cc @aduh95 ","targos",2352663,"2023-05-10 07:47:00","refactor internal use public api tamper
"
1142,218,"The underlying issue being that `Atomics.waitAsync` does not keep the event loop alive, which has been reported to them already. That being said, we should be able to work around this without triggering `beforeExit` events on the main thread (on the loader thread though, I don’t think we can work around it, and calling `process.removeAllListeners('beforeExit')` from the loader thread needs to be forbidden probably. ","aduh95",14309773,"2023-05-10 12:40:35","issue atomics waitasync keep event loop alive report able work around trigger beforeexit event main thread loader thread call process removealllisteners beforeexit loader thread forbid
"
1143,219,"So, I'm reasonably sure this is caused by the use of `v8::ScriptCompiler::CompileFunction()` vs. `v8::Script::Run()`. The former is used to evaluate require'd code (that includes the main script), the latter for `-e` / `--eval` and also `vm.runInContext()` and friends.

You can see it for yourself with these two test scripts:
```js
// Flags: --use_strict
with ({}) {} // no exception
```
vs.
```js
// Flags: --use_strict
require(""vm"").runInThisContext(`with ({}) {}`) // throws
```

`v8::ScriptCompiler::CompileFunction()` does look at the `--use_strict` flag in `v8::internal::Compiler::GetWrappedFunction()` but I still have every reason to believe this is a V8 bug, not a Node.js bug.
https://github.com/nodejs/node/blob/8244e6c35c0e9af3976511f31db2575bd2fc9d7a/deps/v8/src/codegen/compiler.cc#L3656","bnoordhuis",275871,"2023-05-12 07:35:44","use scriptcompilercompilefunction script run former use evaluate require code include main script latter eval vmexecutecontext friend see two test script flag usestrict exception flag usestrict require vmruninthiscontext throw scriptcompilercompilefunction look flag v8internalcompilergetwrappedfunction reason believe v8 bug node bug
"
1144,219,"Duplicate of https://github.com/nodejs/node/issues/30039 ?","targos",2352663,"2023-05-12 08:13:16","duplicate
"
1145,219,"Oh, indeed! I'll go ahead and close this one then.","bnoordhuis",275871,"2023-05-12 15:52:52","go ahead close one
"
1146,220,"/cc @nodejs/url ","himself65",14026360,"2023-05-05 23:01:27","nodejs url
"
1147,220,"I think this is the issue of Ada 2.0","himself65",14026360,"2023-05-05 23:33:44","issue ada
"
1148,220,"> I think this is the issue of Ada 2.0

Reasonable.","Leask",233022,"2023-05-05 23:46:35","think issu ada
"
1149,220,"Yes. It is from ada.","lemire",391987,"2023-05-05 23:47:22","yes ada
"
1150,220,"@anonrig Please review the potential fix.","lemire",391987,"2023-05-05 23:51:14","review potential fix
"
1151,220,"```
➜  node git:(master) ./out/Debug/node   
Welcome to Node.js v21.0.0-pre.
Type "".help"" for more information.
> new URL('..#', 'a:b');
Assert at line 5861 of file ../deps/ada/ada.h
FAIL: validate()
[1]    78476 abort      ./out/Debug/node
```","himself65",14026360,"2023-05-06 01:05:27","node type information url file fail validate abort
"
1152,220,"@Himself65 Yes. We definitively had a bug in ada. I think @anonrig will push a fix.","lemire",391987,"2023-05-06 02:52:24","bug ada fix
"
1153,220,"Released Ada v2.3.1 with the fix to this issue thanks to @lemire ","anonrig",1935246,"2023-05-06 03:01:21","ada fix issue
"
1154,220,"Thank you all for fixing this issue. 👏","Leask",233022,"2023-05-08 15:43:04","fix issue
"
1155,221,"Review requested:

- [ ] @nodejs/crypto","nodejs-github-bot",18269663,"2023-05-05 10:47:25","review request nodejs crypto
"
1156,221,"How do we deal with the semverness of this? The keys were unusable before, they are non-importable now. It is unlikely any code depended on import of keys that weren't usable for any operation but I'm keen to get more opinions.","panva",241506,"2023-05-05 10:48:04","deal semver key unusable importable unlikely code depend import key operation keen opinion
"
1157,221,"CI: https://ci.nodejs.org/job/node-test-pull-request/51667/","nodejs-github-bot",18269663,"2023-05-05 17:08:06","CI
"
1158,221,"CI: https://ci.nodejs.org/job/node-test-pull-request/51669/","nodejs-github-bot",18269663,"2023-05-05 18:31:24","CI
"
1159,221,"> How do we deal with the semverness of this? The keys were unusable before, they are non-importable now. It is unlikely any code depended on import of keys that weren't usable for any operation but I'm keen to get more opinions.

Furthermore if any interoperable code uses webcrypto (kinda its whole point) it already can't depend on this as other implementations properly reject. 

I'm proposing to ship this is as a fix not as a breaking change. ","panva",241506,"2023-05-06 07:02:26","deal semver key unusable importable unlikely code depend import key operation keen opinion interoperable code use webcrypto point depend implementation properly reject propose ship fix breaking change
"
1160,221,"I'd expect near-zero breakage, so spec-compliance outweighs that concern.","tniessen",3109072,"2023-05-06 12:31:51","expect near zero breakage spec compliance outweigh concern
"
1161,221,"In that case this is ready for reviews. ","panva",241506,"2023-05-06 12:37:23","case ready review
"
1162,221,"Landed in 71eda57ba3bd8ef31fc23ec783a4a45de29ab751","nodejs-github-bot",18269663,"2023-05-07 10:54:30","Landed
"
1163,222,"cc @panva","tniessen",3109072,"2023-05-05 10:08:42","panva retornar
"
1164,222,"I'll have a look later today. ","panva",241506,"2023-05-05 10:10:12","look today
"
1165,222,"Thank you @fhanau, I've opened individual PRs to address each point. ","panva",241506,"2023-05-06 15:11:58","thank open individual pr address point
"
1166,222,"You're welcome, thanks for the quick response!","fhanau",12156995,"2023-05-06 15:46:57","welcome thanks quick response
"
1167,222,"All PRs landed. ","panva",241506,"2023-05-07 10:58:33","PR land
"
1168,223,"The confusing thing is that it's mandatory for `test`, imo.","ljharb",45469,"2023-05-03 17:09:48","confusing mandatory test
"
1169,224,"`git bisect` blames ead407915e510014e5294dd4446e29d8f3f04bdc / https://github.com/nodejs/node/pull/47339. cc @anonrig","tniessen",3109072,"2023-04-26 16:11:07","blame ead407915e510014e5294dd4446e29d8f3f04bdc
"
1170,224,"I'm looking into it. ","anonrig",1935246,"2023-04-26 16:27:39","look
"
1171,224,"It works with Node 18 (Ada v1.0.4)

```
> node -v
v18.16.0

> node test/internet/test-dns-ipv6.js
test_resolve6
test_reverse_ipv6
test_lookup_ipv6_explicit
test_lookup_ipv6_explicit_object
test_lookup_ipv6_hint
test_lookup_ip_ipv6
test_lookup_all_ipv6
test_lookupservice_ip_ipv6
```","anonrig",1935246,"2023-04-26 16:29:16","work node ada test resolve reverse lookup hint ip service
"
1172,224,"`lib/internal/dns/promises.js` line 277 calls `toASCII` which is:

- `const err = resolver._handle[bindingName](req, toASCII(hostname));`","anonrig",1935246,"2023-04-26 16:36:36","line 277 call toascii


"
1173,224,"I found the bug: `2001:4860:4860::8888` passed to `domainToASCII` previously returned the same payload, but with `ada::idna,` it returns an empty string (detecting invalid). cc @lemire","anonrig",1935246,"2023-04-26 16:43:48","bug pass domainToASCII payload return empty string detect invalid
"
1174,224,"@tniessen the following diff fixes the issue, although, we need to fix this and release a new version of Ada...

```diff
diff --git a/lib/internal/idna.js b/lib/internal/idna.js
index 566f8590d8..8591226d10 100644
--- a/lib/internal/idna.js
+++ b/lib/internal/idna.js
@@ -1,4 +1,9 @@
 'use strict';

-const { domainToASCII, domainToUnicode } = require('internal/url');
-module.exports = { toASCII: domainToASCII, toUnicode: domainToUnicode };
+if (internalBinding('config').hasIntl) {
+  const { toASCII, toUnicode } = internalBinding('icu');
+  module.exports = { toASCII, toUnicode };
+} else {
+  const { domainToASCII, domainToUnicode } = require('internal/url');
+  module.exports = { toASCII: domainToASCII, toUnicode: domainToUnicode };
+}
```","anonrig",1935246,"2023-04-26 16:45:27","diff fix issue need fix release new version ada
"
1175,224,"So pretty much reverting ead407915e510014e5294dd4446e29d8f3f04bdc, or at least the `lib/` changes of that? I assume it's still going to fail if `!hasIntl`. Then again, I don't think we care about non-ICU builds.","tniessen",3109072,"2023-04-26 16:48:14","revert change assume still fail care non icu build
"
1182,227,"I'm also seeing a similar issue with [ssh2](https://github.com/mscdex/ssh2) after upgrading to Node 20.

**Repro steps:**

1. Connect to an invalid host
2. Add an `error` event handler

```ts
client.connect({
  host: 'yahoo.com',
  port: 22,
  username: 'bob',
  password: 'secret'
})

// Adding this line crashes the process.
client.on('error', () => {})
```","kamagatos",1569859,"2023-04-26 00:00:38","see similar issue upgrade node connect invalid host add error event handler crash process
"
1183,227,"seeing this issue as well on production



Error [ERR_INTERNAL_ASSERTION]: This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
--
  | 2023-04-29T13:32:31.670-04:00 | Please open an issue with this stack trace at https://github.com/nodejs/node/issues
  | 2023-04-29T13:32:31.670-04:00 | at new NodeError (node:internal/errors:399:5)
  | 2023-04-29T13:32:31.670-04:00 | at assert (node:internal/assert:14:11)
  | 2023-04-29T13:32:31.670-04:00 | at internalConnectMultiple (node:net:1106:3)
  | 2023-04-29T13:32:31.670-04:00 | at Timeout.internalConnectMultipleTimeout (node:net:1637:3)
  | 2023-04-29T13:32:31.670-04:00 | at listOnTimeout (node:internal/timers:575:11)
  | 2023-04-29T13:32:31.670-04:00 | at process.processTimers (node:internal/timers:514:7)


Our old build from 10 days ago still works, but all new builds seem to run into this issue.","asp3",11220954,"2023-04-29 17:32:28","see issue production error cause bug nodejs incorrect usage nodejs internal new nodeerror assert internalconnectmultiple timeout internalconnectmultipletimeout listontimeout processprocesstimers old build day ago work new build run issue
"
1184,227,"Just a note, subscribing as still present in `v20.1.0`:

In a net and async/await heavy program:

```
node:internal/assert:14
    throw new ERR_INTERNAL_ASSERTION(message);
    ^

Error [ERR_INTERNAL_ASSERTION]: This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at new NodeError (node:internal/errors:399:5)
    at assert (node:internal/assert:14:11)
    at internalConnectMultiple (node:net:1107:3)
    at Timeout.internalConnectMultipleTimeout (node:net:1638:3)
    at listOnTimeout (node:internal/timers:575:11)
    at process.processTimers (node:internal/timers:514:7) {
  code: 'ERR_INTERNAL_ASSERTION'
}

Node.js v20.1.0
```","MikeRalphson",21603,"2023-05-09 10:20:44","node internal assert error internal assertion bug nodejs incorrect usage nodejs internal issue stack trace github nodejs node node error assert internal connect multiple timeout internal connect multiple timeout listontimeout process processtimers code err internal assertion nodejs
"
1185,227,"This might be fixed by https://github.com/nodejs/node/pull/47860.
Will keep you posted on this.","ShogunPanda",201101,"2023-05-09 10:32:32","fix post
"
1186,227,"@kamagatos @yuki12321 The PR above has landed in master. If you can compile Node locally, do you mind checking it if solves your issues as well?","ShogunPanda",201101,"2023-05-11 22:51:43","PR land master compile Node locally mind check solve issue
"
1187,227,"I now see the following on `master`:

```
/Users/mikeralphson/c/node/node[73535]: ../../src/crypto/crypto_tls.cc:1233:static void node::crypto::TLSWrap::GetServername(const FunctionCallbackInfo<v8::Value> &): Assertion `(wrap->ssl_) != nullptr' failed.
 1: 0x100bc1cf0 node::Abort() [/Users/mikeralphson/c/node/out/Release/node]
 2: 0x100bc1a30 node::PrintCaughtException(v8::Isolate*, v8::Local<v8::Context>, v8::TryCatch const&) [/Users/mikeralphson/c/node/out/Release/node]
 3: 0x100d14700 node::crypto::TLSWrap::GetServername(v8::FunctionCallbackInfo<v8::Value> const&) [/Users/mikeralphson/c/node/out/Release/node]
 4: 0x100dca0d4 v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, unsigned long*, int) [/Users/mikeralphson/c/node/out/Release/node]
 5: 0x100dc9928 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [/Users/mikeralphson/c/node/out/Release/node]
 6: 0x10164cb24 Builtins_CEntry_Return1_ArgvOnStack_BuiltinExit [/Users/mikeralphson/c/node/out/Release/node]
 7: 0x1015c43e4 Builtins_InterpreterEntryTrampoline [/Users/mikeralphson/c/node/out/Release/node]
 8: 0x10664d2cc
 9: 0x1015c250c Builtins_JSEntryTrampoline [/Users/mikeralphson/c/node/out/Release/node]
10: 0x1015c21f4 Builtins_JSEntry [/Users/mikeralphson/c/node/out/Release/node]
11: 0x100eb082c v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) [/Users/mikeralphson/c/node/out/Release/node]
12: 0x100eb00a8 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) [/Users/mikeralphson/c/node/out/Release/node]
13: 0x100d77e80 v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) [/Users/mikeralphson/c/node/out/Release/node]
14: 0x100afdf84 node::InternalMakeCallback(node::Environment*, v8::Local<v8::Object>, v8::Local<v8::Object>, v8::Local<v8::Function>, int, v8::Local<v8::Value>*, node::async_context) [/Users/mikeralphson/c/node/out/Release/node]
15: 0x100b120b8 node::AsyncWrap::MakeCallback(v8::Local<v8::Function>, int, v8::Local<v8::Value>*) [/Users/mikeralphson/c/node/out/Release/node]
16: 0x100b292dc node::ConnectionWrap<node::TCPWrap, uv_tcp_s>::AfterConnect(uv_connect_s*, int) [/Users/mikeralphson/c/node/out/Release/node]
17: 0x100c917b0 node::MakeLibuvRequestCallback<uv_connect_s, void (*)(uv_connect_s*, int)>::Wrapper(uv_connect_s*, int) [/Users/mikeralphson/c/node/out/Release/node]
18: 0x1015acf94 uv__stream_io [/Users/mikeralphson/c/node/out/Release/node]
19: 0x1015b5650 uv__io_poll [/Users/mikeralphson/c/node/out/Release/node]
20: 0x1015a2e94 uv_run [/Users/mikeralphson/c/node/out/Release/node]
21: 0x100afe7d0 node::SpinEventLoopInternal(node::Environment*) [/Users/mikeralphson/c/node/out/Release/node]
22: 0x100c03504 node::NodeMainInstance::Run() [/Users/mikeralphson/c/node/out/Release/node]
23: 0x100b899d0 node::LoadSnapshotDataAndRun(node::SnapshotData const**, node::InitializationResultImpl const*) [/Users/mikeralphson/c/node/out/Release/node]
24: 0x100b89c24 node::Start(int, char**) [/Users/mikeralphson/c/node/out/Release/node]
25: 0x1a2ad3f28 start [/usr/lib/dyld]
zsh: abort      
```","MikeRalphson",21603,"2023-05-12 11:10:14","assertion wrap ssl nullpointer node abort print caughtexception tlswrap getservername handleapicallhelper builtin handleapicall builtincentreyreturn1argvonstackbuiltinexit builtins interpreterentrytrampoline builtins jsentrytrampoline builtins jsentry invoke call function call internalmakecallback asyncwrap makecallback connectionwrap afterconnect makelibuvrequestcallback wrapper uv stream io uv io poll uv run spineventloopinternal nodemaininstance run loadsnap shotdataandrun start
"
1188,227,"@MikeRalphson Can you please provide a repro file, along with the `dig` query of all the hosts you are trying to reach?","ShogunPanda",201101,"2023-05-12 12:42:54","mike ralphson provide repro file dig query host reach
"
1189,227,"The same internal assertion is causing CI to fail on Fedora machines, see https://github.com/nodejs/node/issues/48000. However, it is not the `ERR_INTERNAL_ASSERTION` that this issue was about originally.

Side note: the main branch is called `main`. We intentionally abandoned the previous branch name.","tniessen",3109072,"2023-05-14 10:53:36","internal assertion cause CI fail Fedora machine issue originally main branch call main intentionally abandon previous branch name
"
1190,227,"This randomly started happening on my production build after a deployment. I'm using lts-alpine image in my docker file, has there been a recent change that could be causing this? ","bradleybeighton",6638439,"2023-05-16 14:47:36","happen production build deployment use lts alpine image docker file recent change cause
"
1191,227,"@brandon-beacher It's the network family auto selection which was enabled by default in 20.0.0.
I fixed this issue (already merged in main) and once I'll fix some other problems it should go out on 20.2.0 or 20.3.0.","ShogunPanda",201101,"2023-05-16 15:29:16","fix issue merge main fix problem go


"
1192,227,"This is still an issue in Node.js 20.2.0. As a workaround, you can try restoring the more predictable pre-20 behavior by setting this environment variable:

```shell
NODE_OPTIONS=""--no-network-family-autoselection""
```","tniessen",3109072,"2023-05-19 11:33:58","issue node.js workaround restore predictable behavior set environment variable node options no network family autoselection
"
1193,227,"this happened when i open signal app on mac laptop. has this been fixed? thanks.","arllop",12599890,"2023-06-03 15:04:33","happen open signal app mac laptop fix thank
"
1194,227,"@arllop If Signal does not override `NODE_OPTIONS`, the workaround in https://github.com/nodejs/node/issues/47644#issuecomment-1554440759 might work.","tniessen",3109072,"2023-06-03 16:03:01","signal override node option workaround work
"
1195,227,"I've pinned this issue in the (possibly in vain) hope it'll stem the tide of duplicate bug reports.","bnoordhuis",275871,"2023-06-05 09:56:16","pin issue hope stem tide duplicate bug report
"
1256,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51177/","nodejs-github-bot",18269663,"2023-04-12 22:38:33","CI
"
1257,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51179/","nodejs-github-bot",18269663,"2023-04-12 23:55:19","CI
"
1258,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51184/","nodejs-github-bot",18269663,"2023-04-13 01:03:17","CI
"
1196,227,"Also got this just now from Signal (6.20.0) after waking macOS from sleep with Signal running:

```
Unhandled Error

Error [ERR_INTERNAL_ASSERTION]: This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at new NodeError (node:internal/errors:399:5)
    at assert (node:internal/assert:14:11)
    at internalConnectMultiple (node:net:1077:3)
    at afterConnectMultiple (node:net:1532:5)
```","Shnub",29605254,"2023-06-06 09:57:34","erro interno caus bug node js uso incorreto interno node js abrir issue stack trace github node js
"
1197,227,"Vain hope indeed, dear god. I've changed the title, let's hope it's enough for Signal users to put two and two together 🤦","bnoordhuis",275871,"2023-06-06 13:28:35","hope change title hope enough signal user
"
1198,227,"While I see how this is annoying for developers here, do kindly keep in mind that this error message is shown to Signal end users, very few of which are developers. And the message explicitly asks to open an issue here, so that's what folks are doing. With the error message itself being basically gibberish to laypeople, it's little wonder some end up opening redundant issues with little more than good intentions.","Shnub",29605254,"2023-06-06 13:56:22","see annoy developer kindly keep mind error message show signal end user few developer message explicitly ask open issue folk error message basically gibberish layperson little wonder end open redundant issue little good intention
"
1199,227,"I wonder if we should just disable `network_family_autoselection` by default again until the bug is fixed. The `assert()` we have is under the assumption that this should rarely get hit and when it does get hit we want to know about it. In this case this gets hit too often that the `assert()` here already becomes more annoying than it is helpful.","joyeecheung",4299420,"2023-06-06 15:17:03","disable network family autoselection default bug fix assert assumption rarely hit want know case hit often assert annoying helpful
"
1200,227,"@joyeecheung According to @ShogunPanda, this will be fully resolved by 20.3.0. However, even then, the implementation does not conform to the Happy Eyeballs RFC and may result in timeouts that did not occur in previous versions of Node.js, so I wouldn't be opposed to disabling it by default.","tniessen",3109072,"2023-06-06 21:25:44","resolve implement conform happy eyeball rfc result timeout oppose disable default
"
1201,227,"I can confirm I fixed all variants of this bug so after 20.3.0 all should be good.
About deviating from RFC, well, we never committed to have a compliant implementation of that, but just a loose one. 

Disabling it again by default will cause harm to people with broken IPv6 stack.

The best course of action, IMVHO, would be to wait for 20.3.0 to settle a little bit and see if bug reports stop. If not we disable it. WDYT?","ShogunPanda",201101,"2023-06-07 06:05:44","confirm fix variant bug good deviate rfc commit compliant implement loose disable cause harm people broken ipv6 stack best course action wait settle little bit see bug report stop disable
"
1202,227,"Unhandled Error

Error [ERR_INTERNAL_ASSERTION]: This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at new NodeError (node:internal/errors:399:5)
    at assert (node:internal/assert:14:11)
    at internalConnectMultiple (node:net:1077:3)
    at afterConnectMultiple (node:net:1532:5)","RBCK",3863652,"2023-06-07 07:54:01","error caus bug nodejs incorreto uso nodejs interno abrir issue stack trace
"
1203,227,"
 you can include the NODE_OPTIONS environment variable in the script command to avoid this error. For example:
json

""scripts"": {
  ""start"": ""NODE_OPTIONS=no-network-family-autoselection node your-app.js""
}","Veercodeprog",91560462,"2023-06-08 02:39:07","include NODE_OPTIONS environment variable script command avoid error example NODE_OPTIONS no network family autoselection node app
"
1204,227,"@Veercodeprog Confirmed. This can temporarily disable the problem until 20.3.0 is released.","ShogunPanda",201101,"2023-06-08 06:06:25","Confirmed temporarily disable problem release
"
1205,227,"what the correct solution then. i can see this mainly arises while trying to upload images from server to cloudinary.","Veercodeprog",91560462,"2023-06-08 06:13:37","solution arise upload image server cloudinary
"
1206,227,"There's no other required on your side. This bug was in node and I already fixed it. It will be publicly available once 20.3.0 is released.

Once you update to 20.3.0 everything will work as it was before.","ShogunPanda",201101,"2023-06-08 06:15:30","bug fix release update work
"
1207,227,"do we get this error in stable versions too 
?
","Veercodeprog",91560462,"2023-06-08 06:25:51","get error stable version
"
1208,227,"> There's no other required on your side. This bug was in node and I already fixed it. It will be publicly available once 20.3.0 is released.
> 
> Once you update to 20.3.0 everything will work as it was before.

I've updated to `20.3.0`, however I still exhibit this issue.
It does seem like it's fixed some IPv6 timeout issues for me tho.","brian6932",18603393,"2023-06-10 04:23:52","bug fix node release update issue ipv6 timeout
"
1209,227,"@brian6932 Can you post here for which hosts this failed and the `dig` query for them? Thanks!","ShogunPanda",201101,"2023-06-10 04:57:16","brian post host fail dig query thanks
"
1210,228,"I've experienced the same problem in one my projects which uses `ava` test runner. Great job with a no-dependency reproduction.

Not sure if https://github.com/nodejs/node/labels/test_runner or https://github.com/nodejs/node/labels/loaders. Better ping both.

cc @nodejs/loaders, @nodejs/test_runner ","panva",241506,"2023-04-19 10:27:57","problem project use ava test runner job no dependency reproduction ping loader test runner
"
1211,228,"I suspect this is a duplicate of https://github.com/nodejs/node/issues/47566.","aduh95",14309773,"2023-04-19 10:30:06","suspect duplicate
"
1212,228,"Can you please test now against latest `main` or nightly?","GeoffreyBooth",456802,"2023-04-26 01:23:50","test latest main nightly
"
1213,228,"@GeoffreyBooth  I have tried the nightly, and it's still failing: https://github.com/iambumblehead/esmock/actions/runs/4804121738/jobs/8549299803?pr=199","aladdin-add",13050025,"2023-04-26 06:01:36","tried nightly still fail
"
1214,228,"It seems to be the same thing as https://github.com/nodejs/help/issues/3902#issuecomment-1520818062","aduh95",14309773,"2023-04-26 08:01:11","seem thing
"
1215,228,"I have performed some testing, and it seems like the real issue is the combination of `--test` `--loader`, and `--require`.
on my machine this only reproduces inside vscode where `NODE_OPTIONS` is set to `--require` the bootloader file from https://github.com/microsoft/vscode-js-debug/blob/main/src/targets/node/bootloader.ts

@iambumblehead can you please compare your repro when running through vscode and through an external cli interface?","MoLow",8221854,"2023-04-27 20:39:40","test seem issue combination test loader require machine reproduce inside vscode node option require bootloader file compare repro run vscode external cli interface
"
1216,228,"see this repro for example: 
https://github.com/nodejs/node/commit/27e08d434b1408931aa3f56d3d39bfee0e0bbc94","MoLow",8221854,"2023-04-27 20:54:16","repro example
"
1217,228,"@MoLow politely, neither `--require` nor vscode were used to repro the issue reported here","iambumblehead",2058705,"2023-04-27 21:12:19","politely repro issue report
"
1218,228,"@nodejs/loaders I have checked the repro provided by @iambumblehead, and the root cause is `process.on('beforeExit'` is called multiple times (`node:test` uses `beforeExit` to cancel all ongoing tests),

see this repro


```js
// file.js
process.on('beforeExit', () => {
  console.log('beforeExit')
})
import('./anyfile.js')
console.log('THIS CONSOLE LOG IS PREINTED')
```

```shell
./node  file.js                                                                                              ✔
THIS CONSOLE LOG IS PREINTED
beforeExit
```

```shell
./node --experimental-loader=""data:text/javascript,export default true""  file.js                             ✔
(node:62415) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
THIS CONSOLE LOG IS PREINTED
beforeExit
beforeExit
beforeExit
```
","MoLow",8221854,"2023-04-27 21:32:53","process beforeexit chamar multiplo vez node test usar beforeexit cancelar teste processo console log imprimir beforeexit experimental warning custom esm loader experimental feature mudar tempo console log imprimir beforeexit beforeexit beforeexit
"
1219,228,"Shorter example (20.1.0, macOS):

test.mjs
```js
import { test } from ""node:test"";

import ""fs""; // any other module

test(""test"", async (t) => {
  await import(""data:text/javascript,"");
});
```

```sh
node --experimental-loader 'data:text/javascript,' test.mjs
```

<img width=""958"" alt=""image"" src=""https://user-images.githubusercontent.com/20106607/236315075-a7c1843e-f274-4ef0-b8e4-2261a57bda54.png"">
","koshic",20106607,"2023-05-04 19:56:26","test mjs import test node test import fs test async t await import data javascript
"
1220,228,"I have verified - this has been fixed via https://github.com/nodejs/node/pull/47964","MoLow",8221854,"2023-05-14 07:44:57","verified fix
"
1221,229,"@nodejs/loaders ","aduh95",14309773,"2023-04-15 13:55:29","nodejs loader
"
1222,229,"I'm able to reproduce with the suggested code snippet, but it looks like there's more to it than just combining `--require` and `--loader`, here's what I get when running the following at the root of the node repo:

```console
$ out/Release/node --no-warnings --require ./test/fixtures/printA.js --import ./test/fixtures/printB.js --loader ./test/fixtures/empty.js ./test/fixtures/printC.js
A
A
B
C
```

It looks like the reported bug only happens on REPL. Worth noting that we also another bug that makes the `--require`d script run twice instead of once.","aduh95",14309773,"2023-04-17 13:59:12","reproduzir código snippet parecer mais combinar require loader executar raiz repositório node aviso require testfixturesprinta js import testfixturesprintb js loader testfixturesempty js testfixturesprintc js parecer bug relatar acontecer repl valer notar outro bug fazer script require executar vez
"
1223,229,"> It looks like the reported bug only happens on REPL

I can also reproduce the issue without the REPL:
```sh
touch require.cjs
touch loader.mjs
echo ""setInterval(() => {}, 1000);"" > test.cjs
node --require ./require.cjs --loader ./loader.mjs test.cjs
```","merceyz",3842800,"2023-04-17 14:07:22","look report bug happen repl reproduce issue repl
"
1224,229,"I don't think it has much to do with `--require`:


```console
$ out/Release/node --loader ./test/fixtures/empty.js
[…never ending output of experimental warning…]
```","aduh95",14309773,"2023-04-17 14:08:30","think much relate require
"
1225,229,"Indeed, I've updated the issue to reflect that 👍 

> Worth noting that we also another bug that makes the --required script run twice instead of once

That's expected behaviour in my opinion, once in the main process and once in the Worker for the loaders.","merceyz",3842800,"2023-04-17 14:13:20","atualiz issue refletir comportamento esperado processo principal worker loader bug script requerido executar vez
"
1226,229,"I can't repro at all (admittedly on macOS ARM, but I don't see how this could be OS-related):

At `main`'s current HEAD (e050cecad1), the OP's

<details>
<summary>snippet</summary>

```js
touch loader.mjs
echo ""setInterval(() => {}, 1000);"" > test.cjs
node --loader ./loader.mjs test.cjs
```
</details>

runs endlessly (as expected) and memory stays constant (at 20.2 MB, after start-up), with only 1 experimental warning.

I get the same behaviour on [v20.0.0-proposal](https://github.com/nodejs/node/tree/v20.0.0-proposal)'s current HEAD (bb533f78ba), but with slightly less memory consumption (20.1 MB after start-up).

The code that controls whether the warning is emitted is quite simple and handles multiple instances of the module loader:

https://github.com/nodejs/node/blob/b342a1b5652785cc08238ddd26f7dc13ad61a622/lib/internal/modules/esm/loader.js#L405-L420

(`emittedExperimentalWarning` lives at the top level of esm/loader.js)

Am I missing something?","JakobJingleheimer",3012099,"2023-04-17 18:10:16","repro mac os relat OS head snippet touch loader mjs echo setinterval memory constant mb experimental warning comportamento consumo codigo controla warning emitido instancia loader emittedExperimentalWarning esm loader algo
"
1227,229,"I think this is happening because the loader is going to try to spawn a worker thread from within the worker thread, which is also going to do the same thing, and that's how we end up with Mr Meeseeks situation until the system is out of memory or the process terminates. I'm working on a fix.","aduh95",14309773,"2023-04-17 18:33:07","think happen loader go try spawn worker thread worker thread also go thing end mr meeseeks situation system memory process terminate work fix
"
1228,229,"I'd note that some systems like ServiceWorkers / SharedWorkers avoid this
by having a shared cache based upon URL of the entrypoint. That would also
reduce overall burden.

On Mon, Apr 17, 2023 at 1:33 PM Antoine du Hamel ***@***.***>
wrote:

> I think this is happening because the loader is going to try to spawn a
> worker thread from within the worker thread, which is also going to do the
> same thing, and that's how we end up with Mr Meeseeks situation until the
> system is out of memory or the process terminates. I'm working on a fix.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/nodejs/node/issues/47566#issuecomment-1511883970>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AABZJI4ZGXW3P53XYIGMCPDXBWEHBANCNFSM6AAAAAAW66HUD4>
> .
> You are receiving this because you are on a team that was mentioned.Message
> ID: ***@***.***>
>
","bmeck",234659,"2023-04-17 19:50:30","sistema evitar compartilhado base url entrada reduzir carga geral trabalhador tentar gerar trabalhador trabalhador acabar situação memória sistema terminar trabalhar correção
"
1259,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51185/","nodejs-github-bot",18269663,"2023-04-13 01:39:40","CI
"
1260,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51187/","nodejs-github-bot",18269663,"2023-04-13 02:12:14","CI
"
1261,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51191/","nodejs-github-bot",18269663,"2023-04-13 04:17:47","CI
"
1262,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51193/","nodejs-github-bot",18269663,"2023-04-13 07:17:16","CI
"
1263,231,"CI: https://ci.nodejs.org/job/node-test-pull-request/51196/","nodejs-github-bot",18269663,"2023-04-13 10:25:10","CI
"
1264,231,"Landed in 6fb74c743cef513e4bf03afb0d3b4535558e1f18","nodejs-github-bot",18269663,"2023-04-13 13:40:52","Landed
"
1411,247,"node/lib/stream.js
node/lib/stream/promises.js","ronag",3065230,"2023-01-09 14:41:45","node stream promise
"
1584,273,"CI: https://ci.nodejs.org/job/node-test-pull-request/44925/","nodejs-github-bot",18269663,"2022-06-28 04:50:41",NULL
1229,229,"Experiencing the same. The loader is loaded over and over again as soon as I import specific libraries.

> node --experimental-loader ./esm-loader.mjs index.mjs

esm-loader.mjs
```
// works
import { get } from 'node:https';

// both do not work and restart the loader in a loop
import CoffeeScript from 'coffeescript';
import mysql from 'mysql';
```

> (node:9286) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:9286) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:9286) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:9286) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)

Works fine with Node v18","kirrg001",1160712,"2023-04-19 08:17:41","experiencing same loader load import specific library work import coffeescript mysql node experimental loader custom esm loader experimental feature change node version work fine node
"
1230,229,"> Indeed, I've updated the issue to reflect that 👍
https://github.com/nodejs/node/issues/47566#issuecomment-1511439087

@aduh95 I tested again and the `--require` flag is required to reproduce, I've updated the reproduction again.
Seems I forgot that the terminal in VSCode adds `NODE_OPTIONS` with a `--require` flag for it's auto attach feature.","merceyz",3842800,"2023-04-19 09:55:30","update issue reflect test flag require reproduce update reproduction forget terminal vscode add node_options require flag auto attach feature
"
1231,229,"> > Indeed, I've updated the issue to reflect that +1
> > [#47566 (comment)](https://github.com/nodejs/node/issues/47566#issuecomment-1511439087)
> 
> @aduh95 I tested again and the `--require` flag is required to reproduce, I've updated the reproduction again. Seems I forgot that the terminal in VSCode adds `NODE_OPTIONS` with a `--require` flag for it's auto attach feature.

How so? I am seeing the following in v20.0.0 (release) on x86_64 GNU/Linux, running from CLI and `NODE_OPTIONS` is not set, using blank/empty loader and script that just waits indefinitely so the process doesn't exit immediately:

```sh
$ touch empty.cjs # (does it / should it matter if we use .js .cjs or .mjs here??)
$ echo ""setInterval(() => null, 1000);"" > wait.js
$ node --loader ./empty.cjs wait.js
(node:668264) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:668264) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:668264) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:668264) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
(node:668264) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
....
```

Passing `--trace-warnings` just add stack traces to each message:
```
(node:668371) ExperimentalWarning: Custom ESM Loaders is an experimental feature and might change at any time
    at emitExperimentalWarning (node:internal/util:273:11)
    at createModuleLoader (node:internal/modules/esm/loader:418:9)
    at loadESM (node:internal/process/esm_loader:18:19)
    at runMainESM (node:internal/modules/run_main:53:21)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:79:5)
    at node:internal/main/run_main_module:23:47
...
```

I mean....I guess the message did say that the feature could change at any time, but I am sure that this kind of change was not on purpose :)","jacobq",1633459,"2023-04-19 21:30:07","teste flag require reproduzir atualizar reproducao esquecer terminal vscode adicionar node_options flag auto attach feature mensagem experimental warning custom esm loader experimental feature mudar tempo stack trace mensagem feature mudar tempo proposito
"
1232,229,"FWIW I'm also able to reproduce without `--require`. We already have a fix ready FYI.","aduh95",14309773,"2023-04-19 21:35:25","able reproduce fix ready
"
1233,229,"> How so? 

@jacobq Interestingly it depends on the extensions used.

```sh
# OK
node --loader ./loader.mjs
# KO
node --loader ./loader.cjs
node --loader ./loader.js
node --require ./require.cjs --loader ./loader.mjs
```","merceyz",3842800,"2023-04-19 22:21:17","interestingly depend extension use node loader loader loader require loader
"
1234,229,"> > How so?
> 
> @jacobq Interestingly it depends on the extensions used.
> 
> ```shell
> # OK
> node --loader ./loader.mjs
> # KO
> node --loader ./loader.cjs
> node --loader ./loader.js
> node --require ./require.cjs --loader ./loader.mjs
> ```

The reason is it must invoke the CJS module loader to repro (the default is CJS, so `node --loader ./loader.js` will default to CJS when nothing tells it otherwise, and the other 2 are explicitly CJS).","JakobJingleheimer",3012099,"2023-04-20 19:22:52","invoke cjs module loader repro default cjs node loader default cjs explicitly cjs
"
1235,229,"> FWIW I'm also able to reproduce without `--require`. We already have a fix ready FYI.

when is this fix will be released ?, we are experiencing the same and we want to go over node 20 to have the improvements in cold imports that I already saw.

thanks","joacub",2091228,"2023-04-25 19:28:35","fix ready experience want go node improvement cold import
"
1236,229,"Ditto here! Also curious when this will be released.","checkrcarter",113402097,"2023-04-26 00:43:09","curious release
"
1237,229,"> Ditto here! Also curious when this will be released.

With 20.1.0 on 2023-05-02 per https://github.com/nodejs/Release/issues/855, or in a patch release if one is done before then.","GeoffreyBooth",456802,"2023-04-26 01:23:04","release curious
"
1238,229,"FYI 20.1.0 is out and the PR for this issue, #47620, is included in it.","TomasHubelbauer",6831144,"2023-05-04 07:27:07","fyi release pr issue includ
"
1239,229,"I tested with node 20.1.0 and the problem still exists without any changes:
https://github.com/cyco130/vavite/issues/39#issuecomment-1534788105","aheissenberger",200095,"2023-05-05 06:39:02","test node problem exist change
"
1240,229,"Just in case this is useful to anyone - in my case it actually did fix the issue… But it also revealed another one which I think is related: #47880.","TomasHubelbauer",6831144,"2023-05-05 11:38:12","case useful fix issue reveal another relate
"
1241,229,"Thank you. 20.1.0 fixed the issue for us.","kirrg001",1160712,"2023-05-08 11:50:49","fix issue
"
1242,230,"cc @nodejs/url ","KhafraDev",42794878,"2023-04-14 05:08:12","nodejs url
"
1243,230,"I'm able to reproduce this:

```console
➜  ~ node
Welcome to Node.js v18.16.0.
Type "".help"" for more information.
> new URL('HTTP://AMAZON.COM').href
'http://amaZon.com/'
> 
```

Node.js 18.16.0 uses Ada for parsing while 18.15.0 does not, so I strongly suspect this is either a bug in Ada or a bug in Node.js that was introduced as part of the change set to include Ada. 

@anonrig @lemire ","Trott",718899,"2023-04-14 05:27:34","reproduce node version use ada parse suspect bug ada bug node introduce part change include
"
1244,230,"Node.js 19.7.0 and newer has this same issue. 19.6.1 does not.  And again, 19.7.0 is the version where Ada is introduced.","Trott",718899,"2023-04-14 05:30:22","node js issue version ada introducer
"
1245,230,"I will fix this in Ada. Thanks for reporting. ","anonrig",1935246,"2023-04-14 11:40:53","fix ada thanks report
"
1246,230,"That's odd.","lemire",391987,"2023-04-14 13:25:23","odd
"
1247,230,"Wow. ","lemire",391987,"2023-04-14 13:26:43","Wow
"
1248,230,"@lemire's [pull request](https://github.com/ada-url/ada/pull/324#event-9008153572) fixed this in Ada. We'll release a new version.","anonrig",1935246,"2023-04-14 13:55:29","ada release new version
"
1249,230,"Ada v2.1.0 will fix this issue.","anonrig",1935246,"2023-04-17 17:59:00","ada fix issue
"
1250,231,"Yep, I'll fix those in the morning. My editor always seems to want to inject those spaces where they shouldn't be. 🙈","Qard",205482,"2023-04-12 07:15:15","fix morning editor always want inject space
"
1251,231,"Fast-track has been requested by @Qard. Please 👍 to approve.","github-actions[bot]",41898282,"2023-04-12 16:29:11","request approve
"
1269,232,"```
Welcome to Node.js v19.8.1.
Type "".help"" for more information.
> new Date()
2023-04-07T17:45:36.846Z
> new Date
2023-04-07T17:45:52.221Z
> os.release()
'10.0.22621'
```
Seems to be working 🙄","soumyadeepdutta",43964727,"2023-04-07 15:58:15","work
"
1270,232,"Can it be a Windows 11 problem? 
It don't even let me finish the command 
![image](https://user-images.githubusercontent.com/29102315/230640213-26ca26e5-e69e-4447-8827-3f2e3da5f057.png)


There is no problem if I call it inside a function 

```
Welcome to Node.js v19.8.1.
Type "".help"" for more information.
> console.log(new Date())
2023-04-07T16:07:54.389Z
undefined
```","danpeixoto",29102315,"2023-04-07 16:04:35","windows problem even let finish command problem call inside function
"
1271,232,"I don't use Windows, but on macOS, it does not crash. @lemire, do you see any particular reason why would this fail?","anonrig",1935246,"2023-04-07 17:41:02","use macOS crash see particular reason fail
"
1272,232,"This could fail if the input is not valid UTF-8, in which case `utf16_length` would be zero.","lemire",391987,"2023-04-07 18:28:27","fail input valid utf case utf16 length zero
"
1273,232,"It works for me... on a freshly installed node...

<img width=""585"" alt=""image"" src=""https://user-images.githubusercontent.com/391987/230661671-c4c8cdc7-230e-4ddc-81e3-bbf966841b69.png"">
","lemire",391987,"2023-04-07 18:49:48","work freshly install node
"
1274,232,"Works with PowerShell as well.

<img width=""863"" alt=""image"" src=""https://user-images.githubusercontent.com/391987/230663536-99c60f48-f964-4305-a6d2-251d9010a053.png"">
","lemire",391987,"2023-04-07 19:05:32","work powershell
"
1275,232,"I have opened a PR that might help with this issue: https://github.com/nodejs/node/pull/47471


This being said, it is not clear to me where the error comes from. Something in Node expects UTF-8 and tries to convert it to UTF-16 but the UTF-8 is not valid. Where does the invalid UTF-8 comes from? Does it come from Node itself?

","lemire",391987,"2023-04-07 20:13:32","open pr help issue node expect utf convert utf utf valid invalid utf come node
"
1276,232,"Could it be associated with the result preview in the CLI? ","danpeixoto",29102315,"2023-04-07 20:48:05","associate result preview cli
"
1277,232,"> Could it be associated with the result preview in the CLI?

Almost certainly but I see the previews in my terminals as well. It is weird because Date() will result in pure ASCII. That's not the kind of string that should be problematic. There might be an issue elsewhere in Node.js.

If you use a different terminal, does the same problem persists?

Could you try Windows Terminal? ","lemire",391987,"2023-04-08 03:12:21","result preview cli terminal date ascii string issue node different terminal problem persist windows terminal
"
1278,232,"Yes, on all the ones I have installed. I tried CMD, git bash, and power shell. I will try to instal WSL and test in there","danpeixoto",29102315,"2023-04-08 12:56:16","instal try cmd git bash power shell try instal wsl test
"
1279,232,"It works in Ubuntu wsl
```
peixoto@:~$ uname -r
5.15.90.1-microsoft-standard-WSL2
peixoto@:~$ node
Welcome to Node.js v19.8.1.
Type "".help"" for more information.
> new Date()
2023-04-08T13:37:49.706Z
>
```","danpeixoto",29102315,"2023-04-08 13:40:16","work ubuntu wsl node date
"
1280,232,"The issue also occurs in Node 18.16.0 on Windows 11, but not in Node 18.15.0.","HeikoTheissen",67904016,"2023-06-14 08:17:02","issue occur node windows
"
1281,232,"Same problem here. Same circumstances and conditions.

Using Windows 11 with Node **v18.16.1**.

It happens under both PowerShell and Command Prompt.
It also happens within Node REPL.

It doesn't happen when running inside WSL.
Downgrading to v18.15.0 with nvm-windows made the problem go away.

Same message:
```
> node --inspect
Debugger listening on ws://127.0.0.1:9229/c8338e46-617a-4eaa-ad7e-7ffaa12f4158
For help, see: https://nodejs.org/en/docs/inspector
Welcome to Node.js v18.16.1.
Type "".help"" for more information.
> new DateC:\Program Files\PowerShell\7\pwsh.exe[2520]: c:\ws\src\inspector\node_string.cc:39: Assertion `(expected_utf16_length) == (utf16_length)' failed.
 1: 00007FF68280D54F node_api_throw_syntax_error+175743
 2: 00007FF682792E96 DSA_meth_get_flags+59654
 3: 00007FF682793272 DSA_meth_get_flags+60642
 4: 00007FF682661A35 std::basic_ios<char,std::char_traits<char> >::init+597
 5: 00007FF68267A75A std::basic_ostream<char,std::char_traits<char> >::put+101658
 6: 00007FF682678306 std::basic_ostream<char,std::char_traits<char> >::put+92358
 7: 00007FF68266CB62 std::basic_ostream<char,std::char_traits<char> >::put+45346
 8: 00007FF6831F326D v8::internal::Builtins::code+248237
 9: 00007FF6831F2E79 v8::internal::Builtins::code+247225
10: 00007FF6831F313C v8::internal::Builtins::code+247932
11: 00007FF6831F2FA0 v8::internal::Builtins::code+247520
12: 00007FF6832D7D81 v8::internal::SetupIsolateDelegate::SetupHeap+558449
13: 00007FF60341CD37
```

","dami-i",68955399,"2023-06-25 19:31:27","problem circumstance condition use window node happen powershell command prompt also happen node repl not happen run wsl downgrade v18.15.0 nvm window problem go away message node inspect debugger listen ws 127.0.0.1 9229 help see welcome node type help information new date assertion fail node_api_throw_syntax_error dsa_meth_get_flags std basic_ios init std basic_ostream put std basic_ostream put std basic_ostream put v8 internal builtins code v8 internal builtins code v8 internal builtins code v8 internal builtins code v8 internal setupisolatenodelegate setupheap
"
1282,232,"@dami-i  Can you check with Node 20.0 or better?

I proposed a PR https://github.com/nodejs/node/pull/47471 that would allow invalid strings (they get turned to empty strings). I suspect that my PR fixed this issue you are encountering.","lemire",391987,"2023-06-26 14:38:56","check node allow invalid string turn empty string suspect pr fix issue
"
1283,232,"> @dami-i Can you check with Node 20.0 or better?
> 
> I proposed a PR #47471 that would allow invalid strings (they get turned to empty strings). I suspect that my PR fixed this issue you are encountering.

@lemire Your suspicions are right. I've just tried out with 20.3.1 and had no issue whatsoever. 🚀

Do you know if there is any chance to have this bugfix implemented in v18?","dami-i",68955399,"2023-06-27 14:14:16","check node allow invalid string turn empty string suspect pr fix issue try issue whatsoever chance bugfix implement v18
"
1284,232,"@dami-i That's a good question.

@anonrig : what do you think? Can we backport https://github.com/nodejs/node/pull/47471 to node 18?","lemire",391987,"2023-06-27 14:16:10","good question think backport node
"
1285,232,"![Captura de tela 2023-07-10 202524](https://github.com/nodejs/node/assets/139183021/9e041267-5aa5-43ad-9bc8-98bba1929c19)
 alguém me ajuda","107815684",139183021,"2023-07-10 23:26:12","alguém ajuda
"
1286,232,"Welcome to Node.js v20.3.0 versão 
","107815684",139183021,"2023-07-10 23:27:29","Node.js v20 versão
"
1287,232,"Can confirm this issue for 

  - node v18.17 
  - Windows 11

![node18 17](https://github.com/nodejs/node/assets/3647678/165b5542-2e77-401e-9b36-0c7dac95d670)

  
 
Downgrading to node v18.15 resolved the issue for me at the moment 

![node18 15](https://github.com/nodejs/node/assets/3647678/a9650d3b-3be8-4154-bc44-13f6c9e8b07b)

","wiggisser",3647678,"2023-08-01 13:36:51","confirm issue node version downgrade resolve issue
"
1288,232,"> Can confirm this issue for
> 
> * node v18.17

And also for v18.17.1 and Windows 11.","HeikoTheissen",67904016,"2023-08-11 11:31:53","confirm issue node v18 window
"
1289,232,"The issue also occurs for Windows 11 and Node.js v20.6.1 (works with v20.5.1).","HeikoTheissen",67904016,"2023-09-12 06:45:04","issue occur window nodejs version
"
1312,233,"I had the same problem with Node 19.8.0. Deinstalling Node (this way -> https://stackoverflow.com/a/71453065) and installing the LTS version (18.5.0) fixed the problem for me. ","danielkoller",15102417,"2023-03-15 13:02:13","problem node version deinstall node install lts version fix problem
"
1290,232,"The error can also be provoked on Windows 11 and Node v20.5.1 by typing `""𬉼` into the REPL:
```
Welcome to Node.js v20.5.1.
Type "".help"" for more information.
> ""𬉼Command Prompt - node[12224]: c:\ws\src\inspector\node_string.cc:80: Assertion `utf8_length == 0 || utf8_length == expected_utf8_length' failed.
 1: 00007FF6D17ABCDF node_api_throw_syntax_error+203199
 2: 00007FF6D1728226 v8::base::CPU::num_virtual_address_bits+74518
 3: 00007FF6D1728632 v8::base::CPU::num_virtual_address_bits+75554
 4: 00007FF6D15CB0FD uv_loop_size+30349
 5: 00007FF6D15EBF14 uv_loop_size+165028
 6: 00007FF6D15E9496 uv_loop_size+154150
 7: 00007FF6D15DCEE7 uv_loop_size+103543
 8: 00007FF6D21487FE v8::SharedValueConveyor::SharedValueConveyor+416270
 9: 00007FF6D21483FA v8::SharedValueConveyor::SharedValueConveyor+415242
10: 00007FF6D21486BF v8::SharedValueConveyor::SharedValueConveyor+415951
11: 00007FF6D2148530 v8::SharedValueConveyor::SharedValueConveyor+415552
12: 00007FF6D2242F5E v8::PropertyDescriptor::writable+674286
13: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
14: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
15: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
16: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
17: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
18: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
19: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
20: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
21: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
22: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
23: 00007FF6D21EFAB1 v8::PropertyDescriptor::writable+333121
24: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
25: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
26: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
27: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
28: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
29: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
30: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
31: 00007FF6D21B4600 v8::PropertyDescriptor::writable+90256
32: 00007FF6D21B29C0 v8::PropertyDescriptor::writable+83024
33: 00007FF6D21B25BB v8::PropertyDescriptor::writable+81995
34: 00007FF6D205D5F8 v8::StackTrace::GetFrameCount+3944
35: 00007FF6D205CEF3 v8::StackTrace::GetFrameCount+2147
36: 00007FF6D217159B v8::Function::Call+571
37: 00007FF6D17E1948 node::CallbackScope::~CallbackScope+1544
38: 00007FF6D17D9318 v8::base::CPU::has_osxsave+146744
39: 00007FF6D1606D6D RSA_meth_get_flags+17293
40: 00007FF6D1607A3B RSA_meth_get_flags+20571
41: 00007FF6D1602F34 RSA_meth_get_flags+1364
42: 00007FF6D1601E42 v8::CTypeInfoBuilder<bool>::Build+29234
43: 00007FF6D17F6518 uv_udp_set_ttl+17128
44: 00007FF6D180FF7E uv_run+478
45: 00007FF6D17E0C65 node::SpinEventLoop+405
46: 00007FF6D16DA1CB X509_STORE_get_cleanup+151147
47: 00007FF6D17659CE node::InitializeOncePerProcess+2974
48: 00007FF6D1767DB3 node::Start+3779
49: 00007FF6D1766F20 node::Start+48
50: 00007FF6D154E91C AES_cbc_encrypt+151372
51: 00007FF6D297ABAC inflateValidate+19260
52: 00007FF8F6FB257D BaseThreadInitThunk+29
53: 00007FF8F81EAA68 RtlUserThreadStart+40
```
The offending character is `\u{2c27c}`.","HeikoTheissen",67904016,"2023-09-21 08:01:28","error provoke window node type character offend character
"
1291,232,"I can verify the problem with Node 20.7.0 under Windows 11. In fact, it appears that typing any non-ASCII character in the Node shell as the first character seems to trigger the check and lead to an abort. Just 'é' will suffice. 

![image](https://github.com/nodejs/node/assets/391987/f0faaffa-639d-4702-acbc-6b396802a442)


The problem only occurs while typing directly in the Node shell. If you execute a script, it is fine.

If I build Node from source under Windows, using the current Node code, and simply executing vcbuild.bat, and running the generated node.exe, I cannot reproduce the problem.

![image](https://github.com/nodejs/node/assets/391987/89f8021e-2d3e-42a9-a804-9c1f8d5492a6)

So the bug is real, but it seems to have to do with how Node is built for windows as part of the release process. I would normally consider the possibility that the problem was recently fixed in the code, but Node 20.7.0 is a very recent release, and I find it unlikely that something happened in the last three days to the code to fix this issue.","lemire",391987,"2023-09-21 16:04:08","verificar problema node windows  aparentemente digitar caractere ascii node shell primeiro caractere disparar verificação levar interrupção  suficiente problema ocorrer digitar diretamente node shell executar script  construir node fonte windows usar código node executar vcbuild bat executar node exe reproduzir problema erro real parecer relação node construir windows parte processo liberação normalmente considerar possibilidade problema recentemente corrigir código node versão recente achar improvável algo acontecer último três dia código corrigir problema
"
1292,232,"cc @nodejs/platform-windows @nodejs/platform-windows-arm @nodejs/build ","anonrig",1935246,"2023-09-21 16:19:53","nodejs platform windows nodejs platform windows arm nodejs build
"
1293,232,"> In fact, it appears that typing any non-ASCII character in the Node shell as the first character seems to trigger the check and lead to an abort. Just 'é' will suffice.

Not any non-ASCII character: Typing `é` crashes, but typing `𬉼` as the first character does not:
```
Welcome to Node.js v20.5.1.
Type "".help"" for more information.
> 𬉼
Uncaught ReferenceError: 𬉼 is not defined
```","HeikoTheissen",67904016,"2023-09-22 07:21:15","fact appear type non ascii character node shell first character seem trigger check lead abort suffice non ascii character type crash type first character


Note:  The pré-processing removed URLs (none present), HTML tags (none present), and special characters (like the  `é` and  `𬉼`  which were likely causing issues and are not semantically important for issue classification). Stemming/lemmatization (reducing words to their root form) was applied, removing pluralization and verb conjugations. Finally, common English stop words (like ""in,"" ""that,"" ""to,"" ""the,"" ""it,"" ""as,"" ""and,"" ""will"") were eliminated.  The code example was entirely removed as it's not relevant for classifying the issue type.
"
1294,232,"@HeikoTheissen 

Interesting. 

Again, if I build Node from source (Visual Studio 2022), I don’t see this effect. It would be important to know how the releases for Windows are built.","lemire",391987,"2023-09-22 12:14:19","build node source visual studio effect important know release windows build
"
1295,233,"For reference here is the error stack on darwin-arm64:

```
/tmp/.nvm/versions/node/v19.8.0/bin/node[36950]: ../src/module_wrap.cc:599:MaybeLocal<v8::Promise> node::loader::ImportModuleDynamically(Local<v8::Context>, Local<v8::Data>, Local<v8::Value>, Local<v8::String>, Local<v8::FixedArray>): Assertion `(it) != (env->id_to_function_map.end())' failed.
 1: 0x102500e00 node::Abort() [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 2: 0x102500bcc node::PrintCaughtException(v8::Isolate*, v8::Local<v8::Context>, v8::TryCatch const&) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 3: 0x1024c932c node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::Data>, v8::Local<v8::Value>, v8::Local<v8::String>, v8::Local<v8::FixedArray>) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 4: 0x1027b092c v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::MaybeHandle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>, v8::internal::MaybeHandle<v8::internal::Object>) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 5: 0x102bb7604 v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 6: 0x102f43524 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvInRegister_NoBuiltinExit [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 7: 0x102fe849c Builtins_CallRuntimeHandler [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 8: 0x102ec0064 Builtins_InterpreterEntryTrampoline [/tmp/.nvm/versions/node/v19.8.0/bin/node]
 9: 0x102ec0064 Builtins_InterpreterEntryTrampoline [/tmp/.nvm/versions/node/v19.8.0/bin/node]
10: 0x102ec0064 Builtins_InterpreterEntryTrampoline [/tmp/.nvm/versions/node/v19.8.0/bin/node]
11: 0x102ef68b4 Builtins_AsyncFunctionAwaitResolveClosure [/tmp/.nvm/versions/node/v19.8.0/bin/node]
12: 0x102f96e38 Builtins_PromiseFulfillReactionJob [/tmp/.nvm/versions/node/v19.8.0/bin/node]
13: 0x102ee6834 Builtins_RunMicrotasks [/tmp/.nvm/versions/node/v19.8.0/bin/node]
14: 0x102ebe3c4 Builtins_JSRunMicrotasksEntry [/tmp/.nvm/versions/node/v19.8.0/bin/node]
15: 0x1027939a0 v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
16: 0x102793e90 v8::internal::(anonymous namespace)::InvokeWithTryCatch(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
17: 0x10279406c v8::internal::Execution::TryRunMicrotasks(v8::internal::Isolate*, v8::internal::MicrotaskQueue*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
18: 0x1027bbfe4 v8::internal::MicrotaskQueue::RunMicrotasks(v8::internal::Isolate*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
19: 0x1027bc880 v8::internal::MicrotaskQueue::PerformCheckpoint(v8::Isolate*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
20: 0x1026c65ec v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, unsigned long*, int) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
21: 0x1026c5d5c v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
22: 0x102f433ec Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/tmp/.nvm/versions/node/v19.8.0/bin/node]
23: 0x107b53568 
24: 0x102ebe4f0 Builtins_JSEntryTrampoline [/tmp/.nvm/versions/node/v19.8.0/bin/node]
25: 0x102ebe184 Builtins_JSEntry [/tmp/.nvm/versions/node/v19.8.0/bin/node]
26: 0x1027939d0 v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
27: 0x102792f28 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
28: 0x102676a2c v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
29: 0x102448d0c node::InternalCallbackScope::Close() [/tmp/.nvm/versions/node/v19.8.0/bin/node]
30: 0x102448fd8 node::InternalMakeCallback(node::Environment*, v8::Local<v8::Object>, v8::Local<v8::Object>, v8::Local<v8::Function>, int, v8::Local<v8::Value>*, node::async_context) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
31: 0x10245ef9c node::AsyncWrap::MakeCallback(v8::Local<v8::Function>, int, v8::Local<v8::Value>*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
32: 0x1025ba658 node::StreamBase::CallJSOnreadMethod(long, v8::Local<v8::ArrayBuffer>, unsigned long, node::StreamBase::StreamBaseJSChecks) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
33: 0x1025bbe94 node::EmitToJSStreamListener::OnStreamRead(long, uv_buf_t const&) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
34: 0x1025bff40 node::LibuvStreamWrap::OnUvRead(long, uv_buf_t const*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
35: 0x1025c06dc node::LibuvStreamWrap::ReadStart()::$_1::__invoke(uv_stream_s*, long, uv_buf_t const*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
36: 0x102ea8244 uv__stream_io [/tmp/.nvm/versions/node/v19.8.0/bin/node]
37: 0x102eb035c uv__io_poll [/tmp/.nvm/versions/node/v19.8.0/bin/node]
38: 0x102e9e088 uv_run [/tmp/.nvm/versions/node/v19.8.0/bin/node]
39: 0x1024496f4 node::SpinEventLoopInternal(node::Environment*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
40: 0x10253dee4 node::NodeMainInstance::Run() [/tmp/.nvm/versions/node/v19.8.0/bin/node]
41: 0x1024ce260 node::LoadSnapshotDataAndRun(node::SnapshotData const**, node::InitializationResultImpl const*) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
42: 0x1024ce4c8 node::Start(int, char**) [/tmp/.nvm/versions/node/v19.8.0/bin/node]
43: 0x19bbbbe50 start [/usr/lib/dyld]
```","JLHwung",3607926,"2023-03-14 21:26:08","assertion failed node importmoduledynamically
"
1313,233,"We're facing the same issue; we've solved pinning 19.7","csuriano23",34414634,"2023-03-15 14:18:55","face issue solve pin
"
1314,233,"> > We're also having the issue, and downgrading to 19.7 fixed it.
> 
> @ErCollao chan you share command to downgrade node version?

We actually had the problem in CI (with the `setup-node` GitHub action), so I just had to edit the node version on our workflow (`node_version: '19.7'` instead of `node_version: '19'` as we had before)","ErCollao",13274520,"2023-03-15 15:47:56","issue downgrade node version fix workflow
"
1315,233,"> This is happening on shopify-cli
> 
> When installing with homebrew, we can't force shopify-cli to use a different version, nor can we easily install an older version on homebrew.

I just found out that you can install shopify-cli through NPM instead of homebrew to avoid this issue","marjol",5325287,"2023-03-15 17:09:34","install shopify cli different version older version install shopify cli npm avoid issue
"
1296,233,"We have a similar issue but a slightly different stack trace. Might be related?

```
Mar 14 02:53:16 PM  /opt/render/project/nodes/node-19.8.0/bin/node[78]: ../src/module_wrap.cc:599:v8::MaybeLocal<v8::Promise> node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::Data>, v8::Local<v8::Value>, v8::Local<v8::String>, v8::Local<v8::FixedArray>): Assertion `(it) != (env->id_to_function_map.end())' failed.
Mar 14 02:53:16 PM   1: 0xbf9680 node::Abort() [/opt/render/project/nodes/node-19.8.0/bin/node]
Mar 14 02:53:16 PM   2: 0xbf96fe  [/opt/render/project/nodes/node-19.8.0/bin/node]
Mar 14 02:53:16 PM   3: 0xbaf577  [/opt/render/project/nodes/node-19.8.0/bin/node]
Mar 14 02:53:16 PM   4: 0xf5966f v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::MaybeHandle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>, v8::internal::MaybeHandle<v8::internal::Object>) [/opt/render/project/nodes/node-19.8.0/bin/node]
Mar 14 02:53:16 PM   5: 0x13c2ffb v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) [/opt/render/project/nodes/node-19.8.0/bin/node]
Mar 14 02:53:16 PM   6: 0x18425f4  [/opt/render/project/nodes/node-19.8.0/bin/node]
Mar 14 02:53:16 PM  Aborted
Mar 14 02:53:16 PM  error Command failed with exit code 134.
```","azianmike",4706498,"2023-03-14 22:11:16","similar issue slightly different stack trace relate assertion failed abort error command fail exit code 134
"
1297,233,"Note: We hard-pinned our node version to 19.7 (without any other code changes) and that fixed our issue. Obviously would love to see if the issue can be fixed so we can upgrade to 19.8","azianmike",4706498,"2023-03-14 22:21:10","node version fix issue upgrade
"
1298,233,"We're consistently hitting the following on 19.8.0:

```
/opt/hostedtoolcache/node/19.8.0/x64/bin/node[18122]: ../src/module_wrap.cc:599:v8::MaybeLocal<v8::Promise> node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::Data>, v8::Local<v8::Value>, v8::Local<v8::String>, v8::Local<v8::FixedArray>): Assertion `(it) != (env->id_to_function_map.end())' failed.
 1: 0xbf9680 node::Abort() [/opt/hostedtoolcache/node/19.8.0/x64/bin/node]
 2: 0xbf96fe  [/opt/hostedtoolcache/node/19.8.0/x64/bin/node]
 3: 0xbaf577  [/opt/hostedtoolcache/node/19.8.0/x64/bin/node]
 4: 0xf5966f v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::MaybeHandle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>, v8::internal::MaybeHandle<v8::internal::Object>) [/opt/hostedtoolcache/node/19.8.0/x64/bin/node]
 5: 0x13c2ffb v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) [/opt/hostedtoolcache/node/19.8.0/x64/bin/node]
 6: 0x18425f4  [/opt/hostedtoolcache/node/19.8.0/x64/bin/node]
```

Previous runs on 19.7.0 were not hitting this.","justinvp",710598,"2023-03-15 00:20:03","hit follow assertion fail
"
1299,233,"I also have this problem.","samuelbailey123",60560571,"2023-03-15 01:33:40","problem
"
1300,233,"I have this problem as well 😢 My deployment is failing on : /nodes/node-19.8.0/. Downgraded to an older version and it worked. 
 ","APiligrim",28320272,"2023-03-15 03:29:00","deployment fail downgrade older version work
"
1301,233,"I confirm that reverting https://github.com/nodejs/node/pull/46785 fixes the crash.

/cc @joyeecheung @nodejs/cpp-reviewers ","targos",2352663,"2023-03-15 06:37:42","confirm revert fix crash
"
1302,233,"> I have this problem as well cry My deployment is failing on : /nodes/node-19.8.0/. Downgraded to an older version and it worked.

For me downgrading to 19.7 also fixed the issue","antonimarek",45034890,"2023-03-15 09:06:28","deployment fail downgrade older version work
"
1303,233,"We're also having the issue, and downgrading to 19.7 fixed it.","ErCollao",13274520,"2023-03-15 09:23:28","issue downgrade fix
"
1304,233,"This is happening on shopify-cli

When installing with homebrew, we can't force shopify-cli to use a different version, nor can we easily install an older version on homebrew.","ekwoka",43540491,"2023-03-15 09:41:17","install homebrew force shopify cli version install older version homebrew
"
1305,233,"> This is happening on shopify-cli
> 
> When installing with homebrew, we can't force shopify-cli to use a different version, nor can we easily install an older version on homebrew.

@ekwoka you can run `brew edit shopify-cli` and replace `depends_on ""node""` with `depends_on ""node@18""` as a quick workaround.
","Arkham",62895,"2023-03-15 10:16:51","install homebrew force shopify cli use different version easily install older version quick workaround run brew edit shopify cli replace depend node depend node
"
1306,233,"Ah, interesting! I was trying to edit node to get it to use 19.7 but it always would use 19.8 no matter what I tried.","ekwoka",43540491,"2023-03-15 10:18:12","edit node use 19.7 always use 19.8
"
1307,233,"> We're also having the issue, and downgrading to 19.7 fixed it.

@ErCollao chan you share command to downgrade node version?","NaveenaTsLivearea",68386068,"2023-03-15 11:07:22","issue downgrade fix command node version
"
1308,233,"@NaveenaTsLivearea it depends son how you installed it.

But you can use nvm to have multiple.installed version to use the last one until this is fixed.","ekwoka",43540491,"2023-03-15 11:33:54","depend install use nvm multiple install version use last fix
"
1309,233,"> @NaveenaTsLivearea it depends son how you installed it.
> 
> But you can use nvm to have multiple.installed version to use the last one until this is fixed.

@ekwoka I'm using homebrew to install shopify CLI and it will always install latest version of Node","NaveenaTsLivearea",68386068,"2023-03-15 11:36:58","use nvm multiple install version use last fix use homebrew install shopify cli always install late version node
"
1310,233,"@NaveenaTsLivearea in that case, I just installed the js CLI and have used that instead.

`pnpm add -g @shopify/cli @shopify/theme`

You may also need to tell your terminal to use the homebrew ruby instead of the MacOS ruby. Instructions for that are at `brew info ruby`","ekwoka",43540491,"2023-03-15 11:38:19","install js cli use instead pnpm add shopify cli shopify theme may need tell terminal use homebrew ruby instead macos ruby instruction brew info ruby
"
1311,233,"node[10938]: ../src/module_wrap.cc:599:MaybeLocal<v8::Promise> node::loader::ImportModuleDynamically(Local<v8::Context>, Local<v8::Data>, Local<v8::Value>, Local<v8::String>, Local<v8::FixedArray>): Assertion `(it) != (env->id_to_function_map.end())' failed.
 1: 0x10ef1c8fc node::Abort() [/usr/local/Cellar/node/19.8.0/bin/node]
 2: 0x10ef1c8e7 node::Abort() [/usr/local/Cellar/node/19.8.0/bin/node]
 3: 0x10eede7c5 node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::Data>, v8::Local<v8::Value>, v8::Local<v8::String>, v8::Local<v8::FixedArray>) [/usr/local/Cellar/node/19.8.0/bin/node]
 4: 0x10f1a707b v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::MaybeHandle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>, v8::internal::MaybeHandle<v8::internal::Object>) [/usr/local/Cellar/node/19.8.0/bin/node]
 5: 0x10f51aacf v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) [/usr/local/Cellar/node/19.8.0/bin/node]
 6: 0x10ed5d334 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvInRegister_NoBuiltinExit [/usr/local/Cellar/node/19.8.0/bin/node]
[1]    10930 abort      npm run dev","100apps",8075583,"2023-03-15 12:37:56","assertion failed importmoduledynamically abort node
"
1316,233,"v19.8.1 was just released to fix this issue.","targos",2352663,"2023-03-15 17:20:33","release fix issue
"
1585,273,"Landed in 660d17dde7b1b8140d2513ab180a6531f43e1e66","nodejs-github-bot",18269663,"2022-07-14 11:05:52",NULL
1317,233,"Nice. But why is this happening?
And why it attempts to download `win` and `exe` for Ubuntu?
Is it possible that the released version is listed incorrectly in some registry?
CC @targos 

![image](https://user-images.githubusercontent.com/13189514/225424118-4a5671d9-9ec5-419a-9de3-f3cadda51e77.png)
","RobinTail",13189514,"2023-03-15 19:40:33","nice happen attempt download win exe ubuntu possible release version list incorrectly registry
"
1318,233,"Related issue in actions/setup-node
https://github.com/actions/setup-node/issues/714","RobinTail",13189514,"2023-03-15 19:48:22","issue action setup node
"
1319,233,"Works for me! Thanks for fixing.

","bobvdvalk",7026174,"2023-03-15 21:50:54","work thanks fix
"
1320,233,"Also broke in vite:
```
/usr/local/Cellar/node/19.8.0/bin/node[3421]: ../src/module_wrap.cc:599:MaybeLocal<v8::Promise> node::loader::ImportModuleDynamically(Local<v8::Context>, Local<v8::Data>, Local<v8::Value>, Local<v8::String>, Local<v8::FixedArray>): Assertion `(it) != (env->id_to_function_map.end())' failed.
 1: 0x10c63c87c node::Abort() [/usr/local/Cellar/node/19.8.0/bin/node]
 2: 0x10c63c867 node::Abort() [/usr/local/Cellar/node/19.8.0/bin/node]
 3: 0x10c5fe745 node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::Data>, v8::Local<v8::Value>, v8::Local<v8::String>, v8::Local<v8::FixedArray>) [/usr/local/Cellar/node/19.8.0/bin/node]
 4: 0x10c8c706f v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::MaybeHandle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>, v8::internal::MaybeHandle<v8::internal::Object>) [/usr/local/Cellar/node/19.8.0/bin/node]
 5: 0x10cc3aac3 v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) [/usr/local/Cellar/node/19.8.0/bin/node]
 6: 0x10c47d0b9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_NoBuiltinExit [/usr/local/Cellar/node/19.8.0/bin/node]
 7: 0x113ef93c1
 8: 0x113f44a4c
 9: 0x10c42cb04 Builtins_AsyncFunctionAwaitResolveClosure [/usr/local/Cellar/node/19.8.0/bin/node]
```","Huelse",37256164,"2023-03-16 02:13:05","broke vite assertion fail node importmoduledynamically runtime dynamicimportcall asyncfunctionawaitresolveclosure
"
1321,235,"It seems this could be solved by adding the ansi escape symbol `\x1B` to the `#isEscapeSymbol(char)` function? something like 

```diff
diff --git a/lib/internal/test_runner/tap_lexer.js b/lib/internal/test_runner/tap_lexer.js
index a27e6ab35e..8af5453b28 100644
--- a/lib/internal/test_runner/tap_lexer.js
+++ b/lib/internal/test_runner/tap_lexer.js
@@ -525,7 +525,7 @@ class TapLexer {
   }
 
   #isEscapeSymbol(char) {
-    return char === '\\';
+    return char === '\\' || char === '\x1b';
   }
 
   #isYamlStartSymbol(char) {
```","debadree25",20257253,"2023-03-11 16:55:14","add ansi escape symbol function like return char
"
1322,235,"@debadree25 do you want to open a PR? ","MoLow",8221854,"2023-03-12 06:49:14","want open pr
"
1323,235,"Doing so!","debadree25",20257253,"2023-03-12 07:31:31","Doing
"
1324,236,"cc @anonrig ","panva",241506,"2023-02-26 17:09:25","anonrig retornar
"
1325,236,"cc @nodejs/url ","anonrig",1935246,"2023-02-26 19:28:16","nodejs url
"
1326,236,"Looks like a bug in ada.

https://github.com/ada-url/ada/pull/242","lemire",391987,"2023-02-26 20:03:49","bug ada
"
1327,236,"It seems like web platform tests do not cover this edge case...","anonrig",1935246,"2023-02-26 20:14:38","web platform test cover edge case
"
1328,236,"We have a patch release in ada (v1.0.4). Upgrading ada in node should fix the issue.","lemire",391987,"2023-02-26 20:20:55","patch release ada node fix issue
"
1329,237,"You accidentally wrote the expected in the current behavior","rluvaton",16746759,"2023-02-24 11:28:53","accidentally write expect current behavior
"
1330,237,"> You accidentally wrote the expected in the current behavior

I corrected it, thank you","zuozp8",1228107,"2023-02-24 11:32:42","write expect current behavior correct thank
"
1331,237,"Do you think you can make an even simpler example?","ronag",3065230,"2023-02-24 11:55:15","think make simple example
"
1332,237,"What I saw is when you remove the `construct` it works well
","rluvaton",16746759,"2023-02-24 12:21:56","saw remove construct work well
"
1333,237,"That's a good hint.","ronag",3065230,"2023-02-24 12:39:27","good hint
"
1334,237,"sometimes it starts/stops occuring when you change some `process.nextTick(callback)` into `callack()` or the other way around, so it's some kind of race-condition

I wasn't able to replicate the problem without nested Transforms","zuozp8",1228107,"2023-02-24 13:16:33","start stop occur change process nexttick callback race condition replicate problem nest transform
"
1335,237,"When you wrap the:
```js
else if (innerTranfrorm.write(row)) {
                process.nextTick(callback);
            } else
```

like this:

```js
} else if (innerTransform.write('outer | ' + row)) {
          process.nextTick(() => {
            process.nextTick(callback);
          });
        } else {
```

it solves the problem","rluvaton",16746759,"2023-02-24 13:26:24","solve problem
"
1336,237,"Found another solution and updated my PR","rluvaton",16746759,"2023-02-24 13:34:41","solution update pr
"
1337,237,"This is indeed a bug. Here is a simplified version:

```js
const stream = require(""node:stream"");
const s = new stream.Transform({
  objectMode: true,
  construct(callback) {
    this.push('header from constructor\n');
    callback();
  },
  transform: (row, encoding, callback) => {
    callback(null, JSON.stringify(row) + '\n');
  },
});

s.pipe(process.stdout);
s.write('firstLine');
process.nextTick(() => s.write('secondLine'));
```

This fixes the example:

```js
const stream = require(""node:stream"");
const s = new stream.Transform({
  objectMode: true,
  construct(callback) {
    this.push('header from constructor\n');
    process.nextTick(callback);
  },
  transform: (row, encoding, callback) => {
    callback(null, JSON.stringify(row) + '\n');
  },
});

s.pipe(process.stdout);
s.write('firstLine');
process.nextTick(() => s.write('secondLine'));
```

So I think we are missing a `nextTick` in the constructor logic.","mcollina",52195,"2023-02-24 14:10:34","bug fix miss nexttick constructor logic
"
1338,237,"I think https://github.com/nodejs/node/blob/1f75a9513fc829fbd5326a5c9bfa7678b7431eb8/lib/internal/streams/readable.js#LL222C7-L222C7 should be delayed with a `nextTick`.","mcollina",52195,"2023-02-24 14:11:45","think delay nextTick
"
1339,237,"> I think [`1f75a95`/lib/internal/streams/readable.js#LL222C7-L222C7](https://github.com/nodejs/node/blob/1f75a9513fc829fbd5326a5c9bfa7678b7431eb8/lib/internal/streams/readable.js#LL222C7-L222C7) should be delayed with a `nextTick`.

delaying it with `nextTick` did not worked...","rluvaton",16746759,"2023-02-24 14:36:02","think delay nextTick delay nextTick work
"
1370,242,"This should have been fixed in #51045. Once it gets in 21.x or 20.x please let me know if you have additional problems.","ShogunPanda",201101,"2023-12-22 10:06:15","fix problem
"
1375,243,"@ronag  could you please provide an example? I'm not sure how to set headers after a `res.write` since it will always throw `ERR_HTTP_HEADERS_SENT`","marco-ippolito",36735501,"2023-02-13 09:45:26","provide example sure set header res write always throw err http header sent
"
1376,243,"You are right. My mistake.","ronag",3065230,"2023-02-13 09:48:03","right mistake
"
1420,248,"Whatever happened to ""thank you, you're awesome, I want to have your babies""?

...Yes, eventually.","bnoordhuis",275871,"2023-01-12 14:20:46","thank awesome want baby
"
1340,237,"Given the following script:

```
const stream = require(""node:stream"");
const consumers = require(""node:stream/consumers"");
const createInnerTransfrom = () => new stream.Transform({
    objectMode: true,
    construct(callback) {
        this.push('header from constructor\n');
        process.nextTick(callback);
    },
    transform: (row, encoding, callback) => {
        callback(null, JSON.stringify(row) + '\n');
    },
});
const createOuterTransfrom = () => {
    let innerTranfrorm;
    return new stream.Transform({
        objectMode: true,
        transform(row, encoding, callback) {
            if (!innerTranfrorm) {
                innerTranfrorm = createInnerTransfrom();
                innerTranfrorm.on('data', (data) => this.push(data));
                callback();
            }
            else if (innerTranfrorm.write(row)) {
                process.nextTick(callback);
            }
            else {
                innerTranfrorm.once('drain', callback);
            }
        },
    });
};
consumers.text(stream.Readable.from([
    'create InnerTransform',
    'firstLine',
    'secondLine',
]).pipe(createOuterTransfrom())).then((text) => console.log('output:\n', text));
```

It will error:

```
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

Error [ERR_STREAM_PUSH_AFTER_EOF]: stream.push() after EOF
    at new NodeError (node:internal/errors:399:5)
    at readableAddChunk (node:internal/streams/readable:285:30)
    at Readable.push (node:internal/streams/readable:234:10)
    at Transform.<anonymous> (/Users/matteo/tmp/aaa.js:20:58)
    at Transform.emit (node:events:513:28)
    at addChunk (node:internal/streams/readable:324:12)
    at readableAddChunk (node:internal/streams/readable:297:9)
    at Readable.push (node:internal/streams/readable:234:10)
    at node:internal/streams/transform:182:12
    at Transform.transform [as _transform] (/Users/matteo/tmp/aaa.js:10:9) {
  code: 'ERR_STREAM_PUSH_AFTER_EOF'
}
```

This is correct, as you are pushing things after the stream ended.","mcollina",52195,"2023-02-24 15:09:06","stream push eof error node stream readable transform
"
1341,237,"I tested with your simplified version","rluvaton",16746759,"2023-02-24 15:10:19","test simplify version
"
1342,237,"Here is the fix: https://github.com/nodejs/node/pull/46818","mcollina",52195,"2023-02-24 15:54:01","fix
"
1343,238,"cc: @nodejs/url @anonrig ","lpinca",1443911,"2023-02-21 19:55:21","nodejs url anonrig
"
1344,238,"> ```js
> const url = new URL('file:///var/log/system.log');
> url.href = 'http://0300.168.0xF0';
> url.href; // => 'file://192.168.0.240/', should be 'http://0300.168.0xF0'
> ```

This is an expected and in compliance with the WHATWG URL standard. `url.href` setter directly calls basic URL parser on the given value. Safari also returns the same. Reference: https://url.spec.whatwg.org/#dom-url-href

> ```js
> new URL('', 'about:blank'); // should be an error, now it's not
> ```

This is indeed a bug. Safari throws an error, but we don't. It seems like web platform tests do not cover this case. ","anonrig",1935246,"2023-02-21 20:22:38","expected compliance whatwg url standard url href setter call basic url parser value safari return reference bug safari throw error seem web platform test cover case
"
1345,238,"> This is an expected and in compliance with the WHATWG URL standard. url.href setter directly calls basic URL parser on the given value. Safari also returns the same. Reference: [url.spec.whatwg.org/#dom-url-href](https://url.spec.whatwg.org/#dom-url-href)

Nope. See the spec and ALL other implementations.

![image](https://user-images.githubusercontent.com/2213682/220451048-41aed1b4-ce95-4e50-a941-14a24049117d.png)
","zloirock",2213682,"2023-02-21 20:28:43","expected compliance whatwg url standard url href setter call basic url parser value safari return reference spec implementation
"
1346,238,"Your response also returns 192.168.0.240, the same as Node.js?

```
➜  url-parser git:(perf-improve-undici) ✗ node
Welcome to Node.js v19.7.0.
Type "".help"" for more information.
> const url = new URL('file:///var/log/system.log');
undefined
> url.href = 'http://0300.168.0xF0';
'http://0300.168.0xF0'
> url.href
'file://192.168.0.240/'
>
```","anonrig",1935246,"2023-02-21 20:33:08","response return node
"
1347,238,"See the protocol.","zloirock",2213682,"2023-02-21 20:33:31","see protocol
"
1348,238,"> See the protocol.

I see. Looking into it now. Thanks.","anonrig",1935246,"2023-02-21 20:40:51","see protocol look thanks
"
1349,238,"Fixed the bug on Ada (https://github.com/ada-url/ada/pull/225). Thanks for the issue. I'll release a new version of Ada in the next couple of days and update Node.js","anonrig",1935246,"2023-02-21 20:54:57","fix bug ada thanks issue release new version ada day update node js
"
1350,239,"The behavior is the same with v18.14.1 and v18.13.0, but works fine with v18.12.1. The only relevant change I can see between the two is from #45539, but I'm not sure why that would be causing this issue. It's also a little too in the weeds for me to spend much more time on it right now, unfortunately. Hopefully this information helps at least.","harrisi",14868079,"2023-02-19 19:03:21","behavior same v18.14.1 v18.13.0 work fine v18.12.1 relevant change see cause issue little weed spend time hopefully information help
"
1351,239,"I did some testing and this seems to also relate to newline characters:
The infinite loop does not occur if the loaded file does not end with a newline character.

<table><tr><th></th><th>Node 18.12.0</th><th>Node 20.0.0-pre</th></tr>
<tr>
<td>without ending newline character</td>
<td>
<pre lang=""js"">
> const testFile = `function a(b) {\n  return b }\na(1)`
> fs.writeFileSync('foo.js', testFile)
> .load foo.js
function a(b) {
  return b }
  a(1)
1
</pre>
</td>
<td>
<pre lang=""js"">
> const testFile = `function a(b) {\n  return b }\na(1)`
> fs.writeFileSync('foo.js', testFile)
> .load foo.js
function a(b) {
  return b }
undefined
</pre>
</td>
</tr>
<tr><td>with ending newline character</td>
<td>
<pre lang=""js"">
> const testFile = `function a(b) {\n  return b }\na(1)\n`
> fs.writeFileSync('foo.js', testFile)
> .load foo.js
function a(b) {
  return b }
  a(1)

1
</pre>
</td>
<td>
<pre lang=""js"">
> const testFile = `function a(b) {\n  return b }\na(1)\n`
> fs.writeFileSync('foo.js', testFile)
> .load foo.js
  function a(b) {
  function a(b) {
  function a(b) {
  ...
</pre>
</td>
</tr>
</table>

Note that even without the ending newline character, the output between v20.0.0-pre and 18.12.0 is different.","Theo-Steiner",40017636,"2023-02-20 09:36:26","test seem relate newline character infinite loop occur loaded file end newline character end newline character output v20.0.0 pre 18.12.0 different
"
1352,239,"Bisected to https://github.com/nodejs/node/pull/45614

/cc @aduh95 ","targos",2352663,"2023-02-20 09:46:45","bisect node pull
"
1353,239,"I'm confused by the new line situation. For one, you can see that without the newline it's not even reading the last line, apparently. Actually, this is interesting:

```
> const fs = require('fs')
> fs.writeFileSync('foo.js', `function a(b) {\n  return b }`)
> .load foo.js
function a(b) {
... 
```

i.e., the repl is left in editor mode. That seems like a separate issue, however, so I'd be happy to open another issue if so.","harrisi",14868079,"2023-02-20 22:51:03","confus new line situation see newline read last line interesting repl left editor mode separate issu happy open anoth issu
"
1354,239,"Minimum reproduce code: ` \n}\n`

```console
$ node
> fs.writeFileSync('foo.js', ` \n}\n`)
> .load foo.js




```","cola119",22386678,"2023-02-20 23:22:58","node fs writefile foo js


"
1371,242,"MongoDB Compass has encountered an unexpected error
Error [ERR_INTERNAL_ASSERTION]: This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues
    at new NodeError (node:internal/errors:406:5)
    at assert (node:internal/assert:14:11)
    at internalConnectMultiple (node:net:1118:3)
    at Timeout.internalConnectMultipleTimeout (node:net:1687:3)
    at listOnTimeout (node:internal/timers:575:11)
    at process.processTimers (node:internal/timers:514:7)

my node version v20.13.1","naveenjpr",130902942,"2024-06-27 09:16:51","error inesperado mongodb compass causar erro node js uso incorreto interno node js abrir issue rastreamento pilha node versao 20.13.1
"
1372,242,"@naveenjpr lets continue here: https://github.com/nodejs/node/issues/50893#issuecomment-2198217271","ShogunPanda",201101,"2024-06-29 14:43:47","naveenjpr continuar
"
1373,243,"I can work on this","marco-ippolito",36735501,"2023-02-10 14:59:06","work
"
1355,239,"I found the Problem! 

## Problem
The `lineEnding` RegEx is declared on the module scope of `lib/internal/readline/interface.js`.
This means that its state for calling `RegExpPrototypeExec` can be overwritten if called alternately on different strings.
This is exactly what happens here for certain inputs, as the indentation preservation of the editor mode calls the same `write` method in `lib/internal/readline/interface.js` as the `load` method from within a while loop inside `load`. Thus RegEx state is overwritten in a very unfortunate way, and we end up with an infinite loop.

## Detailed Description
1. [the `load` command's action method is called with a file path ('foo.js').](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L1777)
2. [editorMode is turned on](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L1781) and [the file is read](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L1782).
3. [this.write (this === repl) is called with the file content (' \n}\n') while in editorMode](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L1783)
4. [Write is not a method on the `REPLServer` itself, so we go up the prototype chain to the Interface.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L1038)
5. [The Interface has the write method we were looking for](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L565) and it is called with `d = ' \n}\n', key = undefined`.
6. [Since the REPL is not paused and we are in terminal mode, we call `kTtyWrite`, passing along `s = d, key = key`.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L568)
7. Since `key` is `undefined` we [fall right through to the default case](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1323)
8. since `s = ' \n}\n'` we enter the top if clause and [call exec on the `lineEnding` RegEx on our string s.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1325)
9. [`lineEnding` (`/\r?\n|\r(?!\n)/g`) matches \r\n, \n, or \r followed by something other than \n.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L75)
10. [The returned value of calling exec on this RegEx with argument s is saved into a variable named `nextMatch`.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1325) With the minimal reproduction string of ' \n}\n' `nextMatch` is assigned `['\n', index: 1, input: ' \n{\n', groups: undefined]`
11. Since `nextMatch` is not null, we enter the next if clause.
12. [Here, we call `kInsertString` with a slice of the input string.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1327) We slice from 0 to the index of `nextMatch`, which is 1 in our case, hence `' '` is inserted.
13. [Now we move the start of our selection by saving the lastIndex property of the `lineEnding` RegEx that was set during our last invocation of `exec`.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1328)
14.  To move the end of our selection, [`exec` is called with s again, to get the nextMatch.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1329) The variable assignment in our case is: `s = ' \n}\n'`, `lastIndex = 2`, `nextMatch = ['\n', index: 3, input: ' \n{\n', groups: undefined]`.
15.  Since nextMatch is not null, the while loop's body is entered, and `this[kLine]` is called. [`[kLine]` calls `this[kOnLine]`](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L886), which triggers [a callback in `lib/repl.js` with argument `cmd = line`.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L853) In our case we inserted `' '` into the line, so `cmd = ' '`.
16. [Here a feature that is meant to preserve the indentation when writing code in the editorMode, calls a RegEx on the cmd to parse preceding whitespace and prefixes it to the next line.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L862) So it calls write with an argument of `' '`.
18.  [We enter `kTtyWrite` again from here](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L1038) with arguments `c = ' '`,  and `key = undefined`.
19. Since `key=undefined` we end up in the default case, but this time the `lineEnding` RegEx finds no match, so we jump [into the else clause.]
(https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1336)
** However, the problem is that by using the same `lineEnding` RegEx, it loses its state from the top while loop, where we already called `lineEnding.exec(s)` and the next time we would call it, it would return null, since we iterated through all matches ** 
20. After calling `[kInsertString]` and adding `' '` to the current line we return to the next line of the `on line callback` in` internal/repl.js`. 
21. [Here we set the line and cursor](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/repl.js#L867)and return to the while loop that called `kLine` in the first place.
22. We now call kInsertString with the next slice, from `lastIndex = 2` to `nextMatch.index = 3`, which means we add `}` to the current line. 
23. **[lastIndex is set to the newest lastIndex property of the lineEnding RegEx.](https://github.com/nodejs/node/blob/b85b5ba10cd782a31e5b1bb26e496b19309e2084/lib/internal/readline/interface.js#L1332) It was last called in (19), where it was set to `0` as no match was found.**
24. For the next iteration nextMatch *SHOULD BE NULL*, but because the `lineEnding` RegEx was reused in [No. 19] we get `nextMatch = ['\n', index: 1, input: ' \n{\n', groups: undefined]` **again**.
25. Restart from [No. 15] with `lastIndex: 0` and `nextMatch: 1` -> infinite loop","Theo-Steiner",40017636,"2023-02-21 04:00:41","problema lineEnding RegEx declarado escopo modulo arquivo state chamado RegExpPrototypeExec sobrescrever chamado alternadamente string diferente acontece certo entrada preservação indentação modo editor chama metodo write arquivo load metodo dentro loop while dentro load RegEx state sobrescrito forma infeliz resultar loop infinito load comando metodo ação chamado caminho arquivo editorMode ativado arquivo lido write chamado conteúdo arquivo editorMode Write metodo REPLServer subir cadeia protótipo Interface Interface metodo write procurar chamado d key undefined REPL pausado modo terminal chamado kTtyWrite pass s key undefined key undefined cair caso padrão s entrar cláusula superior chamar exec lineEnding RegEx string lineEnding r n r n seguido algo diferente n valor retornado chamar exec RegEx argumento salvar variável nextMatch string mínima reprodução nextMatch atribuído n index input groups undefined nextMatch nulo entrar cláusula seguinte chamar kInsertString fatia string entrada fatia index nextMatch inserir mover início seleção salvar propriedade lastIndex lineEnding RegEx definido última invocação exec mover fim seleção exec chamado novamente obter nextMatch atribuição variável caso lastIndex nextMatch n index input groups undefined nextMatch nulo corpo loop while chamado kLine kLine chama kOnLine disparar callback arquivo argumento cmd cmd inserir cmd entrar recurso preservar indentação escrever código editorMode chamar RegEx cmd analisar espaço precedente prefixar linha seguinte chamar write argumento entrar kTtyWrite novamente argumentos c key undefined key undefined acabar caso padrão vez lineEnding RegEx encontrar correspondência pular cláusula else problema usar lineEnding RegEx perder state loop while superior chamar lineEnding exec vez retornar nulo iterar todas correspondências chamar kInsertString adicionar linha atual retornar linha seguinte callback linha arquivo definir linha cursor retornar loop while chamar kLine primeiro lugar chamar kInsertString fatia próxima lastIndex nextMatch index adicionar linha atual lastIndex propriedade lastIndex lineEnding RegEx chamar definir correspondência encontrar restart lastIndex nextMatch loop infinito
"
1356,240,"Also note that specifying `family: 4` or `family: 6` both work without error.","targos",2352663,"2023-02-16 11:07:50","note specify family work error
"
1357,240,"With `{ autoSelectFamily: true }`, `SSL_get_servername(TLSEXT_NAMETYPE_host_name)` returns NULL.

That is, openssl thinks there's no SNI record and therefore this line returns `false` instead of `'google.com'`:
https://github.com/nodejs/node/blob/a2bbe5ff216bc28f8dac1c36a8750025a93c3827/lib/_tls_wrap.js#L947

I noticed `TLSSocket.prototype._init()` gets called when autoSelectFamily is set. There's also an extra call to `Socket.prototype._read()` that wasn't there before. This block seems responsible.
https://github.com/nodejs/node/blob/a2bbe5ff216bc28f8dac1c36a8750025a93c3827/lib/net.js#L1547-L1550

I suspect this line (possibly other init stuff as well) needs to be reapplied in `TLSSocket.prototype._init()`, otherwise node ""forgets"" relevant TLS context state:
https://github.com/nodejs/node/blob/a2bbe5ff216bc28f8dac1c36a8750025a93c3827/lib/_tls_wrap.js#L1687

An interesting question is if `{ autoSelectFamily: true, secureContext: context }` works and if not, what to do about it.","bnoordhuis",275871,"2023-02-17 09:45:10","autoselectfamily true ssl_get_servername tlsext_nametype_host_name return null openssl think sni record line return false google com tlssocket prototype init call autoselectfamily set extra call socket prototype read block seem respons suspect line init stuff reapply tlssocket prototype init node forget relevant tls context state interest question autoselectfamily true securecontext context work
"
1358,240,"cc @ShogunPanda ","mcollina",52195,"2023-02-18 09:24:36","ShogunPanda
"
1359,240,"Thanks! I'll take a look on Mon when I'll tackle all related problems forever.","ShogunPanda",201101,"2023-02-18 11:00:35","take look monday tackle relate problem
"
1360,240,"I found the issue. This will be fixed once #46587 is merged.","ShogunPanda",201101,"2023-02-21 15:28:44","issue fix merge
"
1361,241,"I'm closing this as a duplicate of https://github.com/nodejs/node/issues/46669 even though the reproduction in this issue is simpler. (cc @ShogunPanda)","tniessen",3109072,"2023-02-17 14:07:54","close duplicate reproduction simple
"
1362,242,"@addaleax you can probably tell if this is a node bug or something mongosh is doing?","bnoordhuis",275871,"2023-02-15 16:26:51","addaleax tell node bug mongosh
"
1363,242,"Fascinating, a mongosh issue here :)

We just enabled calling `net.setDefaultAutoSelectFamily?.(true)` in the latest release, so that’s what would be causing this to occur now. We don’t do anything out of the ordinary when creating network connections, so I would assume for now that this is a real Node.js bug. I’m not sure if https://github.com/nodejs/node/pull/46587 would affect this.

I couldn’t reproduce this out of the box though, I would imagine there’s more to it than generically “connect to a mongod server”.

---

@marcopdonoso A few things: You most likely installed mongosh through homebrew. If you get the compiled version through https://www.mongodb.com/try/download/shell, that should make this issue go away for you.

Then, can you share more information about what exactly you are doing? A [mongosh log file](https://www.mongodb.com/docs/mongodb-shell/logs/) might be a good start (be sure to look through it and redact sensitive information before sharing).","addaleax",899444,"2023-02-15 17:15:03","mongosh issue enable net setDefaultAutoSelectFamily true latest release cause occur ordinary create network connection assume node bug sure affect reproduce box imagine generically connect mongod server install mongosh homebrew get compile version make issue go away share information exactly mongosh log file good start sure look redact sensitive information
"
1364,242,"I'm encountering a similar issue:

```
node:internal/assert:14
    throw new ERR_INTERNAL_ASSERTION(message);
    ^

Error [ERR_INTERNAL_ASSERTION]: This is caused by either a bug in Node.js or incorrect usage of Node.js internals.
Please open an issue with this stack trace at https://github.com/nodejs/node/issues

    at new NodeError (node:internal/errors:399:5)
    at assert (node:internal/assert:14:11)
    at internalConnectMultiple (node:net:1070:3)
    at afterConnectMultiple (node:net:1532:5) {
  code: 'ERR_INTERNAL_ASSERTION'
}

Node.js v19.6.0
```

 This exception occurs when the mongosh endpoint isn't available through dns.

[dns_failure_redacted_log.txt](https://github.com/nodejs/node/files/10748268/dns_failure_redacted_log.txt)

When DNS is available (through vpn), I get failures with the string `MongoServerSelectionError:`

[dns_resolved_redacted_log.txt](https://github.com/nodejs/node/files/10748303/dns_resolved_redacted_log.txt)

I haven't tried using the compiled version of mongosh, but I was able to gain access to the cluster using mongodb compass.

","Bhutania",32190247,"2023-02-15 22:19:38","encounter similar issue error err internal assertion cause bug node js incorrect usage node js internal open issue stack trace node js v19 exception occur mongosh endpoint avail dns dns avail vpn get failure string mongo server selection error try use compile version mongosh able gain access cluster mongodb compass
"
1365,242,"Although the stack traces are different, https://github.com/nodejs/node/issues/46670 looks suspiciously similar.","Trott",718899,"2023-02-15 23:12:32","stack trace differ look suspiciously similar
"
1366,242,"Yeah, I think there’s a very high chance of these being duplicates, esp. considering that mongosh is also a REPL environment. #46670 has a nice isolated reproduction, though, maybe it’s nicer to keep that one open.","addaleax",899444,"2023-02-16 10:56:46","chance duplicate consider mongosh repl environment nice isolate reproduction nice keep open
"
1367,242,"(Funny, I checked for duplicate issues but this was posted just one minute before I submitted #46670.)","tniessen",3109072,"2023-02-16 12:25:07","check duplicate issue post minute submit
"
1368,242,"Refs: https://github.com/nodejs/node/pull/44731

There is also a simpler repro of this issue in https://github.com/nodejs/node/issues/46670.

cc @ShogunPanda","tniessen",3109072,"2023-02-17 14:05:51","repro issue simpler
"
1369,242,"Yes, I discovered this as well and I was already taking care of it in #46587.

I hope I'll able to land a fix next week!","ShogunPanda",201101,"2023-02-17 14:09:36","discover take care hope land fix week
"
1586,275,"CI: https://ci.nodejs.org/job/node-test-pull-request/44756/","nodejs-github-bot",18269663,"2022-06-20 10:43:50",NULL
1377,244,"PR welcome, although the regex used to validate the header is... wrgh.

writeEarlyHints() was added in #44180 and then its validation was updated #44874. Personally I don't see the value in being so rigid. @nodejs/http what was the thinking there?","bnoordhuis",275871,"2023-02-01 09:44:18","welcome regex validate header rigid value thinking
"
1378,244,"> https://github.com/orgs/nodejs/teams/http what was the thinking there?

This is just a bug and no one caught it.
As for the script validation, the contributor proposed it and it seemed ok to me.

Can you take a look @anonrig @uzlopak? You both discussed this problem in: https://github.com/nodejs/node/pull/44820/files#r983969846.","mcollina",52195,"2023-02-01 09:58:10","bug contributor propose seem ok look discuss problem
"
1379,244,"I really doesn't know why `Link` header is the only exception to own a validation.
Maybe it provide a better DX, but in-consistence on behavior really cause a lot of confusion to the user.","climba03003",23028015,"2023-02-02 06:00:18","know link header exception validation provide better dx inconsistence behavior cause confusion user
"
1380,244,"Can this also be fixed on Node 18?","nithin-murali-arch",23058969,"2023-06-05 09:13:52","fix node
"
1381,244,"@nithin-murali-arch Isn't this fixed in 18.16.0? #46466 has been backported there.","ShogunPanda",201101,"2023-06-05 13:28:30","fix isn't backport
"
1382,245,"Can you post a complete, ready-to-run test case? Maybe you've hit a bug, maybe you haven't, but it's impossible to tell right now.","bnoordhuis",275871,"2023-01-31 11:41:02","post complete ready run test case hit bug impossible tell
"
1383,245,"@bnoordhuis 
```javascript
// since it's ESM, save it as .mjs

import fs from 'node:fs'
import process from 'node:process'
import {Readable} from 'node:stream'

// we initialize a stream, but not start consuming it
const randomNodeStream = fs.createReadStream('/dev/urandom')
// after 10 seconds, it'll get converted to web stream
let randomWebStream

// we check memory usage every second
// since it's a stream, it shouldn't be higher than the chunk size
const reportMemoryUsage = () => {
	const {arrayBuffers} = process.memoryUsage()
	console.log(
		`Array buffers memory usage is ${Math.round(
			arrayBuffers / 1024 / 1024
		)} MiB`
	)
	if (arrayBuffers > 256 * 1024 * 1024) {
		// streaming should not lead to such a memory increase
		// therefore, if it happens => bail
		console.log('Over 256 MiB taken, exiting')
		process.exit(0)
	}
}
setInterval(reportMemoryUsage, 1000)

// after 10 seconds we use Readable.toWeb
// memory usage should stay pretty much the same since it's still a stream
setTimeout(() => {
	console.log('converting node stream to web stream')
	randomWebStream = Readable.toWeb(randomNodeStream)
}, 10000)

// after 15 seconds we start consuming the stream
// memory usage will grow, but the old chunks should be garbage-collected pretty quickly
setTimeout(async () => {
	console.log('reading the chunks')
	for await (const chunk of randomWebStream) {
		// do nothing, just let the stream flow
	}
}, 15000)
```

This produces the same behavior on macOS and Linux:

```
michal@dzieni ~ % node test.mjs
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
converting node stream to web stream
Array buffers memory usage is 0 MiB
Array buffers memory usage is 617 MiB
Over 256 MiB taken, exiting
```

Immediately after using `Readable.toWeb` the memory usage spikes. Since we use `/dev/urandom` (so the file that never ends), the usage will grow indefinitely.

You can compare it to a [third-party library `readable-stream-node-to-web`](https://www.npmjs.com/package/readable-stream-node-to-web), where it works properly:
```javascript
// since it's ESM, save it as .mjs

import fs from 'node:fs'
import process from 'node:process'
import nodeToWebStream from 'readable-stream-node-to-web'

// we initialize a stream, but not start consuming it
const randomNodeStream = fs.createReadStream('/dev/urandom')
// after 10 seconds, it'll get converted to web stream
let randomWebStream

// we check memory usage every second
// since it's a stream, it shouldn't be higher than the chunk size
const reportMemoryUsage = () => {
	const {arrayBuffers} = process.memoryUsage()
	console.log(
		`Array buffers memory usage is ${Math.round(
			arrayBuffers / 1024 / 1024
		)} MiB`
	)
	if (arrayBuffers > 256 * 1024 * 1024) {
		// streaming should not lead to such a memory increase
		// therefore, if it happens => bail
		console.log('Over 256 MiB taken, exiting')
		process.exit(0)
	}
}
setInterval(reportMemoryUsage, 1000)

// after 10 seconds we use nodeToWebStream
// memory usage should stay pretty much the same since it's still a stream
setTimeout(() => {
	console.log('converting node stream to web stream')
	randomWebStream = nodeToWebStream(randomNodeStream)
}, 10000)

// after 15 seconds we start consuming the stream
// memory usage will grow, but the old chunks should be garbage-collected pretty quickly
setTimeout(async () => {
	console.log('reading the chunks')
	for await (const chunk of randomWebStream) {
		// do nothing, just let the stream flow
	}
}, 15000)
```

In that case, the memory usage is fine:

```
michal@dzieni ~ % node src/test.mjs 
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
converting node stream to web stream
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
reading the chunks
Array buffers memory usage is 1 MiB
Array buffers memory usage is 6 MiB
Array buffers memory usage is 9 MiB
Array buffers memory usage is 15 MiB
Array buffers memory usage is 5 MiB
Array buffers memory usage is 9 MiB
Array buffers memory usage is 11 MiB
Array buffers memory usage is 4 MiB
Array buffers memory usage is 19 MiB
Array buffers memory usage is 16 MiB
Array buffers memory usage is 1 MiB
Array buffers memory usage is 30 MiB
Array buffers memory usage is 24 MiB
Array buffers memory usage is 6 MiB
Array buffers memory usage is 4 MiB
Array buffers memory usage is 2 MiB
Array buffers memory usage is 1 MiB
```","Dzieni",5893812,"2023-02-02 15:02:54","memory usage spike readable toweb node stream web stream memory management garbage collection stream chunk  javascript  node  mjs  dev urandom  library readable stream node web  performance
"
1384,245,"Thanks, I see what you mean. The stream starts reading before there's something consuming it.

@nodejs/whatwg-stream this is a legitimate bug. You can see it even more clearly when you switch from /dev/urandom to /dev/zero.

edit: bug also exists in v19.6.0.","bnoordhuis",275871,"2023-02-03 11:33:30","bug legitimate stream read consume switch dev zero exist v19
"
1385,245,"Hello, @Dzieni I think this issue is solved if you pass a strategy while converting the stream from node stream something like:

```js
randomWebStream = Readable.toWeb(randomNodeStream, {
    strategy: new CountQueuingStrategy({ highWaterMark: 100 }),
  });
```

Tried this on my local machine and memory doesn't seem to be overflowing
<img width=""629"" alt=""Screenshot 2023-02-04 at 12 55 53 AM"" src=""https://user-images.githubusercontent.com/20257253/216690151-9a32af6f-beab-46bd-8798-484d65b4b982.png"">

I think the behavior here is somewhat expected when the readable stream is created, the pull function as described here https://nodejs.org/api/webstreams.html#new-readablestreamunderlyingsource--strategy would be called continuously as soon as the `ReadableStream` is created and  given how adapters from webstreams are defined here https://github.com/nodejs/node/blob/23effb255efe3eb0dc935e3a430d80b41ea1e660/lib/internal/webstreams/adapters.js#L462 this would mean if there is no strategy defined `streamReadable.resume()` will try to consume the whole file causing memory overflow, but when we pass a strategy it ensures backpressure is applied

Maybe the docs here could be updated to include this scenario https://nodejs.org/api/stream.html#streamreadabletowebstreamreadable-options @bnoordhuis ","debadree25",20257253,"2023-02-03 19:28:05","pass strategy convert stream node stream readable web randomnodestream countqueuingstrategy highwatermark behavior expected readablestream pull function call continuously readablestream creat adapter webstreams define strategy streamreadable resume consume whole file cause memory overflow pass strategy ensure backpressure apply doc update scenario streamreadabletowebstreamreadable
"
1386,245,"I think this is a bug. The whole point of streams is to manage the flow of data.","mcollina",52195,"2023-02-03 20:24:17","bug point stream manage flow data
"
1387,245,"> I think this is a bug. The whole point of streams is to manage the flow of data.

So something like a default highWatermark while doing `toWeb()`?","debadree25",20257253,"2023-02-03 20:27:40","bug point stream manage flow data default highwatermark web
"
1388,245,"No I think there is an actual bug somewhere. Instead of resume, this should call read()","mcollina",52195,"2023-02-03 21:02:30","bug resume call read
"
1389,245,"@debadree25 
Sounds like a workaround that is good enough for me, thanks!","Dzieni",5893812,"2023-02-06 11:11:15","sound workaround good thanks
"
1390,245,"Hey guys and gals, could you please confirm my findings. So I've looked into this briefly, and I believe I have traced this to `/lib/internal/webstreams/readablestream.js`.

Now, I am not entirely sure if it's by design but neither `readableByteStreamControllerShouldCallPull` nor `readableStreamDefaultControllerShouldCallPull` seem to check for presence of a reader:
https://github.com/nodejs/node/blob/main/lib/internal/webstreams/readablestream.js#L2458-L2481
https://github.com/nodejs/node/blob/main/lib/internal/webstreams/readablestream.js#L2223-L2240

Refusing to pull when a stream has no reader seems to alleviate the issue. Something like this seems to do the trick:
https://github.com/nodejs/node/pull/46643/commits/1f0e2493f159d61f9974ea416a0efc34df6ad426 (https://github.com/nodejs/node/pull/46643)

Testing against @Dzieni's benchmark - slightly modified to convert to the web stream sooner, - here's before the change is applied:
```
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
converting node stream to web stream
Array buffers memory usage is 0 MiB
Array buffers memory usage is 109 MiB
Array buffers memory usage is 206 MiB
Array buffers memory usage is 336 MiB
Over 256 MiB taken, exiting
```

Here's after the change is applied:
```
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
converting node stream to web stream
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
Array buffers memory usage is 0 MiB
```

For completeness, I'm attaching @Dzieni's benchmark with the slight modification that I mentioned along with this message.

```javascript
// since it's ESM, save it as .mjs

import fs from 'node:fs'
import process from 'node:process'
import {Readable} from 'node:stream'

// we initialize a stream, but not start consuming it
const randomNodeStream = fs.createReadStream('/dev/urandom')
// in a few seconds, it'll get converted to web stream
let randomWebStream

// we check memory usage every second
// since it's a stream, it shouldn't be higher than the chunk size
const reportMemoryUsage = () => {
	const {arrayBuffers} = process.memoryUsage()
	console.log(
		`Array buffers memory usage is ${Math.round(
			arrayBuffers / 1024 / 1024
		)} MiB`
	)
	if (arrayBuffers > 256 * 1024 * 1024) {
		// streaming should not lead to such a memory increase
		// therefore, if it happens => bail
		console.log('Over 256 MiB taken, exiting')
		process.exit(0)
	}
}
setInterval(reportMemoryUsage, 1000)

// after 3 seconds we use Readable.toWeb
// memory usage should stay pretty much the same since it's still a stream
setTimeout(() => {
	console.log('converting node stream to web stream')
	randomWebStream = Readable.toWeb(randomNodeStream)
}, 3000)

// after 30 seconds we start consuming the stream
// memory usage will grow, but the old chunks should be garbage-collected pretty quickly
setTimeout(async () => {
	console.log('reading the chunks')
	for await (const chunk of randomWebStream) {
		// do nothing, just let the stream flow
	}
}, 30000)
```

[Edit, Feb 14]: updated the draft solution link to point to a specific commit.
","lilsweetcaligula",15699226,"2023-02-14 04:30:46","confirm finding look briefly believe trace lib internal webstreams readablestream js entirely sure design readablestreamcontrollercallpull readablestreamdefaultcontrollercallpull seem check presence reader refuse pull stream reader seem alleviate issue something seem trick attach benchmark slight modification mention message array buffer memory usage mib mib convert node stream web stream mib mib mib mib mib mib mib mib convert node stream web stream mib mib mib mib mib mib mib completeness attach benchmark slight modification mention message save mjs import fs node fs import process node process import readablestream node stream initialize stream start consume randomnodestream createstream dev urandom second convert web stream check memory usage second stream higher chunk size reportmemoryusage array buffer memory usage mib streaming lead memory increase happen bail setinterval reportmemoryusage second second use readablestreamtoweb memory usage stay pretty much same stream settimeout console log convert node stream web stream second start consume stream memory usage grow old chunk garbage collect pretty quickly settimeout console log read chunk await chunk randomwebstream nothing let stream flow update draft solution link point specific commit
"
1391,245,"@jasnell @KhafraDev could you take a look?","mcollina",52195,"2023-02-17 10:56:47","look
"
1392,245,"It looks like node implements [`ReadableByteStreamControllerShouldCallPull`](https://streams.spec.whatwg.org/#readable-byte-stream-controller-should-call-pull) and [`ReadableStreamDefaultControllerShouldCallPull`](https://streams.spec.whatwg.org/#readable-stream-default-controller-should-call-pull) correctly, which makes me think it's not an issue with them. I don't know enough about the webstream spec to give a definitive answer though.","KhafraDev",42794878,"2023-02-17 15:24:14","node implement readablytestreamcontrollercallpull readablestreamdefaultcontrollercallpull correctly think issue know enough webstream spec give definitive answer
"
1587,275,"@benjamingr Thanks for your kind feedback. :-)","daeyeon",6630703,"2022-06-20 14:53:33",NULL
1393,245,"@debadree25 I've been looking into this on and off and I may need a clarification. Could you please clarify it for me - whether in the code snippet below, - the `highWaterMark` value of the `randomWebStream`'s default controller should default to 65536 bytes _or_ 65536 chunks of size 65536 bytes each?

```javascript
const randomNodeStream = fs.createReadStream('/dev/urandom')
const randomWebStream = Readable.toWeb(randomNodeStream)
```
","lilsweetcaligula",15699226,"2023-02-19 00:40:36","clarificar código trecho highWaterMark valor randomWebStream controlador padrão 65536 byte 65536 pedaço tamanho 65536 byte
"
1394,245,"From what I understand the high watermark would be 65536 ""chunks"" since here 
https://github.com/nodejs/node/blob/132c383b1872d0114e00722fe0610745f7f09cab/lib/internal/webstreams/adapters.js#L424
we dont set any size function and by default the size function just returns 1 Ref: https://github.com/nodejs/node/blob/132c383b1872d0114e00722fe0610745f7f09cab/lib/internal/webstreams/util.js#L73
so it would be 65536 ""chunks"" each chunk regarded as size 1 

The comment in lines https://github.com/nodejs/node/blob/132c383b1872d0114e00722fe0610745f7f09cab/lib/internal/webstreams/adapters.js#L420-L423
mention `ByteLengthQueuingStrategy` as unecessary but maybe it indeed is?","debadree25",20257253,"2023-02-19 05:34:00","watermark chunk set size function chunk regard size comment line mention bytelengthqueuingstrategy unecessary
"
1395,245,"@debadree25 Thank you for your reply. As I was inspecting the code yesterday, I just found it somewhat odd - hence I had to clarify it with someone.

Another odd thing I found, - if you have code like this:
```javascript
const randomNodeStream = fs.createReadStream('/dev/urandom', {
	highWaterMark: 5556
})

const randomWebStream = Readable.toWeb(randomNodeStream)
```

Upon inspection with a debugger, I found that `randomWebStream`'s controller's queue (!) was eventually filled with 5556 chunks (i.e. `queueTotalSize` === 5556) with seemingly each (!) chunk having a size of 5556 bytes. Changing 5556 to 5557 in the code snippet would give a similar result - 5557 chunks with each chunk having a size 5557 bytes.

That means if a user does not explicitly pass an hwm to `fs.createReadStream` - the resulting stream will have an hwm of 65536, which upon conversion to a web stream results in 65536 chunks 65536 bytes each, which is a total of 4 GB.

Is this a bug or am I misunderstanding it?
","lilsweetcaligula",15699226,"2023-02-19 16:47:27","inspeccionar código ontem encontrar estranho clarificar alguém outro encontrar código semelhante ler arquivo urandom alto marca água chunk tamanho mudar código resultado chunk tamanho semelhante usuário passar alto marca água resultado fluxo alto marca água conversão fluxo web resultar chunk tamanho total gb erro entender
"
1396,245,"This isn't a ""good first issue"", I don't think ""streams"" and ""good first issue"" really mix except for tests/docs","benjamingr",1315533,"2023-02-19 18:11:30","good first issue stream good first issue mix test doc
"
1397,245,"@lilsweetcaligula tbf even I am confused here would need deeper investigation 😅😅","debadree25",20257253,"2023-02-19 18:44:15","confuse need deep investigation
"
1398,245,"@benjamingr I think this might be as simple as it gets for streams.

The problem is that in https://github.com/nodejs/node/blob/0093fd3ca85b35b8bb2f4ff9d97082a71b23a124/lib/internal/webstreams/adapters.js#L462 we call `resume()` and in https://github.com/nodejs/node/blob/0093fd3ca85b35b8bb2f4ff9d97082a71b23a124/lib/internal/webstreams/adapters.js#L436-L437 we call `pause()` only on certain conditions (which I think are never met or similar). This is somewhat dangerous and can cause exactly what we are seeing here.

Note that this should be calling `.read()` and listen to `'readable'` instead.","mcollina",52195,"2023-02-21 22:34:07","think simple stream problem call resume call pause condition dangerous cause note call read listen readable
"
1399,245,"> From what I understand the high watermark would be 65536 ""chunks"" since here
> 
> https://github.com/nodejs/node/blob/132c383b1872d0114e00722fe0610745f7f09cab/lib/internal/webstreams/adapters.js#L424
> 
> 
> we dont set any size function and by default the size function just returns 1 Ref:
> https://github.com/nodejs/node/blob/132c383b1872d0114e00722fe0610745f7f09cab/lib/internal/webstreams/util.js#L73
> 
> 
> so it would be 65536 ""chunks"" each chunk regarded as size 1
> The comment in lines
> 
> https://github.com/nodejs/node/blob/132c383b1872d0114e00722fe0610745f7f09cab/lib/internal/webstreams/adapters.js#L420-L423
> 
> 
> mention `ByteLengthQueuingStrategy` as unecessary but maybe it indeed is?

Hey @mcollina 

I think @debadree25 is right in his comment that we should use the `ByteLengthQueuingStrategy`

nevertheless, I did try using the `readable` event and it worked, I'll create a PR shortly","rluvaton",16746759,"2023-02-26 01:39:56","entender alto marca agua chunk definir tamanho função padrão função retornar chunk considerar tamanho comentario linha mencionar byteLengthQueuingStrategy necessario usar byteLengthQueuingStrategy tentar usar evento funcionar criar PR breve
"
1400,245,"Any updates on this?","karimfromjordan",113807903,"2023-09-13 08:30:18","update
"
1401,245,"In meanwhile I found another workaround - `ReadableStream.from(randomNodeStream)` seems to do the job just right, without having to set the queueing strategy explicitly.","Dzieni",5893812,"2024-05-07 06:09:13","workaround readablestream randomnodestream job right queueing strategy
"
1402,245,"I had the same issue with the memory leak, and after installing Node v22.2 it went away, but not entirely. I still get massive slowdown/memory leak when I use the ReadableStream in fetch (which many probably try with this toWeb function):

```javascript
await fetch(url, {
  method: 'POST',
  body: Readable.toWeb(data),
  ...({ duplex: ""half"" })
});
```

I had to switch to `got` to remove the memory leak, unfortunately","marcj",450980,"2024-06-07 00:59:56","issue memory leak install node v22.2 go away still get massive slowdown memory leak use readablestream fetch many probably try toweb function switch got remove memory leak
"
1412,247,"> @mcollina the problem here is all the global stream init logic lives in 'stream', so at the moment you must first import 'stream' before anything else under 'stream/...'

do other bugs are happening because of it?","ErickWendel",8060102,"2023-01-09 16:46:37","problem global stream init logic live stream moment must import stream anything stream bug happen
"
1413,247,"Analyzing here it works without going on 'node:stream/promises': 

```mjs
import { promises } from 'node:stream'
const { pipeline } = promises
async function* myCustomReadable() {
  yield Buffer.from(`tick: ${new Date().toISOString()}`)
}

async function* myCustomWritable(stream) {
  for await (const chunk of stream) {
    console.log(chunk.toString())
  }
}

await pipeline(
  myCustomReadable,
  myCustomWritable,
)

```

But looking at the code, here is the problem:

if I change from `require('internal/streams/passthrough')` to `require('stream').Passthrough` it works. it seems to be something on the loader side

Gonna take a look at it tonight","ErickWendel",8060102,"2023-01-09 17:07:21","work without go node stream promise problem change require internal stream passthrough require stream passthrough seem something loader side look tonight
"
1421,248,"Yes, you're right, I'm sorry. Nothing happened to kindness, I just simply forgot it. :) thanks for your good work!","mudlee",1439334,"2023-01-12 15:16:08","right sorry happen kindness forget thank good work
"
1523,264,"CC @nodejs/streams 
it seems like changing `await writer.write()` --> `writer.write()` will prevent this from crashing.","MoLow",8221854,"2022-08-07 10:51:03",NULL
1403,245,"I want to note that I'm still experiencing a serious memory leak here as of node `22.9.0`. My use case is the same as mentioned by @marcj – I'm basically running a proxy, passing the request in the fetch body via `Readable.toWeb(request)`. When uploading a several GB file, memory utilization quickly jumps to ~4GB before crashing.

The `ReadableStream.from(request)` approach mentioned above also experiences the same issue. 

I refactored to use the `got` library streaming interface, and the memory overhead completely goes away. Of course, using native fetch with web streams would be preferable.

```js
async function requestHandler(request, response){
        const upstreamUrl = decodeURIComponent(request.query.url);
	const upstreamResponse = await fetch(upstreamUrl, {
		method: request.method,
		duplex: 'half',
		// Both approaches cause memory leaks
		body: Readable.toWeb(request),
		// body: ReadableStream.from(request),
	});

	await upstreamResponse.body.pipeTo(Writable.toWeb(response));
}
```
","imathews",5659375,"2024-09-25 05:06:25","want note still experience serious memory leak node use case mention basically run proxy pass request fetch body via readable web upload several gb file memory utilization quickly jump gb crash readablestream approach mention also experience issue refactor use got library streaming interface memory overhead completely go away course use native fetch web stream preferable async function requesthandler request response upstreamurl decodeuricomponent request query url upstreamresponse await fetch upstreamurl method request method duplex half body readable web body readablestream await upstreamresponse body pipeto writable web
"
1404,246,"Looks to have been introduced in 436f4de38f51 from 2018. The easy fix is to replace `stoull(value)` with `strtoull(value.c_str(), nullptr, 10)`. Want to send a pull request?

Open question: how to handle invalid inputs? The `kInteger` case uses `atoll()` and simply ignores errors. `atoll()` is basically `strtoll()` with base=10.","bnoordhuis",275871,"2023-01-18 20:24:54","introduce easy fix replace stoull strtoull c str want send pull request open question handle invalid input kinteger case use atoll ignore error atoll basically strtoll base
"
1405,246,"Forgot to mention, I can easily reproduce like this:
```
$ node --cpu-prof-interval boom -p 42
libc++abi.dylib: terminating with uncaught exception of type std::invalid_argument: stoull: no conversion
Abort trap: 6
```
So yes, confirmed bug.","bnoordhuis",275871,"2023-01-18 20:26:09","reproduzir facilmente confirmar erro
"
1406,246,"#46290","bnoordhuis",275871,"2023-01-20 10:36:49","46290 Retorne
"
1407,246,"> #46290

Thanks for the quick solution to this problem!","sigdevel",60114847,"2023-01-20 14:53:03","solution problem
"
1408,247,"Adding `import 'node:stream'` at the top fixes it :/ ","ronag",3065230,"2023-01-09 14:38:13","add import node stream top fix
"
1409,247,"@mcollina the problem here is all the global stream init logic lives in 'stream', so at the moment you must first import 'stream' before anything else under 'stream/...'","ronag",3065230,"2023-01-09 14:39:57","problem global stream init logic live moment import stream"
1414,248,"We experience the same. We use similar file encryption/decryption, and what we observed is that with node 16 it just works as it is, but after upgrading to node 18, it **still does work**, but we do get an error at decryption, which does not affect the decrypted result. See below.

The error I get:

```
    Error: Unsupported state or unable to authenticate data
        at Decipheriv._flush (node:internal/crypto/cipher:160:29)
        at Decipheriv.final [as _final] (node:internal/streams/transform:132:10)
        at callFinal (node:internal/streams/writable:698:12)
        at prefinish (node:internal/streams/writable:710:7)
        at finishMaybe (node:internal/streams/writable:720:5)
        at Decipheriv.Writable.end (node:internal/streams/writable:634:5)
        at Readable.onend (node:internal/streams/readable:705:10)
        at Object.onceWrapper (node:events:627:28)
        at Readable.emit (node:events:525:35)
        at endReadableNT (node:internal/streams/readable:1359:12)
        at processTicksAndRejections (node:internal/process/task_queues:82:21)
```
## Code

**Class**

```typescript
const iv = '123456789012'; // for testing

export class FileEncrypter {
  constructor(
    private readonly nonceLength: number,
    private readonly algorithm: CipherCCMTypes,
    private readonly encryptionKey: string,
  ) {}

  encrypt(file: Buffer): Promise<Buffer> {
    return new Promise<Buffer>((res, rej) => {
      const cipher = createCipheriv(this.algorithm, this.encryptionKey, iv, { authTagLength: 16 });
      const input = Readable.from(file);
      const output = new PassThrough();
      const outputData: Buffer[] = [];

      output.write(iv);
      output.on('readable', () => {
        const data = output.read();
        if (data) {
          outputData.push(data);
        }
      });
      output.on('end', () => {
        const encrypted = Buffer.concat(outputData);
        res(encrypted);
      });

      pipeline(input, cipher, output, (err) => {
        if (err) {
          rej(err);
        }
      });
    });
  }

  decrypt(file: StreamableFile): Promise<Buffer> {
    return new Promise<Buffer>((res, rej) => {
      const input = file.getStream();
      const output = new PassThrough();

      input.once('readable', () => {
        const iv = input.read(12);
        const cipher = createDecipheriv(this.algorithm, this.encryptionKey, iv, { authTagLength: 16 });

        output.once('readable', () => {
          const encrypted = output.read();
          res(encrypted);
        });

        pipeline(input, cipher, output, (err) => {
          if (err) {
            rej(err);
          }
        });
      });
    });
  }
}
```

**Test**

```typescript
const testImage = readFileSync(`${E2E_TESTS_ASSETS_DIR}/simonstalenhag.jpg`);
const encrypter = new FileEncrypter(12, 'chacha20-poly1305', ENCRYPTION_KEY);

const encryptedFile = await encrypter.encrypt(testImage);
const decryptedFile = await encrypter.decrypt(new StreamableFile(encryptedFile));

console.log('decrypted');
console.log(decryptedFile);
console.log('original');
console.log(testImage);
expect(Buffer.compare(decryptedFile, testImage)).toStrictEqual(0);
```

AND here `decryptedFile` and `testImage` are the same, despite I get the error above.","mudlee",1439334,"2022-12-16 08:01:50","experiencia similar usar similar arquivo encriptação decriptação observar node 16 funcionar atualizar node 18 funcionar obter erro decriptação afetar resultado descripto ver erro obter unsupported state unable authenticate data node internal crypto cipher decipheriv flush decipheriv final stream transform callfinal prefinish finishmaybe decipheriv writable end readable onend object oncewrapper readable emit endreadablent processticksandrejections code class const iv testing export class fileencrypter constructor readonly noncelength readonly algorithm readonly encryptionkey encrypt file promise buffer const cipher createCipheriv algorithm encryptionkey iv authtaglength input readable output passtrough outputdata output write iv output readable data data outputdata output end encrypted buffer concat outputdata res encrypted pipeline input cipher output err err rej encrypt decrypt file promise buffer const input file getstream input once readable iv input read cipher createDecipheriv algorithm encryptionkey iv authtaglength output once readable encrypted output read res encrypted pipeline input cipher output err err rej decrypt test const testimage readfilesync e2etestsassetsdir simonstalenhag jpg encrypter new fileencrypter cipher chacha poly encryptionkey encryptedfile await encrypter encrypt testimage decryptedfile await encrypter decrypt new streamablefile encryptedfile console log decrypted console log decryptedfile console log original console log testimage expect buffer compare decryptedfile testimage toStrictEqual decryptedfile testimage mesmo obter erro
"
1415,248,"cc @tniessen @nodejs/crypto ","panva",241506,"2022-12-16 12:02:16","tniessen nodejs crypto
"
1416,248,"any update on this guys? @tniessen @panva? thanks!","mudlee",1439334,"2023-01-12 10:39:10","update guy thanks
"
1417,248,"The ""unable to authenticate data"" error is expected; its absence in v16 isn't. I speculate openssl 1.x didn't enforce it but openssl 3.x does.

(There is _some_ special handling for chacha20-poly1305 inside node itself but v16.19.0 and v18.12.1 are identical in that respect so that can't explain it.)

The best suggestion I have is to special-case it in `CipherBase::Final()` in src/crypto/crypto_cipher.cc. Someone want to send a pull request?","bnoordhuis",275871,"2023-01-12 11:25:02","unable authenticate data error expect absence v16 speculate openssl enforce openssl special handling chacha20 poly1305 node v16 19 v18 12 identical respect explain suggestion special case cipherbase final src crypto crypto cipher someone want send pull request
"
1418,248,"> Someone want to send a pull request?

/me raises hand

#46185","bnoordhuis",275871,"2023-01-12 14:11:50","someone want send pull request
"
1422,249,"@tniessen and I tried to find a way of ensuring EC keys use uncompressed point format upon export but short of some very brute and inefficient JS hacks using the Web Crypto API itself we didn't find a way.","panva",241506,"2022-12-14 14:35:19","tried find way ensure ec key use uncompress point format export short brute inefficient js hack use web crypto api find way
"
1423,249,"@jasnell do you have any ideas on how to resolve this issue in either the `spki` import invocation or the `spki` export invocation?","panva",241506,"2022-12-14 14:36:00","jasnell idea resolve issue spki import invocation spki export invocation
"
1424,249,"cc @nodejs/crypto ","panva",241506,"2022-12-14 14:57:04","nodejs crypto
"
1425,249,"> @tniessen and I tried to find a way of ensuring EC keys use uncompressed point format upon export but short of some very brute and inefficient JS hacks using the Web Crypto API itself we didn't find a way.

To clarify, it's certainly possible in C++ but it requires some refactoring because the internal code passes `KeyObjectData` objects around, which we cannot modify, so we either need to create a temporary copy or pass around lower-level OpenSSL types.","tniessen",3109072,"2022-12-14 16:16:48","tried find way ensure ec key use uncompress point format export short brute inefficient js hack use web crypto api find way clarify certainly possible c require refactoring internal code pass keyobjectdata object around modify need create temporary copy pass around lower level openssl type
"
1426,249,"I think that if we can identify the KeyObjectData is using compressed point then creating a temporary copy for the spki export in this edge-case would be okay?","panva",241506,"2022-12-14 16:19:43","think identify KeyObjectData use compress point create temporary copy spki export edge case okay
"
1427,249,"This is about `crypto.subtle.exportKey('spki', key)` not writing uncompressed ECDH and ECDSA keys, correct?

Seems like that should be a trivial fix in `PKEY_SPKI_Export()` from `src/crypto/crypto_keys.cc`; the logic to go from compressed to uncompressed already exists in `ECDH::ConvertKey()`, it's basically a wrapper around openssl's `EC_POINT_point2oct()`. Is there some subtlety that I'm missing?","bnoordhuis",275871,"2022-12-29 10:09:08","export key spki key write uncompress ecdh ecdsa key trivial fix logic compress uncompress wrapper openssl subtlety miss
"
1428,249,"It's just that the existing functionality works with ec point and the key representation we have is ec key. 

If you see an obvious way to do this, great! ","panva",241506,"2022-12-29 10:30:47","exist functionality work ec point key representation ec key way
"
1429,249,"#46021. It's admittedly not very elegant but oh well.","bnoordhuis",275871,"2022-12-30 11:42:26","admittedly elegant
"
1430,249,"> Is there some subtlety that I'm missing?
> It's admittedly not very elegant but oh well.

Only that one :) Thanks for working on this.","tniessen",3109072,"2022-12-30 13:06:43","subtlety miss admittedly elegant thanks work
"
1431,250,"cc @nodejs/crypto ","panva",241506,"2022-12-06 16:52:44","nodejs crypto
"
1432,250,"```
#
# Fatal error in , line 0
# Check failed: byte_length <= i::JSArrayBuffer::kMaxByteLength.
#
#
#
#FailureMessage Object: 0x16d365b68
 1: 0x102baf630 node::NodePlatform::GetStackTracePrinter()::$_3::__invoke()
 2: 0x103ac31dc V8_Fatal(char const*, ...)
 3: 0x102cc068c v8::ArrayBuffer::NewBackingStore(v8::Isolate*, unsigned long)
 4: 0x102c3ff8c node::crypto::CipherBase::Update(char const*, unsigned long, std::__1::unique_ptr<v8::BackingStore, std::__1::default_delete<v8::BackingStore> >*)
 5: 0x102c406d0 node::crypto::CipherBase::Update(v8::FunctionCallbackInfo<v8::Value> const&)::$_0::__invoke(node::crypto::CipherBase*, v8::FunctionCallbackInfo<v8::Value> const&, char const*, unsigned long)
 6: 0x102c3864c void node::crypto::Decode<node::crypto::Verify>(v8::FunctionCallbackInfo<v8::Value> const&, void (*)(node::crypto::Verify*, v8::FunctionCallbackInfo<v8::Value> const&, char const*, unsigned long))
 7: 0x102d0920c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo)
 8: 0x102d08d08 v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments)
 9: 0x102d08534 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*)
10: 0x1034f918c Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit
11: 0x103484198 Builtins_InterpreterEntryTrampoline
12: 0x103484198 Builtins_InterpreterEntryTrampoline
13: 0x103484198 Builtins_InterpreterEntryTrampoline
14: 0x103484198 Builtins_InterpreterEntryTrampoline
15: 0x103484198 Builtins_InterpreterEntryTrampoline
16: 0x103484198 Builtins_InterpreterEntryTrampoline
17: 0x103484198 Builtins_InterpreterEntryTrampoline
18: 0x103484198 Builtins_InterpreterEntryTrampoline
19: 0x1034824d0 Builtins_JSEntryTrampoline
20: 0x103482164 Builtins_JSEntry
21: 0x102dc4eac v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&)
22: 0x102dc43e0 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*)
23: 0x102cb4914 v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*)
24: 0x102b1d204 node::ExecuteBootstrapper(node::Environment*, char const*, std::__1::vector<v8::Local<v8::Value>, std::__1::allocator<v8::Local<v8::Value> > >*)
25: 0x102b1e074 node::StartExecution(node::Environment*, std::__1::function<v8::MaybeLocal<v8::Value> (node::StartExecutionCallbackInfo const&)>)
26: 0x102aa0420 node::LoadEnvironment(node::Environment*, std::__1::function<v8::MaybeLocal<v8::Value> (node::StartExecutionCallbackInfo const&)>)
27: 0x102b8d0f8 node::NodeMainInstance::Run()
28: 0x102b20ec8 node::LoadSnapshotDataAndRun(node::SnapshotData const**, node::InitializationResult const*)
29: 0x102b21190 node::Start(int, char**)
30: 0x18e6efe50 start [/usr/lib/dyld]
[1]    17989 trace trap  node some.cjs
```","panva",241506,"2022-12-06 18:12:01","error check byte length maxbytelength failuremessage object node getstacktraceprinter v8 fatal arraybuffer newbackingstore node crypto cipherbase update node crypto cipherbase update node crypto decode node internal functioncallbackarguments call node internal handleapicallhelper node internal builtin handleapicall builtins centry return dont savefpregs argv onstack builtinex builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins interpreterentrytrampoline builtins jsentrytrampoline builtins jsentry node internal invoke node internal execution call v8 function call node executebootstrapper node startexecution node loadenvironment node nodemaininstance run node loadsnapshotdataandrun node start start trace trap node
"
1433,250,"I'll work on it. If need help can I bother you @panva ?","marco-ippolito",36735501,"2022-12-07 09:59:45","work need help bother
"
1434,250,"It's a signed integer overflow, caused by openssl using ints for sizes and node mixing `int` and `size_t` (and not being diligent enough about overflow checking.)

This particular issue isn't that hard to fix but it's probably just one of many similar bugs lurking in src/crypto.","bnoordhuis",275871,"2022-12-07 10:02:31","signed integer overflow cause openssl use int size node mix int size_t diligent overflow check issue hard fix probably one similar bug lurk src crypto
"
1435,250,"Here is a quick fix:
```diff
diff --git a/src/crypto/crypto_cipher.cc b/src/crypto/crypto_cipher.cc
index b907e9e9cdc..2259e28bec8 100644
--- a/src/crypto/crypto_cipher.cc
+++ b/src/crypto/crypto_cipher.cc
@@ -803,7 +803,11 @@ CipherBase::UpdateResult CipherBase::Update(
   if (kind_ == kDecipher && IsAuthenticatedMode())
     CHECK(MaybePassAuthTagToOpenSSL());
 
-  int buf_len = len + EVP_CIPHER_CTX_block_size(ctx_.get());
+  const int block_size = EVP_CIPHER_CTX_block_size(ctx_.get());
+  CHECK_GT(block_size, 0);
+  if (len + block_size > INT_MAX) return kErrorState;
+
+  int buf_len = len + block_size;
   // For key wrapping algorithms, get output size by calling
   // EVP_CipherUpdate() with null output.
   if (kind_ == kCipher && mode == EVP_CIPH_WRAP_MODE &&
```
Note: `len + block_size` is not UB because `block_size` gets converted to `size_t` since `len` is a `size_t`.","bnoordhuis",275871,"2022-12-07 10:07:49","fix len block size convert size_t
"
1436,250,"@marco-ippolito absolutely, go for it.","panva",241506,"2022-12-07 10:33:15","absolutely
go
"
1437,251,"Just tested and I can reproduce this on linux too.
Node version: 18.12.1
uname -a: Linux <hostname> 5.19.12-200.fc36.x86_64 #1 SMP PREEMPT_DYNAMIC Wed Sep 28 17:11:05 UTC 2022 x86_64 GNU/Linux","tkarls",5672845,"2022-11-16 17:41:51","test reproduce linux node version
"
1438,251,"Probably the same solution as https://github.com/nodejs/node/pull/45377.","mscdex",54666,"2022-11-16 17:47:23","solution
"
1439,251,"> Probably the same solution as #45377.

Ah, thanks, that looks like exactly the same issue but for the verify() function instead.

That PR won't fix this function though. And this probably affects even more functions (like all that do not throw on error unkess they have been marked with that clear on return)

This is pretty serious flaw in the crypto lib I think. Is there any known workaround? Is it possible to clear the openssl error queue manually from node? I cannot find anything like that in the docs.","tkarls",5672845,"2022-11-16 21:08:47","solution issue verify function fix affect function throw error mark return flaw crypto lib workaround clear openssl error queue node doc
"
1442,252,"I'm not able to reproduce on macOS:

```console
$ node
Welcome to Node.js v19.0.1.
Type "".help"" for more information.
>  m=()=>import(`data:text/javascript,`)
[Function: m]
> await m()
[Module: null prototype] {  }
> .exit
```","aduh95",14309773,"2022-11-13 18:40:41","able reproduce macOS node welcome nodejs type information function await module exit
"
1443,252,"Oh wait, I'm actially able to reproduce when I remove the space at the start of the line that assigns `m`:

```console
$ node
Welcome to Node.js v19.0.1.
Type "".help"" for more information.
> m=()=>import(`data:text/javascript,`)
[Function: m]
> await m()
[1]    11470 segmentation fault  node
```

Also, FWIW it reproduces without the `await`:

```console
$ node --no-experimental-repl-await
Welcome to Node.js v19.0.1.
Type "".help"" for more information.
> m=()=>import(`data:text/javascript,`)
[Function: m]
> m()
[1]    29893 segmentation fault  node --no-experimental-repl-await
```","aduh95",14309773,"2022-11-13 18:42:02","reproduce remove space start line assign function await reproduce await experimental repl await segmentation fault node
"
1444,252,"<details>

<summary>gdb doesn't show much info (debug build)</summary>

```
> m=()=>import(`data:text/javascript,`)
[New Thread 0x7fffe5ffb700 (LWP 2723058)]
[Thread 0x7fffe5ffb700 (LWP 2723058) exited]
[Function: m]
> await m()
[New Thread 0x7fffe5ffb700 (LWP 2724111)]

Thread 1 ""node"" received signal SIGSEGV, Segmentation fault.
node::loader::ImportModuleDynamically (context=..., host_defined_options=..., resource_name=..., specifier=...,
    import_assertions=...) at ../../src/module_wrap.cc:594
594         contextify::ContextifyScript* wrap = env->id_to_script_map.find(id)->second;
Missing separate debuginfos, use: yum debuginfo-install glibc-2.28-189.5.el8_6.x86_64 libgcc-8.5.0-10.1.el8_6.x86_64 libstdc++-8.5.0-10.1.el8_6.x86_64
(gdb) bt
#0  node::loader::ImportModuleDynamically (context=..., host_defined_options=..., resource_name=..., specifier=..., import_assertions=...) at ../../src/module_wrap.cc:594
#1  0x00000000017f3637 in v8::internal::Isolate::RunHostImportModuleDynamicallyCallback (this=this@entry=0x6a4abd0, maybe_referrer=..., specifier=..., specifier@entry=...,
    maybe_import_assertions_argument=..., maybe_import_assertions_argument@entry=...) at ../../deps/v8/include/v8-local-handle.h:180
#2  0x0000000001ea894d in v8::internal::__RT_impl_Runtime_DynamicImportCall (isolate=0x6a4abd0, args=...) at ../../deps/v8/src/handles/maybe-handles.h:38
#3  v8::internal::Runtime_DynamicImportCall (args_length=<optimized out>, args_object=<optimized out>, isolate=0x6a4abd0) at ../../deps/v8/src/runtime/runtime-module.cc:24
#4  0x0000000002437034 in Builtins_CEntry_Return1_DontSaveFPRegs_ArgvInRegister_NoBuiltinExit () at ../../deps/v8/src/builtins/torque-internal.tq:101
#5  0x000000000250ef51 in Builtins_CallRuntimeHandler () at ../../deps/v8/src/builtins/torque-internal.tq:101
#6  0x00000000023a52dc in Builtins_InterpreterEntryTrampoline () at ../../deps/v8/src/builtins/torque-internal.tq:236
#7  0x000009fe435c4699 in ?? ()
#8  0x000007a74c9c1e49 in ?? ()
#9  0x0000003b00000000 in ?? ()
#10 0x000009fe435f2f69 in ?? ()
#11 0x0000000000000001 in ?? ()
#12 0x000007a74c9c1e49 in ?? ()
#13 0x00001d250a2c1141 in ?? ()
#14 0x00007fffffff80d8 in ?? ()
#15 0x00000000023a52dc in Builtins_InterpreterEntryTrampoline () at ../../deps/v8/src/builtins/torque-internal.tq:236
#16 0x00001d250a2c1121 in ?? ()
#17 0x00002d70b8d015a9 in ?? ()
#18 0x000007a74c9c1e49 in ?? ()
#19 0x000015588bd5e039 in ?? ()
#20 0x00001d250a2c1141 in ?? ()
#21 0x000015588bd5dfe1 in ?? ()
#22 0x0000005000000000 in ?? ()
#23 0x000009fe435f2d31 in ?? ()
#24 0x0000000000000001 in ?? ()
#25 0x000015588bd5dce9 in ?? ()
#26 0x00001d250a2c1141 in ?? ()
#27 0x00007fffffff8128 in ?? ()
#28 0x00000000023a52dc in Builtins_InterpreterEntryTrampoline () at ../../deps/v8/src/builtins/torque-internal.tq:236
#29 0x00001d250a2c1121 in ?? ()
#30 0x000015588bd5dce9 in ?? ()
#31 0x00002d70b8d015a9 in ?? ()
#32 0x0000003a00000000 in ?? ()
#33 0x000009fe435f2c39 in ?? ()
#34 0x0000000000000002 in ?? ()
#35 0x000009fe435f2e41 in ?? ()
#36 0x00001d250a2c1141 in ?? ()
#37 0x00007fffffff8158 in ?? ()
#38 0x00000000023a34dc in Builtins_JSEntryTrampoline () at ../../deps/v8/src/objects/contexts.tq:201
#39 0x00001d250a2c1121 in ?? ()
#40 0x000015588bd5d981 in ?? ()
#41 0x000009fe435f2e41 in ?? ()
#42 0x000000000000002c in ?? ()
#43 0x00007fffffff81c0 in ?? ()
#44 0x00000000023a3203 in Builtins_JSEntry () at ../../deps/v8/src/objects/contexts.tq:201
Backtrace stopped: previous frame inner to this frame (corrupt stack?)
```

</details>","targos",2352663,"2022-11-14 11:23:25","gdb show info debug build thread exit function await thread receive signal sigsegv node loader importmoduledynamically contextify contextifyscript find missing separate debuginfos use yum debuginfo install glibc libgcc libstdc backtrace node loader importmoduledynamically isolate runhostimportmoduledynamicallycallback isolate runtime dynamicimportcall runtime dynamicimportcall builtins centry return dont save fp regs argv register nobuiltin exit builtins callruntimehandler builtins interpreterentrytrampoline
"
1445,252,"I was able to add a CHECK fail similar to the one a few lines below:

```
auto it = env->id_to_function_map.find(id);
CHECK_NE(it, env->id_to_function_map.end());
```

I don't know enough to say but I guess that the script is being garbage collected and the caller held a weak reference and passed the stale id.","jleedev",23022,"2022-11-14 12:26:46","add check fail similar line guess script garbage collect caller hold weak reference pass stale id
"
1446,252,"Looks like a duplicate of multiple issues which have been filed over time.

https://github.com/nodejs/node/issues/44438
https://github.com/nodejs/node/issues/43205
https://github.com/nodejs/node/issues/43681

possibly be fixed with:  https://github.com/nodejs/node/pull/44923 @legendecas ","dnalborczyk",2903325,"2022-11-14 16:43:18","duplicate issue file time fix
"
1447,252,"Appears to be fixed in v21.0.0-nightly202309156a489df73b","jleedev",23022,"2023-09-15 19:16:21","fix v21 nightly
"
1448,252,"This should be able to be fixed by https://github.com/nodejs/node/pull/48510.","legendecas",8500303,"2023-09-19 15:39:27","fix
"
1449,253,"Workaround:

```ts
try {
    await rm(path, {...});
} catch (e) {
    if ('code' in e && e.code === 'ELOOP') {
         await unlink(p);
     }
}
```","nathanael-ruf",104262550,"2022-11-10 10:20:22","workaround try await rm path catch code e code eloop await unlink p
"
1450,253,"Thanks for the report. Would you be interested in sending a PR to fix this?","aduh95",14309773,"2022-11-10 11:35:45","report interested send pr fix
"
1451,254,"I don't understand you are asking, are you:

- reporting an instance where prototype pollution makes Node.js crash, in which case, can you share the content of `reproduce.mjs`? 
- Asking for Node.js to freeze the built-in objects, in which case, have you heard of [`--frozen-intrinsics`](https://nodejs.org/api/cli.html#--frozen-intrinsics)?","aduh95",14309773,"2022-11-06 16:32:20","report instance prototype pollution make node crash share content reproduce ask node freeze built object hear frozen intrinsics
"
1452,254,"@aduh95 

1.  Below is reproduce.mjs which is modified from `snyk-labs/nopp`
```js
import globals from ""globals"";

for (const k of [...new Set(Object.values(globals).map(x => Object.keys(x)).flat())]) {
  if (k in globalThis) {
    const v = globalThis[k]
    try { Object.freeze(v) } catch { }
    try { Object.freeze(v.prototype) } catch { }
  }
}
```
2. Ah, just know `--frozen-intrinsics` now.","loynoir",78727408,"2022-11-06 17:12:10","reproduzir modificado adicionar saber congelado intrínseco
"
1453,254,"Here's a smaller repro:

```console
$ node --no-experimental-global-webcrypto --use-strict -e 'Object.defineProperty(global, ""crypto"", { configurable: false });crypto'
node:internal/modules/cjs/helpers:181
        delete object[name];
                      ^

TypeError: Cannot delete property 'crypto' of #<Object>
    at get (node:internal/modules/cjs/helpers:181:9)
    at [eval]:1:66
    at Script.runInThisContext (node:vm:129:12)
    at Object.runInThisContext (node:vm:307:38)
    at node:internal/process/execution:83:21
    at [eval]-wrapper:6:24
    at runScript (node:internal/process/execution:82:62)
    at evalScript (node:internal/process/execution:104:10)
    at node:internal/main/eval_string:50:3

Node.js v20.0.0-pre
```","aduh95",14309773,"2022-11-06 18:26:43","repro typeerror delete property crypto object get script run context node version
"
1454,255,"NARROW NO-BREAK SPACE sounds like it's from the CLDR 42 change in ICU 72.1 
https://icu.unicode.org/download/72
> In many formatting patterns, ASCII spaces are replaced with Unicode spaces (e.g., a ""thin space"").

except Node.js 19.0.0 doesn't ship with ICU 72.1 as that only landed on `main` today (https://github.com/nodejs/node/pull/45068). Did you build Node.js yourself?","richardlau",5445507,"2022-10-25 16:28:08","narrow no break space sound like cldr change icu except nodejs ship icu build nodejs
"
1455,255,"Another possibility is that you are using a Node.js linked against your system version of ICU, and that version was updated to 72.1.","targos",2352663,"2022-10-25 17:00:51","possibility use node js link system version icu version update
"
1456,255,"Looks like a bug in v8. It's set up to handle unicode whitespace, but instead treats them as keywords. I created https://bugs.chromium.org/p/v8/issues/detail?id=13490","dharesign",415822,"2022-11-15 03:16:43","bug v8 set handle unicode whitespace treat keyword create
"
1457,255,"seems like user error not a bug, don't assume that Localized date format is parseable by Date. 

Looking at the v8 issue, I can see where there is a coding bug on the V8 side, and I haven't looked at the spec yet.

But that said, I still disagree that the original example code here should always pass… It makes an invalid assumption about the US date format 

Do not use a localized date format if you expect it to be machine readable!","srl295",855219,"2022-11-15 17:46:25","user error bug assume localized date format parseable date look v8 issue see coding bug v8 side look spec disagree original example code always pass make invalid assumption us date format use localized date format expect machine readable
"
1492,258,"I think this is not associated with `toArray`, either use `Promise` or `nextTick` can not reproduce the problem. And I have found the difference between use `setTimeout` and do not use: https://github.com/nodejs/node/blob/main/lib/internal/streams/transform.js#L181-L184
Using `setTimeout` will first trigger `this.push(val)`, but `val` is `null` and second is `foo`. 
But if you do not use `setTimeout`, the first is `foo` and second is `bar`. I'm trying to find more info, but the logic is too complicated
","xtx1130",5475069,"2022-10-11 09:07:19",NULL
1493,258,"> I think this is not associated with `toArray`.

Yes, it should be when the value is resolved or pushed in the `next event cycle`. Then, the stream do not process remaining.
The symptoms is using `readable.toArray` which is `async iterators` and `setTimeout`.
Unlike the above two, `process.nextTick` is resolved in the current `event cycle`. So, it does cause any problem.","climba03003",23028015,"2022-10-11 09:14:56",NULL
1458,255,"The spec is here: https://tc39.es/ecma262/#sec-date.parse

It specifically says:
> The function first attempts to parse the String according to the format described in Date Time String Format ([21.4.1.18](https://tc39.es/ecma262/#sec-date-time-string-format)), including expanded years. If the String does not conform to that format the function may fall back to any implementation-specific heuristics or implementation-specific date formats.

and:
> However, the expression
>
>     Date.parse(x.toLocaleString())
>
> is not required to produce the same Number value as the preceding three expressions and, in general, the value produced by this function is [implementation-defined](https://tc39.es/ecma262/#implementation-defined) when given any String value that does not conform to the Date Time String Format ([21.4.1.18](https://tc39.es/ecma262/#sec-date-time-string-format))

I don't know if there's a more canonical reference for what implementation-defined strings v8 supports other than this comment in its source:
https://github.com/v8/v8/blob/5fe0aa3bc79c0a9d3ad546b79211f07105f09585/src/date/dateparser-inl.h#L23-L69

It does seem more of a coincidence that `Date.parse(d.toLocaleString(""en-US""))` works, rather than a guarantee. But given it does work, and v8 specifically intended to delegate to icu for determining whitespace, it seems reasonable to continue the status quo.

In general though, if you want guaranteed-to-work round-trip date formatting and parsing, then you would want to use the ISO 8601 format given by `toISOString()`.","dharesign",415822,"2022-11-15 21:36:48","spec say function first attempt parse string accord format describ date time string format includ expand year string conform format function may fall back implement specific heuristi implement specific date format expression date parse x tolocalestring requir produc number valu preced three expression general valu produc function implement defin give string valu conform date time string format know canonical refer implement defin string v8 support comment sourc seem coincid date parse d tolocalestring en us work rather guarante given work v8 specific intend delegat icu determin whitespac seem reasonabl continu statu quo general want guarante work round trip date format pars would want use iso format give toisostring
"
1459,255,"This was fixed upstream:

https://bugs.chromium.org/p/v8/issues/detail?id=13494","dharesign",415822,"2022-11-21 23:09:20","fix upstream
"
1460,255,"> This was fixed upstream:
> 
> https://bugs.chromium.org/p/v8/issues/detail?id=13494

FWIW change LGTM","srl295",855219,"2022-11-21 23:44:16","fix upstream change lgtm
"
1461,255,"I just want to leave a note that `new Date(new Date().toLocaleString('en-US'))` works as expected int `node@19.0.1`, but not in `node@19.1.0`.","tukusejssirs",5111894,"2022-11-23 08:59:24",NULL
1462,255,"This is still a problem in 19.1

![image](https://user-images.githubusercontent.com/419737/204165058-f366aa7a-0098-4046-b9c2-470f1b7602a7.png)
","Hexagon",419737,"2022-11-27 23:18:25","problem


**Explicação das etapas:**

1. **Remoção de ruídos:** A URL da imagem e a própria tag `![image](...)` foram removidas.  Não há outros caracteres especiais ou tags HTML no texto fornecido além da imagem.

2. **Padronização:** A palavra ""is"" foi removida pois é um verbo auxiliar sem peso semântico considerável neste contexto curto.  ""19.1"" foi mantido pois, embora seja um número, representa uma versão e pode ser crucial para a classificação do problema.

3. **Remoção de stop words:**  ""This"", ""a"", ""in"" são stop words comuns e foram removidas.


O texto resultante  ""problem"" é o que restou após todas as etapas de pré-processamento.  Note que a versão ""19.1"" foi preservada por ter potencial significado para a classificação do problema.  Uma análise mais completa dependeria de um dicionário de stop words mais completo e possivelmente de um stemmer mais sofisticado que pudesse lidar com a versão.
"
1463,255,"Hi,

It seems working on 19.0
```
echo ""console.log(new Date((new Date(1000000000000)).toLocaleString()))"" | docker run --rm -i node:19.0
```
gives 

> 2001-09-09T01:46:40.000Z

But not on latest/19.1
````
echo ""console.log(new Date((new Date(1000000000000)).toLocaleString()))"" | docker run --rm -i node:19.1
````
fails with 

> Invalid Date

Then it seems fixed and re-broken ?","michelpromonet",26296946,"2022-11-29 17:20:10",NULL
1464,255,"It was never an issue in official 19.0.x releases.  It was broken in 19.1.0 when Node switched to ICU 72.  It is subsequently fixed in 19.2.0 which cherry-picked the v8 commit that fixes it.

The original report here of it breaking against 19.0.0 must have been linking against an external ICU which was ICU 72.","dharesign",415822,"2022-11-30 00:01:49","issue node switch icu fix release report link external
"
1465,255,"Unfortunately, it's a default way to change the timezone for the date https://stackoverflow.com/questions/10087819/convert-date-to-another-timezone-in-javascript  and many libraries use it. 
Do you have a better way?","stalkerg",1853716,"2022-12-28 06:44:54","way change timezone date library better way
"
1466,255,"the stack overflow answer is a misuse of toLocaleString.
","srl295",855219,"2022-12-28 21:51:17","stack overflow answer misuse tolocalestring
"
1467,255,"@srl295 indeed, but I don't know a better way now. A very popular library like dayjs uses it. Will be good to provide a better solution and add it to stack overflow. 
I know it's not directly a nodejs issue but because it's so popular will be better to do something. ","stalkerg",1853716,"2022-12-29 12:30:17","indeed know better way popular library dayjs use good provide better solution add stack overflow know directly nodejs issue popular better something
"
1468,256,"Same thing for Node v16.x","juanarbol",17013303,"2022-10-25 15:58:20","thing node v16x
"
1469,256,"@theanarkh @juanarbol can I give this a try?","thoqbk",1491103,"2023-04-26 05:23:48","give try
"
1470,256,"It's a V8 issue. Don't know why @theanarkh reported it here but this is the wrong bug tracker for it.","bnoordhuis",275871,"2023-04-26 10:10:00",NULL
1471,256,"> It's a V8 issue. Don't know why @theanarkh reported it here but this is the wrong bug tracker for it.

@bnoordhuis is it still worth working on this?","thoqbk",1491103,"2023-04-29 11:02:07","v8 issue worth work
"
1472,256,"I'm sure upstream V8 would accept a fix so you can still work on it, you just need to send your changes upstream. We can cherry-pick the commit into node once it's been merged.

I'll go ahead and close out the issue because it isn't actionable right now but let me know if you still have questions.","bnoordhuis",275871,"2023-04-29 11:09:08","sure upstream v8 accept fix still work need send change upstream cherry pick commit node merge go ahead close issue action let know question
"
1473,257,"interestingly it does work as documented when run as a `commonjs` module, either by requiring `process` or by using the global.","dnalborczyk",2903325,"2022-10-18 15:05:57","work document run commonjs module require process use global
"
1474,257,"Yeah, looks like it was never tested when the mjs version was added. This is a known scheduling difference between cjs and mjs. The mjs example just needs to be updated to reflect the correct ordering. Interested in opening a PR?","jasnell",439929,"2022-10-18 15:45:23",NULL
1475,257,"I can put up a PR for a doc fix. I wonder tho if it would be good to add an additional note or comment about the different behavior in both module systems?","dnalborczyk",2903325,"2022-10-19 20:25:44","PR doc fix wonder good add additional note comment different behavior module system
"
1476,257,"That would be helpful yes.","jasnell",439929,"2022-10-19 21:10:31",NULL
1499,259,"@nodejs/crypto ","Trott",718899,"2022-09-08 14:36:27",NULL
1507,261,"A minimum code to reproduce
```console
$ node -p ""const a = [/a/]; a.toString();""
/a/

$ node
> const a = [/a/]; a.toString();
'/a/'
> a.toString();
''
```","cola119",22386678,"2022-08-27 13:56:55",NULL
1508,261,"Do you think this issue could be suitable for a new contributor? If so, I would like to be assigned to it and give it a try. ","vorbrodt",64839037,"2022-08-31 12:11:11",NULL
1524,264,"@jasnell ","ronag",3065230,"2022-08-07 11:04:41",NULL
1477,257,"This code imports the nextTick function from the built-in Node.js process module and then creates a chain of asynchronous operations using Promise.resolve(), queueMicrotask(), and nextTick().

Here's a breakdown of what each part of the code does:

The Promise.resolve().then(() => console.log(2)) creates a resolved promise and schedules a callback to be executed when the promise is resolved. In this case, the callback logs the number 2 to the console.

The queueMicrotask(() => console.log(3)) adds a function to the microtask queue, which will be executed after the current task has finished executing. In this case, the function logs the number 3 to the console.

The nextTick(() => console.log(1)) schedules a callback to be executed on the next iteration of the event loop. In this case, the callback logs the number 1 to the console.

Since the callbacks are executed asynchronously, the order in which the numbers are logged to the console may not be what you expect. Here is the expected output:
1
2
3
The reason for this order is that the nextTick() callback is executed before the Promise.resolve() and queueMicrotask() callbacks. Then, the Promise.resolve() callback is executed before the queueMicrotask() callback because Promise.resolve() callbacks are executed before microtask queue callbacks. Finally, the queueMicrotask() callback is executed last.

BUT

The reason why the output is 2 3 1 instead of 1 2 3 is that the nextTick() function and queueMicrotask() function are similar but have slightly different behavior. In this case, the queueMicrotask() callback is executed before the nextTick() callback, which causes the output to be in the order of 2 3 1.

The nextTick() function schedules a callback to be executed on the next iteration of the event loop, but after I/O operations have been processed. The queueMicrotask() function, on the other hand, schedules a callback to be executed on the microtask queue, which is executed before the next event loop iteration.

In this specific case, it's possible that the nextTick() callback was delayed due to I/O operations, which allowed the queueMicrotask() callback to be executed first. This behavior can vary depending on the environment and platform that the code is running on, so it's not always predictable which callback will be executed first.

In general, when scheduling multiple asynchronous operations, it's important to be aware of the differences between the various scheduling functions and their behavior in different contexts.


@jasnell @vyatkin0 
if you Guys want I can do a PR updating it.","parmishh",91942072,"2023-03-02 17:56:48",NULL
1478,257,"Any idea when this will be fixed? @jasnell","nairihar",15065065,"2024-01-05 09:00:00",NULL
1479,258,"Maybe a better issue title would be *`Duplex.from({ writable, readable })` breaks on backpressure*?","pavelhoral",2012726,"2022-10-08 17:10:46","Duplex from writable readable break backpressure
"
1480,258,"In `objectMode`, `highWaterMark` default set to `16`, please see: https://github.com/nodejs/node/blob/v18.10.0/lib/internal/streams/state.js#L15-L17

The stream will temporarily stop reading data from the underlying resource, and `toArray` method is an async function, so nodejs will consider the promise is not resolved yet, and exit with code 13. You can set:
```js
new Transform({
        objectMode: true,
        emitClose: false,
        highWaterMark:100,
        ...
```
to avoid this.","xtx1130",5475069,"2022-10-09 08:55:02",NULL
1481,258,"@xtx1130 this sounds like a bug, no?","rluvaton",16746759,"2022-10-09 09:03:49",NULL
1482,258,"You're calling `await stream.toArray()` inside an async function - i.e., a promise - but what awaits that promise? Try excluding vitest and using only built-in modules.","bnoordhuis",275871,"2022-10-09 09:13:16",NULL
1483,258,"I think you are missing the point. It is not about a specific `highWaterMark` number, it is about resuming the stream after the buffer limit is reached (btw. I have updated the test in the original comment).

And `vitest` and `toArray` here are also irrelevant - the stream never correctly resumes after backpressure occurs. That is the reason the promise is never resolved. If you change `hightWaterMark` so that the backpressure is never an issue the test passes.","pavelhoral",2012726,"2022-10-09 09:22:21",NULL
1484,258,"Without vitest and promises (I expect to see `foo` and `bar` in the console, but get only `foo`):

```js
const { PassThrough, Duplex, Transform, Readable } = require('node:stream');

// Simple pass-through as a placeholder for more complex setup
const through = new PassThrough({ objectMode: true });

// Stream prepared values, pipe through simple duplex and async transformer for backpressure
Readable.from(['foo', 'bar'], { objectMode: true })
  .pipe(Duplex.from({
    writable: through,
    readable: through
  }))
  .pipe(new Transform({
    objectMode: true,
    highWaterMark: 1, // Setting 1 to force backpressure after a single item
    transform(chunk, encoding, callback) {
      setTimeout(() => callback(null, chunk), 0);
    }
  }))
  .on('data', chunk => console.log(chunk));
```","pavelhoral",2012726,"2022-10-09 09:35:50",NULL
1485,258,"Seems like `setTimeout` inside the `transform` break something.
Changing `setTimeout` to `process.nextTick` works perfectly without error.","climba03003",23028015,"2022-10-11 06:42:44",NULL
1486,258,"@nodejs/streams ","targos",2352663,"2022-10-11 06:44:56",NULL
1487,258,"Tried to clone NodeJS repository to write a test for this and found out there are other things broken :(. First thing I did was to change this line to make some existing test fail and start from there https://github.com/nodejs/node/blob/36805e852471cc7a24524a329848da5c8f163864/test/parallel/test-stream-duplex-from.js#L143 and the test did not start failing :(. I guess this is off-topic for this particular issue but wanted to write a comment here.","pavelhoral",2012726,"2022-10-11 06:48:16",NULL
1488,258,"I'm a little low on time atm. But if someone can improve tests (i.e. add failing tests), then I could try to have a quick look at this.","ronag",3065230,"2022-10-11 06:57:18",NULL
1489,258,"Interesting, if I implement the logic with `new Duplex` also works fine with `setTimeout`.
It can be further narrow down to `Duplex.from` is not compatible to `setTimeout`?

```js
import { Duplex, PassThrough, Readable, Transform } from 'node:stream';

// Hold node process for 3s to see result
setTimeout(() => {}, 2999)

// Simple pass-through as a placeholder for more complex setup
const through = new PassThrough({
  objectMode: true, 
  highWaterMark: 1,
  transform(chunk, encoding, callback) { 
    console.log('passthrough', chunk)
    callback(null, chunk)
  }
});

// Self implement of duplex
const duplex = new Duplex({
  readableObjectMode: true,
  writableObjectMode: true,
  read(size) {
    return this.push(passthrough.read(size))
  },
  write(chunk, encoding, callback) {
    passthrough.write(chunk, encoding, callback)
  }
})

// Stream prepared values, pipe through simple duplex and async transformer for backpressure
Readable.from(['foo', 'bar', 'baz'])
  // working with self implemented duplex
  .pipe(duplex)
  // not working with Duplex.from
  // .pipe(Duplex.from({
  //   writable: passthrough,
  //   readable: passthrough
  // }))
  .pipe(new Transform({
    objectMode: true,
    highWaterMark: 1, // Setting 1 to force backpressure after a single item
    transform(chunk, encoding, callback) {
      console.log('transform', chunk)
      // setTimeout is not working with Duplex.from
      setTimeout(() => {
        callback(null, chunk)
      }, 100);
    }
  }))
  .on('data', (chunk) => { console.log('onData', chunk) })
```

The `duplexify` logic is too complicated and hard to follow. Hope my finding give some insight to the others to troubleshoot deeper.","climba03003",23028015,"2022-10-11 07:28:23",NULL
1490,258,"I have added failing test here - https://github.com/pavelhoral/node/tree/duplex-issue / https://github.com/pavelhoral/node/commit/69c7752aa32faa452db8de9dcdaceffe5779be79. The interesting thing is that it fails even without forcing the asynchronous processing (i.e. `setTimeout`), which I thought was significant part of the issue. So I am not that sure about anything anymore :dagger: 

cc @ronag 

P.S.: there is another issue in tests there https://github.com/nodejs/node/issues/44925#issuecomment-1274164620 that should be fixed - https://github.com/pavelhoral/node/commit/d5c069ba5cf55854d3428f43521c253f5e1a0d50","pavelhoral",2012726,"2022-10-11 08:40:42","add fail test interesting thing fail even without force asynchronous process think significant part issue sure anymore cc another issue test fix
"
1491,258,"> The interesting thing is that it fails even without forcing the asynchronous processing

`toArray` is actually [`asynchronous processing`](https://github.com/nodejs/node/blob/36805e852471cc7a24524a329848da5c8f163864/lib/internal/streams/operators.js#L298-L314). It using `async iterators` and returns a `Promise`.
That means whenever it comes to `next event cycle`, it will be failed.

","climba03003",23028015,"2022-10-11 08:49:47",NULL
1643,282,"No problem. Thanks for trying :heart:","szmarczak",36894700,"2022-10-26 17:23:52",NULL
1494,258,"@xtx1130 

Removed all the unnecessary code. It should be small enough to see the symptoms.

`Async Iterators`

```js
import { Duplex, PassThrough, Readable } from 'node:stream';

const passthrough = new PassThrough({ objectMode: true });

const stream = Readable.from(['foo', 'bar', 'baz'])
  .pipe(Duplex.from({
    writable: passthrough,
    readable: passthrough
  }))
  .pipe(new PassThrough({ highWaterMark: 1 }))

for await (const chunk of stream) {
    console.log('async iterator', chunk)
}
```

`setTimeout`, `setImmediate`

```js
import { Duplex, PassThrough, Readable, Transform } from 'node:stream';

const passthrough = new PassThrough({ objectMode: true });

Readable.from(['foo', 'bar', 'baz'])
  .pipe(Duplex.from({
    writable: passthrough,
    readable: passthrough
  }))
  .pipe(new Transform({
    highWaterMark: 1,
    transform(chunk, encoding, callback) {
      console.log('transform', chunk)
      // either one
      setTimeout(() => callback(null, chunk), 0)
      // setImmediate(() => callback(null, chunk))
    }
  }))
```","climba03003",23028015,"2022-10-11 09:39:04",NULL
1495,258,"@climba03003 `highWaterMark` param is needed I think.
```js
   // ...
  .pipe(new Transform({
    highWaterMark: 1,
    transform(chunk, encoding, callback) {
      // ...
    }
  }))
```","xtx1130",5475069,"2022-10-11 09:51:39",NULL
1496,258,"> @climba03003 `highWaterMark` param is needed I think.
> 
> ```js
>    // ...
>   .pipe(new Transform({
>     highWaterMark: 1,
>     transform(chunk, encoding, callback) {
>       // ...
>     }
>   }))
> ```

@xtx1130 Updated","climba03003",23028015,"2022-10-11 09:57:06",NULL
1497,258,"Does this have anything to do with the observed behaviour? https://github.com/nodejs/node/blob/bda460df9403cd749ca93d11f1cb067c764dcdd0/lib/internal/streams/transform.js#L99

Maybe the issue has to do more with `Transform` / `PassThrough` than `Duplex.from` / `Duplexify`?","pavelhoral",2012726,"2022-10-14 17:31:04",NULL
1498,258,"Simpler tes:

```js
  const through = new PassThrough({ objectMode: true });

  let res = '';
  const d = Readable.from(['foo', 'bar'], { objectMode: true })
    .pipe(Duplex.from({
      writable: through,
      readable: through
    }));

  d.on('data', (data) => {
    d.pause();
    process.nextTick(() => {
      process.nextTick(() => {
        d.resume()
      });
    });
    res += data;
  }).on('end', common.mustCall(() => {
    assert.strictEqual(res, 'foobar');
  }));
```

Seems related to pause, tick, tick and resume... somehow... note there has to be 2 ticks before resume.","ronag",3065230,"2022-10-23 13:29:51",NULL
1500,259,"Replicated on macOS too with Node.js 18.8.0 and Node.js 16.17.0.

This problem does *not* exist in Node.js 14.20.0 which throws a `TypeError` instead:

```
Uncaught TypeError [ERR_CRYPTO_INVALID_DIGEST]: Invalid digest: str
    at new NodeError (internal/errors.js:322:7)
    at handleError (internal/crypto/pbkdf2.js:68:11)
    at Object.pbkdf2Sync (internal/crypto/pbkdf2.js:48:3)
    at REPL1:1:35
    at Script.runInThisContext (vm.js:134:12)
    at REPLServer.defaultEval (repl.js:566:29)
    at bound (domain.js:421:15)
    at REPLServer.runBound [as eval] (domain.js:432:12)
    at REPLServer.onLine (repl.js:909:10)
    at REPLServer.emit (events.js:412:35) {
  code: 'ERR_CRYPTO_INVALID_DIGEST'
}
```

","Trott",718899,"2022-09-08 14:38:43",NULL
1501,259,"Node.js 15.0.0 also aborts, so perhaps looking at [the 15.0.0 changelog](https://nodejs.org/en/blog/release/v15.0.0/) might help identify which change likely resulted in this. ","Trott",718899,"2022-09-08 14:43:53",NULL
1502,259,"The two semver-major commits in 15.0.0 are https://github.com/nodejs/node/commit/dae283d96f and https://github.com/nodejs/node/commit/ba77dc8597 so maybe start with those?

@jasnell ","Trott",718899,"2022-09-08 14:46:08","semver major commit maybe start
"
1503,259,"Sigh. This is why unsigned values should not be stored as signed integers.

https://github.com/nodejs/node/pull/44575","tniessen",3109072,"2022-09-08 18:04:04",NULL
1504,260,"@rinne thank you for the report. I'm looking into a fix.","panva",241506,"2022-09-01 11:40:40",NULL
1505,260,"#44475","panva",241506,"2022-09-01 12:13:00",NULL
1509,261,"From my brief investigation, this is seemingly caused by V8 issue, not Node.js. (Node.js just calls V8's APIs to execute scripts line by line, and ChromeDevTools has the same issue too.) I don't know this issue is suitable for you but it is definitely worthwhile to look into the code to find out the cause!","cola119",22386678,"2022-09-01 13:22:54",NULL
1510,261,"> A minimum code to reproduce
> 
> ```
> $ node -p ""const a = [/a/]; a.toString();""
> /a/
> 
> $ node
> > const a = [/a/]; a.toString();
> '/a/'
> > a.toString();
> ''
> ```

A more minimum code to reproduce:
```console
$ node
Welcome to Node.js v18.2.0.
Type "".help"" for more information.
> const a = [/a/];
undefined
> a.toString()
''
```

","F3n67u",12343178,"2022-09-04 10:58:17",NULL
1511,261,"I am able to reproduce this with the Chrome DevTools.

I just reported it to the @nodejs/v8 team. https://bugs.chromium.org/p/v8/issues/detail?id=13259
 ","BridgeAR",8822573,"2022-09-04 11:56:15",NULL
1512,261,"It seems this is not even specific to regex.

```sh-session 
PS C:\Users\mmis1> node
Welcome to Node.js v16.13.2.
Type "".help"" for more information.
> const b = [{ toString() { console.log(1); return '1' } }]
undefined
> b + ''
''
```","mmis1000",2993977,"2022-09-05 15:22:54",NULL
1513,262,"Thanks for the report. It's a libuv bug - or rather, macOS is the outlier on Unix-like platforms in that it reports ru_maxrss in bytes instead of kilobytes. I'll submit a fix.","bnoordhuis",275871,"2022-08-21 18:15:13",NULL
1514,263,"> http.ServerResponse is not an instance of stream.Writable?

Throwing an error here seems to be an expected behavior since `http.ServerResponse` is an instance of `Stream`, not `stream.Writable`.  Is this issue a feature request for the following?

> stream.Writable.toWeb(stream : <stream.Writable>|<http.OutgoingMessage>)","daeyeon",6630703,"2022-08-14 10:43:08",NULL
1515,263,"It seems that the bug is on [@types/node](https://github.com/DefinitelyTyped/DefinitelyTyped/blob/master/types/node/http.d.ts#L334)
```ts
class OutgoingMessage extends stream.Writable {
```

Of course, the @daeyeon proposition is successful.
> stream.Writable.toWeb(stream : <stream.Writable>|<http.OutgoingMessage>)
","sosoba",2843525,"2022-08-17 07:05:21",NULL
1516,263,"`toWeb` should work on `OutgoingMessage`.","ronag",3065230,"2022-11-04 07:19:29",NULL
1517,263,"Has anyone claimed this issue? I haven't contributed before but I think this would be a good first issue for me as I have some ideas on a fix.","daltonna",37551534,"2022-11-09 18:24:13",NULL
1518,263,"Was this issue already assigned? If not, I'd like to try and solve it. Thanks.","AlexKliger",6045542,"2022-11-12 20:26:09",NULL
1519,263,"go for it :)","cola119",22386678,"2022-11-20 12:52:09",NULL
1520,263,"Hey, is this issue still open, because I would like to work on it as my first issue.","zeazad-hub",73724430,"2022-11-29 17:07:39",NULL
1521,263,"Hello, I found out what was going wrong. Our outgoing message defined [here](https://github.com/nodejs/node/blob/ab064d12b79d14a3d02ba420138cc9d24169a951/lib/_http_outgoing.js#L104) does not extend stream.writable. The probelm is that stream.writable has a writable attribute that behaves differently from the OutgoingMessage writabel attribute and this causes test/parallel/test-http-writable-true-after-close.js to fail because it is not writable after it is destroyed. I was wondering if OutgoingMessage.writable should be true when OutgoingMessage.destroyed is true (like the test checks for) or should OutgoingMessage.writable be false when it gets destroyed?","zeazad-hub",73724430,"2022-12-06 23:08:54",NULL
1522,263,"@zeazad-hub FWIW, there seems to be a [performance issue](https://github.com/nodejs/node/issues/28971#issuecomment-518234237) when trying `OutgoingMessage` inheriting `stream.Writable`. ","daeyeon",6630703,"2022-12-09 12:05:06",NULL
1525,264,"I think this might be just Node terminating (normally) because there is no pending I/O and we don't wait for promises before exiting.

Does it ""repro"" if you add a:

```js
setTimeout(() => {
  console.log('here in timer')
}, 100);
```

To the end of the file does it reproduce?","benjamingr",1315533,"2022-08-07 11:38:02",NULL
1526,264,"Yeah, so the `write` never finishes and Node doesn't leave the process alive for that. Spoke with Bnaya on whatsapp","benjamingr",1315533,"2022-08-07 11:39:24",NULL
1527,264,"Thanks @benjamingr!","Bnaya",1304862,"2022-08-07 11:39:52",NULL
1528,265,"I'm able to reproduce (including using the latest [v8 canary][] -- `./node-v19.0.0-v8-canary20220803fac13df4e0-linux-x64/bin/node`):

```
Thread 1 ""node"" received signal SIGTRAP, Trace/breakpoint trap.
0x00000000018777c3 in Builtins_LdaImmutableContextSlotExtraWideHandler ()
(gdb) bt
#0  0x00000000018777c3 in Builtins_LdaImmutableContextSlotExtraWideHandler ()
#1  0x00000000017331dc in Builtins_InterpreterEntryTrampoline ()
#2  0x000033b5352015a9 in ?? ()
#3  0x76a19e0100000000 in ?? ()
#4  0x00003c1d76a19e01 in ?? ()
#5  0x0000000000000001 in ?? ()
#6  0x00003957e521a741 in ?? ()
#7  0x0000072b44e27a71 in ?? ()
#8  0x00007fffffff9108 in ?? ()
#9  0x000000000173195c in Builtins_JSEntryTrampoline ()
#10 0x0000361406f41121 in ?? ()
#11 0x00003957e521a741 in ?? ()
#12 0x0000000000000028 in ?? ()
#13 0x00007fffffff9170 in ?? ()
#14 0x0000000001731683 in Builtins_JSEntry ()

```

edit: here is a much better stacktrace with a debug build:

```
#
# Fatal error in ../../deps/v8/src/debug/debug-scopes.cc, line 496
# Debug check failed: NeedsAndHasContext() implies context_->IsFunctionContext() || context_->IsDebugEvaluateContext().
#
#
#
#FailureMessage Object: 0x7ffc36cc6560
 1: 0x557137311663 node::DumpBacktrace(_IO_FILE*) [./node_g]
 2: 0x5571374f2d0f  [./node_g]
 3: 0x5571374f2d33  [./node_g]
 4: 0x557138f5b57b V8_Fatal(char const*, int, char const*, ...) [./node_g]
 5: 0x557138f5b5ab  [./node_g]
 6: 0x557137926644 v8::internal::ScopeIterator::Type() const [./node_g]
 7: 0x557137924b38 v8::internal::DebugScopeIterator::DebugScopeIterator(v8::internal::Isolate*, v8::internal::FrameInspector*) [./node_g]
 8: 0x55713792dc2d v8::internal::DebugStackTraceIterator::GetScopeIterator() const [./node_g]
 9: 0x557138224165 v8_inspector::V8DebuggerAgentImpl::currentCallFrames(std::unique_ptr<std::vector<std::unique_ptr<v8_inspector::protocol::Debugger::CallFrame, std::default_delete<v8_inspector::protocol::Debugger::CallFrame> >, std::allocator<std::unique_ptr<v8_inspector::protocol::Debugger::CallFrame, std::default_delete<v8_inspector::protocol::Debugger::CallFrame> > > >, std::default_delete<std::vector<std::unique_ptr<v8_inspector::protocol::Debugger::CallFrame, std::default_delete<v8_inspector::protocol::Debugger::CallFrame> >, std::allocator<std::unique_ptr<v8_inspector::protocol::Debugger::CallFrame, std::default_delete<v8_inspector::protocol::Debugger::CallFrame> > > > > >*) [./node_g]
10: 0x55713822799a v8_inspector::V8DebuggerAgentImpl::didPause(int, v8::Local<v8::Value>, std::vector<int, std::allocator<int> > const&, v8::debug::ExceptionType, bool, v8::base::EnumSet<v8::debug::BreakReason, int>) [./node_g]
11: 0x55713820c575  [./node_g]
12: 0x5571382372c3 v8_inspector::V8InspectorImpl::forEachSession(int, std::function<void (v8_inspector::V8InspectorSessionImpl*)> const&) [./node_g]
13: 0x55713820eeea v8_inspector::V8Debugger::handleProgramBreak(v8::Local<v8::Context>, v8::Local<v8::Value>, std::vector<int, std::allocator<int> > const&, v8::base::EnumSet<v8::debug::BreakReason, int>, v8::debug::ExceptionType, bool) [./node_g]
14: 0x55713820f10a v8_inspector::V8Debugger::BreakProgramRequested(v8::Local<v8::Context>, std::vector<int, std::allocator<int> > const&, v8::base::EnumSet<v8::debug::BreakReason, int>) [./node_g]
15: 0x55713794314d v8::internal::Debug::OnDebugBreak(v8::internal::Handle<v8::internal::FixedArray>, v8::internal::StepAction, v8::base::EnumSet<v8::debug::BreakReason, int>) [./node_g]
16: 0x557137943779 v8::internal::Debug::Break(v8::internal::JavaScriptFrame*, v8::internal::Handle<v8::internal::JSFunction>) [./node_g]
17: 0x5571380ca206  [./node_g]
18: 0x5571386c51f9  [./node_g]
Trace/breakpoint trap (core dumped)
```

edit²: I'm able to reproduce on v12.0.0, so not a recent regression

[v8 canary]: https://github.com/nodejs/node-v8","kvakil",22647613,"2022-08-04 02:26:15","able reproduce use latest node receive signal sigtrap trace breakpoint trap builtin ldaimmutablecontextslotextrawidehandler builtin interpreterentrytrampoline fatal error debug check fail need context imply context isfunctioncontext context isdebugevaluatecontext failuremessage object node dumpbacktrace node node v8 fatal node node scopeiterator type debug scopeiterator debugscopeiterator debugscopeiterator debugscopeiterator v8inspector v8debuggeragentimpl currentcallframe v8inspector v8debuggeragentimpl didpause node v8inspector v8inspectorimpl for eachsession v8inspector v8debugger handleprogrambreak v8inspector v8debugger breakprogramrequested v8 internal debug ondebugbreak v8 internal debug break node node trace breakpoint trap core dump able reproduce v12"
1529,265,"Actually, I am able to reproduce this in Chromium by putting it in a function scope. When I follow the same steps, the page crashes with ""Oh snap!"" & signal `SIGTRAP`:

```html
<html><body><script type=""text/javascript"">
(function() {
function identity(v) {
  return v;
}

debugger;

new class {
  #thisWorks = this.constructor.name;
  #thisFails = identity(this.constructor.name);
}
})();</script></body></html>
```

Build: `Version 104.0.5112.79 (Official Build) snap (64-bit)`

@connor4312 can you reproduce on Edge too via this repro? Perhaps we should send the issue to upstream V8?","kvakil",22647613,"2022-08-05 03:43:26",NULL
1530,265,"I can indeed! I just need to hover `this` instead of `this.constructor.name`.

Would someone on the Node team like to open an issue on bugs.chromium, or shall I?","connor4312",2230985,"2022-08-05 15:48:11",NULL
1531,265,"@connor4312 probably makes more sense for you to file it!","kvakil",22647613,"2022-08-06 00:25:00",NULL
1533,266,"Able to reproduce this on `v19.0.0-pre`: 

```
Welcome to Node.js v19.0.0-pre.
Type "".help"" for more information.
> const decoder = new TextDecoder('Shift_JIS');
> const s = decoder.decode(new Uint8Array([255]));
> s
'\x1A'
```

@cola119 are you looking into `ucnv.cpp` for the fix?

","hemanth",18315,"2022-07-23 19:30:32",NULL
1534,266,"@hemanth 
I'm thinking `ConverterObject` can set `?` as a substitution character explicitly since `node::Converter` already have the method to change it.
https://github.com/nodejs/node/blob/7ef069e483e015a803660125cdbfa81ddfa0357b/src/node_i18n.cc#L370-L377","cola119",22386678,"2022-07-24 03:17:27",NULL
1535,267,"I can reproduce.","targos",2352663,"2022-07-18 17:16:28",NULL
1536,267,"/cc @mscdex ","legendecas",8500303,"2022-07-18 17:17:08",NULL
1537,267,"Is it only a problem with debug mode (e.g. is it just the `-O0` causing it)?","mscdex",54666,"2022-07-18 17:47:55",NULL
1538,267,"Also is this limited to clang? Everything seems to have passed for the debug build on Linux arm64 with gcc.","mscdex",54666,"2022-07-18 18:02:45",NULL
1539,267,"Yes, it only affects debug mode. I don't have gcc installed on my mac.","targos",2352663,"2022-07-18 18:33:15",NULL
1541,267,"``` shell
$ gcc -v
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/4.2.1
Apple clang version 13.0.0 (clang-1300.0.29.30)
Target: arm64-apple-darwin21.4.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
```
The same question","xtx1130",5475069,"2022-07-19 03:10:17",NULL
1542,267,"Is there any progress on this issue, or is there any other way for me to compile the main branch codes except `--debug`?","xtx1130",5475069,"2022-07-27 02:40:33",NULL
1543,267,"@xtx1130 Feel free to temporarily apply [this patch](https://github.com/aklomp/base64/pull/97/files). The upstream dependency has a different solution in the works.","mscdex",54666,"2022-07-27 04:01:04",NULL
1544,267,"Can those of you having the problem please test https://github.com/nodejs/node/pull/44032 ?","mscdex",54666,"2022-07-28 22:41:24",NULL
1545,268,"/cc @nodejs/undici ","aduh95",14309773,"2022-07-17 05:28:46",NULL
1546,268,"I confirm this bug @coyotte508. Thanks for reporting!

@aduh95 I suspect this is a problem with some other Node.js v18 Zlib changes.

The following code runs perfectly on Node.js v16, but it fails on Node.js v18:

```js
import { fetch } from 'undici'

const x = await fetch(""http://www.sinlenoble.fr/solidarite/le-ccas"");
const y = await x.text();

console.log(y)
```

```
node:events:491
      throw er; // Unhandled 'error' event
      ^

Error: unexpected end of file
    at Zlib.zlibOnError [as onerror] (node:zlib:189:17)
Emitted 'error' event on Gunzip instance at:
    at emitErrorNT (node:internal/streams/destroy:151:8)
    at emitErrorCloseNT (node:internal/streams/destroy:116:3)
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  errno: -5,
  code: 'Z_BUF_ERROR'
}

Node.js v18.6.0
```

cc @ronag ","mcollina",52195,"2022-07-18 09:30:49",NULL
1547,268,"Here is what that website is doing:

1. the `http://www.sinlenoble.fr/solidarite/le-ccas` URL issue a redirect to `http://www.sinlenoble.fr/solidarite/le-ccas/`. This redirect has an empty body but it wrongly reports `content-encoding: gzip`
2. `fetch()` and undici try to eagerly read that body
3. an exception is thrown only on Node v18 (but not v16)","mcollina",52195,"2022-07-18 10:06:20",NULL
1548,268,"Are we missing an error handler?","ronag",3065230,"2022-07-18 10:07:01",NULL
1549,268,"@ronag I'm fixing this on the undici side (it's the right behavior anyway), but we should investigate why this is happening for streams. There should be an error handler for that stream.","mcollina",52195,"2022-07-18 10:07:01",NULL
1550,268,"> Are we missing an error handler?

Yes, I think in some case one of the pipeline refactoring is causing problems:

https://github.com/nodejs/undici/blob/26f60b7b6e612bb831133d7f85914963d1955011/lib/fetch/index.js#L1962-L1986

`pipeline` should have added one for that.","mcollina",52195,"2022-07-18 10:07:58",NULL
1551,268,"Here is our fix: https://github.com/nodejs/undici/pull/1554","mcollina",52195,"2022-07-18 10:09:18",NULL
1552,268,"The problem is in undici and it's due to https://github.com/nodejs/node/pull/41954/files#diff-95c23fb6674af85f6f23a374851af6cccf58fb4617d73897df5078ba537a862cR243.","mcollina",52195,"2022-07-18 10:28:54",NULL
1553,268,"seeing same error but in different context, occurs when server respond with status 200 but sends duplicating headers (which is server bug but native browser `fetch` can live with it)
```diff
  < HTTP/2 200
  < access-control-allow-headers: accept, accept-encoding, authorization, content-type, dnt, origin, user-agent, x-csrftoken, x-requested-with, content-disposition, x-request-id, x-app-version
  < access-control-allow-methods: DELETE, GET, POST, PUT, PATCH, OPTIONS
  < access-control-allow-origin: *
  < access-control-expose-headers: x-request-id
  < access-control-max-age: 86400
+ < cache-control: private, max-age=0
+ < cache-control: private, no-cache, no-store
  < content-encoding: gzip
  < content-length: 105
  < content-type: application/json
  < date: Tue, 22 Nov 2022 23:50:00 GMT
  < expires: Tue, 22 Nov 2022 23:50:00 GMT
  < server: nginx
+ < strict-transport-security: max-age=31536000
+ < strict-transport-security: max-age=31536000
```
according to the discussion in theory problem also can be with `content-length`, in this case server returns length of gzipped body (which follows specs), original length is `560`","gbiryukov",6758384,"2022-11-23 00:04:15",NULL
1554,268,"That's a different bug than this one, can you open a fresh issue and tag me?","mcollina",52195,"2022-11-23 08:06:21",NULL
1555,269,"@guybedford FYI","aduh95",14309773,"2022-07-11 16:04:28",NULL
1556,269,"@tniessen the repl top-level await doesn't use v8 directly and instead runs through an emulation layer. Short of someone to do the work to refactor that hack, this is a bug in the emulation layer originally implemented I believe by Gus.

The transform is here - https://github.com/nodejs/node/blob/main/lib/internal/repl/await.js, and the tests for the rewriting are here - https://github.com/nodejs/node/blob/main/test/parallel/test-repl-preprocess-top-level-await.js.

I would suggest adding the failing line to the transform tests to debug further what it is actually executing and why it is giving the wrong result. Working out the failing test would be a good start.","guybedford",598730,"2022-07-11 20:09:25",NULL
1557,269,"Thank you for the info @guybedford!

I might be missing something but the transform seems to always wrap the code in an `async` function:

https://github.com/nodejs/node/blob/90bc773fb8e45333a96667e87ac887757911631e/lib/internal/repl/await.js#L155-L156

The REPL then seems to `await` the return value of that function:

https://github.com/nodejs/node/blob/a055337a027cf52f6cd4c19eb80144ab99b00b58/lib/repl.js#L571-L575

https://github.com/nodejs/node/blob/a055337a027cf52f6cd4c19eb80144ab99b00b58/lib/repl.js#L602

https://github.com/nodejs/node/blob/a055337a027cf52f6cd4c19eb80144ab99b00b58/lib/repl.js#L617-L621

In this case, the value that the REPL should evaluate to is a `Promise` itself, and returning a `Promise` from the added `async` function causes the above snippet to incorrectly `await` the `Promise`.

> I would suggest adding the failing line to the transform tests to debug further what it is actually executing and why it is giving the wrong result. Working out the failing test would be a good start.

I'm not sure what I'd expect the transform to produce. Maybe something like `(async () => { return (await Promise.resolve(foo)); })().then((x) => x())` (which seems dangerously complicated).","tniessen",3109072,"2022-07-13 08:52:59",NULL
1558,269,"I think the solution is to rewrite all `return v` to `return { value: v }` and then get that `value` property on the outside.","devsnek",5952481,"2022-07-13 14:49:52",NULL
1559,269,"@devsnek That seems like an amazingly simple solution to me! See #43827.","tniessen",3109072,"2022-07-13 19:10:34",NULL
1560,270,"@nodejs/fs","targos",2352663,"2022-07-07 06:10:53",NULL
1579,272,"I tested this again on Node 16.20.0, the issue persists.

I also tried `--unhandled-rejections=none`, as @benjamingr suggested above, but it didn't help.

Now I'm getting this error not in the tests, but in a real application that synchronize millions of files between hard drives. There is the same thing: Node hangs, CPU is fully loaded, but JavaScript is doing nothing.
","NikolayMakhonin",12973901,"2023-04-29 10:52:31",NULL
1580,272,"> I also tried --unhandled-rejections=none, as @benjamingr suggested above, but it didn't help.

I don't think that change was ever merged (or PR'd.)","bnoordhuis",275871,"2023-04-29 11:11:13",NULL
1561,270,"It's a signed-to-unsigned conversion bug:
```
$ touch -t 196912312359.59 x && node -p 'fs.statSync(""x"", {bigint: true})' | grep Ns
  atimeNs: 18446744073709548015000000000n,
  mtimeNs: 18446744073709548015000000000n,
  ctimeNs: 1657177398636601096n,
  birthtimeNs: 1657177398636510656n,
```
Internally, the stats are handed off from C++ to JS in a BigUint64Array but that makes negative values wrap around. The fix is to use a BigInt64Array instead. Pull request welcome.

edit: in particular, it's this (insidiously misnamed) field:
https://github.com/nodejs/node/blob/7d13f5e34f7a9e98b925d7fdf77ebfadb7ed17d8/src/node_file.h#L21
And here is where it's converted to a stats object:
https://github.com/nodejs/node/blob/7d13f5e34f7a9e98b925d7fdf77ebfadb7ed17d8/lib/internal/fs/utils.js#L534-L545","bnoordhuis",275871,"2022-07-07 07:14:55",NULL
1562,270,"Non-bigint stats are returned as `Float64Array` so perhaps this requires adjusting `unsigned long long`s (or what it's aliased to) in C++ bindings as well.","LiviaMedeiros",74449973,"2022-07-07 07:21:08",NULL
1563,270,"Sorry yes, I forgot to mention that. That logic is here:
https://github.com/nodejs/node/blob/7d13f5e34f7a9e98b925d7fdf77ebfadb7ed17d8/src/node_file-inl.h#L93-L95","bnoordhuis",275871,"2022-07-07 08:32:44",NULL
1564,270,"Note: on Windows platform, there still is an overflow on negative dates, to postpone Y2038 overflow.
It shouldn't lead to `Invalid Date`, and right now is unavoidable without breaking underlying ABI.","LiviaMedeiros",74449973,"2022-07-18 16:27:22",NULL
1565,271,"I can repro this on main, this is a neat find, thanks. 

@nodejs/loaders @nodejs/repl ","benjamingr",1315533,"2022-07-05 12:51:08",NULL
1566,271,"When running the scripts sequentially, the `Local<Script>` created at https://github.com/nodejs/node/blob/main/src/node_contextify.cc#L947 can outlive the `ContextifyScript` so https://github.com/nodejs/node/blob/main/src/module_wrap.cc#L594 may crash because the `ContextifyScript` is released and the access can be invalid.

When running `console.log(6, await Promise.resolve('import(""./mod.mjs"")').then(eval));` in a fresh REPL, the referrer script unexpectedly becomes the `internal/process/task_queues.js` instead of the REPL script. This can be problematic as the host_defined_options is not the expected one for the REPL script.

I'll try to dig into this.","legendecas",8500303,"2022-07-05 16:01:29",NULL
1567,271,"@legendecas I'm not sure whether it's related to this crash, but note that we are still using [`CompileFunctionInContext`](https://github.com/nodejs/node-v8/issues/214) which is deprecated in V8.","targos",2352663,"2022-07-05 16:34:11",NULL
1568,271,"> When running console.log(6, await Promise.resolve('import(""./mod.mjs"")').then(eval)); in a fresh REPL, the referrer script unexpectedly becomes the internal/process/task_queues.js instead of the REPL script. This can be problematic as the host_defined_options is not the expected one for the REPL script.

So, the reason I found this bug is that I was reading https://tc39.es/ecma262/#sec-hostmakejobcallback, which forces non-browser hosts to have a different behavior from browsers. HTML uses that host hook to implement support for ``Promise.resolve('import(`./example.mjs`)').then(eval)`` (https://html.spec.whatwg.org/#hostmakejobcallback), so I wanted to test how Node.js behaves.

So it's possible that the promise rejection (not the crash) is actually expected.","nicolo-ribaudo",7000710,"2022-07-05 20:59:09",NULL
1569,271,"This is actually expected in Node.js I argued at TC39 browsers should fail
too in 2019 or so. However, they didn't like that. Notes term should be
something about ""incumbent realm"". Node can allow it and ignore spec
non-web expectations. We had to do same with JSON impoer assertions due to
how web structured that semantics

On Tue, Jul 5, 2022, 3:59 PM Nicolò Ribaudo ***@***.***>
wrote:

> When running console.log(6, await
> Promise.resolve('import(""./mod.mjs"")').then(eval)); in a fresh REPL, the
> referrer script unexpectedly becomes the internal/process/task_queues.js
> instead of the REPL script. This can be problematic as the
> host_defined_options is not the expected one for the REPL script.
>
> So, the reason I found this bug is that I was reading
> https://tc39.es/ecma262/#sec-hostmakejobcallback, which forces
> non-browser hosts to have a different behavior from browsers. HTML uses
> that host hook to implement support for Promise.resolve('import(
> ./example.mjs)').then(eval), so I wanted to test how Node.js behaves.
>
> So it's possible that the promise rejection (not the crash) is actually
> expected.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/nodejs/node/issues/43681#issuecomment-1175493108>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AABZJIZ3ZJXURUZJ7YW6Z2DVSSO2TANCNFSM52T5DMMQ>
> .
> You are receiving this because you are on a team that was mentioned.Message
> ID: ***@***.***>
>
","bmeck",234659,"2022-07-05 21:29:52",NULL
1570,271,"The crash was fixed by https://github.com/nodejs/node/pull/48510. The uncovered issue behind the crash is being tracked at https://github.com/nodejs/node/issues/49726. ","legendecas",8500303,"2023-10-23 07:58:33",NULL
1571,272,"I can confirm the issue and I speculate it's caused by how V8 internally tracks rejected promises.

Here is a reduced test case:
```js
// Flags: --predictable
(async () => {
  for (let i = 0; i < 36_293; i++) // fast - 36_294 is 3x slower
    await new Promise((_, g) => g()).then(() => {}, () => {}) // not .catch
})()
```
What's remarkable is that performance is not linear. A lower value like 30_000 is 2x slower than 36_923.","bnoordhuis",275871,"2022-07-03 02:00:59",NULL
1572,272,"I see a few similarities with [#29385](https://github.com/nodejs/node/issues/29385). Maybe they are related?","Slayer95",4925744,"2022-07-03 13:35:45",NULL
1573,272,"Rejections are significantly more costly than fulfillment (e.g. because of rejection tracking) which is ""by design"".

Exceptional control flow prioritizes reliability and debuggability over performance and whenever we discussed what to make faster in promises the consensus was always that error flow performance isn't important since errors are rare.","benjamingr",1315533,"2022-07-28 15:45:58",NULL
1574,272,"@bnoordhuis 

>  A lower value like 30_000 is 2x slower than 36_923.

I suspect that since we push to a WeakMap it does something differently when it reaches a threshold.

Comment out `setPromiseRejectCallback` and see if that ""resolves"" the performance difference.

Oh and @NikolayMakhonin :

> I can reproduce it in the Chromium 49 but it work correctly in the Chrome latest. 

The promise impl was entirely swapped and replaced/improved in Chrome since Chrome 49 :)

","benjamingr",1315533,"2022-07-28 15:49:04",NULL
1575,272,"I'll open a PR to not save promises in the map if the unhandled rejection mode is ""none"". Note the cost of not saving rejections is that you will not get notified of unhandled rejections if that helps","benjamingr",1315533,"2022-07-28 16:33:26",NULL
1576,272,"@benjamingr Do you still want to open that PR?","targos",2352663,"2022-11-08 14:36:32",NULL
1577,272,"@NikolayMakhonin can you confirm that the fix (working with --unhandled-rejections=none) would address the issue from your point of view?
","benjamingr",1315533,"2022-11-11 18:41:36",NULL
1578,272,"I think this may be related to issue #47158 which I recently created.","itzmanish",12438068,"2023-03-19 07:07:06",NULL
1581,273,"cc @nodejs/diagnostics @nodejs/domains ","Qard",205482,"2022-06-24 20:06:20",NULL
1582,273,"CI: https://ci.nodejs.org/job/node-test-pull-request/44855/","nodejs-github-bot",18269663,"2022-06-26 00:00:36",NULL
1583,273,"CI: https://ci.nodejs.org/job/node-test-pull-request/44906/","nodejs-github-bot",18269663,"2022-06-27 17:41:35",NULL
1588,275,"CI: https://ci.nodejs.org/job/node-test-pull-request/44779/","nodejs-github-bot",18269663,"2022-06-21 11:26:55",NULL
1589,275,"CI: https://ci.nodejs.org/job/node-test-pull-request/44921/","nodejs-github-bot",18269663,"2022-06-28 02:47:22",NULL
1590,275,"CI: https://ci.nodejs.org/job/node-test-pull-request/44951/","nodejs-github-bot",18269663,"2022-06-29 07:36:20",NULL
1591,275,"Landed in ed1e9ae402684adc84da0094d1a76d7f26d0abc6","nodejs-github-bot",18269663,"2022-06-29 11:26:20",NULL
1594,276,"What is the browser you are using? I cannot reproduce on iOS.

Would you be interested in sending a PR to fix that?","aduh95",14309773,"2022-06-18 09:15:31",NULL
1595,276,"Confirming this on Google Chrome 102.0.5005.78 on Android.

Additionally, horizontal scroll doesn't help (perhaps it should have `position:fixed` in dedicated place?).

<details>
<summary>Long screenshot</summary>

![Screenshot_20220618-181951](https://user-images.githubusercontent.com/74449973/174431547-b83004ff-4d36-4efa-b3dc-47e2652ee3fc.png)

</details>","LiviaMedeiros",74449973,"2022-06-18 09:33:59",NULL
1596,276,"I can reproduce it on the iOS firefox browser.

<details>
  <summary>Long screenshot</summary>

  ![36BD8991-A7D1-4BB8-A633-91843A2EAC2E](https://user-images.githubusercontent.com/12343178/174432196-710a8082-5fdd-4782-9bc3-f4288bfc2256.png)
</details>
","F3n67u",12343178,"2022-06-18 09:44:52",NULL
1597,276,"I found another problem in light mode, CJS/ESM toggle will be covered by the code snippet.

<img width=""354"" alt=""image"" src=""https://user-images.githubusercontent.com/12343178/174433736-29bdd4e3-538c-465d-a6ea-31dba5c86e21.png"">

<details>
  <summary>Long screenshot</summary>

<img width=""375"" alt=""image"" src=""https://user-images.githubusercontent.com/12343178/174433721-9c1a6f56-64ef-4bae-be22-853161511482.png"">
</details> 
","F3n67u",12343178,"2022-06-18 10:29:56",NULL
1598,276,"I could reproduce the above 2 problems using desktop Chrome responsive design mode. I think those problems are not device-specific.

1. Open desktop Chrome
2. Open Chrome devtool, and switch to responsive design mode.
3. Click the ""Toggle the dark/light mode"" button on the doc site, and you will reproduce the above problems.","F3n67u",12343178,"2022-06-18 10:33:29",NULL
1599,276,"> What is the browser you are using? I cannot reproduce on iOS.
> 
> Would you be interested in sending a PR to fix that?

i cannot make a PR sorry about that, i couldnt even make my github website design good","Nit-nit",94877880,"2022-06-19 06:31:24",NULL
1600,276,"I'l try handling this","MoLow",8221854,"2022-06-19 12:38:33",NULL
1601,276,"Sorry to say but it's still not fixed
![Screenshot_20220724-114657.png](https://user-images.githubusercontent.com/94877880/180634921-1c6d3f7f-6e25-4725-a48c-f9da0ccf6970.png)","Nit-nit",94877880,"2022-07-24 06:17:37",NULL
1602,276,"https://github.com/nodejs/node/commit/7cbcc4fc43ec167ae92080be5a4983821ba7ddc7 wasn't included in any release yet. The documentation pages on website are built independently for each version, and upcoming releases will have the fix included.
""Live"" doc builds can be checked out via GHA artifacts, e.g. [this one](https://github.com/nodejs/node/suites/7493519398/artifacts/307731934) for current `main` (https://github.com/nodejs/node/commit/d63a4cbbd85839ecdfc9ed94364be0a78f261cb8).","LiviaMedeiros",74449973,"2022-07-24 06:46:19",NULL
1603,276,"It was included in v18.16.0, it hasn't landed yet on v16.x though.","aduh95",14309773,"2022-07-24 08:23:56",NULL
1604,277,"@nodejs/net ","Trott",718899,"2022-06-09 18:40:37",NULL
1605,277,"@supriyo-biswas would you like to send a PR to address this?","mcollina",52195,"2022-06-09 18:54:26",NULL
1606,277,"@mcollina yes, I will. If I have questions, is it fine to ask in this issue itself?","supriyo-biswas",27079933,"2022-06-10 04:19:11",NULL
1607,277,"@supriyo-biswas Yes, go for it! ^^","ShogunPanda",201101,"2022-06-10 10:13:05",NULL
1608,277,"Alright☺
","tsiferan",96577409,"2022-06-20 09:47:36",NULL
1609,277,"> ### Version
> v18.3.0
> 
> ### Platform
> Darwin xxx 21.5.0 Darwin Kernel Version 21.5.0: Tue Apr 26 21:08:22 PDT 2022; root:xnu-8020.121.3~4/RELEASE_X86_64 x86_64
> 
> ### Subsystem
> net
> 
> ### What steps will reproduce the bug?
> A /32 subnet mask such as `1.1.1.1/32` should match only the IP address `1.1.1.1` as all 32 bits should be compared. However, if a /32 subnet mask is used with `net.Blocklist()`, it erroneously matches all IP addresses.
> 
> The issue can be reproduced by running the following code snippet:
> 
> ```js
> const net = require('net')
> 
> const reservedIPBlocklist = new net.BlockList()
> reservedIPBlocklist.addSubnet('1.1.1.1', 32, 'ipv4')
> 
> for (const ip of [""10.0.0.1"", ""1.1.1.1"", ""4.3.2.4"", ""27.192.11.1"", 
> ""192.168.1.9""]) {
>     console.log(ip, reservedIPBlocklist.check(ip, 'ipv4'))    
> }
> ```
> 
> Even though only `1.1.1.1` should match, `true` is printed for all the IPs:
> 
> ```
> 10.0.0.1 true
> 1.1.1.1 true
> 4.3.2.4 true
> 27.192.11.1 true
> 192.168.1.9 true
> ```
> 
> If the subnet mask is changed to < 32, Node behaves correctly.
> 
> ### How often does it reproduce? Is there a required condition?
> The bug can always be reproduced.
> 
> ### What is the expected behavior?
> See above.
> 
> ### What do you see instead?
> See above.
> 
> ### Additional information
> This bug is present across other versions of Node too, for example see https://www.mycompiler.io/view/1JuZ56bnWhl where the Node version is Node 16.15.0.

","Adambenmabrok",94982461,"2022-06-20 10:01:51",NULL
1611,277,"> > ### Version
> > v18.3.0
> > ### Platform
> > Darwin xxx 21.5.0 Darwin Kernel Version 21.5.0: Tue Apr 26 21:08:22 PDT 2022; root:xnu-8020.121.3~4/RELEASE_X86_64 x86_64
> > ### Subsystem
> > net
> > ### What steps will reproduce the bug?
> > A /32 subnet mask such as `1.1.1.1/32` should match only the IP address `1.1.1.1` as all 32 bits should be compared. However, if a /32 subnet mask is used with `net.Blocklist()`, it erroneously matches all IP addresses.
> > The issue can be reproduced by running the following code snippet:
> > ```js
> > const net = require('net')
> > 
> > const reservedIPBlocklist = new net.BlockList()
> > reservedIPBlocklist.addSubnet('1.1.1.1', 32, 'ipv4')
> > 
> > for (const ip of [""10.0.0.1"", ""1.1.1.1"", ""4.3.2.4"", ""27.192.11.1"", 
> > ""192.168.1.9""]) {
> >     console.log(ip, reservedIPBlocklist.check(ip, 'ipv4'))    
> > }
> > ```
> > 
> > 
> >     
> >       
> >     
> > 
> >       
> >     
> > 
> >     
> >   
> > Even though only `1.1.1.1` should match, `true` is printed for all the IPs:
> > ```
> > 10.0.0.1 true
> > 1.1.1.1 true
> > 4.3.2.4 true
> > 27.192.11.1 true
> > 192.168.1.9 true
> > ```
> > 
> > 
> >     
> >       
> >     
> > 
> >       
> >     
> > 
> >     
> >   
> > If the subnet mask is changed to < 32, Node behaves correctly.
> > ### How often does it reproduce? Is there a required condition?
> > The bug can always be reproduced.
> > ### What is the expected behavior?
> > See above.
> > ### What do you see instead?
> > See above.
> > ### Additional information
> > This bug is present across other versions of Node too, for example see https://www.mycompiler.io/view/1JuZ56bnWhl where the Node version is Node 16.15.0.

Spam comment. User blocked.","Trott",718899,"2022-06-20 19:35:27",NULL
1612,278,"IMO, it's possible to directly pass the listener. Sent a PR for this. :-)
","daeyeon",6630703,"2022-06-11 00:28:44",NULL
1613,279,"> Create an ESM file

For the record: also happens with CJS.","bnoordhuis",275871,"2022-06-07 08:19:07",NULL
1614,279,"This is caused by `normalizeSpawnArguments` being called repeatedly. We should avoid using the normalize function for spawn in execFile, even though it works fine most of the time.

This issue can be assigned to me.","zhmushan",24505451,"2022-06-07 14:25:59",NULL
1615,279,"Could you help me understand why the behavior of execFileSync is expected? 

If `echo foo bar` is interpreted to `bash -c 'echo foo bar'` when shell is `/bin/bash`, then `foo bar` should be printed, right?

```console
$ bash -c ""echo foo bar""
foo bar
```","F3n67u",12343178,"2022-06-07 14:50:23",NULL
1616,279,"@F3n67u Your understanding is correct, but now execFileSync interprets `echo foo bar` as `/bin/bash -c ""/bin/bash -c echo foo bar""`","zhmushan",24505451,"2022-06-08 02:53:16",NULL
1617,279,"> This issue can be assigned to me.

No need to wait for someone to assign you to the issue, feel free to send the PR when your patch is ready. :)","RaisinTen",42526976,"2022-06-08 04:13:49",NULL
1618,279,"> Could you help me understand why the behavior of execFileSync is expected?

That's based on @bnoordhuis' comments in https://github.com/nodejs/node/issues/29466. 


> If `echo foo bar is` interpreted to `bash -c 'echo foo bar'` when shell is `/bin/bash`, then `foo bar` should be printed, right?

That is actually the topic of the discussion I brought up over at https://github.com/nodejs/node/issues/29466 as well.","ericcornelissen",3742559,"2022-06-08 07:32:27",NULL
1619,280,"cc @nodejs/modules ","ljharb",45469,"2022-06-01 05:28:41",NULL
1620,280,"Note: this also seems to be the case in node 14, but not 18. (update: in `resolve`'s tests, but see below; apparently it is broken in node 18)","ljharb",45469,"2022-06-01 05:29:54",NULL
1621,280,"> Note: this also seems to be the case in node 14, but not 18.

I'm able to reproduce on both v18.x and `master`:

```console
$ node -pe 'require.resolve(""node:readline/promises2"")'
node:readline/promises2
$ out/Release/node -pe 'require.resolve(""node:readline/promises2"")'
node:readline/promises2
$ out/Release/node -pe 'require(""node:readline/promises2"")'       
node:internal/modules/cjs/loader:790
      throw new ERR_UNKNOWN_BUILTIN_MODULE(filename);
      ^

Error [ERR_UNKNOWN_BUILTIN_MODULE]: No such built-in module: node:readline/promises2
    at new NodeError (node:internal/errors:388:5)
    at Module._load (node:internal/modules/cjs/loader:790:13)
    at Module.require (node:internal/modules/cjs/loader:1008:19)
    at require (node:internal/modules/cjs/helpers:102:18)
    at [eval]:1:1
    at Script.runInThisContext (node:vm:129:12)
    at Object.runInThisContext (node:vm:305:38)
    at node:internal/process/execution:76:19
    at [eval]-wrapper:6:22
    at evalScript (node:internal/process/execution:75:60) {
  code: 'ERR_UNKNOWN_BUILTIN_MODULE'
}

Node.js v19.0.0-pre
```","aduh95",14309773,"2022-06-01 09:28:56",NULL
1622,280,"oh hm, thanks for confirming. the `resolve` tests didn't fail on node 18, oddly enough.

Either way, this feels like a sizable bug with the `node:` protocol. It would be ideal to get a fix for this landed and backported as far back as possible (14).","ljharb",45469,"2022-06-01 14:18:23",NULL
1623,281,"Thanks for the report. I can also reproduce with v18.2.0. The stack trace looks like this:
```
(lldb) bt
* thread #2, stop reason = EXC_BAD_ACCESS (code=1, address=0x0)
  * frame #0: 0x0000000100097270 node`node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::Data>, v8::Local<v8::Value>, v8::Local<v8::String>, v8::Local<v8::FixedArray>) + 608
    frame #1: 0x00000001003afcb6 node`v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::Handle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>, v8::internal::MaybeHandle<v8::internal::Object>) + 886
    frame #2: 0x0000000100821ff5 node`v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) + 293
    frame #3: 0x0000000100c11a34 node`Builtins_CEntry_Return1_DontSaveFPRegs_ArgvInRegister_NoBuiltinExit + 52
    frame #4: 0x0000000100cb0d0e node`Builtins_CallRuntimeHandler + 78
    frame #5: 0x0000000100b93c4f node`Builtins_InterpreterEntryTrampoline + 207
    frame #6: 0x0000000100bc8e3f node`Builtins_AsyncFunctionAwaitResolveClosure + 63
    frame #7: 0x0000000100c62d38 node`Builtins_PromiseFulfillReactionJob + 56
    frame #8: 0x0000000100bba4c4 node`Builtins_RunMicrotasks + 644
    frame #9: 0x0000000100b91c83 node`Builtins_JSRunMicrotasksEntry + 131
    frame #10: 0x0000000100391f70 node`v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) + 2944
    frame #11: 0x0000000100392533 node`v8::internal::(anonymous namespace)::InvokeWithTryCatch(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) + 83
    frame #12: 0x0000000100392721 node`v8::internal::Execution::TryRunMicrotasks(v8::internal::Isolate*, v8::internal::MicrotaskQueue*, v8::internal::MaybeHandle<v8::internal::Object>*) + 81
    frame #13: 0x00000001003bda7b node`v8::internal::MicrotaskQueue::RunMicrotasks(v8::internal::Isolate*) + 315
    frame #14: 0x00000001003be2b1 node`v8::internal::MicrotaskQueue::PerformCheckpoint(v8::Isolate*) + 97
    frame #15: 0x0000000100001dfe node`node::InternalCallbackScope::Close() + 462
    frame #16: 0x00000001000017de node`node::InternalCallbackScope::~InternalCallbackScope() + 14
    frame #17: 0x000000010006c232 node`node::Environment::RunTimers(uv_timer_s*) + 578
    frame #18: 0x0000000100b6f186 node`uv__run_timers + 54
    frame #19: 0x0000000100b73b07 node`uv_run + 247
    frame #20: 0x0000000100002f9f node`node::SpinEventLoop(node::Environment*) + 287
    frame #21: 0x000000010017da98 node`node::worker::Worker::Run() + 2056
    frame #22: 0x0000000100181472 node`node::worker::Worker::StartThread(v8::FunctionCallbackInfo<v8::Value> const&)::$_3::__invoke(void*) + 50
    frame #23: 0x00007fff7e2722eb libsystem_pthread.dylib`_pthread_body + 126
    frame #24: 0x00007fff7e275249 libsystem_pthread.dylib`_pthread_start + 66
    frame #25: 0x00007fff7e27140d libsystem_pthread.dylib`thread_start + 13
```
From looking at the disassembly I expect the nullptr dereference is around here:
https://github.com/nodejs/node/blob/1531ef1c0c30b35b764981683383187261c97779/src/module_wrap.cc#L585-L605","bnoordhuis",275871,"2022-05-26 08:44:23",NULL
1639,282,"@legendecas I've tried to cherry-pick your commit in node repo, but it looks like it relies on V8 APIs that are not available in the version of V8 we are using. Do you know if it's worth a backport or if we'd be better off waiting for V8 10.5 to stabilize?","aduh95",14309773,"2022-07-09 20:54:14",NULL
1640,282,"@aduh95 thanks for the ping. I think the patch should be straightforward to be backported. Submitted https://github.com/nodejs/node/pull/43751 and added a test case for the issue.","legendecas",8500303,"2022-07-10 00:50:43",NULL
1641,282,"Another reproduction case (it's weird, remove `join` and it works?):

```js
import { join } from 'node:path';
import { isMainThread, Worker } from 'node:worker_threads';

if (isMainThread) {
    new Worker(new URL(import.meta.url));
    await 0;
} else {
    process.exit();
    join();
}
```

Is there a chance for this to be backported into Node.js 14?","szmarczak",36894700,"2022-09-21 17:08:26",NULL
1663,285,"https://github.com/nodejs/node/pull/42616","yanovich",576586,"2022-05-05 15:00:46",NULL
1624,281,"I have located the code location that triggers the null pointer exception: https://github.com/nodejs/node/compare/master...leizongmin:fix/issue-43205

```diff
                     ->Uint32Value(context)
                     .ToChecked();
   if (type == ScriptType::kScript) {
-    contextify::ContextifyScript* wrap = env->id_to_script_map.find(id)->second;
-    object = wrap->object();
+    auto it = env->id_to_script_map.find(id);
+    CHECK_NE(it, env->id_to_script_map.end());
+    object = it->second->object();
   } else if (type == ScriptType::kModule) {
     ModuleWrap* wrap = ModuleWrap::GetFromID(env, id);
     object = wrap->object();
```

Below is the simplified code that reproduces the problem in versions v16.14.2 and v19.0.0-pre:

```js
import { Worker } from ""worker_threads"";

const code = `
(async function () {
  await new Promise((resolve) => setTimeout(resolve, 10 * 1000));
  import('worker_threads');
})();
`;

const worker = new Worker(code, { eval: true });
```

After adding the null pointer check, the error message is like this:

```
node[5913]: ../../src/module_wrap.cc:595:v8::MaybeLocal<v8::Promise> node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::Data>, v8::Local<v8::Value>, v8::Local<v8::String>, v8::Local<v8::FixedArray>): Assertion `(it) != (env->id_to_script_map.end())' failed.
 1: 0x55f5348bd284 node::Abort() [node]
 2: 0x55f5348bd318  [node]
 3: 0x55f53487286c  [node]
 4: 0x55f534c69a30 v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::Handle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>, v8::internal::MaybeHandle<v8::internal::Object>) [node]
 5: 0x55f53510aa86 v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) [node]
 6: 0x55f535577eb4  [node]
```

I will continue to focus on this issue.","leizongmin",841625,"2022-05-30 16:50:07",NULL
1625,281,"I found this issue is related to https://github.com/nodejs/node/issues/38695 and https://github.com/nodejs/node/issues/25424
","leizongmin",841625,"2022-06-06 17:36:02",NULL
1626,281,"Simpler reproducible code
Check https://github.com/nodejs/node/issues/44211#issuecomment-1271137984 for the fix I came with :)

```js
const vm = require('node:vm')

const code = `
new Promise(resolve => {
  setTimeout(() => {
    gc(); // gc the vm.Script instance, causing executing 'import' in microtask a segment fault
    resolve();
  }, 1);
}).then(() => import('http'));`

// under the hood, a vm.Script instance is created
vm.runInThisContext(code)
```","ywave620",60539365,"2022-10-08 03:11:26",NULL
1627,281,"Related: https://github.com/nodejs/node/issues/47096","transitive-bullshit",552829,"2023-03-15 16:37:13",NULL
1628,281,"Another minimized test case from a different perspective is this:
node-segfault.js:
```
let Module = module.constructor;
Module.wrap = Module.wrap; // put the loader into patched mode
let { dynamicImport } = require('./dynamic-import');
gc();
dynamicImport();
```
dynamic-import.js:
```
module.exports.dynamicImport = () => { return import ('./node-segfault.js'); } // dynamically import anything
```
Setting the `Module.wrap` puts the loader into ""patched"" mode, where it uses the vm Script/context object. This creates a `ContextifyScript`, which [records the script ids in the `id_to_script_map` map, but is also weakly referenced](https://github.com/nodejs/node/blob/main/src/node_contextify.cc#L1111-L1112), so the garbage collection causes the id/script to be removed from `id_to_script_map` when GC'ed, and so the offending line from `ImportModuleDynamically` attempts to access a script by id that is no longer there.

To help with anyone searching for the segfault isses, modifying/patching `Module.wrap` is done by some libraries, like the [rewire package](https://www.npmjs.com/package/rewire). And if you came here looking for a terrible and horrible hack to work around this seg fault, you can do this to prevent the GC-induced segfault:
```
const { Script } = require('vm');
let pinnedScripts = [];
let originalRun = Script.prototype.runInThisContext;
Script.prototype.runInThisContext = function (options) {
	pinnedScripts.push(this);
	return originalRun.call(this, options);
};
```
Making `ContextifyScript` not weak also eliminates this issue, but I assume scripts are supposed to be collectable.","kriszyp",34054,"2023-05-04 12:10:28",NULL
1629,281,"I tested https://github.com/nodejs/node/pull/48510 on the repro in the OP, in https://github.com/nodejs/node/issues/43205#issuecomment-1272209939 and https://github.com/nodejs/node/issues/43205#issuecomment-1534663358 and they are all fixed locally. I'll write a test based on the repo in https://github.com/nodejs/node/issues/43205#issuecomment-1272209939 in the PR because it's simpler","joyeecheung",4299420,"2023-06-22 11:18:06",NULL
1630,281,"> To help with anyone searching for the segfault isses, modifying/patching `Module.wrap` is done by some libraries, like the [rewire package](https://www.npmjs.com/package/rewire). And if you came here looking for a terrible and horrible hack to work around this seg fault, you can do this to prevent the GC-induced segfault:
> 
> ```
> const { Script } = require('vm');
> let pinnedScripts = [];
> let originalRun = Script.prototype.runInThisContext;
> Script.prototype.runInThisContext = function (options) {
> 	pinnedScripts.push(this);
> 	return originalRun.call(this, options);
> };
> ```
> 
> Making `ContextifyScript` not weak also eliminates this issue, but I assume scripts are supposed to be collectable.

I've been trying to use this workaround but I'm not getting it to stick. I have the exact same issue as here, but with typescript. Forgive me for being a total js/ts beginner, but can you give a wider example of where to put the workaround? Specifically, I have a jest test with a beforeAll. I tried it both in the top of the file as well as in the beforeAll and my jest test setup script (ts), but to no effect.","etnoy",135728,"2023-07-27 21:10:04",NULL
1631,281,"@etnoy You might try verifying/debugging that the `pinnedScripts` are indeed being appended. And I believe you do need to ensure that this is executed before you load the module that will execute a dynamic import. Sorry, I don't have any suggestions besides that.","kriszyp",34054,"2023-07-28 01:40:15",NULL
1632,281,"> @etnoy You might try verifying/debugging that the `pinnedScripts` are indeed being appended. And I believe you do need to ensure that this is executed before you load the module that will execute a dynamic import. Sorry, I don't have any suggestions besides that.

Thanks, will do!","etnoy",135728,"2023-07-28 10:55:19",NULL
1633,281,"Closing as https://github.com/nodejs/node/pull/48510 has landed and should fix this. We can re-open if that turns out to be incorrect (hopefully not).","joyeecheung",4299420,"2023-09-14 15:47:58",NULL
1634,282,"/cc @nodejs/workers ","aduh95",14309773,"2022-05-22 21:26:06",NULL
1635,282,"V8 asserts the evaluation of the module's async function to succeed without exception. However, the problem is that TerminateExecution initiated by `process.exit` is breaking that assumption. I'll work on this and submit a fix to v8.","legendecas",8500303,"2022-05-31 03:54:47",NULL
1636,282,"@legendecas, are you working on this?","sajal50",6915961,"2022-06-16 18:05:28",NULL
1637,282,"@sajal50 yeah, it is still under review at https://chromium-review.googlesource.com/c/v8/v8/+/3696493.","legendecas",8500303,"2022-06-17 02:03:22",NULL
1638,282,"https://chromium-review.googlesource.com/c/v8/v8/+/3696493 has landed. I'll continue to investigate if node handles these termination exceptions properly.","legendecas",8500303,"2022-06-29 16:42:19",NULL
1642,282,"@szmarczak I tried a backport but V8 has changed a lot since v14. It might need a totally new patch for the issue on v14 (and a refresh review on the patch too).","legendecas",8500303,"2022-10-26 16:45:44",NULL
1644,283,"That's almost certainly caused by the upgrade to openssl 3. I don't know what your https://server.local endpoint is doing but try checking what the TLS version and cipher are with v16 and v18.","bnoordhuis",275871,"2022-05-17 18:34:03",NULL
1645,283,"@bnoordhuis Thanks for reply. Sorry, I forgot to mention about server with ssl

### ssl server
SSL server it is just plain nginx with self signed certificate and one location
```
location / {
    return 200 'hello world';
}
```
In first attempts to debug issue I was using node.js with ssl as a server, but then replaced it with nginx. The problem with node.js which performs outbound ssl requests.

### tls version and cipher
I tried to compare ssl information in v16 and v18, but haven't found difference.
**v16** [node --trace-tls full output](https://pastebin.com/BXKH6Prj)
```
Received Record
Header:
  Version = TLS 1.2 (0x303)
  Content Type = Handshake (22)
  Length = 69
    ServerHello, Length=65
      server_version=0x303 (TLS 1.2)
      Random:
        gmt_unix_time=0x3C4CEC8D
        random_bytes (len=28): 7E124B88A8D3A98A4435610DB3FA64121B975A23E157B3D023ED8310
      session_id (len=0):
      cipher_suite {0xC0, 0x2F} TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
...
    ServerKeyExchange, Length=296
      KeyExchangeAlgorithm=ECDHE
...
```
v18 [node --trace-tls full output](https://pastebin.com/iTGKjcmD)
```
Received Record
Header:
  Version = TLS 1.2 (0x303)
  Content Type = Handshake (22)
  Length = 69
    ServerHello, Length=65
      server_version=0x303 (TLS 1.2)
      Random:
        gmt_unix_time=0x3625953A
        random_bytes (len=28): DDB717917379017CD1B82F3D10ECCBD3CE5FCD94F0BFF08D59C1FBBB
      session_id (len=0):
      cipher_suite {0xC0, 0x2F} TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
...
    ServerKeyExchange, Length=296
      KeyExchangeAlgorithm=ECDHE
...
```

### perf logs comparision
One interesting thing, which I don't know how to treat correctly is in perf logs. 
For **v16** it looks like this
```
 [Summary]:
   ticks  total  nonlib   name
  12338    7.7%   34.2%  JavaScript
  23649   14.7%   65.5%  C++
   3711    2.3%   10.3%  GC
  124857   77.6%          Shared libraries
    131    0.1%          Unaccounted

 [C++ entry points]:
   ticks    cpp   total   name
   2758   21.6%    1.7%  writev@@GLIBC_2.2.5
   2467   19.3%    1.5%  __write@@GLIBC_2.2.5
   1857   14.5%    1.2%  __libc_malloc@@GLIBC_2.2.5
   1203    9.4%    0.7%  cfree@GLIBC_2.2.5
```
For **v18**
```
 [Summary]:
   ticks  total  nonlib   name
   2049    1.2%   11.2%  JavaScript
  16170    9.7%   88.7%  C++
    601    0.4%    3.3%  GC
  148780   89.1%          Shared libraries
     20    0.0%          Unaccounted

 [C++ entry points]:
   ticks    cpp   total   name
   5513   37.9%    3.3%  __pthread_rwlock_unlock@GLIBC_2.2.5
   4488   30.9%    2.7%  __pthread_rwlock_rdlock@GLIBC_2.2.5
   1638   11.3%    1.0%  __libc_malloc@@GLIBC_2.2.5
    746    5.1%    0.4%  __pthread_rwlock_wrlock@GLIBC_2.2.5
    590    4.1%    0.4%  cfree@GLIBC_2.2.5
    349    2.4%    0.2%  writev@@GLIBC_2.2.5
```

If I read this correctly in v18 (openssl 3) application spends most of the time in locks (pthread_rwlock_unlock and pthread_rwlock_rdlock)","str1ke",1708854,"2022-05-18 02:26:17",NULL
1646,283,"Also one interesting observation for node.js **v18.1.0** + `fetch` as http client
```
const http = require(""http"");

const handler = async (req, res) => {
  const response = await fetch(""https://server.local"");
  const body = await response.text();

  res.statusCode = response.status;
  res.setHeader('Content-Type', 'text/plain');
  res.end(body);
};

const server = http.createServer(handler);

server.listen(3000);
```
gives me ~1500 req/s and in `node --prof` I don't see significant locking:
```
 [Summary]:
   ticks  total  nonlib   name
  54935   13.2%   52.7%  JavaScript
  48467   11.7%   46.5%  C++
  14309    3.4%   13.7%  GC
  310969   74.9%          Shared libraries
    761    0.2%          Unaccounted

 [C++ entry points]:
   ticks    cpp   total   name
  11996   41.7%    2.9%  writev@@GLIBC_2.2.5
   8636   30.0%    2.1%  __write@@GLIBC_2.2.5
   3711   12.9%    0.9%  __libc_malloc@@GLIBC_2.2.5
   1252    4.4%    0.3%  cfree@GLIBC_2.2.5
    534    1.9%    0.1%  setsockopt@@GLIBC_2.2.5
    503    1.7%    0.1%  operator new(unsigned long)
    362    1.3%    0.1%  operator delete(void*)
```
TLS info
```
...
Received Record
Header:
  Version = TLS 1.2 (0x303)
  Content Type = Handshake (22)
  Length = 69
    ServerHello, Length=65
      server_version=0x303 (TLS 1.2)
      Random:
        gmt_unix_time=0x5C93AD24
        random_bytes (len=28): 61F44DBFE0F5B0DD517392FB05CDF79E22671C8F512B0DF0A5FC2B2D
      session_id (len=0):
      cipher_suite {0xC0, 0x2F} TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
...
    ServerKeyExchange, Length=296
      KeyExchangeAlgorithm=ECDHE
```
In cpu profiler there is no `SecureContext.init()`

I'm assume that `https.get` and `fetch` are using same openssl version, but performance 180 req/s vs 1500 req/s","str1ke",1708854,"2022-05-18 07:14:45",NULL
1647,283,"I am facing this issue too

My EC2 always use all the CPU resource every few days,
Than I need restart the node every few days.

Then I find out CPU usage 100% when the nodes that used web socket,
Other nodes is normal without used socket.
(I am running 12 nodes on this EC2)

Few days ago, I tried to resolve it by switched the Node.js version from v17.9.0 to v16.15.0.

![image](https://user-images.githubusercontent.com/14261588/169201419-29aab25a-0702-43d4-9d73-5d23f92e0d30.png)
![image](https://user-images.githubusercontent.com/14261588/169201453-aca640ec-0ba2-4596-9ce9-8d8854f022be.png)
","Cow258",14261588,"2022-05-19 03:53:48",NULL
1648,283,"Feb 11
I upgraded to Node.js v17.5.0 and had no issues.

Apr 15
I upgraded to Node.js v17.9.0

Apr 17,21,22,29 and May 5,7,10,14
I got high CPU usage issue

After investigating I believe the problem occurs between v17.5 and v17.9
Also I find this v17.7.2 change log about OpenSSL 3.0.2 that related to is issue.
https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V17.md#2022-03-17-version-1772-current-richardlau

But all the abnormal nodes are not using any TLS and SSL
And all exception nodes use WebSocket identically
`Browser` &lt;HTTPS&gt; `CDN` &lt;HTTP&gt; `EC2 (nodejs reverse proxy)`  &lt;HTTP&gt;  `Node.js Server`

To investigate, I plan to go back to v17.9.0 and do a remote CPU profiling when the problem occurs","Cow258",14261588,"2022-05-19 04:41:32",NULL
1649,283,"In response to https://github.com/nodejs/node/issues/43128#issuecomment-1129500939: the handshake indeed doesn't look materially different and the client and server settle on the same cipher/key exchange algorithm/etc. so that can't really explain it.

The fact that `fetch()` performs well is doubly puzzling. Can you check what the handshake looks like with `fetch()`?

I wonder if HTTP connection pooling / connection reuse (or lack thereof) is the culprit. How many TLS handshakes do you see with v16.x vs. v18.x (and `fetch()`)?","bnoordhuis",275871,"2022-05-19 08:24:48",NULL
1650,283,"@bnoordhuis Looks like I should not use `fetch` with this situation, because it looks like a very different beast in comparison with traditional way to make requests. It indeed use keep-alive and I don't see a way to disable it. According to fetch spec ""Connection"" is a forbidden header and cannot be set. Now it is clear why `fetch` shows such big numbers in req/s

Here is how I checked new tls sessions and connections, there might be a more correct way to count it. I'm listening tls socket events and looking to `https.globalAgent._sessionCache`:
```
...
let secureConnectCount = 0;
let tlsSessionsCount = 0;
let connectCount = 0;

  const outboundRequest = https.get(""https://server.local"", (response) => {
    ...
  }

  outboundRequest.on(""socket"", (tlsSocket) => {
    tlsSocket.on(""connect"", () => { connectCount++ });
    tlsSocket.on(""secureConnect"", () => secureConnectCount++);
    tlsSocket.on(""session"", (...args) => { console.log(""session"", args); tlsSessionsCount++ });
  });
...
```

Both node v16 and v18.1 creates new connection per request and performs tls handshake (secureConnect event on socket). TLS sessions are cached and only one session exists for remote server. So, if I sent 10_000 requests I got 10_000 ""connect"" events, 10_000 ""secureConnect"" events.","str1ke",1708854,"2022-05-19 13:29:27",NULL
1651,283,"Another interesting thing with `v.18.2` release. In same benchmark I got ~480 req/s and `SecureContext.init()` is taking constantly ~35% of total time in profiler without going up during test time. So, right now
v16.15.0 - ~1200 req/s
v18.1.0 - ~180 req/s
v18.2.0 - ~480 req/s

So, v18.2.0 much better and, which is more important, stable result, but I haven't tried it in production yet.","str1ke",1708854,"2022-05-19 13:58:12",NULL
1664,285,"I can duplicate this.

/cc @danbev ","mscdex",54666,"2022-05-05 16:29:45",NULL
1665,285,"I'll open a PR to revert that commit.","danbev",432351,"2022-05-05 17:00:15",NULL
1768,299,"@nodejs/assert ","Trott",718899,"2022-01-27 11:00:42",NULL
1652,283,"Tried to disable ssl sessions at all from nginx side with `ssl_session_cache off` and `ssl_session_tickets off`:

V16.15.0
- 742 req/s
- TLSSocket._start() - 12% total time
- SecureContext.init() - 6-7% total time

v18.1.0 
- 102 req/s
- setSession() - 15% total time
- SecureContext.init() - 60-80% total time

v18.2.0 
- 390 req/s
- setSession() - 32% total time
- SecureContext.init() - 35% total time","str1ke",1708854,"2022-05-19 16:20:36",NULL
1653,283,"I spent some time investigating this and I can indeed confirm that a) it happens, and b) changes in openssl are responsible.

First off, this is v16.15.0 (recorded with perf(1) and `--perf_basic_prof`) at the 1% cut-off point:
```
+    3.79%  node     node                  [.] ssl_cipher_apply_rule
+    3.49%  node     node                  [.] sha512_block_data_order_avx2
+    2.83%  node     node                  [.] fe_mul
+    2.50%  node     libc.so.6             [.] _int_malloc
+    2.49%  node     node                  [.] x25519_fe64_sqr
+    2.03%  node     libc.so.6             [.] malloc
+    1.84%  node     libc.so.6             [.] __strncmp_avx2
+    1.70%  node     libc.so.6             [.] _int_free
+    1.30%  node     node                  [.] v8::internal::StringTable::Data::TryStringToIndexOrLookupExisting<unsigned char>
+    1.07%  node     node                  [.] v8::internal::Scavenger::ScavengeObject<v8::internal::FullHeapObjectSlot>
+    1.00%  node     libc.so.6             [.] cfree@GLIBC_2.2.5
```
And this is v18.2.0:
```
+    5.78%  node     node                  [.] do_name
+    5.35%  node     node                  [.] OPENSSL_LH_retrieve
+    4.88%  node     libc.so.6             [.] pthread_rwlock_unlock@@GLIBC_2.34
+    4.60%  node     libc.so.6             [.] pthread_rwlock_rdlock@GLIBC_2.2.5
+    3.35%  node     node                  [.] OPENSSL_LH_doall_arg
+    3.07%  node     libc.so.6             [.] malloc
+    2.96%  node     node                  [.] ossl_lh_strcasehash
+    2.26%  node     libc.so.6             [.] __strcmp_avx2
+    2.11%  node     libc.so.6             [.] _int_free
+    1.57%  node     libc.so.6             [.] __strcasecmp_l_avx
+    1.41%  node     libc.so.6             [.] _int_malloc
+    1.37%  node     node                  [.] ssl_cipher_apply_rule
+    1.31%  node     node                  [.] ossl_sa_doall_arg
+    1.27%  node     node                  [.] CRYPTO_strndup
+    1.17%  node     node                  [.] ossl_lib_ctx_get_data
+    1.12%  node     node                  [.] sha512_block_data_order_avx2
+    1.10%  node     node                  [.] OPENSSL_LH_strhash
+    1.04%  node     libc.so.6             [.] cfree@GLIBC_2.2.5
```
It's almost all openssl populating hash tables while holding a lock.

This is all coming from `SecureContext.init()` and `setSession()` (and internal function `addCACerts()`) as noted by @str1ke.

The most common call graph for `do_name()` looks like this:
```
     do_name                                                                                                                                                                   ▒
   - ossl_namemap_doall_names                                                                                                                                                  ▒
      - 3.90% evp_cipher_from_algorithm                                                                                                                                        ▒
           construct_evp_method                                                                                                                                                ▒
           ossl_method_construct_this                                                                                                                                          ▒
           algorithm_do_this                                                                                                                                                   ▒
           ossl_provider_doall_activated                                                                                                                                       ▒
           ossl_algorithm_do_all                                                                                                                                               ▒
           ossl_method_construct                                                                                                                                               ▒
           inner_evp_generic_fetch.constprop.3                                                                                                                                 ▒
           evp_generic_fetch                                                                                                                                                   ▒
           EVP_CIPHER_fetch                                                                                                                                                    ▒
           ssl_evp_cipher_fetch                                                                                                                                                ▒
           ssl_load_ciphers                                                                                                                                                    ▒
           SSL_CTX_new_ex                                                                                                                                                      ▒
         - node::crypto::SecureContext::Init 
```
And for `OPENSSL_LH_retrieve()`:
```
-    5.35%  node     node                  [.] OPENSSL_LH_retrieve                                                                                                             ▒
   - OPENSSL_LH_retrieve                                                                                                                                                       ▒
      - 2.25% ossl_namemap_name2num                                                                                                                                            ▒
         - 1.97% OSSL_DECODER_is_a                                                                                                                                             ▒
            - 1.74% OSSL_DECODER_CTX_add_extra                                                                                                                                 ▒
                 OSSL_DECODER_CTX_new_for_pkey                                                                                                                                 ▒
                 x509_pubkey_ex_d2i_ex                                                                                                                                         ▒
                 asn1_item_embed_d2i                                                                                                                                           ▒
                 asn1_template_noexp_d2i                                                                                                                                       ▒
                 asn1_template_ex_d2i                                                                                                                                          ▒
                 asn1_item_embed_d2i                                                                                                                                           ▒
                 asn1_template_noexp_d2i                                                                                                                                       ▒
                 asn1_template_ex_d2i                                                                                                                                          ▒
               - asn1_item_embed_d2i                                                                                                                                           ▒
                  - 1.13% asn1_template_noexp_d2i                                                                                                                              ▒
                       asn1_template_ex_d2i                                                                                                                                    ▒
                       asn1_item_embed_d2i                                                                                                                                     ▒
                       ASN1_item_d2i                                                                                                                                           ▒
                       d2i_SSL_SESSION                                                                                                                                         ▒
                       node::crypto::GetTLSSession                                                                                                                             ▒
                     - node::crypto::TLSWrap::SetSession                                                                                                                       ▒
                          0.81% Builtins_CallApiCallback                                                                                                                       ▒
                  - 0.61% ASN1_item_d2i                                                                                                                                        ▒
                       d2i_X509_AUX                                                                                                                                            ▒
                       PEM_ASN1_read_bio                                                                                                                                       ▒
                     - node::crypto::SecureContext::AddCACert                                                                                                                  ▒
                        - 0.57% v8::internal::(anonymous namespace)::HandleApiCallHelper<false>                                                                                ▒
                             v8::internal::Builtin_HandleApiCall                                                                                                               ▒
                             Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit                                                                                    ▒
                             Function:^ node:internal/tls/secure-context:56                                                                                                    ▒
                             Builtins_ArrayForEach        
```
I've been going over open performance issues in openssl's bug tracker but I don't see an exact match. https://github.com/openssl/openssl/issues/17627 is the bucket issue. Another pair of eyes would be most welcome.

@nodejs/quic How do we confirm this isn't caused by the QUIC patch we carry?","bnoordhuis",275871,"2022-05-20 11:26:29",NULL
1654,283,"> I'm assume that https.get and fetch are using same openssl version, but performance 180 req/s vs 1500 req/s

`fetch()` will reuse the TLS session by default, while `https.get()` will establish a new one. You can likely simulate a similar setup using `https.Agent()`.","mcollina",52195,"2022-05-20 12:53:37",NULL
1655,283,"@mcollina from my observations `fetch()` and `https.get()` would reuse TLS sessions by default. The difference is that by default `fetch()` would use keep-alive, but `https.get()` not. And it is not possible manage ""connection"" header with `fetch()`.

To put `fetch()` and `https.get()` in similar conditions I had to disable keep-alive on nginx side with `keepalive_timeout 0`. In that conditions `fetch()` and `https.get()` perform at similar level (fetch slower by 10%).

To ensure that there is no keep-alive connections I added to nginx access logs information about connections, number of requests within connection, ssl sessions, ciphers and connection header. It looks like this
```
[20/May/2022:17:11:05 +0000] ""GET / HTTP/1.1"" 200 connection=504978 connection_requests=1 protocol=HTTP/1.1 connection=keep-alive ssl_session_id=f6eaf675369fa0a972188eb614b84cb3d53282f749d08cb09709ad70d0f8b7e5 ssl_cipher=ECDHE-RSA-AES128-GCM-SHA256 ssl_session_reused=r ssl_protocol=TLSv1.2
[20/May/2022:17:11:05 +0000] ""GET / HTTP/1.1"" 200 connection=504979 connection_requests=1 protocol=HTTP/1.1 connection=keep-alive ssl_session_id=f6eaf675369fa0a972188eb614b84cb3d53282f749d08cb09709ad70d0f8b7e5 ssl_cipher=ECDHE-RSA-AES128-GCM-SHA256 ssl_session_reused=r ssl_protocol=TLSv1.2
```
Both reuse tls session, and despite fetch sends `keep-alive`, nginx does not allow it and number of connections increased and always one request per connection.","str1ke",1708854,"2022-05-20 17:20:57",NULL
1656,283,"> https://github.com/orgs/nodejs/teams/quic How do we confirm this isn't caused by the QUIC patch we carry?

@jasnell is there any dependency left on the QUIC patches. If I remember correctly you removed it and https://github.com/nodejs/node/pull/38233 is the PR to add it back. If there is no dependency then we should be able to build from the OpenSSL source instead of the QUIC branch.  That might be a way to confirm.","mhdawson",9373002,"2022-05-27 19:05:41",NULL
1657,283,"Any update on this issue?","OzySky",12676982,"2022-12-17 20:05:47",NULL
1658,283,"I can't be 100% sure but preponderance of evidence suggests the QUIC patches aren't responsible because they don't touch that part of openssl.

In other words, it's likely an upstream issue. We don't have control over that so I'm going to close this. If someone wants to pursue this upstream, please do.","bnoordhuis",275871,"2022-12-29 10:36:34",NULL
1659,283,"Please excuse my ignorance, but is the theory, that upgrading OpenSSL from 1.1.1 to 3.x caused the issue? If so, could OpenSSL 1.1.1 still be bundled/used?","paulmenzel",9318792,"2022-12-29 11:10:10",NULL
1660,283,"@paulmenzel Yes, the upgrade to 3.x is the likely culprit. Building from source and linking dynamically against v1.1.1 should work; it's tested by node's CI matrix.","bnoordhuis",275871,"2022-12-29 11:39:47",NULL
1661,283,"This could be related to https://github.com/openssl/openssl/issues/15199, which is fixed in https://github.com/openssl/openssl/pull/17881, which would be part of OpenSSL 3.1.","krk",1447853,"2022-12-29 19:50:32",NULL
1662,284,"I can reproduce the problem in the main branch. I'll take a look at this.","legendecas",8500303,"2022-05-17 02:42:37",NULL
1666,285,"I think that it is time for at least a basic addon building unit test - 18.1.0 is seriously broken because of this","mmomtchev",31410344,"2022-05-09 11:02:22",NULL
1667,285,"Hope to ship the fix in a Node.js 18 release this week (as long as we do not hit any unexpected problems/delays). ","BethGriggs",8297234,"2022-05-09 11:49:51",NULL
1668,285,"Closing, this was fixed months ago by #42978.","bnoordhuis",275871,"2022-12-19 12:28:11",NULL
1669,286,"Isn't this expected behavior? https://github.com/nodejs/node/blob/2691222b650a76bb90893c22d82b654f3cc7e4d5/lib/internal/modules/esm/handle_process_exit.js#L3-L8","RaisinTen",42526976,"2022-04-25 16:07:53",NULL
1670,286,"You're right, it seems that node recognizes that  there are no pending handlers and closes, i got the same result from code
```
await new Promise(r => setTimeout(r, 100).unref())
```

for me return code 13 (that usually means ACCESS_DENIED in linux) was suspicious, I expected it to come from kernel

Printing there a warning (like we had with UnhandledPromiseRejectionWarning) would be nice","zuozp8",1228107,"2022-04-25 16:43:05",NULL
1671,286,"All possible Node.js exit codes are documented in https://nodejs.org/api/process.html#exit-codes
It seems they are just assigned sequentially.","targos",2352663,"2022-04-25 18:20:48",NULL
1672,286,"> Printing there a warning (like we had with UnhandledPromiseRejectionWarning) would be nice

Would you like to send a PR to implement that?

@nodejs/loaders does this sound like a good idea?","RaisinTen",42526976,"2022-04-26 04:23:43",NULL
1673,286,"Sorry, how is this related to loaders? Is it happening inside a custom loader? I don't see anything here to suggest it is—but if it is, I'm wondering if this is something I might catch in #42623.","JakobJingleheimer",3012099,"2022-04-26 06:18:59",NULL
1674,286,"I'm sorry, I meant to ping @nodejs/modules  because of https://github.com/nodejs/node/blob/4f9bc41f1ef325f43b96c5cfacd493c853034315/doc/contributing/collaborator-guide.md?plain=1#L822. Please ignore my previous ping.","RaisinTen",42526976,"2022-04-26 06:36:27",NULL
1675,286,"I can prepare PR after modules team approves the idea","zuozp8",1228107,"2022-04-26 06:57:10",NULL
1676,286,"you might need to revive this change in v8: https://chromium-review.googlesource.com/c/v8/v8/+/2341765","devsnek",5952481,"2022-04-26 13:31:58",NULL
1677,286,"@devsnek what would it take to revive that? @mhdawson @jasnell does Node.js have a process for directing development work on V8 where it does not directly align with the needs of Chrome? There's a few modules things like this, and this is a great example of differing needs of V8 for Chrome and the needs of V8 for Node.js (like modules GC and other hooks). ","guybedford",598730,"2022-04-29 13:16:03",NULL
1678,286,"fwiw they were not against that change, i just lost track of working on it. i'm sure they'd be happy if someone were to CL an updated version.","devsnek",5952481,"2022-04-29 13:31:39",NULL
1679,286,"@guybedford I don't think we have a process. In the past I think individuals like @joyeecheung and possible @legendecas have submitted PRs and stickhandled them through the V8 process.  @devsnek mentions generally V8 has accepted changes.","mhdawson",9373002,"2022-04-29 18:13:37",NULL
1680,286,"I guess the best we can do is clearly mark the direction here then. I've updated the title and added the confirmed bug label, and further suggestions welcome as well.

Top-level await stalled promise handling should be supported by V8. The V8 solution to this problem has already been worked on by @devsnek in https://github.com/nodejs/node/issues/42868#issuecomment-1109802385, but it needs further work to land.","guybedford",598730,"2022-04-29 18:33:22",NULL
1681,286,"Changes to V8 are not necessary per se, the pending promise can be found with the inspector's `Runtime.queryObjects` RPC method. I did a proof of concept in 2019: https://gist.github.com/bnoordhuis/e4f935a0c81c477533c9bdc54b22e837","bnoordhuis",275871,"2022-05-05 01:28:03",NULL
1682,286,"> does Node.js have a process for directing development work on V8 where it does not directly align with the needs of Chrome? There's a few modules things like this, and this is a great example of differing needs of V8 for Chrome and the needs of V8 for Node.js (like modules GC and other hooks).

I think the general convention is that once we confirm a V8 change is necessary (e.g. can reproduce with a V8-only test) we open a bug in the V8 issue tracker and maybe ping someone who's the owner of related V8 components. V8's issue tracker has a NodeJS-Hotlist label for Node.js-related requests. Then someone may take that bug from there.","joyeecheung",4299420,"2022-05-05 04:51:47",NULL
1683,286,"Also about the bug here specifically - I can try to take a look at the bug and the CL and see if I can revive it, as @devsnek suggested. (From a quick glance I think having a V8 API for this case has its merits, as the inspector isn't always available in all of our builds)","joyeecheung",4299420,"2022-05-05 04:57:18",NULL
1684,286,"FYI I have modified the v8 patch a bit and re-uploaded it in the original CL - https://chromium-review.googlesource.com/c/v8/v8/+/2341765/ may need to take some time to take care of the dynamic import use cases mentioned in the previous reviews though.","joyeecheung",4299420,"2022-06-02 08:52:45",NULL
1685,286,"I have a prototype [here](https://github.com/joyeecheung/node/tree/tla-message) which prints this for the repro in the OP

```
Error: Detected unfinished top-level await at file:///Users/joyee/projects/node/unfinished.mjs:1
await new Promise(() => {});
^
``` 

For imported unfinished TLA:

```
Error: Detected unfinished top-level await at file:///Users/joyee/projects/node/mod.mjs:1
await new Promise(() => { 'mod' });
^
```

(By the time we exit and check for the unfinished TLA, the stack is already lost. I guess it's better than printing nothing at all).
","joyeecheung",4299420,"2024-03-02 05:29:04",NULL
1686,287,"Refs: https://github.com/nodejs/node/pull/42701#issuecomment-1105943105","tniessen",3109072,"2022-04-22 20:26:17",NULL
1687,287,"~~I'm currently investigating an issue I'm experiencing in Prettier and was wondering if this is the same issue https://github.com/prettier/prettier/issues/12753~~ Thanks for the help 😄","oliversalzburg",1658949,"2022-05-05 13:47:09",NULL
1688,288,"Related: https://github.com/nodejs/node/blob/a75d4e272481dfaa1353a063a27baf035a6cc37a/lib/internal/perf/timerify.js#L74-L123","himself65",14026360,"2022-04-24 21:54:03",NULL
1689,288,"Upstream PR: https://github.com/nodejs/node/pull/37136

It seems like the memorization is for the performance","himself65",14026360,"2022-04-24 21:55:47",NULL
1690,288,"I'm working on this issue","himself65",14026360,"2022-04-24 21:59:20",NULL
1691,289,"/cc @nodejs/loaders ","aduh95",14309773,"2022-04-13 15:42:31",NULL
1710,289,"> Ah, I think maybe it got lost when the repo was moved into nodejs.

I think you two are talking about different repos. My old repo that got moved into the `nodejs` org is https://github.com/nodejs/loaders-test. The one @guybedford is referring to is https://github.com/node-loader/node-loader-http, part of a separate org https://github.com/node-loader/.","GeoffreyBooth",456802,"2022-05-01 23:17:48",NULL
1711,289,"> Once the chaining PR is in, I'll focus on fixing this :)

Not sure I agree with the prioritization here, but thanks for keeping it on the radar!","guybedford",598730,"2022-05-02 00:06:00",NULL
1712,289,"The chaining PR is almost done.","GeoffreyBooth",456802,"2022-05-02 02:22:43",NULL
1713,289,"Chaining PR has landed. Focusing on this now.","JakobJingleheimer",3012099,"2022-05-04 16:32:37",NULL
1832,305,"/cc @BridgeAR ","targos",2352663,"2021-12-06 09:48:00",NULL
1833,306,"@nodejs/async_hooks ","targos",2352663,"2021-11-29 12:27:45",NULL
1692,289,"Dynamic import appears to be a red herring—I get the same error for a regular import:

```console
node \
  --experimental-loader=/…/https-loader.mjs \
  --input-type=module \
  -e ""import lodash from 'https://unpkg.com/lodash-es@4.17.21/lodash.js'; console.log(lodash)""
```

My `https-loader.mjs` is a copy-paste of the example in the docs.

The error thrown is from `ESMLoader::getBaseURL()`, which is part of [experimental network imports](https://nodejs.org/api/esm.html#https-and-http-imports) (and subsequently uses `esm/fetch_module`). I think this code should not be hit as `--experimental-network-imports` was not supplied 🤔

I think the introduction of network imports broke this example, causing ESMLoader to try to use pieces of itself that haven't been hydrated as it expects (because the code went through a different journey).

Switching from a custom loader to a network import does work:

```console
node \
  --experimental-network-imports \
  --input-type=module \
  -e ""import('https://unpkg.com/lodash-es@4.17.21/lodash.js').then(console.log)""
```

I'll need to dig into this a little more to see if this is worth fixing, or if we should just tell people to use a network import.","JakobJingleheimer",3012099,"2022-04-16 20:17:05",NULL
1693,289,"It should be possible to make a custom loader to do what `--experimental-network-imports` does, both in principle and so that people have a way to achieve use cases that `--experimental-network-imports` excludes (like supporting `http:` URLs, for example).","GeoffreyBooth",456802,"2022-04-17 23:05:44",NULL
1694,289,"The problem occurs when the request is not made through network imports: `ModuleJob::linked` looks up the cached value of the request, which, when network imports is circumvented, is an unsettled promise. It uses `ESMLoader::getBaseURL()` to do that, and this error is `ESMLoader::getBaseURL()` detecting the problem. I think `ESMLoader::getBaseURL()` needs to stay synchronous (so it can't `await` the pending request) (cc @bmeck ?).

ModuleJob can't `await` `ESMLoader::getBaseURL()`'s return because `ESMLoader::getBaseURL()` needs to pluck `resolvedHREF` from the pre-settled promise's value.

In my above example, the problem occurs when resolving `lodash.js`'s imports (`parentURL` should be `https://…`, but it's nothing because of the unsettled promise), and then hits `defaultResolve()`.

On the surface, this seems like a catch-22. I'll try to look more into this later this week.

EDIT: Perhaps if we only throw in `ESMLoader::getBaseURL()` when the network imports flag is set and then anywhere that would receive the unsettled promise awaits it and themselves pluck `resolvedHREF`, that could maybe do it 🤔 That might spiral though.","JakobJingleheimer",3012099,"2022-04-18 09:52:57",NULL
1695,289,"> EDIT: Perhaps if we only throw in `ESMLoader::getBaseURL()` when the network imports flag is set and then anywhere that would receive the unsettled promise awaits it and themselves pluck `resolvedHREF`, that could maybe do it 🤔 That might spiral though.

<details>
<summary>esm/module_job.js</summary>

```js
      const promises = this.module.link(async (specifier, assertions) => {
        const base = await this.loader.getBaseURL(url);
        const baseURL = typeof base === 'string' ?
          base :
          base.resolvedHREF;

        const jobPromise = this.loader.getModuleJob(specifier, baseURL, assertions);
        ArrayPrototypePush(dependencyJobs, jobPromise);
        const job = await jobPromise;
        return job.modulePromise;
      });
```
</details>

<details>
<summary>esm/loader.js</summary>

```js
  getBaseURL(url) {
    if (
      StringPrototypeStartsWith(url, 'http:') ||
      StringPrototypeStartsWith(url, 'https:')
    ) {
      // The request & response have already settled, so they are in
      // fetchModule's cache, in which case, fetchModule returns
      // immediately and synchronously
      const module = fetchModule(new URL(url), { parentURL: url });

      if (typeof module?.resolvedHREF === 'string') { // [2]
        url = module.resolvedHREF;
      } else { // This should only occur if the module hasn't been fetched yet
        if (getOptionValue('--experimental-network-imports')) {
          throw new ERR_INTERNAL_ASSERTION(
            `Base url for module ${url} not loaded.`
          );
        } else {
          url = module;
        }
      }
    }

    return url;
  }
```
</details>

A quick test suggests this route is viable and continues to work when using network imports instead.

@bmeck @GeoffreyBooth thoughts?

A fringe-benefit is the error message no-longer cites `undefined` in ""Base url for module ${url} not loaded."" (`url` was previously getting overwritten before the error message is printed), and it instead includes the URL of the parent.","JakobJingleheimer",3012099,"2022-04-18 17:04:15",NULL
1696,289,"I haven't dug into the code, but can you explain why the base URL isn't known while the promise is unsettled? Like don't we know what URL we're in the process of resolving, and therefore we also know its base URL?","GeoffreyBooth",456802,"2022-04-18 17:19:35",NULL
1697,289,"I think because of redirects?","JakobJingleheimer",3012099,"2022-04-18 17:29:37",NULL
1698,289,"I can verify this bug is breaking JSPM support for network imports with Node.js import maps. We can't use `--experimental-network-imports` because packages import core modules from the network.","guybedford",598730,"2022-04-21 14:39:28",NULL
1699,289,"It's pretty ironic that the PR that introduced network imports broke network imports. Is anyone working on a fix?","guybedford",598730,"2022-04-29 13:07:07",NULL
1700,289,"C'est moi. Loader chaining is inches from done and the fix I outlined above touches the same piece that appears to be blocking Loader chaining; I've been trying to investigate the issue blocking loader chaining for a few weeks now and reaallly don't want to flip the table on that and have to start all over.","JakobJingleheimer",3012099,"2022-04-29 14:13:49",NULL
1701,289,"@JakobJingleheimer is that the async hooks thing? Note that the Node.js bootstrap cannot be altered in terms of timing... I lost a lot of cycles to that as well in the past.","guybedford",598730,"2022-04-29 14:30:38",NULL
1702,289,"Yes, it's the async_hooks thing, and I'm super baffled cuz everything looks exactly like it should.

If that is it, I don't understand why that would be affected by my change: my change only affects things when multiple custom loaders are supplied. The existing code that handles regular imports isn't changed.","JakobJingleheimer",3012099,"2022-04-29 14:33:38",NULL
1703,289,"Is it possible to be a bit more specific regarding `Yes, it's the async_hooks thing`?

I have not that much idea about loaders,... but I know async hooks. if there is a concrete problem I should look into let me know.","Flarna",18708370,"2022-04-29 16:22:56",NULL
1704,289,"@JakobJingleheimer if you're interested in trying out the case against the chaining PR, this is the loader that is broken - https://github.com/node-loader/node-loader-http.","guybedford",598730,"2022-04-29 16:26:20",NULL
1705,289,"@Flarna I'd certainly appreciate some insight into what the heck is wrong; shall we move to the chaining PR though? There's a specific test cited there that provides a very concrete example (but I have absolutely no idea what the actual problem is). I'd also be happy to jump on a call.

@guybedford haha thanks, but you know I wrote that, right? 😜","JakobJingleheimer",3012099,"2022-04-29 21:25:13",NULL
1706,289,"@Flarna I believe ""the async_hook thing"" is https://github.com/nodejs/node/pull/42623#issuecomment-1105349759","targos",2352663,"2022-04-30 07:43:52",NULL
1707,289,"@targos I responded in #42623","JakobJingleheimer",3012099,"2022-04-30 09:05:37",NULL
1708,289,"> haha thanks, but you know I wrote that, right? 😜

No, because you aren't attributed at all! Are you definitely sure the chaining PR will fix this issue? I can also put some time aside to test that if it would help.","guybedford",598730,"2022-05-01 15:18:35",NULL
1709,289,"> No, because you aren't attributed at all!

Ah, I think maybe it got lost when the repo was moved into nodejs.

> Are you definitely sure the chaining PR will fix this issue?

No, I don't think the chaining PR will fix this issue at all.

Once the chaining PR is in, I'll focus on fixing this :)

> I can also put some time aside to test that if it would help.

I'll hit you up soon for it!","JakobJingleheimer",3012099,"2022-05-01 22:01:13",NULL
1854,313,"@nodejs/http @rickyes ","ronag",3065230,"2021-10-14 06:50:31",NULL
1714,289,"@GeoffreyBooth we didn't catch this because https://coffeescript.org/browser-compiler-modern/coffeescript.js (from [nodejs/loaders-test/https-loader](https://github.com/nodejs/loaders-test/tree/main/https-loader)) is a bundle and has no imports of its own.","JakobJingleheimer",3012099,"2022-05-04 19:28:31",NULL
1715,290,"I'd be happy to take a look at this one and open a PR!","austinkelleher",3771924,"2022-04-08 01:11:20",NULL
1716,290,"Thanks for volunteering @austinkelleher, PR’s welcome :)","aduh95",14309773,"2022-04-08 07:46:53",NULL
1717,291,"It seems we already have a series of heap snapshot crashes on v14.x. And their crash backtrace is similar to the one in the OP:

- https://github.com/nodejs/node/issues/38961
- https://github.com/nodejs/node/issues/39258
- https://github.com/nodejs/node/issues/37878
- ~~https://github.com/nodejs/node/issues/37069~~
","legendecas",8500303,"2022-04-01 09:02:13",NULL
1718,291,"I can confirm the problem can be fixed by a small v8 patch: https://chromium-review.googlesource.com/c/v8/v8/+/2277806","legendecas",8500303,"2022-04-07 06:06:28",NULL
1719,291,"V8 bug tracking the problem: https://bugs.chromium.org/p/v8/issues/detail?id=10629","legendecas",8500303,"2022-04-07 06:17:31",NULL
1720,291,"Closing as https://github.com/nodejs/node/pull/42637 has landed.","legendecas",8500303,"2022-04-29 14:06:32",NULL
1721,292,"Hi,
Can I have a try on this issue?","ritikBhandari",69508348,"2022-03-14 17:17:00",NULL
1722,292,"This affects all platforms, not just Windows. It's an oversight in https://github.com/nodejs/node/pull/39069.

I've opened https://github.com/nodejs/node/pull/48522 to fix.","richardlau",5445507,"2023-06-22 15:31:55",NULL
1723,293,"@nodejs/url @nodejs/buffer ","Trott",718899,"2022-03-04 02:08:44",NULL
1724,294,"Shouldn't this always use the this value of the caller instead of the async resource?","bmeck",234659,"2022-03-03 15:18:45",NULL
1725,294,"> Shouldn't this always use the this value of the caller instead of the async resource?

Yes, this is basically what it's doing:

- Default to the caller.
- If `thisArg` is passed explicitly then that's used instead.
- The async resource is no longer used unless explicitly passed as the `thisArg`.","rochdev",1596303,"2022-03-03 22:03:04",NULL
1726,294,"CI: https://ci.nodejs.org/job/node-test-pull-request/42862/","nodejs-github-bot",18269663,"2022-03-04 10:43:04",NULL
1727,294,"CI: https://ci.nodejs.org/job/node-test-pull-request/42863/","nodejs-github-bot",18269663,"2022-03-04 12:49:11",NULL
1728,294,"CI: https://ci.nodejs.org/job/node-test-pull-request/42866/","nodejs-github-bot",18269663,"2022-03-04 14:17:30",NULL
1729,294,"CI: https://ci.nodejs.org/job/node-test-pull-request/42901/","nodejs-github-bot",18269663,"2022-03-07 22:59:23",NULL
1730,294,"CI: https://ci.nodejs.org/job/node-test-pull-request/42907/","nodejs-github-bot",18269663,"2022-03-08 10:01:31",NULL
1731,294,"CI: https://ci.nodejs.org/job/node-test-pull-request/42909/","nodejs-github-bot",18269663,"2022-03-08 13:55:32",NULL
1732,294,"CI: https://ci.nodejs.org/job/node-test-pull-request/42915/","nodejs-github-bot",18269663,"2022-03-08 20:38:36",NULL
1733,294,"Landed in 409c594887b077701ce69e2959445049b84aaa50","nodejs-github-bot",18269663,"2022-03-08 22:00:57",NULL
1734,296,"> TypeError [ERR_INVALID_URL]: Invalid URL

From this error, it seems the loader doesn't support relative URL references yet, which would mean it won't work with... almost anything 🤔 Or maybe it's the `.js` extension that's the issue?","MartinKolarik",6192491,"2022-02-18 21:56:59",NULL
1735,296,"@nodejs/modules ","ljharb",45469,"2022-02-23 19:14:30",NULL
1736,296,"This looks like a bug with `--experimental-network-imports`, which is very new (shipped about a week ago). The ESM support that Node has had for the last few years hasn’t included support for `http:` or `https:` URLs, until `--experimental-network-imports`, so the docs around ESM are generally referring to local file URLs.","GeoffreyBooth",456802,"2022-02-23 19:25:23",NULL
1737,296,"I'm working on a fix (for https modules that contain relative imports)","JakobJingleheimer",3012099,"2022-02-23 19:26:58",NULL
1738,296,"This may be obvious, but putting it here in case it isn't: even if relative imports worked, `uuid`-s `wrapper.mjs` won't work because `./dist/index.js` is a CJS module.","giltayar",403268,"2022-02-24 06:49:56",NULL
1739,296,"> This may be obvious, but putting it here in case it isn't: even if relative imports worked, `uuid`-s `wrapper.mjs` won't work because `./dist/index.js` is a CJS module.

`import 'https://ga.jspm.io/npm:uuid@8.3.2/wrapper.mjs'` should work. jspm transforms CJS to ESM.","targos",2352663,"2022-02-24 06:57:31",NULL
1740,296,"So does jsDelivr, `import { v4 as uuidv4 } from 'https://cdn.jsdelivr.net/npm/uuid@8.3.2/wrapper.mjs/+esm';` should work once the paths issue is fixed.","MartinKolarik",6192491,"2022-02-24 12:34:52",NULL
1741,296,"A fix would be something like:

```js
index 61e609d9ad..d0579e5e5b 100644
--- a/lib/internal/modules/esm/loader.js
+++ b/lib/internal/modules/esm/loader.js
@@ -574,11 +574,12 @@ class ESMLoader {
       );
     }
 
-    new URL(url); // Intentionally trigger error if `url` is invalid
+    // Error early and resolve base urls for https imports
+    const withParent = new URL(url, parentURL);
 
     return {
       format,
-      url,
+      url:  withParent.href,
     };
   
```

Note @MartinKolarik that https://cdn.jsdelivr.net/npm/uuid@8.3.2/wrapper.mjs/+esm returns a 404 so I wasn't able to test that with the patch.


(Edit: note a real patch would also include fixing local imports that is fixing checkIfDisallowedImport )","benjamingr",1315533,"2022-02-24 13:18:34",NULL
1742,296,"> Note @MartinKolarik that https://cdn.jsdelivr.net/npm/uuid@8.3.2/wrapper.mjs/+esm returns a 404 so I wasn't able to test that with the patch.

Thanks for the ping, I forgot it now enforces the `exports` field entry points, so it would be just `https://cdn.jsdelivr.net/npm/uuid@8.3.2/+esm` but that's the browser version 🤔 I suppose restricting the entry points on a CDN is not a good idea, we'll change it.","MartinKolarik",6192491,"2022-02-24 13:23:56",NULL
1743,296,"> but that's the browser version 🤔 

Yeah, that returns:

```
Error: crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported
```

With the patch but at least it loads the package. ","benjamingr",1315533,"2022-02-24 14:25:52",NULL
1744,296,"> With the patch but at least it loads the package.

👍 we'll tweak the jsDelivr behavior to support the first link in the next few days.","MartinKolarik",6192491,"2022-02-24 14:33:03",NULL
1745,296,"https://cdn.jsdelivr.net/npm/uuid@8.3.2/wrapper.mjs/+esm now works.","MartinKolarik",6192491,"2022-03-02 20:28:42",NULL
1746,296,"can we get confirmation to close this? It should be fixed now that the PR is closed and 17.7.0 is released. I'd note that the unpkg URL still fails due to referencing a URL that is a 404 though, node can't fix that one.","bmeck",234659,"2022-03-10 21:05:26",NULL
1747,296,"Confirmed fixed on 17.7.1. It will still fail due to the `crypto.getRandomValues()` issue, but module loading now works.

```javascript
import { v4 as uuidv4 } from 'https://cdn.jsdelivr.net/npm/uuid@8.3.2/wrapper.mjs/+esm';
console.log(uuidv4());
```","yavorg",1086030,"2022-03-11 00:37:00",NULL
1764,298,">  won't resume it when the target drains? 

Do you have an example of this?","ronag",3065230,"2022-01-31 20:34:22",NULL
1765,298,"> @benjamingr regarding your example, 'drain' is emitted in the same tick as the callback invocation, hence the readable is read immediately and again fills the writable, hence it is paused again.

Oh yeah that makes sense. I was sleepy after all :]","benjamingr",1315533,"2022-01-31 21:05:06",NULL
1748,296,"Hi this is slightly unrelated but figured I would post it here in case anyone else finds this thread like I did. In my case I was getting the same error `Unknown module format: null for URL` for a completely different reason. The file I was importing had another file with the same name but different extension in the directory, so I guess node was confused which one to actually import. Deleting the other file solved the issue. This makes sense since I was importing the file without an extension in the import line -- thus it was ambiguous. ","sheunaluko",10824190,"2022-06-02 04:24:37",NULL
1749,296,"```javascript
import fetch from 'https://cdn.jsdelivr.net/npm/node-fetch/+esm'

const run = async () => {
...
}

run()
```

```
$ node --experimental-network-imports index.mjs 
(node:45992) ExperimentalWarning: Network Imports is an experimental feature and might change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
node:internal/errors:490
    ErrorCaptureStackTrace(err);
    ^

Error [ERR_NETWORK_IMPORT_DISALLOWED]: import of 'node:http' by https://cdn.jsdelivr.net/npm/node-fetch/+esm is not supported: only relative and absolute specifiers are supported.
    at new NodeError (node:internal/errors:399:5)
    at checkIfDisallowedImport (node:internal/modules/esm/resolve:1026:13)
    at defaultResolve (node:internal/modules/esm/resolve:1124:23)
    at nextResolve (node:internal/modules/esm/loader:163:28)
    at ESMLoader.resolve (node:internal/modules/esm/loader:838:30)
    at ESMLoader.getModuleJob (node:internal/modules/esm/loader:424:18)
    at ModuleWrap.<anonymous> (node:internal/modules/esm/module_job:77:40)
    at link (node:internal/modules/esm/module_job:76:36)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5) {
  code: 'ERR_NETWORK_IMPORT_DISALLOWED'
}
```

Slightly related.","brandonros",8949910,"2023-04-17 15:43:31",NULL
1750,297,"Confirmed this reproduces on master, taking a look","benjamingr",1315533,"2022-02-10 09:59:35",NULL
1751,297,"Opened a PR to fix at https://github.com/nodejs/node/pull/41919 thanks for the detailed report","benjamingr",1315533,"2022-02-10 10:05:10",NULL
1752,297,"There is a second issue here (other than the EINVAL) - the fact it's not catchable, I'll investigate","benjamingr",1315533,"2022-02-10 11:37:33",NULL
1753,297,"This causes a segfault for example:

```js
    // Writev with bad array-like
    await assert.rejects(async () => {
      const handle = await fs.open(getFileName(), 'w');
      const badArray = new Proxy([], { get(target, prop) {
        if(prop === 'length') return -1;
        return Reflect.get(target, prop);
      }});      
      const result = await handle.writev(badArray);
      handle.close();
    }, { code: 'EINVAL' });
```

```
➜  node git:(fix-ev-error) ./out/Release/node --inspect test/parallel/test-fs-writev-promises.js
Debugger listening on ws://127.0.0.1:9229/39dd654c-3663-4e18-8c83-684b1d8fe862
For help, see: https://nodejs.org/en/docs/inspector
./out/Release/node[10237]: ../src/node_file.cc:1891:void node::fs::WriteBuffers(const FunctionCallbackInfo<v8::Value> &): Assertion `args[1]->IsArray()' failed.
 1: 0x10549f6f5 node::Abort() [/Users/bgruenbaum/Documents/Projects/node/out/Release/node]
 2: 0x10549f521 node::Assert(node::AssertionInfo const&) [/Users/bgruenbaum/Documents/Projects/node/out/Release/node]
 3: 0x1054b1856 node::fs::WriteBuffers(v8::FunctionCallbackInfo<v8::Value> const&) [/Users/bgruenbaum/Documents/Projects/node/out/Release/node]
 4: 0x105680228 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/Users/bgruenbaum/Documents/Projects/node/out/Release/node]
 5: 0x10567fd25 v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/Users/bgruenbaum/Documents/Projects/node/out/Release/node]
 6: 0x10567f3fb v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [/Users/bgruenbaum/Documents/Projects/node/out/Release/node]
 7: 0x105f5edb9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/Users/bgruenbaum/Documents/Projects/node/out/Release/node]
```

So it looks like there are few other places to fix as well","benjamingr",1315533,"2022-02-10 11:46:48",NULL
1754,297,"Yeah - we check IsArray which the v8 docs say:

> Returns true if this value is an array. Note that it will return false for an [Proxy](https://v8.github.io/api/head/classv8_1_1Proxy.html) for an array.","benjamingr",1315533,"2022-02-10 11:50:07",NULL
1755,297,"Should this remain open to track the other problems discussed in #41919?","isker",5225653,"2022-02-12 18:08:24",NULL
1756,297,"Probably a good idea to open a new issue","benjamingr",1315533,"2022-02-12 18:41:55",NULL
1757,298,"Probably https://github.com/nodejs/node/commit/4793f165dc from https://github.com/nodejs/node/pull/36563 to fix https://github.com/nodejs/node/issues/36544","benjamingr",1315533,"2022-01-31 15:21:03",NULL
1758,298,"cc @ronag ","benjamingr",1315533,"2022-01-31 15:22:17",NULL
1759,298,"> The fact that Readable.pipe() decides if it should pause or resume the source depending on the status of the target looks a bit inconsistent to me, and if not fixed, I believe that at least it would need to be documented.

I think it makes sense not to resume a source if you currently can't (conceptually) take more data. Showing interest in data you can't consume is probably not good?

I think the issue here is that even after the data is drained the source isn't resumed?","benjamingr",1315533,"2022-01-31 15:25:16",NULL
1760,298,"I might be sleepy but I think it's a bug:

```js
const { Readable, Writable } = require('stream');

const readable = new Readable({
    read() {
        this.push('hello');
        this.push('world');
        this.push(null);
    },
    objectMode: true
});

let cb;
const writable = new Writable({
    write(chunk, encoding, callback) {
        // don't call callback, save for later
        cb = callback;
    },
    highWaterMark: 1,
    objectMode: true
});
writable.write('a');
console.log(writable.writableNeedDrain); // true
console.log(readable.isPaused()); // false
readable.pipe(writable);
console.log(readable.isPaused()); // true
cb();
console.log(readable.isPaused()); // true, but I'd expect it to be false
```","benjamingr",1315533,"2022-01-31 15:31:19",NULL
1761,298,"Thanks for your prompt response and your input, @benjamingr 

> I think it makes sense not to resume a source if you currently can't (conceptually) take more data. Showing interest in data you can't consume is probably not good?

Yep, that might make sense. Although the previous behaviour (resuming it) would make sense as well. When you pipe a source is like adding a `data` listener somehow, and it makes sense to resume a source when a `data` listener.

And what about to pause a source when you pipe it to a target that needs drain? I would say that in this case, `Readable.pipe()` is overdoing things a bit. Anyway, both things should be documented somewhere, because they are far from being intuitive.

> I think the issue here is that even after the data is drained the source isn't resumed?

Definitely. I would expect pipe to handle that.
","tufosa",5946180,"2022-01-31 19:47:44",NULL
1762,298,"I'm not sure I see a problem here.

@benjamingr regarding your example, `'drain'` is emitted in the same tick as the callback invocation, hence the readable is read immediately and again fills the writable, hence it is paused again. Whether the `'drain'` event should occur in same tick as the callback invocation I guess we could think about.

> Yep, that might make sense. Although the previous behaviour (resuming it) would make sense as well. When you pipe a source is like adding a data listener somehow, and it makes sense to resume a source when a data listener.

I don't think it makes sense and also leads to potential memory leaks. The whole `'data'` resumes the stream behaviour is there due to compatibility reasons and something I would consider a mistake from long ago that we can't fix.

>  Anyway, both things should be documented somewhere, because they are far from being intuitive.

PR welcome!

","ronag",3065230,"2022-01-31 20:04:58",NULL
1763,298,"And what about the fact that `pipe` might decide to pause your source because the target needs to drain and won't resume it when the target drains? Does it make sense to you, @ronag? If it does, then I think it should be documented in block capital letters. I am happy to send a PR myself.","tufosa",5946180,"2022-01-31 20:21:42",NULL
1766,298,"> Do you have an example of this?

Yep, @ronag, try the following code:
```
const { PassThrough } = require('stream');

// THIRD EXPERIMENT
console.info('\n********** THIRD EXPERIMENT **********');
const source3 = new PassThrough();
const target3 = new PassThrough();

// stall target3
const chunk = Buffer.allocUnsafe(1000);
let chunks = 1;
while (target3.write(chunk)) chunks++;
console.info(`${chunks} chunks of ${chunk.length} bytes to stall target3`);

// `Readable.pipe()` PAUSES the source if the target needs drain (only in
// version >= v14.17.0) and it does not resume it after drain
console.info(`source3 before pipe. Paused: ${source3.isPaused()}`);
source3.pipe(target3);
console.info(`source3 after pipe. Paused: ${source3.isPaused()}`);
target3.on('drain', () => { 
  console.info('target3 drained');
  console.info(`source3 after drain. Paused: ${source3.isPaused()}`);
});                          
target3.on('data', () => {});
```
if you run this with a version of Nodejs >= v14.17.0, you will get something like
```
********** THIRD EXPERIMENT **********
34 chunks of 1000 bytes to stall target3
source3 before pipe. Paused: false
source3 after pipe. Paused: true
target3 drained
source3 after drain. Paused: true
```
It looks like `Readable.pipe()` pauses the source and does not resume it when the target drains","tufosa",5946180,"2022-02-01 06:16:06",NULL
1767,298,"The flowing part of things work. It's just that `isPaused` returns false even though it kind of shouldn't here.

Looks like a bug with the flowing/paused state of Readable.","ronag",3065230,"2022-02-02 16:03:56",NULL
1769,299,"I don't think we make any guarantees on equality of proxies to non-proxies of the same object in assert so this is more of a feature request than a bug I think?","benjamingr",1315533,"2022-01-27 11:12:48",NULL
1770,299,"Hmm

```
> require('internal/test/binding').internalBinding('util').getOwnNonIndexProperties(new Proxy(['foo'], { ownKeys: (target) => Reflect.ownKeys(target) }), 0)
[ 0, 'length' ]
```

So the issue is that 0 is considered an index property.

So the issue is that

```
object->GetPropertyNames(
        context, KeyCollectionMode::kOwnOnly,
        filter,
        IndexFilter::kSkipIndices)
          .ToLocal(&properties)
```

Does not ignore index properties with a proxy trap?","benjamingr",1315533,"2022-01-27 11:17:39",NULL
1771,299,"Reflect.ownKeys doesn’t just take one argument, and when used in proxy traps, you’re supposed to use the other arguments. What happens if your handler is `{ ownKeys: Reflect.ownKeys }`?","ljharb",45469,"2022-01-27 14:32:24",NULL
1772,299,"@ljharb what are the other arguments?","targos",2352663,"2022-01-27 14:35:37",NULL
1773,299,"The last one is “target”, ie, the receiver. https://tc39.es/ecma262/#sec-proxy-object-internal-methods-and-internal-slots-ownpropertykeys I’m on mobile rn so i haven’t checked to see if it makes a difference.","ljharb",45469,"2022-01-27 14:40:37",NULL
1774,299,"@ljharb it wouldn't matter in this case:

```
> require('internal/test/binding').internalBinding('util').getOwnNonIndexProperties(new Proxy(['foo'], { ownKeys: Reflect.ownKeys }), 0)
[ 0, 'length' ]
> (node:70102) internal/test/binding: These APIs are for internal testing only. Do not use them.
(Use `node --trace-warnings ...` to show where the warning was created)
```

This is a ""bug"" either in v8 or how we use v8 which returns index properties from the call above. (I saw bug because I don't believe we ever discussed what proxy behavior should be)","benjamingr",1315533,"2022-01-27 14:44:12",NULL
1775,299,"@ljharb, The problem still occurs with passing `{ownKeys: Reflect.ownKeys}`
```js
assert.deepEqual(new Proxy(['foo'], { ownKeys: Reflect.ownKeys }), ['foo']) // throws
```
I see in the spec that you're right, it should be passing a `target` argument, but that argument isn't listed in the MDN documentation of `Reflect.ownKeys`.
https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Reflect/ownKeys","itaylor",38120,"2022-01-27 15:46:43",NULL
1776,299,"Proxies are an advanced feature only intended to be used in concert with a membranes implementation, so it’s not surprising that MDN’s docs are incomplete there.","ljharb",45469,"2022-01-27 15:56:50",NULL
1777,299,"A fix can be something like this:

```diff
diff --git a/lib/internal/util/comparisons.js b/lib/internal/util/comparisons.js
index c126bd6346..6a529c100f 100644
--- a/lib/internal/util/comparisons.js
+++ b/lib/internal/util/comparisons.js
@@ -36,6 +36,7 @@ const {
   isRegExp,
   isSet,
   isNativeError,
+  isProxy,
   isBoxedPrimitive,
   isNumberObject,
   isStringObject,
@@ -68,6 +69,14 @@ function areSimilarRegExps(a, b) {
          a.lastIndex === b.lastIndex;
 }
 
+function getOwnNonIndexPropertiesHandleProxies(target, filter) {
+  const res = getOwnNonIndexProperties(target, filter);
+  if (isProxy(target)) {
+    return res.filter((x) => typeof x !== 'number');
+  }
+  return res;
+}
+
 function areSimilarFloatArrays(a, b) {
   if (a.byteLength !== b.byteLength) {
     return false;
@@ -176,8 +185,8 @@ function innerDeepEqual(val1, val2, strict, memos) {
       return false;
     }
     const filter = strict ? ONLY_ENUMERABLE : ONLY_ENUMERABLE | SKIP_SYMBOLS;
-    const keys1 = getOwnNonIndexProperties(val1, filter);
-    const keys2 = getOwnNonIndexProperties(val2, filter);
+    const keys1 = getOwnNonIndexPropertiesHandleProxies(val1, filter);
+    const keys2 = getOwnNonIndexPropertiesHandleProxies(val2, filter);
     if (keys1.length !== keys2.length) {
       return false;
     }
@@ -217,8 +226,8 @@ function innerDeepEqual(val1, val2, strict, memos) {
     // only contain numeric keys, we don't need to exam further than checking
     // the symbols.
     const filter = strict ? ONLY_ENUMERABLE : ONLY_ENUMERABLE | SKIP_SYMBOLS;
-    const keys1 = getOwnNonIndexProperties(val1, filter);
-    const keys2 = getOwnNonIndexProperties(val2, filter);
+    const keys1 = getOwnNonIndexPropertiesHandleProxies(val1, filter);
+    const keys2 = getOwnNonIndexPropertiesHandleProxies(val2, filter);
     if (keys1.length !== keys2.length) {
       return false;
     }
```

We should also _probably_ file a v8 bug?","benjamingr",1315533,"2022-01-27 15:57:53",NULL
1778,299,"Wouldn’t that fix potentially interfere with proxies of arrays, or proxies of objects with numeric string keys?","ljharb",45469,"2022-01-27 15:59:39",NULL
1779,299,"@ljharb 

> Wouldn’t that fix potentially interfere with proxies of arrays, or proxies of objects with numeric string keys?

It would as in today they don't work and following this patch they do and return the same keys as the non-proxy version","benjamingr",1315533,"2022-01-27 16:01:09",NULL
1780,299,"`0` is an index regardless of what kind of object it is pulled off of. If this is coming from `IndexFilter::kSkipIndices` I would suggest fixing it there.","devsnek",5952481,"2022-01-27 16:01:56",NULL
1781,299,"> `new ...Proxy(..., { ownKeys: (target) => Reflect. ... }`

@itaylor Why do you even expect assertion to succeed in the second cases?
Proxy essentially modifies the way proxy target behaves and therefore is different from the target itself.

In the first case you didn't supply any handlers (i.e. `Proxy(..., { })`) meaning it won't modify output of the original target proprties in any way. Meanwhile in the second one it's likely that target will differ and therefore it fails to pass assertion accordingly. 

I think it works as expected.

```javascript
var foo = [`foo`];
var bar = [`foo`];
var fooProxy = new Proxy(foo, { ownKeys: (target) => Reflect.ownKeys(target) });
assert.deepEqual(
  Reflect.ownKeys(fooProxy)
, Reflect.ownKeys(bar)
);
```

","hinell",8136158,"2022-02-11 22:14:53",NULL
1782,299,"@hinell, I respectfully disagree that it's working as expected.  It is currently impossible for a `Proxy` operating on an `Array` with the `ownKeys` trap to be compared as equal to one without the trap.  This is different than how `deepEqual` works for the other trap types.  It's also different than how the `ownKeys` trap works on non-array `Object`s.

Some examples: 
`deepEqual` doesn't throw on the using the `get` trap with an array.
```js
const fooArr = ['foo'];
assert.deepEqual(new Proxy(fooArr, { get: (...args) => Reflect.get(...args) }), fooArr) // doesn't throw 
assert.deepEqual(new Proxy(fooArr, { get: (target, key) => target[key] }), fooArr) // doesn't throw 
```

`deepEqual` doesn't throw on using the `ownKeys` trap with an object
```js
const fooObj = { foo: 'bar' };
assert.deepEqual(new Proxy(fooObj, { ownKeys: (...args) => Reflect.ownKeys(...args) }),  fooObj); //doesn't throw
assert.deepEqual(new Proxy(fooObj, { ownKeys: () => ['foo'] }), fooObj); // doesn't throw
```

`deepEqual` does throw on using the `ownKeys` trap with an array
```js
const fooArr = ['foo'];
assert.deepEqual(new Proxy(fooArr, { ownKeys: (...args) => Reflect.ownKeys(...args) }),  fooArr) // throws
```

I think this is happening not because `ownKeys` returns a different result, it returns the same result.  It is happening because on a proxy, the code that filters to non-iterable keys doesn't work right, so the `deepEqual` comparison fails because it checks length of the filtered keys, and they don't match.","itaylor",38120,"2022-02-12 00:17:26",NULL
1783,299,"To be clear: Proxy is NOT intended to be used except with membranes; in other words, any time someone expects to be able to make a Proxy of something and have it be indistinguishable from the thing itself (modulo identity), they're using Proxy incorrectly.

Despite that by exposing whether something *is* a Proxy, node has chosen to violate the explicit intent of the language, you also can not expect that a Proxy of X is always equivalent to an X.

That said, there may be a bug here worth fixing - but there's a lot of fundamentally flawed expectations around Proxy in the ecosystem that are worth pointing out.","ljharb",45469,"2022-02-12 00:20:45",NULL
1805,301,"@DerekNonGeneric the same with `structuredClone`. I'm not an expert in Web IDL, but looks like here specified that they should take a required argument, so they should throw an error if the argument is missed. This is the behavior of all actual browsers, so I think that's interpreted correctly.","zloirock",2213682,"2022-01-09 01:38:41",NULL
1834,306,"It seems to be a recurring issue of vm and async hooks not playing well together. I believe @Qard noticed it too.","vdeturckheim",7135896,"2021-12-01 14:05:33",NULL
1784,299,"@ljharb the issue is much simpler than that  I think? no one updated the assert code to support proxies and there are (likely) a bunch of bugs in the V8 APIs used like Gus said.

So I think this feature request is definitely worth doing but am waiting for someone with more regular commits to V8 to either fix it there or tell us it's intended so we work around it similar to https://github.com/nodejs/node/issues/41714#issuecomment-1023365510

Note node is _not_ distinguishing something based on whether or not it's a proxy in that workaround - it just works around the underlying v8 bug that does.","benjamingr",1315533,"2022-02-12 07:10:18",NULL
1785,299,"@benjamingr sure, there's surely something to fix here.

What I meant is, node's inspection output in the thrown assertion error clearly marks the proxy as a Proxy; that's the part i was saying is a violation of the language's intent.","ljharb",45469,"2022-02-12 07:22:14",NULL
1786,299,"@ljharb 

> What I meant is, node's inspection output in the thrown assertion error clearly marks the proxy as a Proxy; that's the part i was saying is a violation of the language's intent.

Yes though that's not intentional it's just since assert was never made to work with proxies. This is a v8 bug not something intentional Node chose to do.","benjamingr",1315533,"2022-02-12 08:20:58",NULL
1787,299,"@itaylor I see you point now, thanks.

I would still expect `assert.deepEqual(proxyOfTarget, target)` throwing errors because by the logic of language intent the `proxyOfTarget` and `target` are different instances.

Even though `Proxy()` class has no `prototype` (and therefore not a class per se) it still modifies the original object in some ways (expected or not). As a consumer of the proxies I would expect them behaving differently from targets at all times just as precaution.

Hope node.js folks establish some convention for `assert` module treating proxy-like objects so devs would stick to it. It should also probably documented...","hinell",8136158,"2022-02-12 09:10:57",NULL
1788,299,"I had trouble seeing the comments that were directly related to the issue, so I just hid some comments as off-topic.

@nodejs/v8 the issue here clearly looks like a V8 bug. Would it be possible to fix `getPropertyNames` using `IndexFilter::kSkipIndices` to filter indices even if there is a proxy trap? See https://github.com/nodejs/node/issues/41714#issuecomment-1023103706","BridgeAR",8822573,"2022-07-16 15:06:28",NULL
1789,299,"There is actually an explicit comment about the behavior in V8: https://github.com/nodejs/node/blob/dabda03ea9ef4baab20e3a377a753174475eb468/deps/v8/src/objects/keys.h#L33-L37

We could either implement the behavior in FilterProxyKeys or have to check for proxies on our own and do the filtering manually as @benjamingr suggested. https://github.com/nodejs/node/blob/dabda03ea9ef4baab20e3a377a753174475eb468/deps/v8/src/objects/keys.cc#L182-L213","BridgeAR",8822573,"2022-07-16 17:16:03",NULL
1790,299,"It is actually somewhat confusing for me that there's a separate `IndexFilter` vs. `PropertyFilter`.","BridgeAR",8822573,"2022-07-16 17:19:16",NULL
1791,299,"What should we do with this?","targos",2352663,"2022-11-08 15:02:06",NULL
1792,299,"I opened https://bugs.chromium.org/p/v8/issues/detail?id=13728. Let's see if this can be fixed in V8.","BridgeAR",8822573,"2023-02-09 23:49:16",NULL
1793,299,"I tried a solution something like 

```diff
diff --git a/deps/v8/src/objects/keys.cc b/deps/v8/src/objects/keys.cc
index a0796864f1..4f84cd9094 100644
--- a/deps/v8/src/objects/keys.cc
+++ b/deps/v8/src/objects/keys.cc
@@ -182,8 +182,9 @@ ExceptionStatus KeyAccumulator::AddKeys(Handle<JSObject> array_like,
 MaybeHandle<FixedArray> FilterProxyKeys(KeyAccumulator* accumulator,
                                         Handle<JSProxy> owner,
                                         Handle<FixedArray> keys,
-                                        PropertyFilter filter) {
-  if (filter == ALL_PROPERTIES) {
+                                        PropertyFilter filter,
+                                        bool skip_indices) {
+  if (filter == ALL_PROPERTIES  && !skip_indices) {
     // Nothing to do.
     return keys;
   }
@@ -191,7 +192,7 @@ MaybeHandle<FixedArray> FilterProxyKeys(KeyAccumulator* accumulator,
   int store_position = 0;
   for (int i = 0; i < keys->length(); ++i) {
     Handle<Name> key(Name::cast(keys->get(i)), isolate);
-    if (key->FilterKey(filter)) continue;  // Skip this key.
+    if (key->FilterKey(filter) || (skip_indices && key->IsNumber())) continue;  // Skip this key.
     if (filter & ONLY_ENUMERABLE) {
       PropertyDescriptor desc;
       Maybe<bool> found =
@@ -218,7 +219,7 @@ Maybe<bool> KeyAccumulator::AddKeysFromJSProxy(Handle<JSProxy> proxy,
   // Postpone the enumerable check for for-in to the ForInFilter step.
   if (!is_for_in_) {
     ASSIGN_RETURN_ON_EXCEPTION_VALUE(
-        isolate_, keys, FilterProxyKeys(this, proxy, keys, filter_),
+        isolate_, keys, FilterProxyKeys(this, proxy, keys, filter_, skip_indices_),
         Nothing<bool>());
   }
   // https://tc39.es/ecma262/#sec-proxy-object-internal-methods-and-internal-slots-ownpropertykeys
```

On v8 but doesn't seem to make a change 😕","debadree25",20257253,"2023-03-01 13:42:51",NULL
1794,299,"Hey! was able to get this fixed in v8 @ https://chromium.googlesource.com/v8/v8/+/975ff4dbfd1be3a7395e26d412774bc955b47341 so the next update of v8 in node should fix it or do we have to patch the commit here?

cc @benjamingr @BridgeAR ","debadree25",20257253,"2023-03-18 05:46:30",NULL
1795,300,"If you want to open an issue without using a template, you can go to https://github.com/nodejs/node/issues/new","targos",2352663,"2022-01-22 14:02:09",NULL
1796,300,"@targos TIL, thanks!","benjamingr",1315533,"2022-01-22 14:03:35",NULL
1797,300,"I'm opening an issue rather than a fix since I think this issue is a good place for people other than myself and ronag to get involved with the iterator-helpers initiative :)","benjamingr",1315533,"2022-01-22 14:04:06",NULL
1798,300,"Confirmed the behavior should be to throw synchronously with the proposal - so this is a bug that should be fixed.","benjamingr",1315533,"2022-01-22 16:22:00",NULL
1799,300,"Is the intention for stream methods to match the iterator helpers interface?","ljharb",45469,"2022-01-22 16:24:27",NULL
1800,300,"@ljharb the intention to add most iterator helper proposal methods to the node streams interface.

I intend Node to pass the tc39 tests as much as possible (read: all of them) and would strongly prefer not to move these methods out of ""experimental"" until the proposal gets to (at least) stage 3.

There are some divergences that exist (for example - https://github.com/tc39/proposal-iterator-helpers/issues/162 which is why I asked for future-compatibility there).

In addition - if/when the spec changes I believe Node.js should change its implementation to align.","benjamingr",1315533,"2022-01-22 16:31:56",NULL
1801,300,"(This is a good area to be involved in by the way!)","benjamingr",1315533,"2022-01-22 16:33:16",NULL
1802,300,"@benjamingr I'll happily take this, does seem like a great starting point to get involved :)","iMoses",1083065,"2022-01-22 17:42:03",NULL
1803,300,"@iMoses great, let me know if you need help getting started - the sooner we land this the better since these APIs are shipping :) ","benjamingr",1315533,"2022-01-22 17:53:18",NULL
1804,301,"@zloirock, thanks for opening this issue. As far as I understand, these utility methods evolved w/o any standard or official specification. The nearest I can find is the link below.

https://html.spec.whatwg.org/multipage/webappapis.html#atob

By any chance, would you be able to link a more complete specification or should we derive this specification from current web browser behavior?","DerekNonGeneric",17770407,"2022-01-09 01:32:56",NULL
1806,301,"For example, similarly, [in the `URL` spec we could see that `URLSearchParams#append` should accept 2 params](https://url.spec.whatwg.org/#dom-urlsearchparams-append) - and if not, that throws an error everywhere - in Node and all browsers:

![image](https://user-images.githubusercontent.com/2213682/148666060-798b8010-4fa4-4920-a79f-73d97a09a5b3.png)

And the error is not specified directly.","zloirock",2213682,"2022-01-09 01:49:40",NULL
1807,301,"As far as I understand, the WHATWG spec for both of the `atob()` and `btoa()` functions/methods states that a required argument must be taken and must be a value with the primitive type of `string`.

As for the `structuredClone()` function, the value can be anything other than specified C++ natives; so I guess it's already giving out the intended output as passing nothing falls back to the `undefined` value, which it's structured clone is `undefined`, we could also require the user to pass a value regardless of the fallback behavior by checking the amount of arguments they've passed to the function, but I'm -0 on that.","VoltrexKeyva",62040526,"2022-01-09 13:55:44",NULL
1808,301,"Spec for `atob` and `btoa`: https://html.spec.whatwg.org/multipage/webappapis.html#dom-atob-dev

- Firefox: `TypeError: Window.atob: At least 1 argument required, but only 0 passed`
- Safari: `TypeError: Not enough arguments`
- Chromium: `TypeError: Failed to execute 'atob' on 'Window': 1 argument required, but only 0 present.`
- Deno: `DOMException: Failed to decode base64.`

Spec for `structuredClone`: https://html.spec.whatwg.org/multipage/structured-data.html#dom-structuredclone

- Firefox: `TypeError: Window.structuredClone: At least 1 argument required, but only 0 passed`
- Safari: `TypeError: Not enough arguments`
- Chromium: `TypeError: Failed to execute 'structuredClone' on 'Window': 1 argument required, but only 0 present.`
- Deno: `TypeError: Failed to execute 'structuredClone': 1 argument required, but only 0 present.`

It looks like Node.js indeed not aligned with the rest of the ecosystem.","aduh95",14309773,"2022-01-09 23:38:11",NULL
1809,301,"I think this is the part of Web IDL that defines what should happen: https://webidl.spec.whatwg.org/#es-overloads

> If there is no valid overload for the type of value passed in here, then we throw a TypeError.","targos",2352663,"2022-01-10 07:24:42",NULL
1810,301,"Sure I'll open a quick PR that throws `ERR_INVALID_ARG_TYPE` and adds a test good catch","benjamingr",1315533,"2022-01-11 16:15:22",NULL
1811,301,"I can also add a fix for structuredClone to the PR but I'd rather make a good-first-issue out of it if everyone is OK with it given how straightforward it is maybe?","benjamingr",1315533,"2022-01-11 16:24:48",NULL
1812,301,"@benjamingr, do you think it would be best to add a new `ERR_INVALID_ARGS_NUMBER` code first, or do you plan to go w/ `ERR_MISSING_ARGS`? Without the name of this missing argument, it might be tough to determine what to provide to the error for the message text.

If you want me to open a PR to include this `ERR_INVALID_ARGS_NUMBER` first, it might be best since adding a whole new error code seems a bit much for a GFI, and it can be tricky.","DerekNonGeneric",17770407,"2022-01-11 17:40:25",NULL
1813,301,"@DerekNonGeneric I think it's important to understand what `.code` is used for and its importance and I don't think it matters in this case. I just think it's important we should raise a `TypeError` and `atob` is for browser compatibility anyway so I doubt anyone is checking `.code` on anything atob related.

That said, if you feel strongly about this feel free to push whatever code you want on that branch or ask that I change it to ERR_MISSING_ARGS both are fine by me :) ","benjamingr",1315533,"2022-01-11 19:41:03",NULL
1814,301,"I'll be happy to take the `structuredClone` fix. What would be the error of choice in this case? `ERR_MISSING_OPTION('value')` or `ERR_INVALID_ARG_TYPE('value', [...'everything specified in #1'], value)`?

* 1: https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm","gioragutt",13711224,"2022-01-22 18:40:36",NULL
1815,301,"`ERR_MISSING_ARGS`? I honestly just care that it's a TypeError and is spec compliant :)","benjamingr",1315533,"2022-01-22 19:27:44",NULL
1816,301,"Oh right, `ERR_MISSING_OPTION` sounds like an error for a missing key in an options object, `ERR_MISSING_ARGS` makes more sense 👍🏻","gioragutt",13711224,"2022-01-22 19:42:08",NULL
1817,301,"Only a subset was fixed in the PR - so reopening.","benjamingr",1315533,"2022-01-24 23:22:50",NULL
1818,302,"https://github.com/TypeStrong/ts-node/issues/1587#issuecomment-1004576774","Scared-Heart",26789238,"2022-01-04 07:41:02",NULL
1819,302,"This bug is triggered by `require('repl')`, it does not require a REPL to be created.  It is a side-effect of `require('repl')`, which means it can reproduce without running in the REPL.","cspotcode",376504,"2022-01-04 16:54:53",NULL
1820,303,"A minimal reproducible example:

```javascript
const a = {
    b: {
        get [Symbol.iterator]() {
            throw Error();
        }
    }
};

console.log(a);
```

This happens because the userland Error is caught by the internal module:
https://github.com/nodejs/node/blob/4cb2a4786711e304314313aabb24ed2dc46134ef/lib/internal/util/inspect.js#L1026-L1038

Maybe we can improve this by filtering the userland error?

","meixg",9262426,"2022-02-28 09:24:17",NULL
1821,303,"From my reading @meixg's above minimal example causes an error because of the dynamic `Symbol.iterator` access at L862.
https://github.com/nodejs/node/blob/a81b4ebb7598a020fa95d80da13fc0b331c35c2a/lib/internal/util/inspect.js#L862

I'm still not sure if @fabiancook's error is happening for the same reason but I'll try to fix it by removing access to `Symbol.iterator`.","cola119",22386678,"2022-07-05 00:29:58",NULL
1822,303,"@meixg it is actually a separate issue that you highlight.

I have a local fix for this issue as well.","BridgeAR",8822573,"2022-07-05 11:50:35",NULL
1823,303,"This is no longer reproducible AFAICT.","avivkeller",38299977,"2024-10-14 22:31:59",NULL
1824,304,"there is some kind of bug with the async id stack with this PR, DO NOT MERGE yet","bmeck",234659,"2021-12-17 15:25:33",NULL
1825,304,"@qard and I did some poking and it seems some other stuff is likely messed up around here https://github.com/nodejs/node/issues/41222 , I cannot write a test that covers all the branches of unhandledRejection + uncaughtExceptionMonitor because of it.","bmeck",234659,"2021-12-17 15:26:42",NULL
1826,304,"@bmeck does that mean only the tests are broken and not the actual feature?","vdeturckheim",7135896,"2021-12-17 15:29:08",NULL
1827,304,"@vdeturckheim the feature isn't fully fixed it looks like, if you register `uncaughtExceptionMonitor` things look like they aren't correct. `unhandledRejection` seems to work fine with this PR. Registering both events gets all sort of broken (regardless of this PR).","bmeck",234659,"2021-12-17 15:44:01",NULL
1828,304,"@Qard please re-review","bmeck",234659,"2021-12-20 18:31:57",NULL
1829,304,"CI: https://ci.nodejs.org/job/node-test-pull-request/41566/","nodejs-github-bot",18269663,"2021-12-20 21:28:16",NULL
1830,304,"CI: https://ci.nodejs.org/job/node-test-pull-request/41567/","nodejs-github-bot",18269663,"2021-12-20 21:52:17",NULL
1831,304,"Landed in c3866b09c189","bmeck",234659,"2021-12-21 15:34:18",NULL
1835,306,"As far as I can tell it's less an async_hooks issue and more an issue with domains, vm contexts, and gc timing. I don't really have the time to investigate properly right now though. 😕 ","Qard",205482,"2021-12-09 03:38:13",NULL
1836,306,"Having seen this failure a couple of times in production (and not wanting to use node v12.x pending an actual fix), I tinkered a bit, and found what seems like a reliable workaround: setting a dummy timeout prior to using any newly-created domain.  Here's a revision of the minimal repro from the original issue description, with such a timeout added:

```js
let createDomain = require(""domain"").create;
let vm = require(""vm"");

let context = vm.createContext({});
function eval(code) {
  let domain = createDomain();
  setTimeout(_ => {
    domain.run(() => {
      vm.runInContext(code, context)()
        .catch(console.error);
    })
  }, 0);
}

for (i = 0; i < 10000; i++) {
  eval(""async () => null"");
}
```

Whether this works because it's helping the program dodge a timing bug or not is definitely above my pay grade here, but maybe someone will find it helpful.

(Interestingly, v12 runs the above in half the time as v16. Obviously it's a pathological bit of code, but it seems notable.)","cemerick",47489,"2021-12-29 18:11:03",NULL
1837,306,"I've noticed this is not an issue in 14.15, but is still an issue in 14.19.","bagelbits",353626,"2022-03-08 01:39:35",NULL
1838,306,"Anecdotally, this issue is also not present in 14.17. ","bagelbits",353626,"2022-03-08 01:52:05",NULL
1839,306,"Chiming in - I get this issue consistently with code like this on the latest node 16:

```js
const transform = (...args) =>
  new Promise((resolve, reject) => {
    const internalDomain = domains.create()
     internalDomain.on('error', reject) // report async errors
     let out
     internalDomain.run(() => {
       out = fn(...args)
     })
     resolve(out)
  })
```

This is creating a domain within a promise, then running a function created using the VM2 module inside of the domain. This consistently reproduces for me even with 1 or 2 invocations, usually on the first invocation but every so often it will continue on for a bit before failing. Wrapping each `domain.run` call with a setTimeout(0) or a nextTick does not seem to help as suggested above.","yocontra",425716,"2022-06-05 18:16:03",NULL
1840,307,"Thank you for the report. This is an interesting one. I've been debugging this for a while now and something seems very wrong here.

Most spectacularly, in Node.js 17 (both on Windows and Ubuntu), the first attempt to load an `aes-128-ecb` encrypted key appears to fail, but the second succeeds:

```
==256055== Memcheck, a memory error detector
==256055== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==256055== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==256055== Command: node
==256055== 
Welcome to Node.js v17.1.0.
Type "".help"" for more information.
> let {privateKey, publicKey} = crypto.generateKeyPairSync(""rsa"", {
...     modulusLength: 2048,
...     publicKeyEncoding: {
.....         type: ""spki"",
.....         format: ""pem""
.....     },
...     privateKeyEncoding: {
.....         type: 'pkcs8',
.....         format: 'pem',
.....         cipher: ""aes-128-ecb"",
.....         passphrase: ""abcdef""
.....     }
... });
undefined
> crypto.createPrivateKey({ key: privateKey, passphrase: 'abcdef' })
Uncaught Error: error:0300007A:digital envelope routines::cipher parameter error
    at Object.createPrivateKey (node:internal/crypto/keys:608:12) {
  library: 'digital envelope routines',
  reason: 'cipher parameter error',
  code: 'ERR_OSSL_EVP_CIPHER_PARAMETER_ERROR'
}
> crypto.createPrivateKey({ key: privateKey, passphrase: 'abcdef' })
PrivateKeyObject { [Symbol(kKeyType)]: 'private' }
> 
(To exit, press Ctrl+C again or Ctrl+D or type .exit)
> 
==256055== 
==256055== HEAP SUMMARY:
==256055==     in use at exit: 1,011,381 bytes in 2,199 blocks
==256055==   total heap usage: 84,213 allocs, 82,014 frees, 51,234,514 bytes allocated
==256055== 
==256055== LEAK SUMMARY:
==256055==    definitely lost: 0 bytes in 0 blocks
==256055==    indirectly lost: 0 bytes in 0 blocks
==256055==      possibly lost: 416 bytes in 3 blocks
==256055==    still reachable: 1,010,965 bytes in 2,196 blocks
==256055==                       of which reachable via heuristic:
==256055==                         stdstring          : 7,429 bytes in 161 blocks
==256055==         suppressed: 0 bytes in 0 blocks
==256055== Rerun with --leak-check=full to see details of leaked memory
==256055== 
==256055== For lists of detected and suppressed errors, rerun with: -s
==256055== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
```","tniessen",3109072,"2021-11-16 17:50:50",NULL
1841,307,"I'm seeing something similar on  node 16.3.1 on Ubuntu 20.04, but with a sightly different error:

Error: error:0D0C5006:asn1 encoding routines:ASN1_item_verify:EVP lib
    at Object.createPrivateKey (node:internal/crypto/keys:608:12)
    at readPrivateKeyBuffer (/opt/ct/node_modules/@configuredthings/sfjs-language/lib/parser/sfjsCrypto.js:51:22)
    at readPrivateKeyFile (/opt/ct/node_modules/@configuredthings/sfjs-language/lib/parser/sfjsCrypto.js:43:12)
    at decryptDoc (/opt/ct/node_modules/@configuredthings/sfjs-language/lib/parser/sfjsCrypto.js:748:55)
    at ConfigGateway.<anonymous> (/opt/ct/node_modules/@configuredthings/sfjs-components/lib/ConfigGateway/ConfigGateway.js:132:66)
    at ConfigGateway.<anonymous> (/opt/ct/node_modules/@configuredthings/sfjs-components/lib/ConfigGateway/ConfigGateway.js:59:103)
    at FileMonitor.<anonymous> (/opt/ct/node_modules/@configuredthings/sfjs-components/lib/Abstract/FileMonitor.js:185:17)
    at FileMonitor.<anonymous> (/opt/ct/node_modules/@configuredthings/sfjs-components/lib/Abstract/FileMonitor.js:166:18)
    at FSWatcher.emit (node:events:390:28)
    at FSWatcher.emitWithAll (/opt/ct/node_modules/chokidar/index.js:540:8) {
  opensslErrorStack: [ 'error:0D0C5006:asn1 encoding routines:ASN1_item_verify:EVP lib' ],
  library: 'asn1 encoding routines',
  function: 'ASN1_item_verify',
  reason: 'EVP lib',
  code: 'ERR_OSSL_ASN1_EVP_LIB'
}

It doesn't seem to be a first or second call that always fails, I'm getting this both after a successful call and when this is the fist call. 
What I have seen is that catching the exception and retrying the call always seems to work.
```
    try {
        res = crypto.createPrivateKey(key);
    }
    catch(err) {
        console.log(""*** FAILED"")
        console.error(err)
        try {
            res = crypto.createPrivateKey(key);
        }
        catch(err) {
            console.log(""*** FAILED Again"")
            console.error(err)
            throw err;
        }        
    }
    return res;
}
```





","PhilDay-CT",69908274,"2021-12-29 20:18:44",NULL
1842,307,"Alright, fix seemingly works, but for only ECB ciphers, other ciphers like -ccm -ctr -ocb -xts variants and other cipher types are still broken with more or less the same error... or a variant of it
I used the following snippet to test all ciphers given by `crypto.getCiphers()`
```js
const crypto = require(""crypto"");
crypto.getCiphers().forEach((cipherString) => {
    console.log(`Testing: ${cipherString}`);
    if(cipherString == ""des3-wrap"" || cipherString == ""aes128-wrap"" || cipherString == ""aes192-wrap"" || cipherString == ""aes256-wrap"" || cipherString == ""id-aes128-wrap"" || cipherString == ""id-aes128-wrap-pad"" || cipherString == ""id-aes192-wrap"" || cipherString == ""id-aes192-wrap-pad"" || cipherString == ""id-aes256-wrap"" || cipherString == ""id-aes256-wrap-pad"") {
        console.log(`\x1b[33m[SKIPPED] ${cipherString} due to segmentation fault`);
        console.log(""\x1b[37m""); // turn text back to white
        return;
    }
    try {
        let { privateKey, publicKey } = crypto.generateKeyPairSync(""rsa"", {
            modulusLength: 2048,
            publicKeyEncoding: {
                type: ""spki"",
                format: ""pem""
            },
            privateKeyEncoding: {
                type: 'pkcs8',
                format: 'pem',
                cipher: cipherString,
                passphrase: ""abcdef""
            }
        });
        const encryptedString = crypto.privateEncrypt({
            key: privateKey,
            passphrase: ""abcdef""
        }, Buffer.from(""The quick brown fox jumps over the lazy dog"")).toString(""base64"");
        const decryptedString = crypto.publicDecrypt(publicKey, Buffer.from(encryptedString, ""base64"")).toString();
        console.log(`\x1b[32m[PASS]`);
        console.log(`Encrypted: ${encryptedString}`);
        console.log(`Decrypted: ${decryptedString}`);
    } catch(err) {
        console.log(`\x1b[31m[FAILED] ${err.stack}`);
    }
    console.log(""\x1b[37m""); // turn text back to white
});
```
Broken ciphers:
```
aes-128-ccm - error:0300006B:digital envelope routines::unsupported cipher
aes-128-ctr - error:0680006C:asn1 encoding routines::cipher has no object identifier
aes-128-gcm - error:0300007A:digital envelope routines::cipher parameter error
aes-128-ocb - error:0680006C:asn1 encoding routines::cipher has no object identifier
aes-128-xts - error:0300006B:digital envelope routines::unsupported cipher
aes-192-ccm - error:0300006B:digital envelope routines::unsupported cipher
aes-192-ctr - error:0680006C:asn1 encoding routines::cipher has no object identifier
aes-192-gcm - error:0300007A:digital envelope routines::cipher parameter error
aes-192-ocb - error:0680006C:asn1 encoding routines::cipher has no object identifier
aes-256-ccm - error:0300006B:digital envelope routines::unsupported cipher
aes-256-ctr - error:0680006C:asn1 encoding routines::cipher has no object identifier
aes-256-gcm - error:0300007A:digital envelope routines::cipher parameter error
aes-256-ocb - error:0680006C:asn1 encoding routines::cipher has no object identifier
aes-256-xts - error:0300006B:digital envelope routines::unsupported cipher
aria-128-ccm - error:0300006B:digital envelope routines::unsupported cipher
aria-128-cfb1 - error:0680006C:asn1 encoding routines::cipher has no object identifier
aria-128-cfb8 - error:0680006C:asn1 encoding routines::cipher has no object identifier
aria-128-gcm - error:0300007A:digital envelope routines::cipher parameter error
aria-192-ccm - error:0300006B:digital envelope routines::unsupported cipher
aria-192-cfb1 - error:0680006C:asn1 encoding routines::cipher has no object identifier
aria-192-cfb8 - error:0680006C:asn1 encoding routines::cipher has no object identifier
aria-192-gcm - error:0300007A:digital envelope routines::cipher parameter error
aria-256-ccm - error:0300006B:digital envelope routines::unsupported cipher
aria-256-cfb1 - error:0680006C:asn1 encoding routines::cipher has no object identifier
aria-256-cfb8 - error:0680006C:asn1 encoding routines::cipher has no object identifier
aria-256-gcm - error:0300007A:digital envelope routines::cipher parameter error
camellia-128-cfb1 - error:0680006C:asn1 encoding routines::cipher has no object identifier
camellia-128-cfb8 - error:0680006C:asn1 encoding routines::cipher has no object identifier
camellia-192-cfb1 - error:0680006C:asn1 encoding routines::cipher has no object identifier
camellia-192-cfb8 - error:0680006C:asn1 encoding routines::cipher has no object identifier
camellia-256-cfb1 - error:0680006C:asn1 encoding routines::cipher has no object identifier
camellia-256-cfb8 - error:0680006C:asn1 encoding routines::cipher has no object identifier
chacha20 - error:0680006C:asn1 encoding routines::cipher has no object identifier
chacha20-poly1305 - error:0680006C:asn1 encoding routines::cipher has no object identifier
des-ede-cbc - error:0680006C:asn1 encoding routines::cipher has no object identifier
des-ede-cfb - error:0680006C:asn1 encoding routines::cipher has no object identifier
des-ede-ofb - error:0680006C:asn1 encoding routines::cipher has no object identifier
des-ede3 - error:0680006C:asn1 encoding routines::cipher has no object identifier
des-ede3-cfb - error:0308010C:digital envelope routines::unsupported
des-ede3-cfb1 - error:0308010C:digital envelope routines::unsupported
des-ede3-cfb8 - error:0308010C:digital envelope routines::unsupported
des-ede3-ecb - error:0680006C:asn1 encoding routines::cipher has no object identifier
des-ede3-ofb - error:0680006C:asn1 encoding routines::cipher has no object identifier
id-aes128-CCM - error:0300006B:digital envelope routines::unsupported cipher
id-aes128-GCM - error:0300007A:digital envelope routines::cipher parameter error
id-aes192-CCM - error:0300006B:digital envelope routines::unsupported cipher
id-aes192-GCM - error:0300007A:digital envelope routines::cipher parameter error
id-aes256-CCM - error:0300006B:digital envelope routines::unsupported cipher
id-aes256-GCM - error:0300007A:digital envelope routines::cipher parameter error
id-smime-alg-CMS3DESwrap - error:1C800066:Provider routines::cipher operation failed
```
Additionally, the following ciphers throw an Segmentation fault:
```
aes128-wrap
aes192-wrap
aes256-wrap
id-aes128-wrap
id-aes128-wrap-pad
id-aes192-wrap
id-aes192-wrap-pad
id-aes256-wrap
id-aes256-wrap-pad
```

With the exception of `des3-wrap` who fails with `error:1C800066:Provider routines::cipher operation failed` before throwing the following as I try a few more times to encrypt:
```
corrupted size vs. prev_size
Aborted (core dumped)
```

Versions i tried:
 - v20.0.0-nightly2022110286088ab78e
 - v20.0.0-nightly20221101590cf569fe

I'm not really *sure* if these would apply for an separate issue, or it should be an continuation of this issue... or even if it should be valid, in my opinion *it is* since I would expect this to work with all ciphers at `crypto.getCiphers()` at least.","PANCHO7532B",92986867,"2022-11-02 22:23:58",NULL
1843,307,"@PANCHO7532B you should probably open a new issue, or a directly a PR if you know what is the fix.","aduh95",14309773,"2022-11-02 22:25:38",NULL
1844,309,"Bisected with official versions. It broke between 16.6.2 and 16.7.0.","orgads",1246544,"2021-11-02 05:11:25",NULL
1845,309,"Bisected with git. Caused by #38468.

```
a80c989306c152e76fc03b59634303a11183e0c5 is the first bad commit
commit a80c989306c152e76fc03b59634303a11183e0c5
Author: Darshan Sen <raisinten@gmail.com>
Date:   Thu Apr 29 20:47:09 2021 +0530

    async_hooks: merge resource_symbol with owner_symbol

    Signed-off-by: Darshan Sen <darshan.sen@postman.com>

    PR-URL: https://github.com/nodejs/node/pull/38468
    Reviewed-By: James M Snell <jasnell@gmail.com>
    Reviewed-By: Anna Henningsen <anna@addaleax.net>
    Reviewed-By: Rich Trott <rtrott@gmail.com>
    Reviewed-By: Benjamin Gruenbaum <benjamingr@gmail.com>
```","orgads",1246544,"2021-11-02 05:33:15",NULL
1846,309,"@nodejs/async_hooks ","targos",2352663,"2021-11-02 07:17:40",NULL
1847,309,"ping? @RaisinTen?","orgads",1246544,"2021-11-04 10:43:22",NULL
1848,309,"PR: https://github.com/nodejs/node/pull/40741","RaisinTen",42526976,"2021-11-06 09:53:23",NULL
1849,310,"Seems like a bug to me indeed. The function is called as a constructor and it returns an instance of it instead of the true return value.","targos",2352663,"2021-10-27 07:06:53",NULL
1850,310,"/cc @jasnell ","targos",2352663,"2021-10-27 07:07:51",NULL
1851,310,"Caught by this bug today!

Workaround: using arrow function.","hax",159840,"2022-04-12 20:39:28",NULL
1852,310,"Note, node 14 do not have this bug. So it's the bug of rewriting it from C++ to JS :-)","hax",159840,"2022-04-18 13:26:09",NULL
1853,313,"I agree it looks suspicious that `totalSocketCount` is increment on socket re-use.","ronag",3065230,"2021-10-14 06:50:24",NULL
1855,313,"It looks like a bug.","lpinca",1443911,"2021-10-14 12:55:11",NULL
1856,313,"Thank you for looking into that. Glad I spotted it.","snytkine",606771,"2021-10-14 13:55:07",NULL
1857,313,"@snytkine would you like to send a PR?","mcollina",52195,"2021-10-14 16:27:37",NULL
1858,313,"Ok, I'll do it","snytkine",606771,"2021-10-14 18:57:41",NULL
1859,313,"How do you guys work on this project, I mean do I have to clone this project and push change to my own clone then make PR from my repo to this repo. (Actually not sure if github supports that). Should I create new branch first then make PR or just make PR from master to master?","snytkine",606771,"2021-10-14 19:05:24",NULL
1860,313,"@snytkine see https://github.com/nodejs/node/blob/master/CONTRIBUTING.md","lpinca",1443911,"2021-10-14 19:07:49",NULL
1861,313,"Also do I have to put defect number in commit message? Sorry, I'm now to this project, I know every project has certain standards for making PRs.
","snytkine",606771,"2021-10-14 19:08:35",NULL
1862,313,"Got it. I'll follow the steps and will make a PR","snytkine",606771,"2021-10-14 19:12:14",NULL
1863,313,"looks like it's not a bug. We decrease the maxFreeSockets when we remove the socket from the list of sockets:
https://github.com/nodejs/node/blob/master/lib/_http_agent.js#L187

I was also able to verify that using the following test : #40572 


I think we have other issues, like the maxFreeSockets going down to -1 ( check my comments on the PR) 
","jodevsa",14154314,"2021-10-23 00:29:10",NULL
1864,313,"@jodevsa the counter should be incremented only when a socket is created and decremented only a the socket is closed  or released. This seems to fix the issue:

```diff
diff --git a/lib/_http_agent.js b/lib/_http_agent.js
index a42c0e8399..87450993a6 100644
--- a/lib/_http_agent.js
+++ b/lib/_http_agent.js
@@ -284,7 +284,6 @@ Agent.prototype.addRequest = function addRequest(req, options, port/* legacy */,
     this.reuseSocket(socket, req);
     setRequestSocket(this, req, socket);
     ArrayPrototypePush(this.sockets[name], socket);
-    this.totalSocketCount++;
   } else if (sockLen < this.maxSockets &&
              this.totalSocketCount < this.maxTotalSockets) {
     debug('call onSocket', sockLen, freeLen);
@@ -383,6 +382,7 @@ function installListeners(agent, s, options) {
     // This is the only place where sockets get removed from the Agent.
     // If you want to remove a socket from the pool, just close it.
     // All socket errors end in a close event anyway.
+    agent.totalSocketCount--;
     agent.removeSocket(s, options);
   }
   s.on('close', onClose);
@@ -406,6 +406,7 @@ function installListeners(agent, s, options) {
     // (defined by WebSockets) where we need to remove a socket from the
     // pool because it'll be locked up indefinitely
     debug('CLIENT socket onRemove');
+    agent.totalSocketCount--;
     agent.removeSocket(s, options);
     s.removeListener('close', onClose);
     s.removeListener('free', onFree);
@@ -438,7 +439,6 @@ Agent.prototype.removeSocket = function removeSocket(s, options) {
         // Don't leak
         if (sockets[name].length === 0)
           delete sockets[name];
-        this.totalSocketCount--;
       }
     }
   }
diff --git a/test/parallel/test-http-agent-keepalive.js b/test/parallel/test-http-agent-keepalive.js
index a1f902fab0..faf605e38d 100644
--- a/test/parallel/test-http-agent-keepalive.js
+++ b/test/parallel/test-http-agent-keepalive.js
@@ -70,9 +70,11 @@ function second() {
     res.on('end', common.mustCall(() => {
       assert.strictEqual(agent.sockets[name].length, 1);
       assert.strictEqual(agent.freeSockets[name], undefined);
+      assert.strictEqual(agent.totalSocketCount, 1);
       process.nextTick(common.mustCall(() => {
         assert.strictEqual(agent.sockets[name], undefined);
         assert.strictEqual(agent.freeSockets[name].length, 1);
+        assert.strictEqual(agent.totalSocketCount, 1);
         remoteClose();
       }));
     }));
@@ -91,10 +93,12 @@ function remoteClose() {
       process.nextTick(common.mustCall(() => {
         assert.strictEqual(agent.sockets[name], undefined);
         assert.strictEqual(agent.freeSockets[name].length, 1);
+        assert.strictEqual(agent.totalSocketCount, 1);
         // Waiting remote server close the socket
         setTimeout(common.mustCall(() => {
           assert.strictEqual(agent.sockets[name], undefined);
           assert.strictEqual(agent.freeSockets[name], undefined);
+          assert.strictEqual(agent.totalSocketCount, 0);
           remoteError();
         }), common.platformTimeout(200));
       }));
@@ -110,10 +114,12 @@ function remoteError() {
     assert.strictEqual(err.message, 'socket hang up');
     assert.strictEqual(agent.sockets[name].length, 1);
     assert.strictEqual(agent.freeSockets[name], undefined);
+    assert.strictEqual(agent.totalSocketCount, 1);
     // Wait socket 'close' event emit
     setTimeout(common.mustCall(() => {
       assert.strictEqual(agent.sockets[name], undefined);
       assert.strictEqual(agent.freeSockets[name], undefined);
+      assert.strictEqual(agent.totalSocketCount, 0);
       server.close();
     }), common.platformTimeout(1));
   }));
@@ -129,9 +135,11 @@ server.listen(0, common.mustCall(() => {
     res.on('end', common.mustCall(() => {
       assert.strictEqual(agent.sockets[name].length, 1);
       assert.strictEqual(agent.freeSockets[name], undefined);
+      assert.strictEqual(agent.totalSocketCount, 1);
       process.nextTick(common.mustCall(() => {
         assert.strictEqual(agent.sockets[name], undefined);
         assert.strictEqual(agent.freeSockets[name].length, 1);
+        assert.strictEqual(agent.totalSocketCount, 1);
         second();
       }));
     }));
```","lpinca",1443911,"2021-10-23 05:18:45",NULL
1865,313,"@lpinca I was referring to the fact that the totalSocketCount is decremented when we remove the socket, so it's not the same bug mentioned in this issue, but we had another bug; **totalSocketCount** being equal to 0 when we have a free socket, and **totalSocketCount** being equal to -1 when a free-socket has an error.

yeah I had a similar fix, but yours is cleaner. please review: #40572
","jodevsa",14154314,"2021-10-23 08:07:30",NULL
1866,313,"sorry @snytkine if you already had started :/ I assumed you are no longer interested as 10 days have passed. Also it's really amazing that you spotted the problem just by reading the code!","jodevsa",14154314,"2021-10-24 14:07:09",NULL
1867,314,"@nodejs/streams ","targos",2352663,"2021-10-09 10:14:38",NULL
1868,314,"Don’t mix thenable with callback.","ronag",3065230,"2021-10-09 10:16:13",NULL
1869,314,"The behavior is correct for me. After .destroy() is called, the stream is closed _synchronously_ and no more read or write operation can happen. However the destroy cycle is asynchronous because it might take a while to completely clean up a native resource.","mcollina",52195,"2021-10-09 18:27:43",NULL
1870,314,"@mcollina I forgot to include `Error: oh no!` in expected behavior. The error is not emitted. The issue is that if `_destroy` returns a thenable, there's a race condition - either the callback gets called first or the promise resolves. If it waits for the thenable, it should omit the `callback` argument (or throw when it gets called). Also the documentation doesn't mention anything about `_destroy` being thenable. Therefore I consider this a bug.","szmarczak",36894700,"2021-10-09 19:16:21",NULL
1871,314,"Uh? Using a thenable there should not be supported.","mcollina",52195,"2021-10-09 20:01:22",NULL
1872,314,"I think this is a case of insufficient documentation.","ronag",3065230,"2021-10-09 20:02:54",NULL
1873,314,"I have a feeling I missed something when we added thenable support to destroy.

I'll need to dig into this and check out what's the problem.","mcollina",52195,"2021-10-10 10:12:11",NULL
1874,314,"This was added in https://github.com/nodejs/node/commit/744a284ccc943d352fd2cc15e35aaf720b1139ae without documentation.

The error is not printed because it is not rethrown by the _destroy function. Moreover, the callback should not be mixed with async/await (nor is needed).","mcollina",52195,"2021-10-10 10:23:14",NULL
1875,314,"I think we could maybe emit a warning if function returns a thenable when the function.length has the value for the callback signature.","ronag",3065230,"2021-10-10 10:34:49",NULL
1876,314,"Wouldn't it be better to throw after the promise resolves and the callback gets called?","szmarczak",36894700,"2021-10-10 12:22:31",NULL
1877,314,"> Wouldn't it be better to throw after the promise resolves and the callback gets called?

if you implement _destroy(), you need to rethrow or call the callback with the error passed as an argument.","mcollina",52195,"2021-10-10 12:41:26",NULL
1878,314,"Again there's this situation where callback may be called after the promise  resolves. Currently calling the callback doesn't do anything because at that point the stream is destroyed already because the promise resolved.

One can expect `callback` not to throw, so indeed a warning would be sufficient I think.","szmarczak",36894700,"2021-10-10 13:11:38",NULL
1879,314,"The documentation _must_ be updated to better specify all of this. I would recommend to add a warning as well when using a promise with a callback.","mcollina",52195,"2021-10-11 13:05:12",NULL
1880,314,"I think this is a good first issue.","Mesteery",48163546,"2021-10-11 15:14:10",NULL
1881,314,"@mcollina it can be closed #41040 was merged.","RafaelGSS",26234614,"2021-12-22 17:02:42",NULL
1882,315,"Not sure about this, I was considering reading the docs, but they seem to be outdated, the [socket.connect(options[, connectListener])](https://nodejs.org/dist/latest-v14.x/docs/api/net.html#net_socket_connect_options_connectlistener), or I do not know if this is misuse or we do not support that `bjectMode` option or our docs are outdated","juanarbol",17013303,"2021-10-05 19:19:05",NULL
1883,316,"Thanks for the report @fasttime. Would you like to do a PR to fix it?","targos",2352663,"2021-10-04 06:51:02",NULL
1884,316,"@targos Sure. Thanks for confirming.","fasttime",6367844,"2021-10-04 06:56:36",NULL
1885,318,"We're using the CSS property `content-visibility` (https://web.dev/content-visibility/) on the HTML version of the docs so it doesn't take forever to render pages on Chromium-based browsers. One of the downside of using this property is the scroll bar makes indeed some strange jumps. It was introduced in https://github.com/nodejs/node/pull/37301.","aduh95",14309773,"2021-09-13 22:31:10",NULL
1886,318,"I wonder if the kind of solution described [here](https://infrequently.org/2020/12/resize-resilient-deferred-rendering/) or something similar would solve these problems?

It's very frustrating not being able to properly navigate the documentation a page at a time or by sliding the scroll bar. It seems to me like the browser should keep elements rendered after it's rendered the first time, which should solve the scrolling problem. It seems like the solution I linked to explicitly does this?","mscdex",54666,"2021-09-14 00:59:46",NULL
1887,318,"Yep that looks promising indeed. Would you be interested in sending a PR? On the mean time (and I know this is not a satisfactory answer to that issue, more a temporary workaround), you may find Firefox more suitable to browse the docs as they haven't implemented `content-visibility` and they also able to render large pages in a reasonable time.","aduh95",14309773,"2021-09-14 09:46:10",NULL
1888,318,"It works fine on macOS Chrome","himself65",14026360,"2021-09-18 05:55:09",NULL
1889,318,"I think this also causes an issue if you try to open any URL with a hash in a new tab. It doesn't scroll to the desired method / property.","szmarczak",36894700,"2021-09-24 20:33:57","think cause issue try open url hash new tab scroll desire method property
"
1890,318,"I am working on this rn 

","saltybuckets",49991711,"2021-09-25 13:54:05","work
"
1891,318,"I hate to pile on but this issue has made browsing the API docs an exercise in frustration for a while now. The scrollbar jumps all over the place when trying to drag it, as well as the yellow indicators when you do a ctrl+f. I never end up in the correct place when following an anchor link.

I'm surprised there haven't been more reports after all this time, surely it's more than just a handful of us affected? Chrome on Windows here. Firefox seems fine as mentioned.","noinkling",4338251,"2022-01-15 03:51:49","hate pile issue make browse api doc exercise frustration scrollbar jump place drag yellow indicator ctrl f never end correct place follow anchor link surprise report time surely handful affect chrome window firefox fine mention
"
1892,318,"@mscdex, for reading the current open Issue, for me, the takes are the following:

- The original `content-visibility` was introduced to reduce the re-paint on resizing of pages or other shenanigans
- It also had the benefit of a smaller initial rendering footprint

**Then there's the discussion about if it should be removed:**

- It would fix anchor link positioning behaviour, which is an important aspect of the experience
- It would allow scrolling behaviour to be respected

There's, of course, the approach of doing some JavaScript spaghetti, as I saw in some random blog post. Still, I'm severely against having arbitrary JavaScript code that tries to ""fix"" the web (by inherently trying to change how certain behaviours happen).

**What I imagine as an ""ideal"" solution for now:**

- Remove the content-visibility API.
  - 99th percentile of devices nowadays are efficient enough to render even the longest pages hassle-free. Of course, constant resizes of the page on desktop browsers will increase the CPU heap during the resize by a lot, but that's an OKAY outcome. People will only sometimes resize their pages; that is an edge case, imho.
- Add CSS grids for the two columns.
  - This page was probably done before the time of CSS grids.
  - It would allow us to remove a few margin-padding hacks
  - It would fix the width issue that happens due to content-visibility being removed
  - Enforces the maximum width of the second column and respects the page size

**Regarding modern technologies:**

Modern browsers and rendering engines are already smart enough to offload computing from complex parts.

I did some synthetic loads on the current API website with `content-visibility` disabled and requested Chrome to profile the page. I tried to do intensive scrolling behaviour to check for bottlenecks. I saw no significant bottlenecks, CPU-heap increase or significant delays/increase on the repainting/re-rendering of the page.

Moreover, disabling `content-visibility` shouldn't be a problem. I tried the same behaviour on an iPhone by using remote DevTools to disable those CSS rules. Didn't see any noticeable lag.

Of course, some real old phones or hardware would struggle a little. But given that technology is ever-evolving, I doubt someone would consistently open our API docs on a tiny smartphone from 7 years ago...

I feel inclined toward the approach/solution I mentioned above.","ovflowd",12037269,"2023-05-05 08:27:23","remove content visibility api add css grid fix anchor link position scrolling behavior improve page render performance modern browser efficient enough handle long page resize edge case remove margin padding hack fix width issue enforce maximum width second column respect page size  synthetic load test show insignificant bottleneck cpu heap increase delay repaint rerender disable content visibility iphone no noticeable lag old hardware struggle little technology evolve unlikely consistently open api doc tiny smartphone year ago prefer remove content visibility api add css grid
"
1893,318,"> * 99th percentile of devices nowadays are efficient enough to render even the longest pages hassle-free.

I wonder where you get that figure from, in my experience loading the `all.html` on a Chromium browser was a real struggle for my 2019 MBP, and I’m pretty sure that’s not the lowest spec you’ll find out there. But maybe Google or Microsoft fixed that since I made the measurements reported in https://github.com/nodejs/node/pull/37301#issue-804958274","aduh95",14309773,"2023-05-05 15:52:59","99th percentile device nowadays efficient render long page hassle free wonder figure experience load chromium browser real struggle 2019 mbp pretty sure low spec google microsoft fix measurement
"
1894,318,"Well, the percentile is based on Browserslists on which browsers supporting supporting the 95th percentile. (https://browserslist.dev/?q=Y292ZXIgOTUl)

And sorry, I meant the 95th percentile not the 99th.

I can at least on all my devices open it perfectly without any issues. Using Chrome DevTools to mimic hardware constrained situations it also seems to work fine.

Of course to a certain degree I'm doing an opinionated guess.","ovflowd",12037269,"2023-05-05 15:58:33","percentile base browser support percentile  sorry mean percentile  device open perfectly issue use chrome devtool mimic hardware constrain situation also seem work fine course degree opinionated guess
"
1895,318,"To clarify, do you mean that building the docs locally commenting out the `content-visibility` from the CSS has no effect on the rendering time? That’s surprising to say the least, but a very good news if true (I can’t confirm, I’m away from computer). Can you share the rendering time on both versions please?","aduh95",14309773,"2023-05-05 16:30:20","clarify mean build doc locally comment content visibility css effect render time surprising good news confirm away computer share render time version
"
1896,318,"> To clarify, do you mean that building the docs locally commenting out the content-visibility from the CSS has no effect on the rendering time?

No need to rebuild the docs; just disable the property directly on the browser.

> That’s surprising to say the least, but a very good news if true (I can’t confirm, I’m away from computer). Can you share the rendering time on both versions please?

I'm not sure I can give you a reliable rendering time or statistics as they're bound to my computer. But by even doing a 6x CPU slow down and checking GPU raster it sounds OK. Feel free to check by yourself.","ovflowd",12037269,"2023-05-05 16:49:45","clarify mean build doc locally comment content visibility css effect render time need rebuild doc disable property directly browser surprise say least good news confirm away computer share render time version sure give reliable render time statistic bound computer even  cpu slow check gpu raster sound feel free check
"
1897,318,"> No need to rebuild the docs; just disable the property directly on the browser.

Yes you need to rebuild the docs, because `content-visibility` (used to?) affect the rendering time, so disabling it from DevTools won’t help there because it won’t let you disable it until after the first rendering is done (unless I’m missing something). I can try later, as I said I’m away from the computer at the moment. 

> I'm not sure I can give you a reliable rendering time or statistics as they're bound to my computer

That’s OK, what I’m interested in is the difference (on the same CPU) of rendering time, absolute values don’t matter in this case. ","aduh95",14309773,"2023-05-05 16:58:19","need rebuild doc disable property directly browser need rebuild doc content visibility affect render time disable devtool help let disable first render unless miss try later away computer moment sure give reliable render time statistic bound computer ok interest difference cpu render time absolute value matter case
"
1906,318,"> I don't know if anything changed recently, but I've noticed that many references now jump to wrong locations, which makes navigating through the docs frustrating. This happens both for anchors within the same document and across different HTML pages, and more frequently with anchors towards the bottom of long documents, which is why I assume it's some CSS gimmick that's not working well with the current version of Firefox. Also, clicking anywhere in the document or attempting to select text sometimes randomly scrolls to a new location.

It is a new bug, https://issues.chromium.org/issues/333443429","ovflowd",12037269,"2024-06-17 14:56:42","refer reference jump wrong location navigate doc frustrating happen anchor document html page frequently anchor bottom long document assume css gimmick work well current version firefox click document attempt select text randomly scroll new location bug
"
1907,318,"@ovflowd FWIW, I am using Firefox :)","tniessen",3109072,"2024-06-17 15:07:42","use firefox
"
2022,330,"Landed in 45420013eea07c5b80e1e2833ee21de2dba89193...4ece669c6205ec78abfdadfe78869bbb8411463e","github-actions[bot]",41898282,"2021-08-11 17:44:14","Landed
"
1898,318,"> Yes you need to rebuild the docs, because content-visibility (used to?) affect the rendering time, so disabling it from DevTools won’t help there because it won’t let you disable it until after the first rendering is done (unless I’m missing something). I can try later, as I said I’m away from the computer at the moment.

Well, you know you can just download all the assets, change the style.css and then run a local server 😅 

I'm not on my MacBook, hence why I didn't have the tools to build the docs. But afaik just downloading a copy of the built website (Ctrl + S) + Editing the CSS files + some random simple `node` server should be enough.

> That’s OK, what I’m interested in is the difference (on the same CPU) of rendering time, absolute values don’t matter in this case.

Well, I saw a difference of just shy ~500ms (Mostly) on the Rendering Time. Note that I started the profiling before opening the Website.","ovflowd",12037269,"2023-05-05 17:00:49","need rebuild doc content visibility affect render time disable devtool help disable first render miss thing try later away computer moment know download asset change style css run local server macbook tool build doc afaik download copy build website edit css file random simple node server enough ok interest difference cpu render time absolute value matter case see difference shy 500ms mostly render time note start profil open website
"
1899,318,"OK so I've got back to my computer, and tried on Chromium 112.0.5615.137 on my M2 MBP: using `content-visibility: auto` makes the rendering happens 6x faster, and it takes 70% of the time to load the same page.

With <code>content-visibility: auto</code>: rendering takes 269ms:

<img width=""314"" alt=""image"" src=""https://user-images.githubusercontent.com/14309773/236599823-24182a22-30f3-475a-a4e2-629dc0f0a1c4.png"">

Without <code>content-visibility: auto</code>: rendering takes 1732ms:

<img width=""315"" alt=""image"" src=""https://user-images.githubusercontent.com/14309773/236599762-e3d5ab1e-7852-4d5b-b502-b93cd878a679.png"">

(I promise I didn't cherry-picked it, I run the performance profiller once on `all.html` for each and took a screenshot; still using a sample of 1 is not a very scientific way of comparing the two, but IMO it's really not insignificant).","aduh95",14309773,"2023-05-06 04:42:11","content visibility auto render fast load page content visibility auto render take ms content visibility auto render take ms promise cherry pick run performance profiler html take screenshot sample scientific way compare insignificant
"
1900,318,"> (I promise I didn't cherry-picked it, I run the performance profiller once on all.html for each and took a screenshot; still using a sample of 1 is not a very scientific way of comparing the two, but IMO it's really not insignificant).

Yeah agreed. For me, for example, the rendering time with `content-visibility` costs me around 870ms, without `content-visibility`, I get around 1540ms. So it is also dependent on your hardware, which is fair. Regardless, we see a consistent 120% uplift in rendering time, which is fine.

But honestly speaking, I feel that in the future (with the API Docs redesign), we should eliminate the ""all.html"" page. It genuinely doesn't make sense to have a gigantic page containing everything simultaneously. No other Docs Page I know does this. All other pages on our API Docs, including http.html, take around 33ms to load... So, all other pages have reasonable loading times.","ovflowd",12037269,"2023-05-06 23:24:53","promise cherry pick run performance profiler all html screenshot sample scientific way compare imo insignificant agree example render time content visibility cost around ms content visibility get around ms depend hardware fair regardless see consistent uplift render time fine honestly feel future api doc redesign eliminate all html page genuinely make sense gigantic page contain everything simultaneously doc page know page api doc includ http html take around ms load page reasonable load time
"
1901,318,"`fs.html` is another huge one that you can test to see how it affects the load. We can decide that it’s fine indeed, and ask folks to use a non-Chromium browser if they hardware has a hard time loading our docs, as long as that trade off that might work for most of our visitors (is it possible to have data on that?) and we are open about making that choice. ","aduh95",14309773,"2023-05-06 23:36:51","decide fine ask folk use non chromium browser hardware hard time load doc long trade work visitor possible data open choice
"
1902,318,"I genuinely feel right now the fact that we have content-visibility is actually breaking features of the docs pages such as scrolling and anchor links.

Not to mention the redesign docs will pretty much not have this, so my 2 cents:

- either we remove content-visibility and add the css grid
- we just ignore this until we switch to the new redesigned docs page that is owned by the Website Team","ovflowd",12037269,"2023-05-06 23:40:51","feel fact content visibility break feature doc page scroll anchor link mention redesign doc pretty much ignore switch redesign doc page own website team remove content visibility add css grid
"
1903,318,"Until this is hashed out, there's a trivial incremental improvement that we can make to mitigate some of the usability issues here (which are particularly bad/unusable in Firefox Nightly & Firefox-with-`content-visibility`-enabled-in-about-config).  We can avoid much of the trouble by adding `auto` to the `contain-intrinsic-size` CSS declaration, which just lets the browser save the sizes that it lazily computes, once it's been forced to compute them (by scrolling an element on-screen).

See https://github.com/nodejs/node/pull/48195 - if anyone with the ability to review/merge PRs here wouldn't mind taking a look over there, that would be much appreciated.","dholbert",426803,"2023-05-26 17:56:28","add auto contain intrinsic size css declaration browser save size lazily compute force compute scroll element screen improve mitigate usability issue firefox nightly firefox content visibility enable about config avoid trouble
"
1904,318,"@mscdex this issue maybe resolve by pr above, could you please check it?","KuthorX",49077331,"2023-10-11 09:41:09","issue resolve check
"
1905,318,"I don't know if anything changed recently, but I've noticed that many references now jump to wrong locations, which makes navigating through the docs frustrating. This happens both for anchors within the same document and across different HTML pages, and more frequently with anchors towards the bottom of long documents, which is why I assume it's some CSS gimmick that's not working well with the current version of Firefox. Also, clicking anywhere in the document or attempting to select text sometimes randomly scrolls to a new location.","tniessen",3109072,"2024-06-13 11:28:25","reference jump wrong location navigate doc frustrate anchor document html page frequently anchor bottom long document assume css gimmick work current version firefox click document attempt select text randomly scroll new location
"
1908,318,"I think what's new is that recent versions of Firefox support the `content-visibility` CSS property (unflagged in version 125) – which is unfortunate, as contrarily to Chromium, Firefox has (had) no problem rendering the very large HTML pages from our docs.","aduh95",14309773,"2024-06-17 15:41:05","new version firefox support content visibility css property unfortunate contrarily chromium firefox problem render large html page doc
"
1909,318,"Yeah, I've never had any issues opening our docs until recently. Now, navigating through them is frustrating.","tniessen",3109072,"2024-06-17 15:44:45","issue open doc navigate frustrat
"
2023,332,"@nodejs/streams ","targos",2352663,"2021-07-19 14:51:20","nodejs stream
"
1910,318,"I see, so now Firefox users are actually seeing the already existing behaviour for Chrome.

Well, the only reason for such `content-visibility` flag to exist, is that otherwise rendering the massive `all.html` page would be pretty much disgraceful for devices (in terms of performance)

That simple CSS rule allows the browser to not render/process such elements until they're not visible on your viewport. This also causes the issue that the scrollbar calculation is wrong due to... well, the scrollbar at the time of load != once you start jumping/scrolling to these sections.

I need to check if we have some weird JavaScript code regarding smooth scrolling, but these are pains that, IMO, would be mitigated with the new API docs.","ovflowd",12037269,"2024-06-17 16:15:30","browser render element scrollbar calculation api doc javascript smooth scroll performance mitigate
"
1911,318,"> Well, the only reason for such `content-visibility` flag to exist, is that otherwise rendering the massive `all.html` page would be pretty much disgraceful for devices (in terms of performance)

If that is quite literally the only reason, can we just set the flag for `all.html`? I personally never use that page and we don't cross-reference it to point to specific APIs either as far as I am aware.","tniessen",3109072,"2024-06-18 08:18:02","reason content visibility flag exist render massive page disgraceful device term performance reason set flag page personally never use page cross reference point specific api aware
"
1912,318,"> > Well, the only reason for such `content-visibility` flag to exist, is that otherwise rendering the massive `all.html` page would be pretty much disgraceful for devices (in terms of performance)
> 
> If that is quite literally the only reason, can we just set the flag for `all.html`? I personally never use that page and we don't cross-reference it to point to specific APIs either as far as I am aware.

I think we could get rid of that page altogether... Which is already the goal. I unfortunately don't have the capacity at the moment to make changes on the old API docs tooling as Im writing the new one... But I assume that it shouldn't be so hard to remove the all.html from the code.

I wonder if we even care about the broken links to all.html and if we can somewhat do redirects... I wonder why that page got created to begin with.","ovflowd",12037269,"2024-06-18 11:36:01","render massive page disgraceful device term performance reason set flag page personally use page cross reference point specific api aware think could get rid page goal unfortunately capacity moment make change old api doc tool write new one assume hard remove code wonder care broken link redirect wonder page get create begin
"
1913,318,"cc @Trott or @mhdawson maybe one of you know more about the context behind it","ovflowd",12037269,"2024-06-18 11:36:32","Trott mhdawson know context
"
1914,318,"It’s also the case for e.g. `fs.html`, or any doc page that’s large enough. ","aduh95",14309773,"2024-06-18 13:40:59","case doc page large
"
1915,319,"Seen on the CITGM run for 16.9.0, https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754
e.g. https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754/nodes=ubuntu1804-64/testReport/junit/(root)/citgm/jest_v27_1_0/
","richardlau",5445507,"2021-09-07 13:50:28","seen citgm run e.g nodejs citgm job citgm smoker test report junit root citgm jest v


**Explicação das etapas:**

1. **Remoção de ruídos:**  As URLs  `https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754` e `https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754/nodes=ubuntu1804-64/testReport/junit/(root)/citgm/jest_v27_1_0/` foram removidas.  O ponto final após o ""e.g."" também foi removido.

2. **Padronização de palavras:**  Não foi possível realizar a stemming ou lemmatização de forma precisa sem o uso de uma biblioteca de processamento de linguagem natural (NLTK, spaCy, etc.).  A resposta simplifica mantendo a forma básica das palavras onde possível.  Por exemplo, ""smoker"" e ""nodes"" não foram alterados.  Uma padronização mais completa exigiria um lemmatizer ou stemmer.

3. **Remoção de stop words:**  Não foi possível remover as stop words sem uma lista específica de stop words para a língua inglesa.  ""On"", ""for"", e ""the"" são stop words, mas a remoção delas depende de uma lista predefinida e da escolha de se incluir ou não stop words como ""e.g."" (que significa ""por exemplo"").  A resposta foi mantida mais conservadora para este exemplo, mantendo algumas palavras que *poderiam* ser consideradas stop words, mas que poderiam ser relevantes para o contexto de um sistema de classificação de issue.


Para um pré-processamento mais robusto, é altamente recomendável usar bibliotecas de processamento de linguagem natural em Python (como NLTK ou spaCy) que oferecem funcionalidades de stemming/lemmatization e remoção de stop words.
"
1916,319,"> Seen on the CITGM run for 16.9.0, https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754
> e.g. https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754/nodes=ubuntu1804-64/testReport/junit/(root)/citgm/jest_v27_1_0/

I'm sad I did not see that one, because I looked at the result for other machines and it was related to MongoDB process issues as usual...

Here's another run with the same failure against the master branch: https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2756/nodes=ubuntu1804-64/testReport/junit/(root)/citgm/jest_v27_1_0/
So we can at least exclude the ABI compat patch (that's only in v16.9.0) from the possible causes.

/cc @nodejs/v8","targos",2352663,"2021-09-07 14:41:21","sad see one look result machine relate mongodb process issue usual another run failure master branch exclude abi compat patch possible cause cc nodejs v8
"
1917,319,"I think the failing check is from https://github.com/v8/v8/commit/76b9d98fc90ecb76c6002f937d6eb5487873db5d

/cc @schuay","targos",2352663,"2021-09-07 15:07:56","think fail check
"
1918,319,"The following can be used to reproduce this bug (in my case it crashes at 140):

```js
describe('holder_map.has_named_interceptor crash', () => {
  for (let i = 0; i < 140; i++) {
    it(`${i}`, () => {
      //
    });
  }
});
```

Run test:
```sh
jest test.js
```","akornatskyy",13451015,"2021-09-07 15:08:38","reproduce bug crash test
"
1919,319,"The bug is triggered by the compilation of this function:

https://github.com/facebook/jest/blob/36208850c82313e48caa1adc1ef35f83f84f0c75/packages/jest-circus/src/state.ts#L48-L52","targos",2352663,"2021-09-07 15:29:51","bug trigger compilation function
"
1920,319,"Repro without Jest:

```js
const vm = require('vm');

vm.runInNewContext(`

const STATE_SYM = Symbol('JEST_STATE_SYMBOL')
const eventHandlers = [() => {}];
const dispatch = async () => {
  for (const handler of eventHandlers) {
    await handler(this[STATE_SYM]);
  }
};

for (let i = 0; i < 1e6; i++) {
  dispatch();
}

`);
```","targos",2352663,"2021-09-07 15:42:32","repro jest


state sym symbol eventhandler dispatch handler state sym


"
1921,319,"I created an upstream bug: v8:12188
Cannot do more from my side.","targos",2352663,"2021-09-07 15:52:44","create upstream bug side
"
1955,320,"Same here...","RaphaelMechali",23741720,"2023-09-05 13:35:38","same
"
1956,320,"You might try using https://www.npmjs.com/package/jest-light-runner to use Jest without `vm.Script`.","nicolo-ribaudo",7000710,"2023-09-05 13:45:39","try use jest light runner use jest without vm script
"
2020,330,"CI: https://ci.nodejs.org/job/node-test-pull-request/39527/
V8 CI: https://ci.nodejs.org/job/node-test-commit-v8-linux/4198/","nodejs-github-bot",18269663,"2021-08-09 17:53:15","CI V8 CI
"
2021,330,"CI: https://ci.nodejs.org/job/node-test-pull-request/39528/","nodejs-github-bot",18269663,"2021-08-10 05:40:15","CI
"
1922,319,"Is this caused by a v8 update? If so, any chance of reverting it? Or do we think (hope 😀) a fix will land upstream relatively quickly and it'll be cherry picked?

> > Seen on the CITGM run for 16.9.0, [ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754](https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754)
> > e.g. [ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754/nodes=ubuntu1804-64/testReport/junit/(root)/citgm/jest_v27_1_0](https://ci.nodejs.org/view/Node.js-citgm/job/citgm-smoker/2754/nodes=ubuntu1804-64/testReport/junit/(root)/citgm/jest_v27_1_0/)
> 
> I'm sad I did not see that one, because I looked at the result for other machines and it was related to MongoDB process issues as usual...

We should skip the mongo test if it causes noise hiding real issues. I'll open an issue in CITGM to track

EDIT: https://github.com/nodejs/citgm/issues/875","SimenB",1404810,"2021-09-08 08:58:09","causar v8 update chance reverter pensar fix land upstream rapidamente cherry pick ver citgm run 16.9.0 triste ver resultado maquina relacionado mongodb process issue usual pular mongo test causar ruido esconder issue real abrir issue citgm track
"
1923,319,"> Is this caused by a v8 update? If so, any chance of reverting it? Or do we think (hope ) a fix will land upstream relatively quickly and it'll be cherry picked?

I expect we'll fix this upstream in the next couple of days.","schuay",36006,"2021-09-08 09:01:55","fix upstream day
"
1924,319,"@SimenB In the mean time, would you be open to tweaking the problematic function in `jest-circus` so that it doesn't trigger this bug (I can help with it)?
Edit: well, actually I can't find a way to prevent this optimization from happening 🙃 ","targos",2352663,"2021-09-08 10:22:02","time open tweak problematic function jest circus trigger bug help find way prevent optimization happen
"
1925,319,"Happy to land any change that would prevent it or just make it better in general and avoiding the problem altogether 🙂 ","SimenB",1404810,"2021-09-08 11:08:31","happy land change prevent make good avoid problem
"
1926,319,"Jest tests are failing on Github actions also for the same reason like reproduction script after using `jest.useFakeTimers()` before each test case. Downgrading Nodejs ci version to 16.8 worked for me.

```
beforeEach(() => {
    jest.useFakeTimers()
})
```","matinzd",24797481,"2021-09-08 12:43:46","test fail github action reason reproduction script use faketimer downgrade nodejs version 16 work
"
1927,319,"This has been [fixed upstream](https://bugs.chromium.org/p/v8/issues/detail?id=12188) one hour ago. Release upcoming, I guess... ","JJ",500,"2021-09-09 06:42:44","fix hour ago release upcoming
"
1928,319,"> This has been [fixed upstream](https://bugs.chromium.org/p/v8/issues/detail?id=12188) one hour ago. Release upcoming, I guess...

https://github.com/nodejs/node/pull/40046","gengjiawen",3759816,"2021-09-09 06:43:15","fix hour ago release upcoming guess
"
1929,319,"@nodejs/releasers we need a new release for 16.9","gengjiawen",3759816,"2021-09-10 03:46:06","nodejs releaser need new release
"
1930,320,"And another amazing thing:

1. run `node --expose-gc --max-heap-size=100 --inspect=9229 test.js` for a while, OOM.
2. run `node --expose-gc --max-heap-size=100 --inspect=9229 test.js` and then run `node inspect localhost:9229`, everything will be OK and there's no OOM any more.","XadillaX",2842176,"2021-09-06 11:03:22","run node expose gc max heap size 100 inspect 9229 test js while oom run node expose gc max heap size 100 inspect 9229 test js run node inspect localhost 9229 ok oom
"
1931,320,"I added

```js
if (times === 330) {
  require('v8').writeHeapSnapshot();
}
```

To the code, and found there're full of the `str` object like:

![深度截图_选择区域_20210906190745](https://user-images.githubusercontent.com/2842176/132208239-0053adef-39f5-4f68-8fce-ad1e9186e06a.png)
","XadillaX",2842176,"2021-09-06 11:08:25","add code find full str object
"
1932,320,"The leak seems in `CompilationCache`.

![深度截图_选择区域_20210907140356](https://user-images.githubusercontent.com/2842176/132292373-878c30b3-8952-4678-b07b-b14de8ca58ee.png)

That means when I run command below in Node.js 14 / 16:

```bash
$ node --expose-gc --max-heap-size=100 --no-compilation-cache test2.js
```

The behavior is right - no longer OOM.","XadillaX",2842176,"2021-09-07 06:05:00","leak seem compilationcache mean run command nodejs expose gc max heap size compilation cache behavior right longer oom
"
1933,320,"/cc @nodejs/v8","targos",2352663,"2021-09-07 06:06:44","nodejs v8
"
1934,320,"In Node.js 12, the heap size will up to about 100M either. But after it cannot allocate more space, it will trigger `kLastResort` GC because:

https://github.com/nodejs/node/blob/v12.22.6/deps/v8/src/heap/heap.cc#L4904-L4925

After `kLastResort` GC, the heap size will down to very small.

And Node.js 14 / 16 will never trigger `kLastResort` GC:

https://github.com/nodejs/node/blob/v14.16.0/deps/v8/src/heap/heap.cc#L5205-L5226

And heap size still increases until OOM.","XadillaX",2842176,"2021-09-07 08:31:23","node heap size 100m allocate space trigger klastresort gc klastresort gc heap size small node 14 16 never trigger klastresort gc heap size increase oom
"
1935,320,"https://github.com/nodejs/node/blob/master/deps/v8/src/heap/mark-compact.cc#L1458-L1469

`EvacuateNewSpaceVisitor::Visit()` in GC, this new code (After Node.js 14) requires allocating an old space block and returns an `AllocateResult.IsRetry()` object. `heap_->FatalProcessOutOfMemory()` here at last.

So we should think what should we do when we're under GC but we have no enough space to allocate old space block.

Old V8 (Node.js 12) just no this `if` logic, and allocate old space anyway. And it will do `kLastResort` GC later.

What's more, it seems that I can't disable `always promote young mc` by `--no-always-promote-young-mc` because of `DEFINE_IMPLICATION(array_buffer_extension, always_promote_young_mc)` in v8's `src/flags/flag-defination.h`.

---

## Refs

+ https://github.com/nodejs/node/commit/2c59f9bbe29df1ee3e714671de1433369992eba7#diff-d53f68b29a1c48c958c2e6779cc25c916a986357c6010dd01421c17adcf2f09bR150
+ https://github.com/v8/v8/commit/13ddba2a64d62cda6d4b9058b6c82974e54547fc
+ https://github.com/v8/v8/commit/6279a75ee55a618ca7679ffeb4c641e542b56d8b
+ https://github.com/v8/v8/commit/67702104f1b439b5c855fd385b888f39006cb2ff","XadillaX",2842176,"2021-09-07 10:11:30","evacuatenewspacevisitor visit gc new code node require allocate old space block return allocateresult isretry object heap fatalprocessoutofmemory think enough space allocate old space block old v8 node just logic allocate old space anyway klastresort gc seem disable always promote young mc no always promote young mc defineimplication array buffer extension always promote young mc v8 src flags flag defination
"
1936,320,"I think we have 2 ways to fix this bug:

1. Fix `_always_promote_young`'s logic in GC - make allocate old space not throw error when heap size up to exceeded.
2. Set `array_buffer_extension` in gyp back to 0, and set  `--always-promote-young-mc` defaults to `false`.

btw. why UnboundScript's script cache and its code string won't GCed until `kLastResort` (aka. heap size up to exceeded)? Can this be fixed?","XadillaX",2842176,"2021-09-07 14:23:11","fix bug way logic gc make allocate old space throw error heap size exceed set array buffer extension gyp set always promote young mc default false unboundscript script cache code string gc klastresort heap size exceed fix
"
2016,329,"V8 CI: https://ci.nodejs.org/job/node-test-commit-v8-linux/4227/","Qard",205482,"2021-08-27 06:25:57","V8 CI
"
2017,329,"Retry: https://ci.nodejs.org/job/node-test-commit-v8-linux/4228/

","targos",2352663,"2021-08-27 09:13:41","Retry
"
1937,320,"There're several problems (bugs) occur this one issue:

1. All `Script`'s `CompilationCache` in the heap and won't be GCed until Last Resort GC; (It will make heap size to the limit and `--no-compilation-cache` can resolve it)
2. `--always-promote-young-mc` will OOM when old space cannot allocate more memory (e.g. when heap size limit exceeded); (I think it should do a Last Resort GC when we meet this situation like Node.js 12's V8)
3. We cannot close `--always-promote-young-mc` because `--array-buffer-extension` always `true` at compile time.

/cc @targos 
/ping @nodejs/v8 ","XadillaX",2842176,"2021-09-08 05:01:13","problem bug occur issue script compilationcache heap gc last resort gc make heap size limit no compilation cache resolve always promote young mc oom old space allocate memory heap size limit exceed think last resort gc situation node v8 close always promote young mc array buffer extension true compile time
"
1938,320,"https://bugs.chromium.org/p/v8/issues/detail?id=12198","XadillaX",2842176,"2021-09-08 11:37:35","v8 issue detail id 12198
"
1939,320,"This answer helped me: [StackOverflow](https://stackoverflow.com/questions/38558989/node-js-heap-out-of-memory/66914674#66914674)","sidverma32",10995431,"2021-10-29 12:54:47","answer help
"
1940,320,"@XadillaX given you did such detailed analysis do you have any idea what is the path forward now v8 closed the bug you raised as won’t fix ? With some suggestions for the node team ?","lukeapage",309321,"2021-12-15 16:00:37","given detailed analysis idea path forward v8 close bug raise wont fix suggestion node team
"
1941,320,"> @XadillaX given you did such detailed analysis do you have any idea what is the path forward now v8 closed the bug you raised as won’t fix ? With some suggestions for the node team ?

Hmmm... I'm not sure since V8 closed that issue. I think we can't do anything without v8's change.","XadillaX",2842176,"2021-12-16 06:26:04","dado detalhado analise ideia caminho v8 fechar erro sugerir equipe node certo v8 fechar problema pensar nada v8 mudar
"
1942,320,"@XadillaX Is this still a problem for you in Node 14.19.0?","typeofweb",1338731,"2022-02-21 15:46:36","problem node
"
1943,320,"I decided to do some digging and built on the sample script provided by @XadillaX.

```
'use strict';
const { getHeapStatistics } = require('v8');

let times = 0;
// The largest heap size observed since last logging output.
let heapMax = 0;
// The absolute largest heap size seen.
let absoluteHeapMax = 0;

function run() {
  let str = 'var a = ""';
  for (let i = 0; i < (100 * 1024) / 18; i++) str += Math.random().toString();
  str += '"";';

  const script = new (require('vm').Script)(str);
  times++;

  const heap = getHeapStatistics();
  heapMax = Math.max(heapMax, heap.total_heap_size);
  absoluteHeapMax = Math.max(absoluteHeapMax, heap.total_heap_size);

  if (times % 50 === 0) {
    console.log(
      times,
      `Heap - Since last: ${bytesToSize(heapMax)} | Absolute: ${bytesToSize(
        absoluteHeapMax
      )}`
    );

    heapMax = 0;
  }
}

// https://stackoverflow.com/a/18650828/468214
function bytesToSize(bytes) {
  var sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];
  if (bytes == 0) return '0 Byte';
  var i = parseInt(Math.floor(Math.log(bytes) / Math.log(1024)));
  return Math.round(bytes / Math.pow(1024, i), 2) + ' ' + sizes[i];
}

(async () => {
  while (true) {
    run();

    await new Promise((resolve) => {
      setTimeout(() => {
        resolve();
      }, 10);
    });

    gc();
  }
})();
```

```
node --expose-gc --max-heap-size=100 scripts/heap.js
```

* 12.16.1 - 5000+ iterations
* 14.0.0 - 5000+ iterations
* 14.3.0 - 5000+ iterations
* 14.4.0 - 5000+ iterations
* [14.5.0](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V14.md#14.5.0) - Crash @ 350 iterations - V8 upgrade to 8.3
* 14.6.0 - Crash @ 350 iterations
* 14.10.0 - Crash @ 350 iterations
* 14.12.0 - Crash @ 350 iterations
* 14.15.0 - Crash @ 350 iterations
* 14.18.2 - Crash @ 350 iterations
* 14.19.0 - Crash @ 350 iterations
* 16.3.0 - Crash @ 350 iterations
* 16.9.1 - Crash @ 350 iterations
* 16.10.0 - Crash @ 350 iterations
* 16.11.0 - Crash @ 350 iterations
* [16.14.0](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V16.md#16.14.0) - Crash @ 750 iterations
* [16.14.1](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V16.md#16.14.1) - Crash @ 750 iterations.
* 16.14.2 - Crash @ 750 iterations
* 17.0.0 - Crash @ 350 iterations
* 17.8.0 - Crash @ 350 iterations
* 18.1.0 - [Crash @ 750 iterations](https://github.com/nodejs/node/issues/40014#issuecomment-1154110266)

As has been noted, the versions that don't crash appear to correctly GC as they approach the heap limit.
```
Now using node v12.16.1 (npm v6.13.4)
50 Heap - Since last: 17 MB | Absolute: 17 MB
100 Heap - Since last: 30 MB | Absolute: 30 MB
150 Heap - Since last: 42 MB | Absolute: 42 MB
200 Heap - Since last: 55 MB | Absolute: 55 MB
250 Heap - Since last: 67 MB | Absolute: 67 MB
300 Heap - Since last: 80 MB | Absolute: 80 MB
350 Heap - Since last: 91 MB | Absolute: 91 MB
400 Heap - Since last: 99 MB | Absolute: 99 MB
450 Heap - Since last: 21 MB | Absolute: 99 MB
500 Heap - Since last: 34 MB | Absolute: 99 MB
550 Heap - Since last: 46 MB | Absolute: 99 MB
600 Heap - Since last: 59 MB | Absolute: 99 MB
650 Heap - Since last: 71 MB | Absolute: 99 MB
```

@mmiszy yes it's still an issue at 14.19.0.
```
Now using node v14.19.0 (npm v6.14.16)
50 Heap - Since last: 18 MB | Absolute: 18 MB
100 Heap - Since last: 31 MB | Absolute: 31 MB
150 Heap - Since last: 43 MB | Absolute: 43 MB
200 Heap - Since last: 56 MB | Absolute: 56 MB
250 Heap - Since last: 68 MB | Absolute: 68 MB
300 Heap - Since last: 81 MB | Absolute: 81 MB
350 Heap - Since last: 92 MB | Absolute: 92 MB

<--- Last few GCs --->

[91848:0x104a08000]     6074 ms: Mark-sweep 72.2 (91.5) -> 71.7 (91.8) MB, 4.3 / 0.0 ms  (average mu = 0.735, current mu = 0.757) testing GC in old space requested
[91848:0x104a08000]     6092 ms: Mark-sweep 72.4 (91.8) -> 71.9 (92.0) MB, 4.8 / 0.0 ms  (average mu = 0.732, current mu = 0.730) testing GC in old space requested
[91848:0x104a08000]     6111 ms: Mark-sweep 72.6 (92.0) -> 72.1 (92.3) MB, 6.1 / 0.0 ms  (average mu = 0.707, current mu = 0.682) testing GC in old space requested

```

V16.14.X is a bit weird. 
```
Now using node v16.14.0 (npm v8.3.1)
50 Heap - Since last: 18 MB | Absolute: 18 MB
100 Heap - Since last: 31 MB | Absolute: 31 MB
150 Heap - Since last: 43 MB | Absolute: 43 MB
200 Heap - Since last: 56 MB | Absolute: 56 MB
250 Heap - Since last: 68 MB | Absolute: 68 MB
300 Heap - Since last: 81 MB | Absolute: 81 MB
350 Heap - Since last: 93 MB | Absolute: 93 MB
400 Heap - Since last: 100 MB | Absolute: 100 MB
450 Heap - Since last: 24 MB | Absolute: 100 MB
500 Heap - Since last: 37 MB | Absolute: 100 MB
550 Heap - Since last: 49 MB | Absolute: 100 MB
600 Heap - Since last: 62 MB | Absolute: 100 MB
650 Heap - Since last: 74 MB | Absolute: 100 MB
700 Heap - Since last: 87 MB | Absolute: 100 MB
750 Heap - Since last: 99 MB | Absolute: 100 MB

<--- Last few GCs --->

[6500:0x7fda3c100000]    12269 ms: Mark-sweep 78.5 (99.7) -> 77.9 (99.7) MB, 2.6 / 0.0 ms  (average mu = 0.835, current mu = 0.840) testing GC in old space requested
[6500:0x7fda3c100000]    12286 ms: Mark-sweep 78.7 (99.9) -> 78.1 (99.9) MB, 3.4 / 0.0 ms  (average mu = 0.820, current mu = 0.805) testing GC in old space requested
[6500:0x7fda3c100000]    12292 ms: Mark-sweep 78.6 (99.9) -> 78.2 (100.2) MB, 3.3 / 0.0 ms  (average mu = 0.718, current mu = 0.417) allocation failure GC in old space requested
```

I admit, I'm not experienced in this kind of debugging so there's a good chance I've screwed something up. But if I haven't it suggests the issue appeared in Node V14.5.0, hasn't gotten any worse/better since then apart from a bit of weirdness in In V16.14.X.","phawxby",1090602,"2022-03-24 11:20:23","decide dig build sample script provide version iteration crash gc approach heap limit note version crash appear correctly gc approach heap limit version crash appear correctly gc approach heap limit version crash appear correctly gc approach heap limit version crash appear correctly gc approach heap limit version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration version crash iteration weirdness
"
1944,320,"18.1.0 is also having this issue, happens at 750 

![Screen Shot 2022-06-13 at 9 08 14 AM](https://user-images.githubusercontent.com/1854811/173397062-75025e6a-3eb3-4455-9539-1d6363b29e48.png)

","gabrielcsapo",1854811,"2022-06-13 16:08:31","issue happen


**Explicação do pré-processamento:**

1. **Remoção de ruídos:** A versão ""18.1.0"" e o número ""750"" foram mantidos pois podem ser relevantes para a classificação do issue (versão do software e possivelmente um valor relacionado ao problema).  A URL da imagem e a própria imagem foram removidas.

2. **Padronização de palavras:**  A palavra ""happens"" foi reduzida à sua forma base ""happen"".

3. **Remoção de stop words:**  Não há stop words significativas no texto original.  A palavra ""also"" poderia ser considerada uma stop word, mas sua remoção nesse contexto pequeno pode não ser benéfica para a classificação, pois pode indicar uma ocorrência em múltiplas versões.

O resultado final é uma frase curta e concisa que foca nos aspectos essenciais do problema reportado.  Para um processo mais robusto, seria interessante usar uma biblioteca de processamento de linguagem natural (NLP) como NLTK ou SpaCy, que possuem listas de stop words mais completas e ferramentas de stemming/lemmatization mais sofisticadas.
"
1945,320,"Seeing the same behavior in Node 14, 16, 18 as well, which is surfaced via `runInNewContext` (which I believe internally invokes. vm.Script)","kedarv",1365665,"2022-06-14 21:10:14","see behavior node invoke vm script
"
1946,320,"The v8 issue has a few suggestions for node with some speculation. Even after my last comment about Jest they are still suggesting removing a guard in `node` and asking if it will work. Could some folk from the node team with stronger knowledge than me provide some clear feedback? The team currently believe this isn't a common issue or something that can easily be worked around. This isn't the case ... for the Jest issue we are stuck on node 16.10 with no idea of longer-term solution.

https://bugs.chromium.org/p/v8/issues/detail?id=12198#c20


","mbyrne00",5687982,"2022-06-28 01:04:36","issue suggestion node speculation comment jest suggest remove guard node work folk node team knowledge feedback team believe common issue work case jest issue stuck node solution
"
1947,320,"Oh yes - sorry for the bad link, you are right. I'll also update my comment","mbyrne00",5687982,"2022-06-28 07:57:43","update comment
"
1948,320,"@XadillaX @nodejs/vm @nodejs/v8 are there any updates on this issue or anything that changed in the last year?
","benjamingr",1315533,"2022-07-28 08:50:22","update issue change year
"
1949,320,"Also more context https://github.com/facebook/jest/pull/12205 which implies maybe @nodejs/loaders is also the right ping since adding importModuleDynamically causes the leak","benjamingr",1315533,"2022-07-28 08:58:18","context imply nodejs loader right ping add importModuleDynamically cause leak
"
1950,320,"The problem will be gone in the example of the OP if we simply remove the `gc()` call, as explained in https://bugs.chromium.org/p/v8/issues/detail?id=12198#c4. So I'd believe this issue can be closed.","legendecas",8500303,"2022-07-28 09:08:04","problem gone example remove gc call explain issue close
"
1951,320,"@legendecas my understanding is that the ""explicit gc calling"" issue is in addition and not instead of Jest's issue which they are experiencing without any `gc()` calls.

Namely https://github.com/facebook/jest/pull/12205 changes code with 0 gc calls to 0 gc calls and resolves the issue _except_ if they also pass `importModuleDynamically` which causes the leak again.","benjamingr",1315533,"2022-07-28 10:03:28","understanding explicit gc call issue addition instead jest issue experience gc call namely change code gc call resolve issue except pass importmoduledynamically cause leak
"
1952,320,"@benjamingr I would take it as a different problem so I'd suggest opening a dedicated issue to track it.","legendecas",8500303,"2022-07-28 10:42:18","take different problem suggest open dedicated issue track
"
1953,320,"@benjamingr I've opened https://github.com/nodejs/node/issues/44211 to track the issues with `vm.compileFunction`/`importModuleDynamically`.","legendecas",8500303,"2022-08-15 09:04:24","open track issue vm compilefunction importmoduledynamically
"
1954,320,"Hi, We have been unable to upgrade our node beyond 16.10.0 and have been stuck since higher version regresses the performance of our jest tests. Is there any solution coming for this from node?","sunilsurana",7621111,"2023-09-01 16:02:45","upgrade node version regress performance jest test solution node
"
1957,320,"FYI there is a rewrite of the `vm.Script` / `vm.*Module` memory management that might fix many issues in https://github.com/nodejs/node/pull/48510 (the OP referenced the bugs with small reproducible cases that can be confirmed to be fixed. Can't say it definitely fixes other bugs without reproducible examples, but it should fix a bunch more issues in the issue tracker that I didn't dig out). It is pending on a V8 patch which is probably going to be [relanded](https://chromium-review.googlesource.com/c/v8/v8/+/4834471) soon. (The fix however relies on ABI-breaking changes in V8 so it may or may not get released in v20.x)","joyeecheung",4299420,"2023-09-05 14:55:16","rewrite vm Script vm Module memory management fix issue bug reproducible example fix bunch issue tracker issue pend v8 patch reland soon fix rely abi break change v8 may release v20
"
1958,320,"I think this can be closed now - for normal uses of vm.Script, https://github.com/nodejs/node/pull/48510 should have fixed the leaks. For ""leaks"" caused by the use of `--expose-gc` and `gc()` (which disables code aging), it was marked as wontfix by https://bugs.chromium.org/p/v8/issues/detail?id=12198, which I think is fair because `gc()` is not a publicly supported feature, and it's more of a bug on the repro's side to use it as a way to ""clean up memory thoroughly"" (which can backfire).","joyeecheung",4299420,"2023-10-27 14:45:14","pensar fechar uso normal vm.script corrigir vazamento vazamento causar expor gc gc desabilitar envelhecimento código marcar wontfix pensar justo gc recurso publicamente suportar erro lado reproduzir limpar memória completamente backfire
"
1959,321,"There are a number of quick easy fixes that I'll work on - that is checking the key type upon import. See #39962

That's however about the only thing with a sure resolution from the above list.

When coming up with a resolution for these points it's important to keep in mind that we should strive for the possibility of generate/import/export or import/export/import round trips. We should not force export compliance with the standard if it means we won't be able to import the key material.

Likewise we have the other implementations of Web Cryptography API to interoperate with.

I did not test every browser vendor out there. But I did find a list of caveats from the Chromium project which, wrt. support key OIDs only chose to support (via import and export) the `rsaEncryption` OID for everything RSA based. That means they lack support for the specialized OIDs in the import step, and choose to ignore the specialized OID requirement in the export step. Likewise for `ECDH` it will only support `id-ecPublicKey`.

Firefox apparently also only supports `rsaEncryption` ~and likewise the upcoming Deno implementation~.","panva",241506,"2021-08-31 15:59:34","work check key type import sure resolution point strive possibility generate import export import export import round trip force export compliance standard import key material implementation web cryptography api interoperate test browser vendor find list caveat chromium project support key oid support import export rsaencryption oid rsa base lack support specialize oid import step ignore specialize oid requirement export step likewise ecdh support id ec publickey firefox support rsaencryption deno implementation
"
1960,321,"I believe another reasonable fixes would be to the RSA-PSS import steps checking the `RSASSA-PSS-params` values matching the WebCrypto Algorithm. But that depends on which route we'll take with the OID support.

It is easy to say we only support import/export of `rsaEncryption` and `id-ecPublicKey` but it is harder to explain we'll support import of `id-RSASSA-PSS` but not its 100% spec compliant export.","panva",241506,"2021-08-31 16:06:48","fix reasonable rsa pss import step check rsassa pss param value match webcrypto algorithm depend route oid support easy say support import export rsaencryption id ec publickey hard explain support import id rsassa pss 100 spec compliant export
"
1961,321,"cc @nodejs/crypto @tniessen @jasnell ","panva",241506,"2021-08-31 16:07:00","nodejs crypto tniessen jasnell
"
1962,323,"@nodejs/repl ","targos",2352663,"2021-08-29 13:05:39","nodejs repl
"
1963,323,"By the way there is another unrelated bug: `await <any>;;` != `<any>;;`. I don't know if this is intentional. Should I do another issue?
```js
> await 1;;
undefined
> 1;;
1
```
","Mesteery",48163546,"2021-08-29 14:11:38","bug intencional issue
"
1964,323,"@Mesteery I think it is a seperate issue. it would be worth to open a new issue. 🤔  

Output from chrome dev tool
![Screen Shot 2021-08-29 at 22 15 42](https://user-images.githubusercontent.com/6264033/131253513-bba26203-7481-43ad-b3a6-dd6d73cb3798.png)
","Ayase-252",6264033,"2021-08-29 14:17:49","think separate issue worth open new issue
"
1965,323,"the infinite stream of bugs for fake tla is even better than I thought it would be","devsnek",5952481,"2021-08-29 15:19:26","infinite stream bug fake tla good thought
"
1966,324,"@szmarczak 
According to the additional information you have provided, this is the intended behaviour, the server name is supposed to be a valid domain name in the SSL certificate. Using IP addresses in the SSL certificate is not encouraged.

However, this is just an additional information. The original bug remains a bug. Maybe somewhere the empty `servername` property is being substituted without checking its value, which is resulting in `https://false`. Weird haha.","Narasimha1997",20423357,"2021-08-29 13:10:44","intended behaviour server name valid domain name ssl certificate use ip address ssl certificate encourage additional information original bug bug empty servername property substitute check value result https false weird
"
1967,324,"#39934 seems to fix this bug.","Narasimha1997",20423357,"2021-08-29 16:21:17","fix bug
"
1968,325,"Thanks for bug reporting, could you provide a more precise description about how to repro the error? Does the error occur when _installing_ `canvas` by npm/yarn or _requiring_ it by `require('canvas')`?

I have tried on MacOS

```js
const canvas = require(""canvas"")
const util = require('util')

console.log(util.inspect(canvas))
```


```
node index.js
{
  Canvas: [Function: Canvas] { _registerFont: [Function: _registerFont] },
  Context2d: [Function: CanvasRenderingContext2D],
  CanvasRenderingContext2D: [Function: CanvasRenderingContext2D],
  CanvasGradient: [Function: CanvasGradient],
  CanvasPattern: [Function: CanvasPattern],
  Image: [Function: Image] { MODE_IMAGE: 1, MODE_MIME: 2 },
  ImageData: [Function: ImageData],
  PNGStream: [Function: PNGStream],
  PDFStream: [Function: PDFStream],
  JPEGStream: [Function: JPEGStream],
  DOMMatrix: [Function: DOMMatrix] {
    fromMatrix: [Function (anonymous)],
    fromFloat32Array: [Function (anonymous)],
    fromFloat64Array: [Function (anonymous)]
  },
  DOMPoint: [Function: DOMPoint],
  registerFont: [Function: registerFont],
  parseFont: [Function (anonymous)],
  createCanvas: [Function: createCanvas],
  createImageData: [Function: createImageData],
  loadImage: [Function: loadImage],
  backends: {
    ImageBackend: [Function: ImageBackend],
    PdfBackend: [Function: PdfBackend],
    SvgBackend: [Function: SvgBackend]
  },
  version: '2.8.0',
  cairoVersion: '1.16.0',
  jpegVersion: '9d',
  gifVersion: '5.2.1',
  freetypeVersion: '2.10.4',
  rsvgVersion: '2.50.5'
}
```

It works as intented.
 ","Ayase-252",6264033,"2021-08-25 02:52:21","report bug precise description repro error occur install canvas npm yarn require require canvas try macos work intend
"
2018,329,"Landed in c41466feb501...b3f51ee1746206d5c4653f96b37db92bd644db73","targos",2352663,"2021-08-29 12:18:54","Landed
"
2019,330,"CI: https://ci.nodejs.org/job/node-test-pull-request/39526/","nodejs-github-bot",18269663,"2021-08-09 16:54:46","CI
"
1969,325,"The error occured when i requiring the module, the installation work properly.

my exact code is : 
```js
const code = message.content.slice(prefix.length+command.length+1); // this line work with the module discord.js
const res = await eval(code);
return require(""util"").inspect(res, { showHidden: true, color: false }); // the error is here
```

","lynn2910",73949405,"2021-08-25 08:35:43","error occur require module installation work properly code line work module error
"
1970,325,"To reproduce the error:

```
const canvas = require('canvas')
Object.getOwnPropertyDescriptor(canvas.Canvas.prototype, 'width')
```

```
Object.getOwnPropertyDescriptor(canvas.Canvas.prototype, 'width')
       ^

TypeError: Method width called on incompatible receiver #<Canvas>
    at Function.getOwnPropertyDescriptor (<anonymous>)
```","targos",2352663,"2021-08-25 08:45:16","reproduce error canvas width TypeError method width call incompatible receiver canvas
"
1971,325,"@nodejs/util ","targos",2352663,"2021-08-25 08:45:40","nodejs util
"
1972,325,"Access to getters/setters on prototype of `Canvas` was forbiden intentionally in https://github.com/Automattic/node-canvas/pull/808.

It means that `ObjectGetOwnPropertyDescriptor` may not be guaranteed to work?

https://github.com/nodejs/node/blob/52ebe0f83ad05d77e34946fda9d23dcc77c2bc9c/lib/internal/util/inspect.js#L1674

Refs: https://github.com/Automattic/node-canvas/issues/1460","Ayase-252",6264033,"2021-08-27 09:48:13","acesso getter setter prototype canvas proibir intencionalmente significar objectgetownpropertydescriptor garantir funcionar ref
"
1973,325,"@Ayase-252 it seems to be the issue, but I'm a bit surprised by that.

I don't see in the spec where [`Object.getOwnPropertyDescriptor`](https://tc39.es/ecma262/multipage/fundamental-objects.html#sec-object.getownpropertydescriptor) could throw an error in this situation.

@nodejs/v8","targos",2352663,"2021-08-27 12:59:21","issue surpris spec object getownpropertydescriptor throw error situaçã
"
1974,325,"`Object.getOwnPropertyDescriptor` in V8 will access the getter here: https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-objects.cc;drc=441d37da23011674ee4975b0cb738733f8e72ec9;l=1721
If it fails, it will return the exception.

I guess that's the correct behaviour according to the spec:
```
6. If Desc has a [[Get]] field, then
a. Perform ! CreateDataPropertyOrThrow(obj, ""get"", Desc.[[Get]]).
```","victorgomes",548275,"2021-08-27 14:46:35","getOwnPropertyDescriptor v8 access getter fail return exception guess correct behaviour spec perform createdatapropertyorthrow obj get get
"
1975,325,"How should we handle these cases in general? This is not the first time something like that has come up and it's not specific to logging. We could use an internal `getOwnPropertyDescriptor()` function that catches the error and that returns a object in the expected form with the value e.g., being set to `null` or `undefined`?","BridgeAR",8822573,"2021-11-29 18:34:34","handle case general first time something come specific log use internal getownpropertydescriptor function catch error return object expect form value set null undefined
"
1976,325,"By now I wonder if we really want to special handle this. I don't really think so as it is something that comes from an implementation that does things in a way that V8 is not able to handle and I guess that could happen in multiple places for lots of reasons. If someone disagrees, please leave a comment or reopen.","BridgeAR",8822573,"2022-07-16 14:18:09","wonder really want special handle think something come implementation thing way v8 able handle guess happen multiple place reason someone disagree leave comment reopen
"
1977,326,"SubtleCrypto.sign has the same issue

```js
const crypto = require('node:crypto')
const { webcrypto: { subtle } } = crypto

const pk = Buffer.from(`MIIE7wIBADA9BgkqhkiG9w0BAQowMKANMAsGCWCGSAFlAwQCAaEaMBgGCSqGSIb3DQEBCDALBglghkgBZQMEAgGiAwIBEASCBKkwggSlAgEAAoIBAQDfqNM4C+QtD73iILqOkqfV8ha3O19jpX8UujIk1Z72bbbuwEzh0+sBw0dD0N8CgkXnePOEEd6q7HNmbyCNqRpDK6NDvaCMDWgEaD/PlHkRntvKh81IXSMC5imjRfOcZIE/Gnw7h8tanab0n75+ODvLJrmEWUG2q79Im1mWMx7Spod+Np6XEY+7I7nAUUWivr35Yx5DeyxY8rxFGpsLtGsi7JNQO4aHyeBpj8tz0Fhv23uPywE2nGmPHfnkXWbrTcHGbzYBgEbeSH9KUkRwczqDXNOPhtfaEHEFTm0MoeKCnJe1VOjSywev77dV1KZfpVh3Kh0ZRQIe9YOVJhj4lMx3AgMBAAECggEBAIc+IgK5Bg/NfgeXvNdrjPuM+PlxeHvb3h1dfebSGd5vd3elZpgDug6F07kJO2Db/4M5mx7YY2m9swZU2j1u7MeDQqU6rDMkBCruEu/lmtPx2Hv+ZD6Gux4MqU7mhKmkCJds34Rr16aCwCsZ0WmnfViZoQKLqnXYIsG31pNBdDjxgke0HhX1LkA9yTVwlk8xOaHPqI4KfsFAyoiiHzyttGDexzb1PzmM0pybAPDMhpN/wXp2kLjyzmUmPe2Y2yva69WVWo7qS6joKjY75MQ1t20HYgEL69IApvCPu4CANfi9j3FAaV/+WrnhKCi6QyUi5PCI/+AJLsjNQmqTXIdBEoECgYEA+XsgFbeZ6+ZzEHa7HyFH6kiyBLd0q7w+ZLPsoOmEApDaP3yXSC7eJU7M/tPUPj8VQMMSK2D6fgmUDwhb3mEXFZxf67UlPFsFjweYcBihwy4r8QKBwury6dEbHPSUq4mXFJF5XRQdGqRGkr/F8OLZ0MwmHLUzczA67PxP/wF8TsECgYEA5YD4RxxJJYfAk1rFbqHRhNB8UeYVL+WowsRET1JeFg+S5grLGUga+KBB8Jn7Ahaip7MVE0Iud1cgaDi4WBEJsbJ6oJTlHJEgJq7QAaBafwjeSCSnaEsVBVNvriy2WF7uAomLSKmW6uSUOBBFFt4+G+akG56EfOPc7YKBfsf5ITcCgYBvjVZzX307tfeNTQmuibsWTxsKcN2CTNG5RZpw+PlGDG8KJDOg2xQJqoqPBzjH/H0MUC03qE1ZPf8uGZa6gL9JsnpRctYLfselhMfsl5b9JxAO3AgZl+S2GAH/mH1BlmwvjjyuGehJmVrVE1r2sviiHCaOf5dZ0h8HCGrco1VqAQKBgQCffYkMofOTSUvjG2mpAHuCOQCsSaDfsFIfSBXQqgUIf7ouc8HAyAM2VOh+NAPj56cRs7opsAxqkvnKc+BoEy8Rdl8RyWeO+qvFNicHelBph9gxeod8SvFIyjsKZ7gwoYf163AIBxMCGeeHLodU5Q10hkv1hau8vv2BcPhdCstu8QKBgQDgO4Rr36Pa5rjbNbGNPsJqALjthTeU0yaU8hdC7Hc7B/T6npEIhw3s1eNq7e0eeDltqz7tDnY8qysazbQZp1cV5TJ8+gtwGmDoADBnU1NXqX4Squfml6OhNEucpTdjux7JdLVmmQFraOT2Eu5f9uuNtA+d8uhBEXhskuvEC552ug==`, 'base64')

subtle.importKey('pkcs8', Buffer.from(pk), { name: 'RSA-PSS', hash: { name: `SHA-384` } }, true, ['sign']).then((pk) => {
  const alg = {
    hash: { name: 'SHA-384' },
    name: 'RSA-PSS',
    saltLength: 384 >> 3,
  }
  subtle.sign(alg, pk, Buffer.from('foo')).then(console.log)
})
```","panva",241506,"2021-08-20 16:27:06","issue sign
"
1978,326,"cc @tniessen @jasnell @nodejs/crypto ","panva",241506,"2021-08-20 16:27:38","tniessen jasnell nodejs crypto
"
1979,326,"A usable error message is throw when using `crypto.createSign`, this is therefore unique to the one shot APIs.","panva",241506,"2021-08-20 16:41:04","usable error message throw use crypto create sign unique shot api
"
1980,326,"I've ported the RSA-PSS tests from `test-crypto-key-objects.js` to `test-crypto-sign-verify.js`, see https://github.com/panva/node/commit/8b7e5c61893fe60981417427a9ad7f0ed7beb0a9","panva",241506,"2021-08-20 16:59:03","port rsa pss test test crypto key object test crypto sign verify
"
1981,327,"Confirmed. That's strange. @nodejs/website ","Trott",718899,"2021-08-16 02:21:05","strange
"
1982,327,"I can reproduce on Chrome 92 but not on Firefox 91. It work as expected there.

Edit: Microsoft Edge 92 also works fine so I suspect it is a Chrome issue.","lpinca",1443911,"2021-08-16 05:28:19","reproduce chrome firefox work expect microsoft edge suspect chrome issue
"
1983,327,"Tested on Safari, it also works as expected. 🤔 ","Ayase-252",6264033,"2021-08-16 06:15:06","test safari work expect
"
1984,327,"Posted as Chromium issue to be on the safe side: https://bugs.chromium.org/p/chromium/issues/detail?id=1240147","vsemozhetbyt",10393198,"2021-08-16 13:42:10","chromium issue safe side
"
1985,327,"Chrome version 117.0.5938.92 on Windows10 can be reproduced.
But I use ctrl+shift+R reload page, it will scroll to wrong position, and the probability of occurrence is 50%.
The gif can be found at [here](https://github.com/KuthorX/public_res/blob/main/chrome_nodejs_doc_hash_navigation.gif?raw=true)","KuthorX",49077331,"2023-10-11 10:16:28","chrome version window reproduce use ctrl shift r reload page scroll wrong position probability occurrence gif find
"
1986,327,"I can reproduce this problem on Firefox. Clicking on a link in the ToC will very often send me to a completely different part of the page:

https://github.com/nodejs/node/assets/79560998/e3b820f7-f87e-481c-8f91-2e7d0c3a3e4d

I don't believe this is a browser issue.","valadaptive",79560998,"2024-06-28 23:52:27","reproduce problem firefox click link toc often send completely different part page believe browser issue
"
1987,327,"I posted this in #53584, but posting it here as well.

This is *not* a Chromium bug, and occurs in Firefox as well. I believe it was not previously showing up in Firefox simply because [they had not yet implemented the relevant CSS feature](https://caniuse.com/?search=content%20visibility).

This appears to be an effect of https://github.com/nodejs/node/pull/37301. Lazy-loading the content means it is *impossible* for the browser to tell where to jump to, because it hasn't done the layout. And it hasn't done the layout because we *explicitly told it not to*. This is not a bug, this is the feature working as intended.

Optimizing for the case of reading the entire API docs on a single huge page, at the expense of making it frustrating and difficult to navigate the individual documentation sections that show up way more often in web search results, seems like the wrong decision to me.","valadaptive",79560998,"2024-06-29 00:13:47","effect lazy load content impossibl browser tell jump layout layout explicit tell bug feature work intend optimiz case read entir api doc singl hug page expens make frustrat difficult navigat individu document section show way often web search result seem wrong decis
"
1988,327,"If you find the culprit, feel free to submit a patch :-)","avivkeller",38299977,"2024-06-29 00:47:44","find culprit feel free submit patch
"
1989,327,"The fix would be reverting #37301. Would that be acceptable?","valadaptive",79560998,"2024-06-29 00:52:54","fix revert acceptable
"
1990,327,"You can try, whether or not it lands is a discussion for the PR, not this issue.","avivkeller",38299977,"2024-06-29 00:54:17","try land discussion pr issue
"
1991,327,"Ah, looks like it was already attempted in https://github.com/nodejs/node/pull/41869. Apparently removing the hack causes some breakage, although no screenshots were provided. Currently trying to figure out how to build the documentation...","valadaptive",79560998,"2024-06-29 00:59:21","attempt remove hack cause breakage try figure build documentation
"
1992,327,"OK, just tracked it down and it was fixed in https://github.com/nodejs/node/pull/53510 already which hasn't landed yet","valadaptive",79560998,"2024-06-29 01:05:27","track fix land
"
1993,327,"> OK, just tracked it down and it was fixed in https://github.com/nodejs/node/pull/53510 already which hasn't landed yet

That PR has landed","avivkeller",38299977,"2024-06-29 01:32:08","fix track land
"
1994,328,"@jasnell @nodejs/streams ","ronag",3065230,"2021-08-13 22:07:32","jasnell nodejs stream
"
1995,328,"If to replace `process.nextTick` with `queueMicrotask` in the example then it works. Maybe a bug (race condition) in the spec?

Edit:

The spec uses `queueMicrotask` but `process.nextTick` results in race condition, so we need to `controller.close()` when all other web streams work is done - `Promise.resolve()` should be sufficient enough in the example.","szmarczak",36894700,"2021-08-15 15:29:52","replace queueMicrotask example work bug race condition spec use queueMicrotask process nextTick result race condition need controller close web stream work promise resolve sufficient example
"
1996,328,"@jasnell ","ronag",3065230,"2021-08-18 07:02:20","jasnell
"
1997,328,"Yeah, I've got this queued up to look at this week. Just haven't yet had the opportunity. ","jasnell",439929,"2021-08-18 13:29:18","opportunity look week
"
1998,328,"@jasnell ","ronag",3065230,"2021-09-26 10:51:47","Retorne
"
1999,328,"@jasnell Sorry to bother. I think this is a rather bad bug. Any chance you will have time to look at it?","ronag",3065230,"2021-10-28 07:56:01","sorry bother think bad bug chance time look
"
2000,328,"Hi, I'll work on it","ofirbarak",33656859,"2021-10-29 08:35:00","work
"
2001,328,"Sorry I've been buried and haven't had the opportunity to dig in. It's not a bug in the spec, keep in mind that nextTick is a Node specific concept. ","jasnell",439929,"2021-10-29 12:06:46","sorry bury opportunity dig bug spec keep mind nexttick node specific concept
"
2002,328,"@szmarczak We had this issue on undici and there we don't really use nextTick in this context? i.e. we always wrap `controller.close` in a microtask to ensure this doesn't happen (https://github.com/nodejs/undici/blob/main/lib/fetch/util.js#L153-L155).  Is it just related to nextTick?","ronag",3065230,"2021-10-29 12:15:58","issue undici use nexttick context wrap controller close microtask ensure relate nexttick
"
2003,328,"Well Node.js streams use `nextTick` so that's where the incompatibility comes from. I'm thinking of the `finished` function exactly.","szmarczak",36894700,"2021-10-30 11:40:12","node stream use nexttick incompatibility come think finish function
"
2004,328,"I've created a PR to address it. However, just to bring more context to the described issue:

```js
import {ReadableStream} from 'stream/web';

let controller;
let start = c => (controller = c);
let pull = () => {
  if (pull.called) return;
  pull.called = true;

  process.nextTick(() => {
   controller.enqueue(new Uint8Array([102, 111, 111, 98, 97, 114]))

    process.nextTick(() => {
     controller.close()
    });
  });
};

const [a, b] = new ReadableStream({start, pull}).tee();

for (const stream of [a, b]) {
  const chunks = [];

  for await (const chunk of stream) {
    chunks.push(chunk);
  }

  console.log('received:', Buffer.concat(chunks).toString());
}
```

As mentioned by @szmarczak it returns:

```
received: foobar
received:
```
On ES Modules, however, when you change it to commonjs it works as expected:

```diff
- import {ReadableStream} from 'stream/web';
+ const {ReadableStream} = require('stream/web');
```

```
received: foobar
received: foobar
```

---

The https://github.com/nodejs/node/pull/40901 aims to solve it
","RafaelGSS",26234614,"2021-11-21 02:45:58","criado pr resolver problema adicionar contexto problema mencionar retornar es modulo mudar commonjs funcionar esperado objetivo resolver
"
2005,328,"This issue had been solved. Can we close it?","MoonBall",13298548,"2022-01-04 15:11:13","solve close
"
2006,329,"CI: https://ci.nodejs.org/job/node-test-pull-request/39546/","nodejs-github-bot",18269663,"2021-08-12 02:05:23","CI
"
2007,329,"CI: https://ci.nodejs.org/job/node-test-pull-request/39554/","nodejs-github-bot",18269663,"2021-08-12 15:57:23","CI
"
2008,329,"V8 CI: https://ci.nodejs.org/job/node-test-commit-v8-linux/4215/","targos",2352663,"2021-08-21 09:31:36","V8 CI teste linux
"
2009,329,"Weird that it's getting that error that `d8` is missing. It was working before. Are you aware of any changes related to `d8` being exposed?","Qard",205482,"2021-08-23 19:52:53","weird get error d8 miss work aware change relate d8 expose
"
2010,329,"I'm not aware but maybe this global was only recently added","targos",2352663,"2021-08-23 20:37:18","aware maybe global recently add
"
2011,329,"Ah, yep. Seems the version in 14.x dumps everything in global rather than the d8 namespace. This test failure is coming from past changes that have already landed though. Not sure what we should do about that.","Qard",205482,"2021-08-24 03:05:35","version dump global namespace test failure change land sure
"
2012,329,"> Ah, yep. Seems the version in 14.x dumps everything in global rather than the d8 namespace. This test failure is coming from past changes that have already landed though. Not sure what we should do about that.

Ah you're right, we forgot to start V8 CI for https://github.com/nodejs/node/pull/38577","targos",2352663,"2021-08-25 08:01:21","version dump global namespace test failure change land sure


Note:  The original text contains several phrases that, while grammatically correct, are not easily stemmable or lemmatized to single words without losing significant meaning for issue classification.  For example, ""test failure"" is a meaningful unit, but stemming it would result in potentially ambiguous terms.  I've chosen to retain such phrases as single units for better context in the resulting pre-processed text.  A more sophisticated approach might involve using n-grams or more advanced NLP techniques to handle this.  The removal of stop words is also highly dependent on the specific stop word list used,  and I've omitted words like ""ah"", ""yep"", ""right"", and ""sure"" which could be considered stop words depending on the application.  A more thorough analysis might involve a corpus specific stop word list.
"
2013,329,"The global variable was added in https://github.com/v8/v8/commit/c9224589cf538d722ee1adccf378bbacef80eccc. Can you try backporting it?

Edit: if it's too difficult to backport, it seems fine to me to adapt the tests instead.","targos",2352663,"2021-08-25 08:13:15","global variable add try backport difficult backport adapt test
"
2014,329,"V8 CI: https://ci.nodejs.org/job/node-test-commit-v8-linux/4225/

Side note: I seem to be unable to run `make test-v8` locally. It blows up with all sorts of correctness check errors from gn for some reason. I keep fixing one and stumbling into another. Not sure why the tools seem to be so broken at this revision. 😕 ","Qard",205482,"2021-08-26 20:51:34","run make test v8 locally blow correctness check error gn reason keep fix stumble sure tool seem broken revision
"
2015,329,"Whoops, missed a spot.

V8 CI: https://ci.nodejs.org/job/node-test-commit-v8-linux/4226/","Qard",205482,"2021-08-27 02:03:28","Whoops miss spot
"
2024,332,"The problem is that `process.stdout()` never gets closed.

```js
'use strict'

const { Transform, Writable, pipeline } = require('stream')

const w = new Writable({
  write (chunk, enc, cb) {
    cb()
  }
})

function createTransformStream (tf, context) {
  return new Transform({
    readableObjectMode: true,
    writableObjectMode: true,

    transform (chunk, encoding, done) {
      tf(chunk, context, done)
    }
  })
}

const ts = createTransformStream((chunk, _, done) => done(new Error('Artificial error')))

pipeline(ts, w, (err) => {
  if (err) console.log(err)
  console.log('done')
})

console.log('run test')
ts.write('test')
```

In theory, this should have been solved by https://github.com/nodejs/node/pull/32373, but I guess there is something different from using a child_process and a tty.

@ronag wdyt?","mcollina",52195,"2021-07-19 15:09:51","problem stdout close solve use child_process tty
"
2025,332,"Oh, makes sense. Thanks @mcollina for clarifying this issue for me.","mightyaleksey",5006221,"2021-07-19 15:19:40","sense thanks clarify issue
"
2026,332,"@mcollina I have some questions... 
Can i work on that issue?
Where is located the entry points for streams ""Transformer""? 
I can put the test on test folder and the execution happen because the existance of a mechanism for execution?","ktfth",44123854,"2021-07-23 23:17:13","work issue locate entry point stream transformer put test test folder execution happen exist mechanism execution
"
2027,332,"I'm made some progress investigating the code base, but if it's possible to talk more about that could be helpful.","ktfth",44123854,"2021-07-24 21:33:27","progress investigate code base talk helpful
"
2028,332,"I have made a change who passes on tests with the case described by you @mcollina here some refs: https://github.com/ktfth/node/tree/fix/stream-pipeline-error-callback","ktfth",44123854,"2021-07-25 00:14:53","change pass test case describe ref
"
2029,332,"You need to add a test for stdout. Look in https://github.com/nodejs/node/tree/master/test/pseudo-tty.","mcollina",52195,"2021-07-25 07:03:45","add test stdout
"
2030,332,"Included another test with process.stdout, but looking the reference you shared @mcollina to create more tests","ktfth",44123854,"2021-07-25 19:54:44","test process stdout reference create test
"
2031,332,"Do you have an hint to what I can search for to made a good test?","ktfth",44123854,"2021-07-25 23:35:24","hint search good test
"
2032,332,"@ktfth Can you please do this as a[ proper PR](https://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md)?","ronag",3065230,"2021-07-26 07:34:06","please proper pr
"
2033,332,"I can do that","ktfth",44123854,"2021-07-26 13:19:53","can do
"
2034,332,"PR: https://github.com/nodejs/node/pull/39533","ktfth",44123854,"2021-07-26 17:27:18","PR
"
2035,332,"I wanted to know if the problem persist when using an `async itaretable` function, and it does:

```js
const { Transform, pipeline } =  require('stream')

function createTransformStream () {
  return async function*(stream) {
      yield 'test';
      throw new Error('Artificial Error');
  };
}

const ts = createTransformStream()

pipeline(ts, process.stdout, (err) => {
  if (err) console.log(err);
  console.log('done')
})
console.log('run test')
```","rluvaton",16746759,"2021-07-30 14:15:58","persist problem use async function yield test throw error artificial error run test
"
2036,332,"If I'm right in my assumption about the error - https://github.com/nodejs/node/pull/39533#issuecomment-891143444 (in 3-4 words - the `process.stdout` closed)

A workaround would be to just wrap the `process.stdout` with it's own async iterator / `Writable` and it should work","rluvaton",16746759,"2021-08-02 16:23:10","right assumption error process stdout close workaround wrap process stdout async iterator writable work
"
2037,332,"After doing some work, I think this is not a bug. The following pass:

```js
'use strict'

const { Transform, pipeline } = require('stream')

function createTransformStream (tf, context) {
  return new Transform({
    readableObjectMode: true,
    writableObjectMode: true,

    transform (chunk, encoding, done) {
      tf(chunk, context, done)
    }
  })
}

const ts = createTransformStream((chunk, _, done) => done(new Error('Artificial error')))

process.stdout.on('error', function () {
  process._rawDebug('error emitted')
})


process.stdout.on('close', function () {
  process._rawDebug('close emitted')
})

pipeline(ts, process.stdout, (err) => {
  if (err) process._rawDebug(err)
  process._rawDebug('done')
})

console.log('run test')
ts.write('test')
```

The reason why you do not see the output is that `process.stdout` is closed. Maybe we should print a warning in this case (or maybe `console.log()` should bypass it.","mcollina",52195,"2021-08-05 17:11:23","run test artificial error process stdout close console log bypass warning
"
2038,332,"> After doing some work, I think this is not a bug.
> 
> [...]
> 
> The reason why you do not see the output is that `process.stdout` is closed. Maybe we should print a warning in this case (or maybe `console.log()` should bypass it.

According to https://github.com/nodejs/node/issues/7606#issuecomment-231293476 stdio should never be closed","rluvaton",16746759,"2021-08-05 17:22:10","work think bug reason see output process stdout close maybe print warning maybe console log bypass stdio close
"
2039,332,"the actual file descriptor is never closed. However the stream object ` process.stdout` can be closed as it is a stream.
Otherwise the callback to `pipeline` would never be called.","mcollina",52195,"2021-08-05 17:38:07","file descriptor never close stream object process stdout close stream callback pipeline never call
"
2040,332,"I understand and totally agree","ktfth",44123854,"2021-08-05 17:46:08","understand agree
"
2041,332,"> the actual file descriptor is never closed. However the stream object ` process.stdout` can be closed as it is a stream.
> Otherwise the callback to `pipeline` would never be called.

Closing the stdio can have an unwanted results:
1. If you run the code in the issue above in REPL you wouldn't see any character you type after that ran
2. Loggers that use process.stdout would not output anything if it will close.

I'm sure there are more reasons, this is just at the top of my head.

I think we should fix the `pipeline` rather than the `process.stdout`","rluvaton",16746759,"2021-08-05 17:53:09","file descriptor never close stream object process stdout close stream otherwise callback pipeline never call stdio unwanted result run code issue repl wouldn't see character type logger use process stdout output close sure reason top head think fix pipeline process stdout
"
2042,332,"Here is an alternative way to fix this: https://github.com/nodejs/node/pull/39670","mcollina",52195,"2021-08-05 18:11:22","alternative way fix
"
2043,333,"I think this might be expected behavior: consider your code like
```javascript
import http2 from 'http2';
import stream from 'stream';

const session = http2.connect('https://petstore.swagger.io/v2/pet/findByStatus?status=available');
const request = session.request({
	':path': '/findByStatus?status=available',
	'x-trace-id': 'foo',
	'user-agent': 'foo-bar/baz, bash'
});

request.on('data', () => {
	request.destroy(new Error('error'));
});

request.on('end', () => {
	console.log('end');
});

request.end();

stream.promises.pipeline(
    request,
    new stream.PassThrough()
).then(x => {
    console.log('success');
    session.close();
});
```

the pipeline method just connects an empty stream when request is already ended...
","asanoic",70875479,"2021-07-15 19:48:59","behavior código conectar fluxo vazio pedido terminar  método conectar fluxo vazio pedido terminar
"
2044,333,"It's not possible as it's not possible to be connected in the same tick you initiate a connection.","szmarczak",36894700,"2021-07-15 23:30:45","possible connect tick initiate connection
"
2045,333,"It seems the `'end'` event is emitted even if the TCP connection is not established:

```js
import http2 from 'http2';

const session = http2.connect('https://0273ea441bca0690c5454e2f3380fe0e/');
const request = session.request();

request.on('data', () => {
  request.destroy(new Error('error'));
});

request.on('end', () => {
  console.log('end');
});

request.end();
```","lpinca",1443911,"2021-07-27 13:35:18","emit tcp connection establish error
"
2046,333,"I think the issue here is that `stream.pipeline` swallows the error:

```
$ cat test.mjs
import stream from 'stream';

const duplex = new stream.Duplex({
  read() {},
  write(chunk, encoding, callback) {
    callback();
  }
});

duplex.on('data', function () {
  this.destroy(new Error('error'));
});

duplex.on('end', function () {
  console.log('end');
});

// duplex.on('error', console.error);

duplex.push('foo');
duplex.push(null);

stream.pipeline(duplex, new stream.PassThrough(), (err) => {
  if (err) throw err;

  console.log('success');
});
```

```
$ node test.mjs
end
success
```","lpinca",1443911,"2021-07-28 11:23:41","issue stream pipeline swallow error cat test mjs import stream duplex stream duplex read write chunk encoding callback callback data function destroy error end function console log end duplex error console error duplex push foo duplex push stream pipeline duplex stream passthrough err err throw err console log success node test mjs end success
"
2047,333,"cc: @nodejs/streams ","lpinca",1443911,"2021-07-28 11:25:48","nodejs streams
"
2048,333,"This is a very interesting edge case. Consider the following:

```js
import stream from 'stream';

const duplex = new stream.Duplex({
  read() {},
  write(chunk, encoding, callback) {
    callback();
  }
});

let tick = false
duplex.on('data', function () {
  tick = true
  process.nextTick(() => {
    tick = false
  })
  this.destroy(new Error('error'));
});

duplex.on('end', function () {
  console.log('end', tick);
});

duplex.on('error', console.error);

duplex.push('foo');
duplex.push(null);
```

The problem is that `'error'` will be emitted _after_ end. However the logical order we would expect is for error to come before `'end'`. The reason is `'end'` is emitted on the same tick of the last `'data'` event instead of a subsequent tick.

`pipeline` see the stream as correctly ended, that's why it swallows the error - its behavior is correct.

This looks like a bug we should fix.

@ronag wdyt?","mcollina",52195,"2021-07-28 19:48:27","case consider problem logical order expect error come end reason emit tick last event instead subsequent tick pipeline see stream correctly end swallow error behavior correct look bug fix
"
2049,333,"> `pipeline` see the stream as correctly ended, that's why it swallows the error - its behavior is correct.

It's a duplex that emitted only `'end'`, it is still writable and the error is emitted before `'close'`. Is it the expected behavior for pipeline? Shouldn't it wait for `'error'` or `'close'` for a duplex?

Edit: I guess pipeline does not care about the writable side which makes sense as there is no more data to read/pipe to the next stream.","lpinca",1443911,"2021-07-28 19:53:33","pipeline see stream correctly end swallow error behavior correct duplex emit end writable error emit close expected behavior pipeline wait error close duplex guess pipeline care writable side make sense data read pipe stream
"
2050,333,"@mcollina In the issue the writable side has ended but the readable not.","szmarczak",36894700,"2021-07-28 19:58:08","issue writable side end readable
"
2051,333,"> Edit: I guess pipeline does not care about the writable side which makes sense as there is no more data to read/pipe to the next stream.

@szmarczak from @lpinca words ^.","mcollina",52195,"2021-07-28 20:18:51","guess pipeline care writable side make sense data read pipe next stream
"
2052,333,"Looks like https://github.com/nodejs/node/blob/89adc16ff0a66b447df3e12f82aa43e495665636/lib/internal/streams/readable.js#L1336 should be `state.errored` instead of `state.errorEmitted`","szmarczak",36894700,"2021-07-30 18:14:11","look like state errored state erroremitted
"
2053,333,"@mcollina I believe in that case `end` should be never emitted. https://nodejs.org/api/stream.html#stream_event_end_1","szmarczak",36894700,"2021-07-30 22:51:45","believe case end emit
"
2054,333,"[http2 failed tests.txt](https://github.com/nodejs/node/files/6910232/http2.failed.tests.txt) with `state.errored` instead of `state.errorEmitted`. All the tests depend on the `end` event. If they used `close` instead, I think they would pass.","szmarczak",36894700,"2021-07-30 22:53:23","test depender evento usar passar
"
2055,333,"Is the change `semver-major` or `semver-minor`?","szmarczak",36894700,"2021-07-30 22:55:33","change semver major semver minor
"
2056,333,"I would go with a patch as it's a bad bug. I'd just wait to backport to LTS lines for a bit (or at all).","mcollina",52195,"2021-07-31 11:04:45","patch bad bug wait backport lts line
"
2057,333,"> Looks like https://github.com/nodejs/node/blob/89adc16ff0a66b447df3e12f82aa43e495665636/lib/internal/streams/readable.js#L1336 should be `state.errored` instead of `state.errorEmitted`

I _think_ so.","mcollina",52195,"2021-07-31 11:05:06","look like should state errored instead state error emitted think
"
2058,334,"Similar. Cannot upgrade from 14.17.1 to 14.17.2

![2021-07-01_202225](https://user-images.githubusercontent.com/11320080/124165321-4d3beb00-daaa-11eb-85d7-c56ba3360df2.png)
","ghost",10137,"2021-07-01 17:24:46","Não consigo atualizar de 14.17.1 para 14.17.2
"
2059,334,"I also have the same problem, could you help me","gusbarzi",81195179,"2021-07-01 18:21:57","problem help
"
2060,334,"Also just encountered this issue. Neither the long term support, nor the latest version work and give the same error message as in the images shared by DvdGiessen and web2933.","Theraa0",62468600,"2021-07-01 19:26:45","encounter issue long term support latest version work give same error message image
"
2061,334,"> EDIT: Presumably also affects v14.17.2 and v12.22.2, as these seem to include this same change. Haven't checked.

For what it's worth: I encountered the same issue when trying to upgrade from 14.17.1 LTS to 14.17.2 LTS, x64 version of the installer. Operating system is Windows 10 Home Edition, version 20H2, 64 bit. Language is German.

Just making a guess here, but the problem may be related to commit d0b449d which includes a fix for _""CVE-2021-22921: Windows installer - Node Installer Local Privilege Escalation (Medium)""_. At least that is the only change mentioned in the [changelog for 14.17.2](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V14.md#14.17.2) _and_ [16.4.1](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V16.md#16.4.1) that references installation on Windows systems.","striezel",20865852,"2021-07-01 20:54:28","problema atualização versão instalador windows problema relacionado commit fix cve windows installer node installer local privilege escalation medium mudança referência instalação sistema windows
"
2062,334,"Same problem here with both msi installers (32 and 64 bit) and Windows in spanish","RamiroPastor",22838883,"2021-07-01 22:08:10","problem msi installer bit window spanish
"
2063,334,"I can confirm it must be a recent change: 16.4.0 and older still work, only 16.4.1 produces this issue.","cecilemuller",681420,"2021-07-01 23:01:58","confirm recent change work produce issue
"
2064,334,"Is it possible to download the bug free version?

Or is there any workaround?","ThadeuFerreira",10009688,"2021-07-02 01:53:32","possible download bug free version workaround
"
2065,334,"@ThadeuFerreira

How about using https://github.com/coreybutler/nvm-windows to install Node.js?","Ayase-252",6264033,"2021-07-02 02:11:14","use install node.js
"
2066,334,"> EDIT: Presumably also affects v14.17.2 and v12.22.2, as these seem to include this same change. Haven't checked.

Thinking about that, i could bypass this error by installing a previous release: https://nodejs.org/download/release/v14.17.1/","Lem0nRavioli",57152284,"2021-07-02 04:24:04","affect v14.17.2 v12.22.2 seem include change check think bypass error install previous release
"
2067,334,"> @ThadeuFerreira
> Is it possible to download the bug free version?

The old versions are still available, for example:
https://nodejs.org/dist/v16.4.0/node-v16.4.0-x64.msi
","cecilemuller",681420,"2021-07-02 04:46:26","possible download bug free version old version available
"
2068,334,"I got the same problem when trying to install the x64 versions 4.17.2 LTS and 16.4.1 on Windows 10 Home Single Language (21H1) (Brazilian Portuguese). But I managed to install normally the 4.17.1 version that I downloaded at: https://nodejs.org/dist/v14.17.1/node-v14.17.1-x64.msi","RubenFilipe07",53026536,"2021-07-02 05:47:14","problema instalar versão windows home linguagem  conseguir instalar normalmente versão
"
2069,334,"/cc @kumarak @nodejs/platform-windows 

And @nodejs/releasers because I think we'll want to publish a new release as soon as this is fixed.","targos",2352663,"2021-07-02 05:56:20","kumarak nodejs platform windows nodejs releaser publish new release soon fix
"
2070,334,"A stupid workaround is to create a user called ""Authenticated Users"". The new user can be removed right after the setup. 🤦 ","peterterbe",3418466,"2021-07-02 12:10:31","workaround criar usuário chamar usuário novo usuário remover setup
"
2071,334,"Installed 16.4.0 for now. Awaiting a fix.","Griha3212",23246215,"2021-07-02 12:36:59","install await fix
"
2072,334,"I confirm, both 14.17.2 and 16.4.1 are unable to install on a French windows 10 system due to the lack of an 'Authenticated Users' group. ","cyrelk",662093,"2021-07-02 13:01:48","confirm install french window system lack authenticat user group
"
2073,334,"> I confirm, both 14.17.2 and 16.4.1 are unable to install on a French windows 10 system due to the lack of an 'Authenticated Users' group.

same with Hungarian windows","szabb",60015127,"2021-07-02 13:05:25","confirm version unable install french window system lack authenticate user group hungarian window
"
2074,334,"Hello, really the problem was solved when creating the user ""Authenticated Users"", however, in my case, I needed to install node via command line with chocolatey.","Eduardo-Carregoza",84537791,"2021-07-02 15:13:05","solve problem create user need install node command line chocolatey
"
2075,334,"Confirm too on Windows 7 (Russian Version).","inzanty",53940590,"2021-07-02 16:14:58","confirm windows russian version
"
2076,334,"I've spent a day trying to install 14.17.2. I even reinstalled windows with no result. I think it is a bad idea to keep it updated","shal-ae",57714611,"2021-07-02 16:22:30","install day reinstall window result bad idea keep update
"
2077,334,"The problem does appear to have been introduced in e817ba7 (fix for CVE-2021-22921) on non-English Windows. There are a few folks investigating the issue. Once an amended patch is available we will issue a new release for each release line.","BethGriggs",8297234,"2021-07-02 16:41:13","problem appear introduce fix cve non english windows folk investigate issue amend patch available issue new release release line
"
2078,334,"Nice @BethGriggs!
","nikeedev",69197950,"2021-07-02 17:52:09","Nice BethGriggs
"
2079,334,"SOLVED THE PROBLEM BY CREATING THE GROUP ""Authenticated Users""","Kosticivan5",85168007,"2021-07-02 21:58:06","solve problem create group authenticate user
"
2080,334,"No Brasil está acontecendo o mesmo erro, Windows10 64bits","LucasOliveirags",86860108,"2021-07-03 00:31:03","Brasil acontecer erro Windows bit
"
2081,334,"> SOLVED THE PROBLEM BY CREATING THE GROUP ""Authenticated Users""

How do I do this?","LucasOliveirags",86860108,"2021-07-03 00:31:39","solve problem create group authenticate user
"
2082,334,"> > SOLVED THE PROBLEM BY CREATING THE GROUP ""Authenticated Users""
> How do I do this?

It's not a real solution, it merely hides the symptom of the problem. Just stick with the previous version until the problem is solved in the next version.
","cecilemuller",681420,"2021-07-03 00:35:28","solve problem create group authenticate user solve problem hide symptom problem stick previous version problem solve next version
"
2083,334,"Estou com o mesmo problema, como faço para resolver???????","mateusmatosleonardo",73812069,"2021-07-03 00:46:51","mesmo problema resolver
"
2084,334,"> Estou com o mesmo problema, como faço para resolver???????

Basta baixar uma versão um pouco mais antiga que elas não estão com este bug, baixei a 14.17.1 LTS e funcionou para mim, caso queira baixar ela use o link: https://nodejs.org/dist/v14.17.1/","RubenFilipe07",53026536,"2021-07-03 01:07:31","problema resolver baixar versão antiga bug baixar funcionar
"
2085,334,"> Instead, we should probably use a SID to reference the correct group. See http://support.microsoft.com/kb/243330.

SID for ""Authenticated Users"": `S-1-5-11`
Powershell command to retrieve the correct localized ""Authenticated Users"" group from SID:
`[wmi]""Win32_SID.SID='S-1-5-11'"" | select -ExpandProperty AccountName`","jazzcript",6136227,"2021-07-03 01:51:40","use sid reference correct group retrieve correct localized authenticated user group sid
"
2086,334,"> @ThadeuFerreira
> 
> How about using https://github.com/coreybutler/nvm-windows to install Node.js?

I was asking about the installer. Getting the specific windows installer before the bug was introduced.
I was able to get the 13.x version, and is working fine.","ThadeuFerreira",10009688,"2021-07-03 01:57:09","use install nodejs ask installer get specific windows installer bug introduce able get 13x version work fine
"
2087,334,"> SOLVED THE PROBLEM BY CREATING THE GROUP ""Authenticated Users""

How? can you describe how to deal with it?","reniuszka",49594210,"2021-07-03 09:29:08","solve problem create group authenticate user describe deal
"
2088,335,"cc @nodejs/crypto (especially @panva @jasnell)","tniessen",3109072,"2021-07-01 17:25:04","nodejs crypto panva jasnell
"
2089,335,"The combination `{ type: ""spki"", format: ""jwk"" }` makes little sense. SPKI is a traditional cryptographic format, JWK is a new format that's incompatible with these older formats.","tniessen",3109072,"2021-07-01 17:26:55","combination type spki format jwk make little sense spki traditional cryptographic format jwk new format incompatible older format
"
2090,335,"@tniessen 

My cryptographic skills are lacking so I just picked ""spki"" because it was the only type that private EC keys supported according to the documentation. But from what I've tested, not using the ""type"" option at all throws the same error.","johannesnydahl",27621620,"2021-07-02 05:56:15","cryptographic skill lack pick spki type private ec key support documentation test use type option throw error
"
2122,340,"Hi, I am getting this error message. 
I see this issue has closed so when I can expect the fix?
```sh
input: './package.json',
  code: 'ERR_INVALID_URL'
``` 
to fix removed `--enable-source-maps` flag.","saostad",16025625,"2021-07-12 20:41:48","error message issue close expect fix remove flag
"
2091,335,"🤦‍♂️ i forgot about this interaction

> If a publicKeyEncoding or privateKeyEncoding was specified, this function behaves as if keyObject.export() had been called on its result.

A simple `{ format: 'jwk' }` should work for the supported key types but currently doesn't.","panva",241506,"2021-07-02 06:06:43","forgot interaction publickeyencoding privatekeyencoding function behave keyobject export simple format jwk work key type currently
"
2092,335,"I code something, there need last one step to finish `write to jwk`

```diff
Index: src/crypto/crypto_keys.h
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/crypto/crypto_keys.h b/src/crypto/crypto_keys.h
--- a/src/crypto/crypto_keys.h	(revision cf2fd0e5617d0bfe3da455685bcbba23e45a90c9)
+++ b/src/crypto/crypto_keys.h	(date 1625734732561)
@@ -31,7 +31,8 @@
 
 enum PKFormatType {
   kKeyFormatDER,
-  kKeyFormatPEM
+  kKeyFormatPEM,
+  kKeyFormatJWK
 };
 
 enum KeyType {
Index: lib/internal/crypto/keys.js
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/lib/internal/crypto/keys.js b/lib/internal/crypto/keys.js
--- a/lib/internal/crypto/keys.js	(revision cf2fd0e5617d0bfe3da455685bcbba23e45a90c9)
+++ b/lib/internal/crypto/keys.js	(date 1625734843024)
@@ -17,6 +17,7 @@
   kKeyTypePrivate,
   kKeyFormatPEM,
   kKeyFormatDER,
+  kKeyFormatJWK,
   kKeyEncodingPKCS1,
   kKeyEncodingPKCS8,
   kKeyEncodingSPKI,
@@ -265,6 +266,8 @@
     return kKeyFormatPEM;
   else if (formatStr === 'der')
     return kKeyFormatDER;
+  else if (formatStr === 'jwk')
+    return kKeyFormatJWK;
   throw new ERR_INVALID_ARG_VALUE(optionName, formatStr);
 }
 
Index: src/crypto/crypto_keys.cc
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/crypto/crypto_keys.cc b/src/crypto/crypto_keys.cc
--- a/src/crypto/crypto_keys.cc	(revision cf2fd0e5617d0bfe3da455685bcbba23e45a90c9)
+++ b/src/crypto/crypto_keys.cc	(date 1625736605694)
@@ -405,6 +405,9 @@
     if (config.format_ == kKeyFormatPEM) {
       // Encode SPKI as PEM.
       return PEM_write_bio_PUBKEY(bio.get(), pkey) == 1;
+    } else if (config.format_ == kKeyFormatJWK) {
+      // todo: support jwk
+      return call_something();
     } else {
       // Encode SPKI as DER.
       CHECK_EQ(config.format_, kKeyFormatDER);
@@ -1380,6 +1383,7 @@
   NODE_DEFINE_CONSTANT(target, kKeyEncodingSEC1);
   NODE_DEFINE_CONSTANT(target, kKeyFormatDER);
   NODE_DEFINE_CONSTANT(target, kKeyFormatPEM);
+  NODE_DEFINE_CONSTANT(target, kKeyFormatJWK);
   NODE_DEFINE_CONSTANT(target, kKeyTypeSecret);
   NODE_DEFINE_CONSTANT(target, kKeyTypePublic);
   NODE_DEFINE_CONSTANT(target, kKeyTypePrivate);

```","himself65",14026360,"2021-07-08 09:31:17","code step finish write jwk add support jwk todo support jwk encode spki pem encode spki der
"
2093,335,"I believe the issue also exist on node 15 but was not fixed: https://github.com/D4nte/js-libp2p-crypto/runs/4438572378?check_suite_focus=true

Can the fix be backported to 15?

Cc @jasnell 
","D4nte",300805,"2022-01-05 00:10:36","believe issue exist node fix backport  
"
2094,335,"@D4nte the fix was never meant to land on v15.x since it has reached End-Of-Life on 2021-06-01.","panva",241506,"2022-01-05 06:04:40","fix never mean land v15 since reach end life
"
2095,336,"@bcoe FYI","aduh95",14309773,"2021-06-25 09:12:12","FYI
"
2096,336,"Prior to #33491 no attempt was made to include a source marker in error output ... so I don't think it introduced the bug, so much as this must be an edge case it doesn't support.

We'll need to dig into this, thanks for the report.","bcoe",194609,"2021-06-25 22:13:25","attempt include source marker error output think introduce bug edge case support need dig thanks report
"
2097,336,"@aduh95 @bcoe In case it helps we are having the same problem on v16.14.0 and v14.19.0 however v14.16.0 works correctly. I am able to replicate with just one character. 

_test.js_
```
{
```

**What is the expected behavior?**
```
>>> node test.js

test.js:1
{
 

SyntaxError: Unexpected end of input
    at wrapSafe (internal/modules/cjs/loader.js:1001:16)
    at Module._compile (internal/modules/cjs/loader.js:1049:27)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1114:10)
    at Module.load (internal/modules/cjs/loader.js:950:32)
    at Function.Module._load (internal/modules/cjs/loader.js:790:12)
    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:75:12)
    at internal/main/run_main_module.js:17:47
```

**What do you see instead?**

```
>>> node --enable-source-maps test.js

SyntaxError: Unexpected end of input
    at wrapSafe (internal/modules/cjs/loader.js:1001:16)
    at Module._compile (internal/modules/cjs/loader.js:1049:27)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1114:10)
    at Module.load (internal/modules/cjs/loader.js:950:32)
    at Function.Module._load (internal/modules/cjs/loader.js:790:12)
    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:75:12)
    at internal/main/run_main_module.js:17:47
```","mediapartners",4029179,"2022-03-19 02:33:44","problema versão trabalho corretamente replicar caractere sintaxe erro inesperado fim entrada
"
2098,336,"We have logic that reads the original source of disk when an error occurs, and uses it to place the source marker, here:

https://github.com/nodejs/node/blob/master/lib/internal/source_map/prepare_stack_trace.js#L173

Will need to dig into if there's way for us to figure out this info in the `prepareStackTrace` method.","bcoe",194609,"2022-03-20 02:53:43","logic read original source disk error use place source marker need dig way figure info prepareStackTrace method
"
2099,336,"We are seeing this same issue using vm here https://github.com/ember-fastboot/ember-cli-fastboot/pull/894, thanks for the PR @cola119 ! ","gabrielcsapo",1854811,"2022-06-13 22:40:55","see issue use vm thanks pr
"
2100,336,"Is still help needed?","SebasQuirogaUCP",28678404,"2022-08-26 20:57:42","help need
"
2101,336,"Fixed in [v18.7.0](https://github.com/nodejs/node/releases/tag/v18.7.0)","cola119",22386678,"2022-08-27 02:53:10","fix version 18.7.0
"
2102,337,"Can be reproduced on master","Lxxyx",13161470,"2021-06-05 02:00:55","reproduce master
"
2103,337,"@nodejs/async_hooks ","targos",2352663,"2021-06-05 06:29:45","nodejs async hook
"
2104,337,"I'm quite sure that #38912 fixes this.","Flarna",18708370,"2021-06-05 19:05:44","sure fix
"
2105,337,"I confirm it is fixed by https://github.com/nodejs/node/pull/38912","targos",2352663,"2021-06-06 09:48:18","confirm fix
"
2106,338,"cc @nodejs/diagnostics ","Qard",205482,"2021-06-03 05:31:33","nodejs diagnostic
"
2107,338,"CI: https://ci.nodejs.org/job/node-test-pull-request/38469/","nodejs-github-bot",18269663,"2021-06-03 05:32:09","CI
"
2108,338,"A regression test would be nice.","Flarna",18708370,"2021-06-03 07:08:20","regression test nice
"
2109,338,"I added a regression test. 👍 ","Qard",205482,"2021-06-03 16:59:10","add regression test
"
2110,338,"CI: https://ci.nodejs.org/job/node-test-pull-request/38474/","nodejs-github-bot",18269663,"2021-06-03 16:59:43","CI
"
2111,338,"CI: https://ci.nodejs.org/job/node-test-pull-request/38478/","nodejs-github-bot",18269663,"2021-06-03 17:15:32","CI
"
2112,338,"CI: https://ci.nodejs.org/job/node-test-pull-request/38480/","nodejs-github-bot",18269663,"2021-06-03 19:22:00","CI
"
2113,338,"Seems the test needs some tuning for workers: https://ci.nodejs.org/job/node-test-commit-custom-suites-freestyle/21064/testReport/(root)/test/parallel_test_async_hooks_correctly_switch_promise_hook/","Flarna",18708370,"2021-06-03 20:28:40","test need tuning worker
"
2114,338,"CI: https://ci.nodejs.org/job/node-test-pull-request/38481/","nodejs-github-bot",18269663,"2021-06-03 20:59:21","CI
"
2115,338,"I had to restructure the test somewhat, but that should work correctly in the worker tests too now. :)","Qard",205482,"2021-06-03 20:59:46","restructure test work correctly worker test
"
2116,338,"CI: https://ci.nodejs.org/job/node-test-pull-request/38482/","nodejs-github-bot",18269663,"2021-06-03 21:43:21","CI
"
2117,338,"Landed in 1c36eefcdbdbd823f37d7006846490da67210f5a","Flarna",18708370,"2021-06-05 19:22:39","Landed
"
2118,338,"Refs: #36394","Flarna",18708370,"2021-06-20 11:23:04","36394
"
2119,339,"cc @nodejs/crypto ","Ayase-252",6264033,"2021-06-01 07:39:48","nodejs crypto
"
2120,340,"Ping @bcoe ","aduh95",14309773,"2021-05-24 08:29:58","ping
"
2121,340,"@aduh95 @maxholman acknowledged, although I'm unlikely to have any time to dig into this bug for at least a week.","bcoe",194609,"2021-06-08 16:34:52","acknowledged unlikely time dig bug week
"
2123,340,"@saostad could you provide a snippet of code that causes this error?","bcoe",194609,"2021-07-12 22:59:51","provide snippet code cause error
"
2124,340,"Having this issue as well on 16.0.0. Here's the command: `node --enable-source-maps --experimental-specifier-resolution=node ./build/index.js`. There isn't much more I can think of to provide, this command just doesn't work without removing the source maps flag.

Edit:
Fixed by using version `16.14.2`","christopher-caldwell",62559469,"2022-08-03 15:46:10","issue command work remove source map flag fix use version
"
2125,341,"/cc @Qard ","targos",2352663,"2021-05-23 12:15:52","Qard
"
2126,341,"It's because it creates new `v8::Context` instances and the new PromiseHook API is context-scoped. It's not _supposed_ to receive events from other contexts. It's only accidental, and somewhat of a security concern, that other parts of async_hooks are accessible from other contexts. Your example is creating an async_hooks instance in one context and then attempting to receive its events from another context.

Consider this:

```js
const vm = require('vm')

const context = vm.createContext({
  require,
  console
})

vm.runInContext(`
  const ah = require('async_hooks')

  ah.createHook({
    init (asyncId, type, triggerAsyncId, resource) {
      if (type === 'PROMISE') {
        console.log('I stole a promise from outside my context!', resource)
      }
    }
  }).enable()
`, context)

Promise.resolve()
```

The intent is to make the rest of async_hooks context-scoped too so resources can't leak into other contexts. Depending on how you look at it, this change either breaks compatibility or is a partial bug fix. Either way, async_hooks is experimental, so breaking compatibility for the sake of correctness _should_ be acceptable, as far as I understand.

I've discussed the context-scoping concerns with a few other Node.js core folks in the past and the thinking from them seemed to be in agreement with me that isolate-scoping was wrong and that it would be a bug fix to context-scope it.

I _would_ understand if we chose to hold off on the context-based PromiseHook API until the rest of async_hooks is also adapted to be context-scoped, however that's a large change in itself which I likely won't have the bandwidth to work on in the near future.","Qard",205482,"2021-05-25 02:59:39","create new context instance new promisehook api context scope receive event context accidental security concern part async hook accessible context example create async hook instance context attempt receive event context intent make rest async hook context scope resource leak context depend look change break compatibility partial bug fix way async hook experimental break compatibility sake correctness acceptable understand discuss context scope concern node js core folk past thinking seem agreement isolate scope wrong bug fix context scope understand choose hold context base promisehook api rest async hook adapt context scope large change likely bandwidth work near future
"
2127,341,"There is _not intent_ for the user to jump between contexts.

See the following:

```js
const vm = require('vm');
const { AsyncLocalStorage } = require('async_hooks')

const context = vm.createContext({
  AsyncLocalStorage,
  console,
});

vm.runInContext(`
  const storage = new AsyncLocalStorage()
  async function test() {
    return storage.run({ test: 'vm' }, async () => {
      console.log(storage.getStore());
      await 42;
      console.log(storage.getStore()); // this logs undefined
    });
  }
  test()
`, context);
```

the `AsyncLocalStorage` instance is fully contained within the `vm` module and there is no crossover, and yet it loses context. From the look of it, we are not attaching some of the mechanism to the new context.","mcollina",52195,"2021-05-25 06:37:44","intent user jump context asynclocalstorage instance fully contain vm module crossover lose context look attach mechanism new context
"
2128,341,"The AsyncLocalStorage instance may be created within that context, but the underlying call to `async_hooks.createHook(...)` which backs it are not. Because the underlying hooks are created external to the class, they are setup at require-time in the outer context. See: https://github.com/nodejs/node/blob/master/lib/async_hooks.js#L255-L264.

Though even if you move the require _into_ the `vm.runInContext(...)` you will still get the init for the AsyncResource created by `storage.run(...)` because, as I said, async_hooks is isolate-scoped, and you will get no resource after the await because PromiseHook is context-scoped and no hooks have been registered in that context.

If you try `vm.runInThisContext(...)` you will see that running with the vm module actually works just fine, the issue with `vm.runInContext(...)` is entirely that it is trying to run in a _different_ context than where the context-scoped PromiseHook is registered, therefore the _rest_ of async_hooks, which is isolate-scoped, will leak into that context, while the PromiseHook provided events will not.

I _do_ agree that the intent in that code sample is not to jump between contexts, but that _is_ how it works currently and, more importantly, is how it worked long before the context-scoping of PromiseHooks. Like I said, async_hooks is leaking information into other contexts when it shouldn't. The PromiseHook change fixes _some_ of that leaking, but there's still the rest of async_hooks leaking into other contexts where it should not.

If we wanted to retain the old way of leaking async_hooks information into other scopes, we could probably do something to keep registered promise hook functions synchronized across all contexts. Personally I think that's a bad idea though and we should be working to context-scope everything properly. I _would_ understand if wanted to have it leak the old way at least _for the time being_ and then make the true context-scoping of everything a major change later.","Qard",205482,"2021-05-25 07:38:12","asynclocalstorage instance may create context underlying call async_hooks createhook back not underlying hook create external class setup require time outer context promisehook context scope hook register context async_hooks isolate scope resource await promisehook context scope hook register context vm runinthiscontext module work issue vm runincontext entirely try run different context context scope promisehook register rest async_hooks isolate scope leak context promisehook provide event not intent code sample jump context work currently importantly work long context scope promisehooks async_hooks leak information context promisehook change fix leak rest async_hooks leak context want retain old way leak async_hooks information scope probably something keep register promise hook function synchronize context personally bad idea work context scope everything properly understand want leak old way time being make true context scope everything major change later
"
2129,341,"The problem is that the above breaks the usage of AsyncLocalStorage and Jest as it runs all tests in a VM - it's a significant regression that is not obvious for the end user. This should be fixed, or I fear we would have to revert the main optimization changes :/ - it's definitely needed for the new PromiseHooks to be backported to v14.

> I would understand if wanted to have it leak the old way at least for the time being and then make the true context-scoping of everything a major change later.

I fully agree with this approach.

@nodejs/diagnostics wdyrt? ","mcollina",52195,"2021-05-25 07:51:32","problem break usage asynclocalstorage jest run test vm significant regression obvious end user fix fear revert main optimization change need new promisehooks backport v14 understand leak old way time make true context scoping major change later agree approach
"
2130,341,"We will have to work with the Jest team on this. Even if AsyncLocalStorage is changed to be context-aware, what is going to happen with promises created within core (for example using the `fs/promises` API in a separate context) ?

/cc @SimenB ","targos",2352663,"2021-05-25 08:37:18","work jest team even asynclocalstorage change context aware happen promise create core example use api separate context
"
2131,341,"Issue raised on Jest side: https://github.com/facebook/jest/issues/11435","kibertoad",1847934,"2021-05-25 08:42:00","Issue raise Jest side
"
2132,341,"I'm not sure if context scoped async hooks are applicable to all use cases.
If I understand this correct this would mean that e.g. an APM tool has to hook into `vm.runInContext` and create and `AsyncLocalStore` there for tracking.
Are e.g. unhandled rejection handlers, uncaught exception handlers per context?","Flarna",18708370,"2021-05-25 09:04:34","sure context scope async hook applicable use case understand mean apm tool hook vm runincontext create asynclocalstore track unhandle rejection handler uncaught exception handler context
"
2133,341,"> If I understand this correct this would mean that e.g. an APM tool has to hook into vm.runInContext and create and AsyncLocalStore there for tracking.

No, this issue means that AsyncLocalStorage would not work _at all_ inside vm because the global hooks that AyncLocalStorage relies upon are outside of the context.","mcollina",52195,"2021-05-25 09:18:50","understand mean apm tool hook vmrnincontext create asynclocalstore track issue mean asynclocalstorage work vm global hook asynclocalstorage rely context
"
2154,346,"`--jitless` can be used to avoid generating code: i.e:
```
node --jitless npm ...
```
will look into the details on why it is segfaulting on ppc.

","miladfarca",46688537,"2021-05-04 01:22:34","use avoid generate code detail segfault ppc
"
2134,341,"> No, this issue means that AsyncLocalStorage would not work _at all_ inside vm because the global hooks that AyncLocalStorage relies upon are outside of the context.

I meant after we move whole async hooks to operate per context.","Flarna",18708370,"2021-05-25 09:22:14","issue mean asynclocalstorage work vm global hook asynclocalstorage rely context move async hook operate context
"
2135,341,"How does it make sense to make async hooks per context, given that async operations can cross contexts? I feel like the promise hooks here should cover all contexts created by Node.js.","addaleax",899444,"2021-05-25 09:26:29","make sense make async hook context given async operation cross context feel promise hook cover context create node js
"
2136,341,"Can we get the previous behavior back without reverting https://github.com/nodejs/node/pull/36394 entirely?","targos",2352663,"2021-05-25 13:38:20","get previous behavior back revert entirely
"
2137,341,"Like I said before, we could synchronize the registered hook functions across every created context. We'd have to store the functions and each created context to make sure that:

1. A new context will automatically set the current promise hook set on creation
2. Changing the promise hook set will update all existing contexts

Still not sure I agree that hooks should broadcast across all contexts, though I intend on eventually ensuring we have sufficient higher-level APIs to just deprecate async_hooks as a public interface anyway, which would eliminate the security concern of leaking resources into other contexts.

I'm not sure if I will have much time to work on this in the immediate term though...I'll see if I can figure something out.","Qard",205482,"2021-05-25 19:08:21","sincronizar função gancho registrado contexto criar armazenar função contexto criar novo contexto automaticamente definir promessa gancho conjunto criação mudar promessa gancho conjunto atualizar contexto existente certo gancho transmitir contexto pretender garantir api nível superior deprecar async_hook interface público eliminar preocupação segurança vazar recurso contexto muito tempo trabalhar imediato ver algo
"
2138,341,"If we can't get a ""quick"" resolution, we might have to revert :(.","mcollina",52195,"2021-05-25 21:10:44","quick resolution revert
"
2139,341,"Yeah. I'll figure out soon if I can rearrange some stuff to get time for this.","Qard",205482,"2021-05-25 21:22:03","figure rearrange time
"
2140,341,"Looks like @bengl is already working on something, but generally, yes, this is not hard to fix, so we should really not revert the original change here.","addaleax",899444,"2021-05-26 08:53:39","work something yes hard fix revert original change
"
2141,341,"Yes, I'll try to round out a PR from that commit (there's some cleanup to do, etc.) in the next day or so, time permitting. It's just manually synchronizing PromiseHooks across the main and vm.Context-created Contexts, using the AsyncHooks class to hold the list of Contexts and the JS hooks (for adding to newly created contexts). I'm happy to adjust the approach here if folks have other ideas.","bengl",110455,"2021-05-26 11:09:23","try round pr commit cleanup day time permit manually synchronize promisehook main vm context create context use asynchook class hold list context js hook add newly create context happy adjust approach folk idea
"
2142,342,"/cc @nodejs/net 
I can reproduce with Node.js 16.1.0","targos",2352663,"2021-05-17 12:18:01","reproduce node.js
"
2143,342,"Debug backtrace on 75340f3c524cbe8602ba8f5a48b8bf8572bad8f1:

```
#0  0x00007ffff6cf683f in raise () from /lib64/libc.so.6
#1  0x00007ffff6ce0c95 in abort () from /lib64/libc.so.6
#2  0x000000000116a0ee in node::Abort () at ../../src/node_errors.cc:254
#3  0x000000000116af3e in node::OnFatalError (location=0x3673e18 ""v8::HandleScope::CreateHandle()"", message=0x3673de8 ""Cannot create a handle without a HandleScope"") at ../../src/node_errors.cc:441
#4  0x00000000013e6751 in v8::Utils::ReportApiFailure (location=location@entry=0x3673e18 ""v8::HandleScope::CreateHandle()"", message=message@entry=0x3673de8 ""Cannot create a handle without a HandleScope"")
    at ../../deps/v8/src/api/api.cc:279
#5  0x0000000001683f91 in v8::Utils::ApiCheck (message=0x3673de8 ""Cannot create a handle without a HandleScope"", location=0x3673e18 ""v8::HandleScope::CreateHandle()"", condition=<optimized out>)
    at ../../deps/v8/src/api/api.h:144
#6  v8::internal::HandleScope::Extend (isolate=isolate@entry=0x6079390) at ../../deps/v8/src/handles/handles.cc:93
#7  0x00000000013c8028 in v8::internal::HandleScope::CreateHandle (value=58450354347249, isolate=0x6079390) at ../../deps/v8/src/handles/handles-inl.h:167
#8  v8::internal::HandleScope::GetHandle (isolate=isolate@entry=0x6079390, value=58450354347249) at ../../deps/v8/src/handles/handles-inl.h:185
#9  0x00000000016ac423 in v8::internal::HandleBase::HandleBase (isolate=0x6079390, object=<optimized out>, this=<optimized out>) at ../../deps/v8/src/handles/handles-inl.h:20
#10 v8::internal::Handle<v8::internal::SeqOneByteString>::Handle (isolate=0x6079390, object=..., this=<optimized out>) at ../../deps/v8/src/handles/handles-inl.h:52
#11 v8::internal::handle<v8::internal::SeqOneByteString> (isolate=0x6079390, object=...) at ../../deps/v8/src/handles/handles-inl.h:64
#12 v8::internal::FactoryBase<v8::internal::Factory>::NewRawOneByteString (this=this@entry=0x6079390, length=35, allocation=allocation@entry=v8::internal::AllocationType::kYoung)
    at ../../deps/v8/src/heap/factory-base.cc:545
#13 0x00000000016d83be in v8::internal::Factory::NewStringFromOneByte (this=this@entry=0x6079390, string=..., allocation=allocation@entry=v8::internal::AllocationType::kYoung)
    at /usr/include/c++/8/ext/new_allocator.h:86
#14 0x00000000013fdc75 in v8::(anonymous namespace)::NewString (string=..., type=v8::NewStringType::kNormal, factory=0x6079390) at ../../deps/v8/src/api/api.cc:6371
#15 v8::String::NewFromOneByte (isolate=0x6079390, data=0x35f4380 ""Canceled because of SSL destruction"", type=v8::NewStringType::kNormal, length=<optimized out>) at ../../deps/v8/src/api/api.cc:6429
#16 0x000000000102c2ba in node::OneByteString (isolate=0x6079390, data=0x35f4380 ""Canceled because of SSL destruction"", length=-1) at ../../src/util-inl.h:187
#17 0x0000000001100dc0 in node::StreamReq::Done (this=0x62d3330, status=-125, error_str=0x35f4380 ""Canceled because of SSL destruction"") at ../../src/stream_base-inl.h:284
#18 0x0000000001382318 in node::crypto::TLSWrap::InvokeQueued (this=0x62d4af0, status=-125, error_str=0x35f4380 ""Canceled because of SSL destruction"") at ../../src/crypto/crypto_tls.cc:379
#19 0x000000000138719c in node::crypto::TLSWrap::Destroy (this=0x62d4af0) at ../../src/crypto/crypto_tls.cc:1243
#20 0x0000000001381fec in node::crypto::TLSWrap::~TLSWrap (this=0x62d4af0, __in_chrg=<optimized out>) at ../../src/crypto/crypto_tls.cc:353
#21 0x00000000013820fa in node::crypto::TLSWrap::~TLSWrap (this=0x62d4af0, __in_chrg=<optimized out>) at ../../src/crypto/crypto_tls.cc:354
#22 0x00000000010c1cf4 in node::BaseObject::DeleteMe (data=0x62d4af0) at ../../src/env.cc:1685
#23 0x00000000010b1655 in node::Environment::RunCleanup (this=0x60f6c50) at ../../src/env.cc:701
#24 0x000000000102a4fd in node::FreeEnvironment (env=0x60f6c50) at ../../src/api/environment.cc:371
#25 0x000000000102727e in node::FunctionDeleter<node::Environment, &node::FreeEnvironment>::operator() (this=0x7fffffffde50, pointer=0x60f6c50) at ../../src/util.h:636
#26 0x0000000001026d31 in std::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment> >::~unique_ptr (this=0x7fffffffde50, __in_chrg=<optimized out>)
    at /usr/include/c++/8/bits/unique_ptr.h:277
#27 0x00000000011d5f5f in node::NodeMainInstance::Run (this=0x7fffffffdef0, env_info=0x6003060 <node::env_info>) at ../../src/node_main_instance.cc:135
#28 0x00000000011118f6 in node::Start (argc=2, argv=0x7fffffffe168) at ../../src/node.cc:1083
#29 0x00000000029c59cd in main (argc=2, argv=0x7fffffffe168) at ../../src/node_main.cc:127
```","targos",2352663,"2021-05-17 18:06:32","abort cancel ssl destruction
"
2144,342,"Will this issue affect other `unref` APIs?
 And are there any workarounds? Currently, it seems like waiting a few milliseconds(like 40) is one way. But code like this is kind of confusing.","niyan-ly",28030655,"2021-05-18 02:17:23","issue affect api workaround wait millisecond code confuse
"
2145,343,"After a bit of digging I think it's the same problem as here: https://github.com/nodejs/node/issues/25424

You can reproduce straightforwardly by creating a function like `const fn = () => import('crypto')`, runnning `global.gc()`, then trying to run `fn()`. The ContexifyScript wrapping `import('crypto')` gets GCd, the destructor removes that entry from `id_to_script_map`, then when `fn()` tries to read the map it segfaults.","seangoedecke",21163718,"2021-05-17 07:05:57","dig problem create function run global gc try run contextifyscript wrap import gc destructor remove entry id to script map try read map segfault
"
2146,343,"Closing as https://github.com/nodejs/node/pull/48510 has landed and should fix this. We can re-open if that turns out to be incorrect (hopefully not).","joyeecheung",4299420,"2023-09-14 15:48:08","fix issue reopen incorrect
"
2147,344,"I think I've found the issue, I'll take a look","Linkgoron",763605,"2021-05-13 22:57:57","think find issue take look
"
2148,344,"Hi, thank you for the fix. Any plan to backport to 16.x LTS?","babatakao",277476,"2021-12-20 09:28:52","fix plan backport 16 LTS
"
2149,344,"@babatakao I understand fixing this ~~caused so many unexpected failures~~ revealed so many uses that needed to catch errors in their CI environment that fixing this is considered a breaking change.","rhwood",297232,"2021-12-20 10:32:25","understand fix reveal many use need catch error ci environment fix consider break change
"
2150,344,"Fixing this issue kind of broke Node.js's build, so we assumed that others would probably face similar issues.","Linkgoron",763605,"2021-12-20 10:38:54","fix issue break node js build assume other face similar issue
"
2151,344,"I understand. Thanks!","babatakao",277476,"2021-12-20 10:41:29","understand thanks
"
2152,346,"/cc @nodejs/platform-ppc 

","targos",2352663,"2021-05-03 16:46:43","nodejs platform ppc
"
2153,346,"@miladfarca are there some options you could recommend to disable V8 optimizations to see if it might be related to code being generated?","mhdawson",9373002,"2021-05-03 21:55:16","miladfarca option recommend disable v8 optimization see relate code generate
"
2155,346,"I can confirm that `--jitless` avoids the crash.","Flarna",18708370,"2021-05-04 08:54:50","confirm avoid crash
"
2156,346,"@Flarna Thanks for confirming. Would you also be able to use the `v16.0.0` node binary from this nightly build and check if the problem still exists? (without using `--jitless`)

https://nodejs.org/download/nightly/v16.0.0-nightly202102126ea9af9906/

PPC file will be: https://nodejs.org/download/nightly/v16.0.0-nightly202102126ea9af9906/node-v16.0.0-nightly202102126ea9af9906-linux-ppc64le.tar.gz","miladfarca",46688537,"2021-05-04 13:14:54","confirm use node binary nightly build check problem exist use jitless
"
2157,346,"@miladfarca This version looks good.

Tried also the next newer version v16.0.0-nightly2021021388d9268d08 => this one shows the problem","Flarna",18708370,"2021-05-04 13:39:36","version good try newer version problem
"
2158,346,"Debug build is not able to compile at the moment. I submitted another PR at https://github.com/nodejs/node/issues/38571 so this might take longer. @targos Would you be able to help on the gyp/GN scraper issue? ","john-yan",1722371,"2021-05-06 15:21:33","debug build able compile submit pr gyp gn scraper issue help
"
2159,346,"can confirm segfault while building qtwebengine/chromium typescript parts on ppc64le with 16.1.0","gyakovlev",168902,"2021-05-07 04:53:44","confirm segfault build qtwebengine chromium typescript part ppc64le
"
2160,346,"I can't reproduce with debug build of node (with #38571 applied)","gyakovlev",168902,"2021-05-07 06:05:37","reproduce debug build node
"
2161,346,"ok I've tried building with `-O0` (default for debug unoptimized build), `-Og` , and  `-O2` for `BUILDTYPE=Debug` it does `SIGTRAP`

```
Core was generated by `/usr/bin/node ../../../../qtwebengine-5.15.2_p20210421/src/3rdparty/chromium/th'.
Program terminated with signal SIGTRAP, Trace/breakpoint trap.
#0  0x00000001042114ac in v8::base::OS::Abort () at ../deps/v8/src/base/platform/platform-posix.cc:502
502         V8_IMMEDIATE_CRASH();
[Current thread is 1 (Thread 0x7fffa1b99010 (LWP 8434))]
(gdb) bt
#0  0x00000001042114ac in v8::base::OS::Abort () at ../deps/v8/src/base/platform/platform-posix.cc:502
#1  0x00000001062d62a0 in V8_Fatal (file=0x106b6ce60 ""../deps/v8/src/deoptimizer/deoptimizer.cc"", line=<optimized out>,
    format=format@entry=0x1089dccd0 ""Debug check failed: %s."") at ../deps/v8/src/base/logging.cc:167
#2  0x00000001062d62e0 in v8::base::(anonymous namespace)::DefaultDcheckHandler (file=<optimized out>, line=<optimized out>,
    message=<optimized out>) at ../deps/v8/src/base/logging.cc:57
#3  0x00000001062d6328 in V8_Dcheck (file=<optimized out>, line=<optimized out>, message=<optimized out>)
    at ../deps/v8/src/base/logging.cc:180
#4  0x00000001048916a4 in v8::internal::Deoptimizer::Deoptimizer (this=0x141d1c380, isolate=<optimized out>, function=...,
    kind=<optimized out>, deopt_exit_index=<optimized out>, from=<optimized out>, fp_to_sp_delta=<optimized out>)
    at ../deps/v8/src/deoptimizer/deoptimizer.cc:574
#5  0x0000000104891964 in v8::internal::Deoptimizer::New (raw_function=<optimized out>, kind=<optimized out>,
    deopt_exit_index=<optimized out>, from=69196732299540, fp_to_sp_delta=<optimized out>, isolate=0x141c6fb40)
    at ../deps/v8/src/deoptimizer/deoptimizer.cc:195
#6  0x000000010563b238 in Builtins_DeoptimizationEntry_Soft () at ../deps/v8/src/builtins/builtins-internal-gen.cc:1107






(gdb) bt full
#0  0x00000001042114ac in v8::base::OS::Abort () at ../deps/v8/src/base/platform/platform-posix.cc:502
No locals.
#1  0x00000001062d62a0 in V8_Fatal (file=0x106b6ce60 ""../deps/v8/src/deoptimizer/deoptimizer.cc"", line=<optimized out>, format=format@entry=0x1089dccd0 ""Debug check failed: %s."") at ../deps/v8/src/base/logging.cc:167
        arguments = 0x7fffcbeb1308 ""\200)4B\001""
        message = {static kStartMarker = <optimized out>, static kEndMarker = <optimized out>, static kMessageBufferSize = <optimized out>, start_marker_ = 3737837072, message_ = ""Debug check failed: 0 == offset % kNonLazyDeoptExitSize (0 vs. 8)."", '\000' <repeats 445 times>,
          end_marker_ = 3737837073}
#2  0x00000001062d62e0 in v8::base::(anonymous namespace)::DefaultDcheckHandler (file=<optimized out>, line=<optimized out>, message=<optimized out>) at ../deps/v8/src/base/logging.cc:57
No locals.
#3  0x00000001062d6328 in V8_Dcheck (file=<optimized out>, line=<optimized out>, message=<optimized out>) at ../deps/v8/src/base/logging.cc:180
No locals.
#4  0x00000001048916a4 in v8::internal::Deoptimizer::Deoptimizer (this=0x141d1c380, isolate=<optimized out>, function=..., kind=<optimized out>, deopt_exit_index=<optimized out>, from=<optimized out>, fp_to_sp_delta=<optimized out>)
    at ../deps/v8/src/deoptimizer/deoptimizer.cc:574
        _msg = 0x142351f00
        offset = <optimized out>
        deopt_start = <optimized out>
        lazy_deopt_start = 69196732299592
        eager_with_resume_deopt_start = <optimized out>
        deopt_data = {<v8::internal::FixedArray> = {<v8::internal::TorqueGeneratedFixedArray<v8::internal::FixedArray, v8::internal::FixedArrayBase>> = {<v8::internal::FixedArrayBase> = {<v8::internal::TorqueGeneratedFixedArrayBase<v8::internal::FixedArrayBase, v8::internal::HeapObject>> = {<v8::internal::HeapObject> = {<v8::internal::Object> = {<v8::internal::TaggedImpl<(v8::internal::HeapObjectReferenceType)1, unsigned long>> = {static kIsFull = <optimized out>, static kCanBeWeak = false, ptr_ = 35165796512481},
                      static kHeaderSize = 0}, <No data fields>}, static kStartOfStrongFieldsOffset = <optimized out>, static kLengthOffset = 8, static kLengthOffsetEnd = 15, static kEndOfStrongFieldsOffset = <optimized out>, static kStartOfWeakFieldsOffset = <optimized out>,
                  static kEndOfWeakFieldsOffset = <optimized out>, static kHeaderSize = 16}, static kMaxSize = 1073741816}, static kStartOfStrongFieldsOffset = <optimized out>, static kHeaderSize = 16, static kObjectsOffset = <optimized out>,
              static kObjectsOffsetEnd = <optimized out>, static kEndOfStrongFieldsOffset = <optimized out>, static kStartOfWeakFieldsOffset = <optimized out>, static kEndOfWeakFieldsOffset = <optimized out>}, static kMaxLength = 134217725, static kMaxRegularLength = 32766,
            static kObjectsOffset = 16}, static kTranslationByteArrayIndex = 0, static kInlinedFunctionCountIndex = 1, static kLiteralArrayIndex = 2, static kOsrBytecodeOffsetIndex = 3, static kOsrPcOffsetIndex = 4, static kOptimizationIdIndex = 5,
          static kSharedFunctionInfoIndex = 6, static kInliningPositionsIndex = 7, static kDeoptExitStartIndex = 8, static kEagerSoftAndBailoutDeoptCountIndex = 9, static kLazyDeoptCountIndex = 10, static kFirstDeoptEntryIndex = 11, static kBytecodeOffsetRawOffset = 0,
          static kTranslationIndexOffset = 1, static kPcOffset = 2, static kDeoptEntrySize = 3, static kNotInlinedIndex = -1}
        eager_soft_and_bailout_deopt_count = 253
        lazy_deopt_count = <optimized out>
        size = <optimized out>
        parameter_count = <optimized out>
        size = <optimized out>
        parameter_count = <optimized out>
        _msg = <optimized out>
        scope = {static kCheckHandleThreshold = 30720, isolate_ = <optimized out>, prev_next_ = <optimized out>, prev_limit_ = <optimized out>}
        deopt_data = {<v8::internal::FixedArray> = {<v8::internal::TorqueGeneratedFixedArray<v8::internal::FixedArray, v8::internal::FixedArrayBase>> = {<v8::internal::FixedArrayBase> = {<v8::internal::TorqueGeneratedFixedArrayBase<v8::internal::FixedArrayBase, v8::internal::HeapObject>> = {<v8::internal::HeapObject> = {<v8::internal::Object> = {<v8::internal::TaggedImpl<(v8::internal::HeapObjectReferenceType)1, unsigned long>> = {static kIsFull = <optimized out>, static kCanBeWeak = false, ptr_ = <optimized out>},
                      static kHeaderSize = 0}, <No data fields>}, static kStartOfStrongFieldsOffset = <optimized out>, static kLengthOffset = 8, static kLengthOffsetEnd = 15, static kEndOfStrongFieldsOffset = <optimized out>, static kStartOfWeakFieldsOffset = <optimized out>,
                  static kEndOfWeakFieldsOffset = <optimized out>, static kHeaderSize = 16}, static kMaxSize = 1073741816}, static kStartOfStrongFieldsOffset = <optimized out>, static kHeaderSize = 16, static kObjectsOffset = <optimized out>,
              static kObjectsOffsetEnd = <optimized out>, static kEndOfStrongFieldsOffset = <optimized out>, static kStartOfWeakFieldsOffset = <optimized out>, static kEndOfWeakFieldsOffset = <optimized out>}, static kMaxLength = 134217725, static kMaxRegularLength = 32766,
            static kObjectsOffset = 16}, static kTranslationByteArrayIndex = 0, static kInlinedFunctionCountIndex = 1, static kLiteralArrayIndex = 2, static kOsrBytecodeOffsetIndex = 3, static kOsrPcOffsetIndex = 4, static kOptimizationIdIndex = 5,
          static kSharedFunctionInfoIndex = 6, static kInliningPositionsIndex = 7, static kDeoptExitStartIndex = 8, static kEagerSoftAndBailoutDeoptCountIndex = 9, static kLazyDeoptCountIndex = 10, static kFirstDeoptEntryIndex = 11, static kBytecodeOffsetRawOffset = 0,
          static kTranslationIndexOffset = 1, static kPcOffset = 2, static kDeoptEntrySize = 3, static kNotInlinedIndex = -1}
        deopt_start = <optimized out>
        eager_soft_and_bailout_deopt_count = <optimized out>
        lazy_deopt_start = <optimized out>
        lazy_deopt_count = <optimized out>
        eager_with_resume_deopt_start = <optimized out>
        _msg = <optimized out>
        _msg = <optimized out>
        _msg = <optimized out>
        offset = <optimized out>
        _msg = <optimized out>
        offset = <optimized out>
--Type <RET> for more, q to quit, c to continue without paging--
        _msg = <optimized out>
        offset = <optimized out>
        _msg = <optimized out>
#5  0x0000000104891964 in v8::internal::Deoptimizer::New (raw_function=<optimized out>, kind=<optimized out>, deopt_exit_index=<optimized out>, from=69196732299540, fp_to_sp_delta=<optimized out>, isolate=0x141c6fb40) at ../deps/v8/src/deoptimizer/deoptimizer.cc:195
        function = {<v8::internal::JSFunctionOrBoundFunction> = {<v8::internal::TorqueGeneratedJSFunctionOrBoundFunction<v8::internal::JSFunctionOrBoundFunction, v8::internal::JSObject>> = {<v8::internal::JSObject> = {<v8::internal::TorqueGeneratedJSObject<v8::internal::JSObject, v8::internal::JSReceiver>> = {<v8::internal::JSReceiver> = {<v8::internal::HeapObject> = {<v8::internal::Object> = {<v8::internal::TaggedImpl<(v8::internal::HeapObjectReferenceType)1, unsigned long>> = {static kIsFull = <optimized out>, static kCanBeWeak = false,
                          ptr_ = 2082690347097}, static kHeaderSize = 0}, <No data fields>}, static kHashMask = 2147482624}, static kStartOfStrongFieldsOffset = v8::internal::JSReceiver::kStartOfStrongFieldsOffset, static kElementsOffset = 16, static kElementsOffsetEnd = 23,
                  static kEndOfStrongFieldsOffset = v8::internal::JSReceiver::kEndOfStrongFieldsOffset, static kStartOfWeakFieldsOffset = v8::internal::JSReceiver::kEndOfStrongFieldsOffset, static kEndOfWeakFieldsOffset = v8::internal::JSReceiver::kEndOfStrongFieldsOffset,
                  static kHeaderSize = 24}, static kMinAddedElementsCapacity = 16, static kMaxElementCount = 4294967295, static kMaxGap = 1024, static kMaxUncheckedFastElementsLength = 5000, static kMaxUncheckedOldFastElementsLength = 500,
                static kInitialGlobalObjectUnusedPropertiesCount = 4, static kMaxInstanceSize = 2040, static kFieldsAdded = 3, static kMaxInObjectProperties = 252, static kMaxFirstInobjectPropertyOffset = 127, static kMaxEmbedderFields = 12},
              static kStartOfWeakFieldsOffset = v8::internal::JSReceiver::kEndOfStrongFieldsOffset, static kEndOfWeakFieldsOffset = v8::internal::JSReceiver::kEndOfStrongFieldsOffset, static kStartOfStrongFieldsOffset = v8::internal::JSReceiver::kStartOfStrongFieldsOffset,
              static kEndOfStrongFieldsOffset = v8::internal::JSReceiver::kEndOfStrongFieldsOffset, static kHeaderSize = 24}, <No data fields>}, static kLengthDescriptorIndex = 0, static kNameDescriptorIndex = 1, static kMinDescriptorsForFastBind = 2,
          static kSharedFunctionInfoOffset = 24, static kContextOffset = 32, static kFeedbackCellOffset = 40, static kCodeOffset = 48, static kPrototypeOrInitialMapOffset = 56, static kHeaderSize = 24, static kSizeWithoutPrototype = 56, static kSizeWithPrototype = 64}
        deoptimizer = <optimized out>
#6  0x000000010563b238 in Builtins_DeoptimizationEntry_Soft () at ../deps/v8/src/builtins/builtins-internal-gen.cc:1107
No locals.

```

so far here's the backtrace for `Release` build with flags overriden to `-O2 -ggdb -fno-omit-frame-pointer`



```
Core was generated by `/usr/bin/node ../../../../qtwebengine-5.15.2_p20210421/src/3rdparty/chromium/th'.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x000000013bb29178 in v8::internal::Object::ReadField<unsigned char, 0> (offset=1612733462, this=0x7fffcc053e28)
    at ../deps/v8/src/objects/objects.h:649
649     ../deps/v8/src/objects/objects.h: No such file or directory.
[Current thread is 1 (Thread 0x7fff80089010 (LWP 7124))]
(gdb) bt
#0  0x000000013bb29178 in v8::internal::Object::ReadField<unsigned char, 0> (offset=1612733462, this=0x7fffcc053e28)
    at ../deps/v8/src/objects/objects.h:649
#1  v8::internal::ByteArray::get (index=1612733447, this=0x7fffcc053e28) at ../deps/v8/src/objects/fixed-array-inl.h:554
#2  v8::internal::TranslationArrayIterator::Next (this=0x7fffcc053e10) at ../deps/v8/src/deoptimizer/translation-array.cc:64
#3  0x000000013bb287b4 in v8::internal::TranslatedState::Init (this=0x143257900, isolate=<optimized out>,
    input_frame_pointer=<optimized out>, stack_frame_pointer=<optimized out>, iterator=<optimized out>, literal_array=...,
    registers=<optimized out>, trace_file=<optimized out>, formal_parameter_count=3, actual_argument_count=3)
    at ../deps/v8/src/deoptimizer/translated-state.cc:1315
#4  0x000000013bb1d9b8 in v8::internal::Deoptimizer::DoComputeOutputFrames (this=0x143257880)
    at ../deps/v8/src/deoptimizer/deoptimizer.cc:889
#5  0x000000013c44b8bc in Builtins_DeoptimizationEntry_Lazy ()








(gdb) bt full
#0  0x000000013bb29178 in v8::internal::Object::ReadField<unsigned char, 0> (offset=1612733462, this=0x7fffcc053e28)
    at ../deps/v8/src/objects/objects.h:649
        v8_pointer_compression_unaligned = false
        v8_pointer_compression_unaligned = <optimized out>
#1  v8::internal::ByteArray::get (index=1612733447, this=0x7fffcc053e28) at ../deps/v8/src/objects/fixed-array-inl.h:554
No locals.
#2  v8::internal::TranslationArrayIterator::Next (this=0x7fffcc053e10) at ../deps/v8/src/deoptimizer/translation-array.cc:64
        next = <optimized out>
        i = 0
        bits = 0
        is_negative = <optimized out>
        result = <optimized out>
#3  0x000000013bb287b4 in v8::internal::TranslatedState::Init (this=0x143257900, isolate=<optimized out>,
    input_frame_pointer=<optimized out>, stack_frame_pointer=<optimized out>, iterator=<optimized out>, literal_array=...,
    registers=<optimized out>, trace_file=<optimized out>, formal_parameter_count=3, actual_argument_count=3)
    at ../deps/v8/src/deoptimizer/translated-state.cc:1315
        opcode = <optimized out>
        count = <optimized out>
        update_feedback_count = <optimized out>
        nested_counts = std::stack wrapping: std::deque with 800736050 elements = {-872071344, 32767, -1877716216, 16018, 1652552377,
          9632, -710525751, 9713, -872071416, 32767, 1126529152, 1, -452450919, 6541, -710525751, 9713, -872071240, 32767, -219972639,
          4549, 1, 0, -219960135, 4549, -219972639, 4549, -1877792416, 16018, -872071232, 32767, -1877794572, 16018, -452450919, 6541,
          -710525751, 9713, -1877682752, 16018, -872071224, 32767, -1877685556, 16018, -219972639, 4549, -710812119, 9713, -452450455,
          6541, 2, 0, -219953863, 4549, -219972639, 4549, -1877671960, 16018, -872071136, 32767, -1877673056, 16018, -452450919, 6541,
          -710525751, 9713, 0, 0, 0, 0, -219972639, 4549, -219953863, 4549, 1, 0, -219960263, 4549, -219972639, 4549, -1877689560, 16018,
--Type <RET> for more, q to quit, c to continue without paging--
          -872071048, 32767, -1877690152, 16018, -452450919, 6541, -710547719, 9713, -452450919, 6541, -452450919, 6541, -213896015,
          6969, 3, 0, -220177007, 4549, -213896015, 6969, -1877612872, 16018, -872070928, 32767, -1877616280, 16018, -452450919, 6541,
          -219953863, 4549, -219960263, 4549, -710547719, 9713, 406791897, 5196, 1, 0, 0, 1, 0, 0, -213896015, 6969, 3, 0, -213747239,
          6969, -213896015, 6969, -1877712128, 16018, -872070816, 32767, -1877716216, 16018, 1652552377, 9632, -710812119, 9713,
          -219953863, 4549, -219960263, 4549, 1557668153, 6257, 1011109664, 1, -872070808, 32767, -219972639, 4549, 1, 0, -219960135,
          4549, -219972639, 4549, -1877662280, 16018, -872070632, 32767, -1877669852, 16018, -452450919, 6541, -710812119, 9713,
          43104233, 12685, 2491401, 507, 0, 0, -452450455, 6541, -452450919, 6541, -452450919, 6541, -452450919, 6541, -452450919, 6541,
          -452450919, 6541, 721453881, 11287, 45, 0, -219972639, 4549, -710878559, 9713, -1315907375, 592, -710878559, 9713, 2, 0...}
#4  0x000000013bb1d9b8 in v8::internal::Deoptimizer::DoComputeOutputFrames (this=0x143257880)
    at ../deps/v8/src/deoptimizer/deoptimizer.cc:889
        timer = {start_ticks_ = {<v8::base::time_internal::TimeBase<v8::base::TimeTicks>> = {<v8::base::TimeConstants> = {
                static kHoursPerDay = 24, static kMillisecondsPerSecond = 1000, static kMillisecondsPerDay = 86400000,
                static kMicrosecondsPerMillisecond = 1000, static kMicrosecondsPerSecond = 1000000,
                static kMicrosecondsPerMinute = 60000000, static kMicrosecondsPerHour = 3600000000,
                static kMicrosecondsPerDay = 86400000000, static kMicrosecondsPerWeek = 604800000000,
                static kNanosecondsPerMicrosecond = 1000, static kNanosecondsPerSecond = 1000000000},
              us_ = <optimized out>}, <No data fields>}}
        input_data = {<v8::internal::FixedArray> = {<v8::internal::TorqueGeneratedFixedArray<v8::internal::FixedArray, v8::internal::FixedArrayBase>> = {<v8::internal::FixedArrayBase> = {<v8::internal::TorqueGeneratedFixedArrayBase<v8::internal::FixedArrayBase, v8::internal::HeapObject>> = {<v8::internal::HeapObject> = {<v8::internal::Object> = {<v8::internal::TaggedImpl<(v8::internal::HeapObjectReferenceType)1, unsigned long>> = {static kIsFull = <optimized out>, static kCanBeWeak = false, ptr_ = <optimized out>},
                      static kHeaderSize = 0}, <No data fields>}, static kStartOfStrongFieldsOffset = <optimized out>,
                  static kLengthOffset = 8, static kLengthOffsetEnd = 15, static kEndOfStrongFieldsOffset = <optimized out>,
                  static kStartOfWeakFieldsOffset = <optimized out>, static kEndOfWeakFieldsOffset = <optimized out>,
                  static kHeaderSize = 16}, static kMaxSize = 1073741816}, static kStartOfStrongFieldsOffset = <optimized out>,
--Type <RET> for more, q to quit, c to continue without paging--
              static kHeaderSize = 16, static kObjectsOffset = <optimized out>, static kObjectsOffsetEnd = <optimized out>,
              static kEndOfStrongFieldsOffset = <optimized out>, static kStartOfWeakFieldsOffset = <optimized out>,
              static kEndOfWeakFieldsOffset = <optimized out>}, static kMaxLength = 134217725, static kMaxRegularLength = 32766,
            static kObjectsOffset = 16}, static kTranslationByteArrayIndex = 0, static kInlinedFunctionCountIndex = 1,
          static kLiteralArrayIndex = 2, static kOsrBytecodeOffsetIndex = 3, static kOsrPcOffsetIndex = 4,
          static kOptimizationIdIndex = 5, static kSharedFunctionInfoIndex = 6, static kInliningPositionsIndex = 7,
          static kDeoptExitStartIndex = 8, static kEagerSoftAndBailoutDeoptCountIndex = 9, static kLazyDeoptCountIndex = 10,
          static kFirstDeoptEntryIndex = 11, static kBytecodeOffsetRawOffset = 0, static kTranslationIndexOffset = 1,
          static kPcOffset = 2, static kDeoptEntrySize = 3, static kNotInlinedIndex = -1}
        stack_guard = 0x14327fb38
        bytecode_offset = {static kNoneId = -1, static kFirstBuiltinContinuationId = 1, id_ = <optimized out>}
        translations = {<v8::internal::TorqueGeneratedByteArray<v8::internal::ByteArray, v8::internal::FixedArrayBase>> = {<v8::internal::FixedArrayBase> = {<v8::internal::TorqueGeneratedFixedArrayBase<v8::internal::FixedArrayBase, v8::internal::HeapObject>> = {<v8::internal::HeapObject> = {<v8::internal::Object> = {<v8::internal::TaggedImpl<(v8::internal::HeapObjectReferenceType)1, unsigned long>> = {
                      static kIsFull = <optimized out>, static kCanBeWeak = false, ptr_ = 2177550646105},
                    static kHeaderSize = 0}, <No data fields>}, static kStartOfStrongFieldsOffset = <optimized out>,
                static kLengthOffset = 8, static kLengthOffsetEnd = 15, static kEndOfStrongFieldsOffset = <optimized out>,
                static kStartOfWeakFieldsOffset = <optimized out>, static kEndOfWeakFieldsOffset = <optimized out>,
                static kHeaderSize = 16}, static kMaxSize = 1073741816}, static kHeaderSize = 16, static kBytesOffset = <optimized out>,
            static kBytesOffsetEnd = <optimized out>, static kStartOfWeakFieldsOffset = <optimized out>,
            static kEndOfWeakFieldsOffset = <optimized out>, static kStartOfStrongFieldsOffset = <optimized out>,
            static kEndOfStrongFieldsOffset = <optimized out>}, static kAlignedSize = 16, static kMaxLength = 1073741800}
        translation_index = 1612733446
        trace_file = 0x0
        state_iterator = {uncompressed_contents_ = std::vector of length 0, capacity 0,
--Type <RET> for more, q to quit, c to continue without paging--
          buffer_ = {<v8::internal::TorqueGeneratedByteArray<v8::internal::ByteArray, v8::internal::FixedArrayBase>> = {<v8::internal::FixedArrayBase> = {<v8::internal::TorqueGeneratedFixedArrayBase<v8::internal::FixedArrayBase, v8::internal::HeapObject>> = {<v8::internal::HeapObject> = {<v8::internal::Object> = {<v8::internal::TaggedImpl<(v8::internal::HeapObjectReferenceType)1, unsigned long>> = {
                        static kIsFull = <optimized out>, static kCanBeWeak = false, ptr_ = 2177550646105},
                      static kHeaderSize = 0}, <No data fields>}, static kStartOfStrongFieldsOffset = <optimized out>,
                  static kLengthOffset = 8, static kLengthOffsetEnd = 15, static kEndOfStrongFieldsOffset = <optimized out>,
                  static kStartOfWeakFieldsOffset = <optimized out>, static kEndOfWeakFieldsOffset = <optimized out>,
                  static kHeaderSize = 16}, static kMaxSize = 1073741816}, static kHeaderSize = 16,
              static kBytesOffset = <optimized out>, static kBytesOffsetEnd = <optimized out>,
              static kStartOfWeakFieldsOffset = <optimized out>, static kEndOfWeakFieldsOffset = <optimized out>,
              static kStartOfStrongFieldsOffset = <optimized out>, static kEndOfStrongFieldsOffset = <optimized out>},
            static kAlignedSize = 16, static kMaxLength = 1073741800}, index_ = 1612733447}
        count = <optimized out>
        frame_index = <optimized out>
        total_output_frame_size = <optimized out>
        topmost = <optimized out>
#5  0x000000013c44b8bc in Builtins_DeoptimizationEntry_Lazy ()
No symbol table info available.

```","gyakovlev",168902,"2021-05-07 07:13:36","tried build default debug unoptimized build sigtrap program terminated signal sigtrap trace breakpoint trap v8 base os abort debug check failed v8 base anonymous namespace defaultdcheckhandler v8 dcheck v8 internal deoptimizer deoptimizer v8 internal deoptimizer new builtins deoptimizationentry soft program terminated signal sigsegv segmentation fault v8 internal object readfield v8 internal bytearray get v8 internal translationarrayiterator next v8 internal translatedstate init v8 internal deoptimizer docomputeoutputframes builtins deoptimizationentry lazy
"
2162,346,"I found the issue. It was caused by trampoline pool emission during deopt exit table generation. Deoptimizer expects deopt exits to be continuous. However, trampoline pool breaks this underlining assumption. I will submit a CL to fix this soon.","john-yan",1722371,"2021-05-08 21:06:51","issue cause trampoline pool emission deopt exit table generation deoptimizer expect deopt exit continuous trampoline pool break underline assumption submit cl fix soon
"
2163,346,"https://chromium-review.googlesource.com/c/v8/v8/+/2881918","john-yan",1722371,"2021-05-08 21:38:56","O texto fornecido contém apenas uma URL.  Após a remoção da URL e não havendo outras etapas de pré-processamento a serem realizadas (pois não há palavras para serem padronizadas ou stop words a serem removidas), o texto resultante é:


vazio
"
2164,346,"CL landed on master and waiting for approval to backport https://bugs.chromium.org/p/v8/issues/detail?id=11764, https://chromium-review.googlesource.com/c/v8/v8/+/2886159, https://chromium-review.googlesource.com/c/v8/v8/+/2888088","john-yan",1722371,"2021-05-13 12:24:50","land master wait approval backport
"
2165,346,"thanks, confirm it builds chromium/qtwebengine typescript fine now, I've backported patch to 16.1.0 in gentoo: https://bugs.gentoo.org/785751","gyakovlev",168902,"2021-05-13 15:29:52","build chromium qtwebengine typescript fine backport patch
"
2166,346,"Should be fixed in v16.4.0","targos",2352663,"2021-06-14 13:20:17","fix version 16.4.0
"
2167,347,"This is the invalid `CHECK`: https://github.com/nodejs/node/blob/c975dff3c0f0f1ecb1574f3b10dd1d135a7704db/src/node_messaging.cc#L1068

> Noticed that paste these codes to REPL all at once seems cannot trigger this abort. Run these codes line by line pls.

Fwiw, this is happening because MessagePorts, like all libuv handles, close asynchronously. Wrapping the crashing call in a `setImmediate()` or similar should make this consistently reproducible.

","addaleax",899444,"2021-05-01 16:27:02","invalid check messageport libuv handle close asynchronously wrap crash call setImmediate consistently reproducible
"
2168,348,"/cc @jasnell ","targos",2352663,"2021-04-26 13:40:53","jasnell retornar
"
2169,348,"PR incoming","jasnell",439929,"2021-04-26 13:43:20","PR
"
2170,348,"Fix in https://github.com/nodejs/node/pull/38414 ...

Btw, the `PerformanceObserver` implementation in 16.0 was updated to match the current version of the spec.

```
obs.observe({ entryTypes: ['gc'], buffered: false });
```

Would now be

```
obs.observe({ type: 'gc' });
```

And the `buffered` option is now a non-op","jasnell",439929,"2021-04-26 13:54:48","fix implementation match current version spec observe entrytype gc buffered option non op
"
2171,348,"Hi @jasnell, do you mind clarifying whether `entryTypes` is likely to be deprecated or removed?

The [v16 documentation still mentions `entryTypes`](https://nodejs.org/docs/latest-v16.x/api/perf_hooks.html#perf_hooks_performanceobserver_observe_options). I understand that these are synonymous and either should be valid, where a single `type` may be provided or a list of `entryTypes`:

```js
obs.observe({ type: 'gc' });          // Observe a single type
obs.observe({ entryTypes: ['gc'] });  // Observe one or more types
```

The former is Node >= 16, while the latter is supported by earlier versions. For a library that wants to support multiple versions, it's simpler to use `entryTypes`.

I looked ad [MDN](https://developer.mozilla.org/en-US/docs/Web/API/PerformanceObserver/observe#parameters) and [this spec](https://w3c.github.io/performance-timeline/#dom-performanceobserver-observe), both of them mention either `types` or `entryTypes` (not both!) are valid observe options.

Thanks!","sirreal",841763,"2021-05-14 09:42:20","mind clarify entrytype likely deprecate remove v16 documentation mention entrytype understand synonymous valid single type may provide list entrytype observe single type observe one type node version earlier version library want support multiple version simpler use entrytype look mdn spec mention type entrytype valid observe option thanks
"
2172,349,"It seems brotli does not has `BrotliEncoderOperation` with `4`:

```cpp
/** Operations that can be performed by streaming encoder. */
typedef enum BrotliEncoderOperation {
  /**
   * Process input.
   *
   * Encoder may postpone producing output, until it has processed enough input.
   */
  BROTLI_OPERATION_PROCESS = 0,
  /**
   * Produce output for all processed input.
   *
   * Actual flush is performed when input stream is depleted and there is enough
   * space in output stream. This means that client should repeat
   * ::BROTLI_OPERATION_FLUSH operation until @p available_in becomes @c 0, and
   * ::BrotliEncoderHasMoreOutput returns ::BROTLI_FALSE. If output is acquired
   * via ::BrotliEncoderTakeOutput, then operation should be repeated after
   * output buffer is drained.
   *
   * @warning Until flush is complete, client @b SHOULD @b NOT swap,
   *          reduce or extend input stream.
   *
   * When flush is complete, output data will be sufficient for decoder to
   * reproduce all the given input.
   */
  BROTLI_OPERATION_FLUSH = 1,
  /**
   * Finalize the stream.
   *
   * Actual finalization is performed when input stream is depleted and there is
   * enough space in output stream. This means that client should repeat
   * ::BROTLI_OPERATION_FINISH operation until @p available_in becomes @c 0, and
   * ::BrotliEncoderHasMoreOutput returns ::BROTLI_FALSE. If output is acquired
   * via ::BrotliEncoderTakeOutput, then operation should be repeated after
   * output buffer is drained.
   *
   * @warning Until finalization is complete, client @b SHOULD @b NOT swap,
   *          reduce or extend input stream.
   *
   * Helper function ::BrotliEncoderIsFinished checks if stream is finalized and
   * output fully dumped.
   *
   * Adding more input data to finalized stream is impossible.
   */
  BROTLI_OPERATION_FINISH = 2,
  /**
   * Emit metadata block to stream.
   *
   * Metadata is opaque to Brotli: neither encoder, nor decoder processes this
   * data or relies on it. It may be used to pass some extra information from
   * encoder client to decoder client without interfering with main data stream.
   *
   * @note Encoder may emit empty metadata blocks internally, to pad encoded
   *       stream to byte boundary.
   *
   * @warning Until emitting metadata is complete client @b SHOULD @b NOT swap,
   *          reduce or extend input stream.
   *
   * @warning The whole content of input buffer is considered to be the content
   *          of metadata block. Do @b NOT @e append metadata to input stream,
   *          before it is depleted with other operations.
   *
   * Stream is soft-flushed before metadata block is emitted. Metadata block
   * @b MUST be no longer than than 16MiB.
   */
  BROTLI_OPERATION_EMIT_METADATA = 3
} BrotliEncoderOperation;
```","XadillaX",2842176,"2021-04-26 03:45:44","brotli encoderoperation seem not has brotliencoderoperation process produce output process input flush finalize stream emit metadata
"
2173,351,"refs https://github.com/nodejs/node/issues/38365","XadillaX",2842176,"2021-04-24 02:46:17","node issue
"
2174,351,"Related: https://github.com/nodejs/node/issues/37874#issuecomment-805325115","aduh95",14309773,"2021-04-24 07:53:27","node issue
"
2175,351,"Closing this as a duplicate of #37874.","jasnell",439929,"2021-04-27 14:38:13","close duplicate
"
2176,352,"I'll take a look","Linkgoron",763605,"2021-04-22 20:22:59","look
"
2177,354,"It seems to be REPL only, the process doesn't crash when executing a file or using eval.

```console
$ node -e 'clearImmediate({hasRef: true, _onImmediate: 100000000000000000})'
internal/timers.js:278
    item._idleNext._idlePrev = item._idlePrev;
                             ^

TypeError: Cannot set property '_idlePrev' of undefined
    at ImmediateList.remove (internal/timers.js:278:30)
    at clearImmediate (timers.js:324:18)
    at [eval]:1:1
    at Script.runInThisContext (vm.js:133:18)
    at Object.runInThisContext (vm.js:310:38)
    at internal/process/execution.js:77:19
    at [eval]-wrapper:6:22
    at evalScript (internal/process/execution.js:76:60)
    at internal/main/eval_string.js:23:3
```

I'm able to reproduce the crash on master branch when executing the given instruction on REPL.","aduh95",14309773,"2021-03-19 09:34:08","crash execute file repl master branch instruction repl typeerror set property undefined
"
2178,357,"Interestingly, if I wrap the subprocess.send() (still inside on('spawn')) in a setTimeout with _at least_ a 29 millisecond delay, it almost always works (~80–90% success rate).

The setTimeout trick outside on('spawn') works but needs a much larger number, like 3 seconds.","JakobJingleheimer",3012099,"2021-03-17 18:13:23","interest wrap subprocess send settimeout least millisecond delay work success rate settimeout trick outside need large number second
"
2179,357,"This looks like a race condition where children `.mjs` take a bit longer to start, and the spawn is called ""too early"".

Look at the following change and console logs:

parent.mjs:
```js
import { fork } from 'child_process';

const subprocess = fork('./tst/child.mjs');
subprocess.on('message', (...args) => { console.log('[PARENT] received', ...args) });
subprocess.on('spawn', () => {
  console.log('spawn was called');
  console.log({
    'parent::subprocess.send': subprocess.send({ hello: 'child' })
  });
});
```

child.mjs:
```js
console.log('pre-message-handler');
process.on('message', (...args) => { console.log('[CHILD] received', ...args) });

process.send({ hello: 'parent' });
```

It prints:
```
spawn was called
{ 'parent::subprocess.send': true }
pre-message-handler
[PARENT] received { hello: 'parent' } undefined
```

The parent sends the message before the child adds the message handler.","Linkgoron",763605,"2021-03-17 18:46:38","race condition child start long spawn call early change console log parent send message child add message handler
"
2180,357,"Yep, that's what I surmised.

The docs for [`Event: 'spawn'`](https://nodejs.org/api/child_process.html#child_process_event_spawn) say:
> the 'spawn' event is emitted once the child process has spawned successfully.

It would appear the doc is either incorrect or (more likely) it's a bug.","JakobJingleheimer",3012099,"2021-03-17 18:53:34","yep surmise doc event spawn say event emit child process spawn successfully appear doc incorrect bug
"
2181,357,"As a workaround, I set up a handshake wherein the child immediately sends a ""READY"" message to its parent, resolving a promise in the parent:

parent.mjs

```js
const settleReadyState = {};

const subprocess = fork('./child.mjs');

subprocess.ready = new Promise((resolve, reject) => Object.assign(settleReadyState, { resolve, reject }));

subprocess.once('message', () => {
  settleReadyState.resolve();
  subprocess.on('message', console.log);
});

subprocess.ready.then(() => subprocess.send({ hello: 'child' });
});
```

child.mjs

```js
process.on('message', console.log);

process.send('READY');
process.send({ hello: 'parent' });
```","JakobJingleheimer",3012099,"2021-03-17 18:54:50","workaround set handshake child immediately send ready message parent resolve promise parent subprocess ready promise resolve reject subprocess message resolve subprocess message subprocess ready send hello child process message process send ready process send hello parent
"
2182,357,"What is interesting is that I found out that it only reproduces, if the child script's extension is `.mjs`, even if ```import { fork } from 'child_process';``` is used in the parent script. Probably ESM is a bit slower at Node startup and revealed a race condition elsewhere, only in the child itself.

child.js: 

```
nikolayshamberg@m1001 /tmp % node ./parent.mjs
{ 'parent::subprocess.send': true }
[PARENT] received { hello: 'parent' } undefined
[CHILD] received { hello: 'child' } undefined
```

child.Mjs: 

```
nikolayshamberg@m1001 /tmp % node ./parent.mjs
{ 'parent::subprocess.send': true }
[PARENT] received { hello: 'parent' } undefined
```

What is even weirder is that `subprocess.connected` is always true, unless disconnect was called. From documentation:
> The subprocess.connected property indicates whether it is still possible to send and receive messages from a child process. When subprocess.connected is false, it is no longer possible to send or receive messages.

Obviously, `true` by default... Is just not true in our case ;)

Otherwise, if `subprocess.connected` was meaningful, we could just check in JS whether the child is already available to interact with. Perhaps `subprocess.connected` should be set to `true` only after the [check akin to that of @JakobJingleheimer's is done first](https://github.com/nodejs/node/issues/37782#issuecomment-801330314)? I think that would be an elegant solution and we wouldn't need to deal with ESM issue

","schamberg97",50446906,"2021-03-18 09:39:36","interesting find reproduce child script extension mjs import fork child process use parent script probably esm bit slow node startup reveal race condition child child js parent mjs parent subprocess send parent receive hello parent child receive hello child weird subprocess connect always true unless disconnect call documentation subprocess connect property indicate still possible send receive message child process subprocess connect false longer possible send receive message obviously true default true case otherwise subprocess connect meaningful check js child already available interact perhaps subprocess connect set true check akin jakobjingleheimer done think elegant solution need deal esm issue
"
2183,357,"I wonder if it's because ESM loader is always async?

**Update**: The handshake workaround  above seems to be working pretty well so far, and is backwards compatible (since the `spawn` event was added in 15.1, but child_process has existed since well before then).

I'd be happy to add it to the docs.","JakobJingleheimer",3012099,"2021-03-18 13:40:04","wonder esm loader async handshake workaround work backward compatible spawn event add doc
"
2184,357,"Yes and yes

I would guess `subprocess.connected` is also a bug—possibly with the same cause?

But the 'spawn' event is  still pretty necessary (otherwise, without the handshake workaround, we'd have to poll `subprocess.connected` til it switches to `true` 😱).

I think `subprocess.send()` returning `true` here is also a bug. If not a bug, I can't think of a use-case for it (as-is, it seems like a lie).","JakobJingleheimer",3012099,"2021-03-18 13:57:41","yes bug cause spawn event necessary handshake workaround poll true bug use case lie
"
2185,357,"I disagree, because the `connected` property and `spawn` event are not Node `cp` specific.  If there's an issue here, and I'm not 100% sure that there is one (except maybe better `spawn` documentation), it's (IMO) in the Node child-process that should probably be able to receive the messages that were sent before a listener could be added, and not in the parent.","Linkgoron",763605,"2021-03-18 14:06:36","disagree connected property spawn event node cp specific issue sure better spawn documentation node child process able receive message sent listener add parent
"
2226,362,"PR: https://github.com/nodejs/node/pull/37480","jasnell",439929,"2021-02-22 20:05:59","PR
"
2186,357,"If the `spawn` event is not specific to child_process, do the others maybe also suffer this problem?

IMHO, the `spawn` event etc should have the same behaviour for both commonjs and esm.","JakobJingleheimer",3012099,"2021-03-18 14:10:54","spawn event specific child process suffer problem spawn event behaviour commonjs esm
"
2187,357,"> I think `subprocess.send()` returning `true` here is also a bug. If not a bug, I can't think of a use-case for it (as-is, it seems like a lie).

As far as I understand documentation, it only shows, whether comm channel was terminated or not. If channel is terminated, it becomes `false`. It will always show `true`, even before IPC is established in the first case.
","schamberg97",50446906,"2021-03-18 14:59:46","think subprocess send return true bug bug think use case seem lie understand documentation show comm channel terminate channel terminate become false always show true ipc establish case
"
2188,357,"> I disagree, because the `connected` property and `spawn` event are not Node `cp` specific. If there's an issue here, and I'm not 100% sure that there is one (except maybe better `spawn` documentation), it's (IMO) in the Node child-process that should probably be able to receive the messages that were sent before a listener could be added, and not in the parent.

I think it's impossible to listen for events retroactively. However, AFAIK `connected` property is specific to only child_process and cluster module (since the latter depends on the former). Otherwise, it is likely I misunderstood you somewhere, @Linkgoron ","schamberg97",50446906,"2021-03-18 15:07:06","disagree connect property spawn event node cp specific issue sure better spawn documentation imo node child process able receive message send listener add parent impossible listen event retroactively afaik connect property specific child process cluster module latter depend former likely misunderstand
"
2189,357,"> > I disagree, because the `connected` property and `spawn` event are not Node `cp` specific. If there's an issue here, and I'm not 100% sure that there is one (except maybe better `spawn` documentation), it's (IMO) in the Node child-process that should probably be able to receive the messages that were sent before a listener could be added, and not in the parent.
> 
> I think it's impossible to listen for events retroactively. However, AFAIK `connected` property is specific to only child_process and cluster module (since the latter depends on the former). Otherwise, it is likely I misunderstood you somewhere, @Linkgoron

I made a mistake thinking that the `connected` property isn't special to a child-process which is a Node process, but reading the documentation more carefully, I'm wrong about that one. So I take back what I've stated previously. The `spawn` event, however, should emit for any type of child-process, and not just Node child-process. 

So, I agree that the connected `true` in the parent seems like a bug, however I still think that the bug is in the child-process, and not the parent itself. I think that the Node process itself, which was already spawned and I assume really is connected to the parent, should buffer the messages until the ""main"" starts (so it can feed the message to a synchronously added listener in the main), but I'm not sure if that's possible or feasible.","Linkgoron",763605,"2021-03-18 16:06:29","disagree connected property spawn event node cp specific issue maybe better spawn documentation node child process receive message listener add parent impossible listen event retroactively afaik connected property specific child process cluster module latter depend former likely misunderstand linkgoron mistake think connected property special child process node process read documentation carefully wrong take back state previously spawn event emit type child process node child process agree connected true parent seem bug think bug child process parent node process spawn assume really connect parent buffer message main feed message synchronously add listener main sure possible feasible
"
2190,357,"@Linkgoron I have been checking the source code in /lib/internal/child_process.js and I also made a mistake, apparently `connected` should only be set to true when IPC is setup. So you are right, it is also a bug and not a feature, as I thought previously. 

I've also been trying different versions of Node.js, the bugs seem to have been present since major 12. Regarding buffering the messages, I agree with your idea, but in a reverse. The messages are getting sent into nowhere, since IPC appears to be unavailable. However, the messages can be potentially buffered in the **_parent_** process ;) But I think it'd be too complicated and not really worth the effort","schamberg97",50446906,"2021-03-18 21:34:51","bug ipc nodejs message parent process connect version major buffer
"
2191,357,"I think I've identified the issue. Recompiling node. Let's hope I return with the good news :D","schamberg97",50446906,"2021-03-18 21:45:06","think identify issue recompile node hope return good news
"
2192,357,"> @Linkgoron I have been checking the source code in /lib/internal/child_process.js and I also made a mistake, apparently `connected` should only be set to true when IPC is setup. So you are right, it is also a bug and not a feature, as I thought previously.
> 
> I've also been trying different versions of Node.js, the bugs seem to have been present since major 12. Regarding buffering the messages, I agree with your idea, but in a reverse. The messages are getting sent into nowhere, since IPC appears to be unavailable. However, the messages can be potentially buffered in the **_parent_** process ;) But I think it'd be too complicated and not really worth the effort

@schamberg97 An `ipc` channel is automatically created when `fork` is called. The message is received by the child process, but is emitted ""too fast"", before the listener is added in `child.mjs`.

I've added `console.log('emitted', process.pid, event, message);` into `  function emit(event, message, handle) {` in `lib/internal/child_process.js` (the function above `handleMessage`).

This is the parent file:

```js
import { fork } from 'child_process';

console.log('parent pid', process.pid)
const subprocess = fork('./child.mjs');
subprocess.on('spawn', () => {
  console.log('spawn was called');
  console.log({
    'parent::subprocess.send': subprocess.send({ hello: 'child' })
  });
});
```

This is the child:
```js
console.log('child pid:', process.pid);
```
this is what was printed:
```
parent pid 93789
spawn was called
{ 'parent::subprocess.send': true }
emitted 93790 message { hello: 'child' }
child pid: 93790
```
","Linkgoron",763605,"2021-03-18 22:21:22","check source code lib internal child process js mistake connected set true ipc setup bug feature try different version node js bug present major buffer message agree idea reverse message get sent nowhere ipc appear unavailable message potentially buffer parent process think complicated worth effort ipc channel automatically create fork call message receive child process emit fast listener add child mjs add console log emitted process pid event message function emit event message handle function handlemessage parent file import fork child process console log parent pid process pid subprocess fork child mjs subprocess spawn console log spawn call console log parent subprocess send subprocess send hello child subprocess spawn console log spawn call console log parent subprocess send subprocess send hello child child console log child pid process pid print parent pid spawn call parent subprocess send true emitted message hello child child pid
"
2193,357,"This problem was solved on #41221 ","ErickWendel",8060102,"2022-03-03 18:32:47","problem solve
"
2194,357,"```
public spawn = (): Promise<void> => {
    return new Promise((resolve, reject) => {
      const cp = spawn(cmd, [], {
        cwd: process.cwd(),
        env: process.env,
        stdio: ['pipe', 'pipe', process.stderr ],        
      });
  
      // Register listeners once the child has spawned
      cp.on('spawn', function () {
        // Resolve promise
        return resolve();
      });

      cp.on('error', (err: Error) => {
        // Reject promise
        return reject(err);
      });
    });
  };
```

I seem to experience this issue too - the 'error' event never fires and my child process seems to spawn succesfully (judging by the output on my console) but the 'spawn' event also never fires. Or maybe it fires before the event handler is registered, but either way - the above code does not work for me.

I've managed to 'fix' this issue with a bit of a hack - With the absence of the 'error' event getting thrown, I'm running a while-loop until `cp.connected` == true after which I return the resolved promise:

```
while (!this._childProcess.connected); return resolve();
```","QNimbus",3206309,"2022-05-23 18:29:03","spawn promise resolve reject child process error event handler register connected  issue work fix hack loop
"
2222,361,"Here's the [Pull Request](https://github.com/nodejs/llhttp/pull/94). Would appreciate a review for it, so that I can merge and release it.","indutny",238531,"2021-03-27 18:41:52","appreciate review merge release
"
2195,357,"This seems to have been fixed in v16.14.0 see:

![screenshot showing that the bug can be reproduced in v16.13.2 but not in v16.14.0](https://github.com/user-attachments/assets/93fa1c7c-f45f-4eab-9c0d-c62597caefc1)

More precisely it got fixed by https://github.com/nodejs/node/pull/41221 (as already noted by @ErickWendel [above](https://github.com/nodejs/node/issues/37782#issuecomment-1058360441))

So I think that this issue can safely be closed","dario-piotrowicz",61631103,"2025-01-25 18:13:53","seem fix v16.14.0 precisely get fix already note issue safely close
"
2196,358,"```zsh
❯ node -v
v15.2.0
❯ cp ~/Downloads/node_https_test.zip .
❯ unzip node_https_test.zip
Archive:  node_https_test.zip
  inflating: cert.conf               
  inflating: cert.pem                
  inflating: https_renew_cert.sh     
  inflating: index.js                
  inflating: key.pem                 
  inflating: run.sh                  
  inflating: server.js               
❯ export NODE_EXTRA_CA_CERTS=""$PWD/cert.pem""
❯ node server.js
^Z
[1]  + 9905 suspended  node server.js
❯ node index.js
^Z
[2]  + 9921 suspended  node index.js
❯ fg %node\ server.js
[1]  - 9905 continued  node server.js
^Z
[1]  + 9905 suspended  node server.js
❯ fg %node\ index.js
[2]  - 9921 continued  node index.js
An error Error: unable to verify the first certificate
    at TLSSocket.onConnectSecure (node:_tls_wrap:1498:34)
    at TLSSocket.emit (node:events:329:20)
    at TLSSocket._finishInit (node:_tls_wrap:933:8)
    at TLSWrap.ssl.onhandshakedone (node:_tls_wrap:707:12) {
  code: 'UNABLE_TO_VERIFY_LEAF_SIGNATURE'
}
```
Can't reproduce. Am I doing something wrong here?","RaisinTen",42526976,"2021-03-15 14:13:30","erro certificado incapaz verificar assinatura folha reproduzir errado
"
2197,358,"Looks fine to me. Just did exactly what you did, reproduces the problem for me. Are you running ubuntu? I also tried it on fedora after you answered and then i get the same error you do.","nils91",7298243,"2021-03-15 15:08:31","look fine reproduce problem run ubuntu try fedora get error
"
2198,358,"Yes, Ubuntu.","RaisinTen",42526976,"2021-03-15 15:14:32","yes ubuntu
"
2199,358,"I´ve set up a repo with an action to reproduce the issue: [https://github.com/nils91/node_https_test](https://github.com/nils91/node_https_test/).
Action output:
```
Run actions/setup-node@v2.1.2
Attempting to download 15.x...
Not found in manifest.  Falling back to download directly from Node
Acquiring 15.11.0 from https://nodejs.org/dist/v15.11.0/node-v15.11.0-linux-x64.tar.gz
Extracting ...
/usr/bin/tar xz --strip 1 --warning=no-unknown-keyword -C /home/runner/work/_temp/b0e5d0e1-53c0-465e-a30d-7fc2e5c30f1e -f /home/runner/work/_temp/49fe5a6a-bbc1-4afa-b53c-46330d65ee3c
Adding to the cache ...
Done
0s
Run uname -a
Linux fv-az189-765 5.4.0-1040-azure 42-Ubuntu SMP Fri Feb 5 15:39:06 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
0s
Run node -v
v15.11.0
5s
Run node server.js &
0s
Run chmod +x ./run.sh
2m 11s
Run ./run.sh

<--- Last few GCs --->

[1730:0x5d04ef0]   106385 ms: Mark-sweep (reduce) 2046.2 (2085.8) -> 2046.1 (2086.3) MB, 2473.3 / 0.0 ms  (average mu = 0.080, current mu = 0.011) allocation failure scavenge might not succeed
[1730:0x5d04ef0]   108843 ms: Mark-sweep (reduce) 2047.1 (2086.3) -> 2047.0 (2087.3) MB, 2427.4 / 0.0 ms  (average mu = 0.047, current mu = 0.013) allocation failure scavenge might not succeed


<--- JS stacktrace --->

FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory
 1: 0xa7f490 node::Abort() [node]
 2: 0x9a5c4d node::FatalError(char const*, char const*) [node]
 3: 0xc6c2ae v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [node]
 4: 0xc6c627 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [node]
 5: 0xe360a5  [node]
 6: 0xe36c4c  [node]
 7: 0xe445db v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node]
 8: 0xe482dc v8::internal::Heap::AllocateRawWithRetryOrFailSlowPath(int, v8::internal::AllocationType, v8::internal::AllocationOrigin, v8::internal::AllocationAlignment) [node]
 9: 0xe0c077 v8::internal::Factory::AllocateRawWithAllocationSite(v8::internal::Handle<v8::internal::Map>, v8::internal::AllocationType, v8::internal::Handle<v8::internal::AllocationSite>) [node]
10: 0xe128b8 v8::internal::Factory::NewJSObjectFromMap(v8::internal::Handle<v8::internal::Map>, v8::internal::AllocationType, v8::internal::Handle<v8::internal::AllocationSite>) [node]
11: 0xe13fa3 v8::internal::Factory::NewJSArrayBuffer(std::shared_ptr<v8::internal::BackingStore>, v8::internal::AllocationType) [node]
12: 0xc96b99 v8::ArrayBuffer::New(v8::Isolate*, std::shared_ptr<v8::BackingStore>) [node]
13: 0xbb79c3 node::crypto::X509ToObject(node::Environment*, x509_st*) [node]
14: 0xbb81e4 node::crypto::GetPeerCert(node::Environment*, std::unique_ptr<ssl_st, node::FunctionDeleter<ssl_st, &SSL_free> > const&, bool, bool) [node]
15: 0xc2b567 node::crypto::TLSWrap::GetPeerCertificate(v8::FunctionCallbackInfo<v8::Value> const&) [node]
16: 0xcd8cbb  [node]
17: 0xcda26c  [node]
18: 0xcda8e6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]
19: 0x14fa219  [node]
./run.sh: line 5:  1730 Aborted                 (core dumped) node index.js
Error: Process completed with exit code 134.
```","nils91",7298243,"2021-03-16 14:11:20","javascript heap memory error nodejs process exit code
"
2200,358,"I might have found a workaround: Removing the line
```
keyUsage = digitalSignature, keyEncipherment
```
from the cert.conf file and regenerating the certificate using the new config allows node to get a connection. However, that might not be applicable to all use-cases, as some applications can be picky about the `keyUsage` configuration.
Edit: `keyUsage`, at least right now, requires `keyCertSign` to be set. See [https://github.com/openssl/openssl/issues/1418](https://github.com/openssl/openssl/issues/1418) for details. For this issue, adding `keyCertSign` to the `keyUsage` works as a workaround.","nils91",7298243,"2021-03-18 11:55:24","workaround remov line keyusage digitalsignature keyencipherment cert conf file regenerat certificat use new config allow node get connection however might appli usecas applic pick keyusage configur edit keyusage requir keycertsign set issu add keycertsign keyusage work workaround
"
2201,358,"I forked your repo [here](https://github.com/RaisinTen/node_https_test) and ran some tests on few other versions. In spite of running the test on `v15.11.0` again, the function called after `X509ToObject` in the stack trace seems to differ:
```console
<--- Last few GCs --->

[1560:0x6003ef0]    85165 ms: Mark-sweep (reduce) 2043.8 (2083.1) -> 2043.4 (2083.8) MB, 1600.2 / 0.0 ms  (+ 0.0 ms in 69 steps since start of marking, biggest step 0.0 ms, walltime since start of marking 1880 ms) (average mu = 0.485, current mu = 0.233) [1560:0x6003ef0]    87646 ms: Mark-sweep (reduce) 2044.4 (2083.8) -> 2044.3 (2084.6) MB, 2454.3 / 0.0 ms  (average mu = 0.255, current mu = 0.011) allocation failure scavenge might not succeed


<--- JS stacktrace --->

FATAL ERROR: MarkCompactCollector: young object promotion failed Allocation failed - JavaScript heap out of memory
 1: 0xa7f490 node::Abort() [node]
 2: 0x9a5c4d node::FatalError(char const*, char const*) [node]
 3: 0xc6c2ae v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [node]
 4: 0xc6c627 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [node]
 5: 0xe360a5  [node]
 6: 0xe65633 v8::internal::EvacuateNewSpaceVisitor::Visit(v8::internal::HeapObject, int) [node]
 7: 0xe721e6 v8::internal::FullEvacuator::RawEvacuatePage(v8::internal::MemoryChunk*, long*) [node]
 8: 0xe5e30f v8::internal::Evacuator::EvacuatePage(v8::internal::MemoryChunk*) [node]
 9: 0xe5e588 v8::internal::PageEvacuationTask::RunInParallel(v8::internal::ItemParallelJob::Task::Runner) [node]
10: 0xe503a9 v8::internal::ItemParallelJob::Run() [node]
11: 0xe74170 void v8::internal::MarkCompactCollectorBase::CreateAndExecuteEvacuationTasks<v8::internal::FullEvacuator, v8::internal::MarkCompactCollector>(v8::internal::MarkCompactCollector*, v8::internal::ItemParallelJob*, v8::internal::MigrationObserver*, long) [node]
12: 0xe749b3 v8::internal::MarkCompactCollector::EvacuatePagesInParallel() [node]
13: 0xe74d75 v8::internal::MarkCompactCollector::Evacuate() [node]
14: 0xe874e1 v8::internal::MarkCompactCollector::CollectGarbage() [node]
15: 0xe433a8 v8::internal::Heap::MarkCompact() [node]
16: 0xe44d38 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node]
17: 0xe482dc v8::internal::Heap::AllocateRawWithRetryOrFailSlowPath(int, v8::internal::AllocationType, v8::internal::AllocationOrigin, v8::internal::AllocationAlignment) [node]
18: 0xe0bf3a v8::internal::Factory::AllocateRaw(int, v8::internal::AllocationType, v8::internal::AllocationAlignment) [node]
19: 0xe05444 v8::internal::FactoryBase<v8::internal::Factory>::AllocateRawWithImmortalMap(int, v8::internal::AllocationType, v8::internal::Map, v8::internal::AllocationAlignment) [node]
20: 0xe07540 v8::internal::FactoryBase<v8::internal::Factory>::NewRawOneByteString(int, v8::internal::AllocationType) [node]
21: 0xe0ddfd v8::internal::Factory::NewStringFromUtf8(v8::internal::Vector<char const> const&, v8::internal::AllocationType) [node]
22: 0xc83882 v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::NewStringType, int) [node]
23: 0xbb774e node::crypto::X509ToObject(node::Environment*, x509_st*) [node]
24: 0xbb81e4 node::crypto::GetPeerCert(node::Environment*, std::unique_ptr<ssl_st, node::FunctionDeleter<ssl_st, &SSL_free> > const&, bool, bool) [node]
25: 0xc2b567 node::crypto::TLSWrap::GetPeerCertificate(v8::FunctionCallbackInfo<v8::Value> const&) [node]
26: 0xcd8cbb  [node]
27: 0xcda26c  [node]
28: 0xcda8e6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]
29: 0x14fa219  [node]
./run.sh: line 5:  1560 Aborted                 (core dumped) node index.js
Error: Process completed with exit code 134.
```","RaisinTen",42526976,"2021-03-18 14:42:18","fork repo run test version test function call stack trace differ mark sweep reduce allocation failure scavenge succeed js stacktrace fatal error markcompactcollector young object promotion fail allocation fail javascript heap memory node abort node fatalerror node util report oomfailure node v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 internal v8 string newfromutf8 node crypto x509toobject node crypto getpeercert node crypto tlswrap getpeercertificate v8 internal builtin handleapicall node process complete exit code
"
2202,358,"https://github.com/RaisinTen/node_https_test/runs/2140664480?check_suite_focus=true says that the crash was introduced in `v15.5.0`, so I think the relevant change lies somewhere in https://github.com/nodejs/node/pull/36597. Since I don't see any change in `src/crypto*`, I can't really tell where the relevant change lies. ¯\\\_(ツ)_/¯","RaisinTen",42526976,"2021-03-18 15:06:47","crash introduce v15.5.0 relevant change lie change src crypto tell relevant change lie
"
2203,358,"cc @nodejs/crypto","RaisinTen",42526976,"2021-03-18 15:18:07","nodejs crypto
"
2204,358,"> https://github.com/RaisinTen/node_https_test/runs/2140664480?check_suite_focus=true says that the crash was introduced in `v15.5.0`, so I think the relevant change lies somewhere in #36597. Since I don't see any change in `src/crypto*`, I can't really tell where the relevant change lies. ¯\_(ツ)_/¯

There, however, was an OpenSSL update in 15.5.0. Perhaps this caused the problem?","schamberg97",50446906,"2021-03-24 11:23:15","crash introduce v15.5.0 relevant change openssl update 15.5.0 problem
"
2205,358,"https://github.com/nodejs/node/issues/37889 contains some background on the OpenSSL change that might be related here, as well as a standalone repro.","addaleax",899444,"2021-03-24 13:28:31","openssl change relate standalone repro
"
2206,358,"Looks like this is the relevant infinite loop: 

https://github.com/nodejs/node/blob/f00c2435922a33f9d866846d0b5d12691b148348/src/crypto/crypto_common.cc#L469

I'm not really familiar enough with the OpenSSL APIs to understand why, though.","addaleax",899444,"2021-03-24 13:50:59","loop relevante api openssl familiar
"
2207,358,"~~According to its [documentation](https://www.openssl.org/docs/manmaster/man3/X509_check_issued.html) `X509_check_issued` checks if 'the keyUsage field (if present) of issuer allows certificate signing'. That method is defined in [here](https://github.com/openssl/openssl/blob/master/crypto/x509/v3_purp.c#L903) and seems to return `X509_V_ERR_KEYUSAGE_NO_CERTSIGN` if no `keyCertSign` is present (what #37889 is about). As far as i can tell after looking through the source for openssl and the snippet @addaleax posted above for a bit there is no branch in the code that stops the loop if that error occurs.~~
Actually it seems to be `X509_V_ERR_UNSPECIFIED`. ","nils91",7298243,"2021-03-25 12:08:48","accord documentation keyusage field issuer allow certificate sign method define return x509 v err keyusage certsign present far tell source openssl snippet branch code stop loop error seem x509 v err unspecified
"
2208,358,"I am not sure if this is relevant, but I've verified the behavior change from OpenSSL 1.1.1g to 1.1.1h. With OpenSSL 1.1.1g the connection `openssl.exe  s_client  -connect 127.0.0.1:4001 -CAfile localhost.cer` fails with the `Verify return code: 21 (unable to verify the first certificate)` error, while it succeeds with OpenSSL 1.1.1h (`Verify return code: 0 (ok)`).","fknx",10907711,"2021-03-29 09:07:38","verify behavior change openssl connection fail verify return code unable verify certificate succeed verify return code ok
"
2209,358,"I can confirm this issue shows up on Mac OS 10.15.7 as well, though it just infinite loops for me (haven't let it run long enough to exhaust available memory, but I see it increasing steadily).

To make matters worse, Let's Encrypt's official recommendation (which I think is correct) includes the exact `keyUsage` extension that triggers this bug: https://letsencrypt.org/docs/certificates-for-localhost/#making-and-trusting-your-own-certificates

thanks for looking into this!","ramosbugs",8505766,"2021-04-20 00:22:58","confirm issue show mac os well infinite loop let run long enough exhaust available memory see increase steadily matter worse let encrypt official recommendation include exact keyusage extension trigger bug thanks look
"
2223,361,"(...and sorry for a very long delay in responding to y'all. Things have been quite busy at my new job)","indutny",238531,"2021-03-27 18:42:19","sorry long delay respond thing busy new job
"
2224,361,"@indutny LGTM","bmeck",234659,"2021-03-30 17:38:09","LGTM
"
2210,358,"> I might have found a workaround: Removing the line
> 
> ```
> keyUsage = digitalSignature, keyEncipherment
> ```
> 
> from the cert.conf file and regenerating the certificate using the new config allows node to get a connection. However, that might not be applicable to all use-cases, as some applications can be picky about the `keyUsage` configuration. Edit: `keyUsage`, at least right now, requires `keyCertSign` to be set. See [openssl/openssl#1418](https://github.com/openssl/openssl/issues/1418) for details. For this issue, adding `keyCertSign` to the `keyUsage` works as a workaround.

I was running into this bug and this comment saved me. With a cert that just had `digitalSignature` and `keyEncipherment`, I could not use tls and node rapidly gobbled up memory until crashing. If I just add certificate signing to the list of usages, the OOM goes away and tls worked. Thank you!","sangaman",3440835,"2022-04-26 00:53:16","keyUsage digitalSignature keyEncipherment cert conf file regenerate certificate node connection application picky keyUsage configuration keyUsage keyCertSign openssl openssl issue keyCertSign keyUsage work workaround bug comment save cert digitalSignature keyEncipherment tls node memory crash certificate sign usage OOM tls thank
"
2211,360,"This might be a good reason to have https://github.com/nodejs/node/pull/36964 in core.

cc: @ronag","lpinca",1443911,"2021-03-10 08:15:32","good reason core
"
2212,360,"Any update or workaround for this?
This is causing a lot of 502 errors when running behind a load balancer and sending requests with very long headers.
`upstream prematurely closed connection while reading response header from upstream`","madmed88",1579388,"2022-08-01 23:02:05","update workaround cause lot 502 error run load balancer send request long header upstream prematurely close connection read response header upstream
"
2213,361,"/cc @indutny @nodejs/http ","jasnell",439929,"2021-03-09 15:30:47","indutny nodejs http
"
2214,361,"I believe this is working as expected. The error message would have been clearer if Node.js used strict mode of llhttp:

    off=71 error code=5 reason=""Data after `Connection: close`""

The spec describes [how to determine the message body length](https://tools.ietf.org/html/rfc7230#section-3.3.3) and there is only one note about `Connection: close` case that `loose` (not strict) mode violates:

    If the final response to the last request on a connection has been
    completely received and there remains additional data to read, a user
    agent MAY discard the remaining data or attempt to determine if that
    data belongs as part of the prior response body, which might be the
    case if the prior message's Content-Length value is incorrect.  A
    client MUST NOT process, cache, or forward such extra data as a
    separate response, since such behavior would be vulnerable to cache
    poisoning.

Which makes me worry that loose mode is implemented this way, but doesn't change the fact that error is expected anyway.","indutny",238531,"2021-03-09 16:15:10","believe work expect error message clear node js use strict mode llhttp spec describe determine message body length note connection close case loose strict mode violate final response last request connection completely receive remain additional data read user agent may discard remain data attempt determine data belong part prior response body might case prior message content length value incorrect client must process cache forward extra data separate response since behavior vulnerable cache poison make worry loose mode implement way change fact error expect anyway
"
2215,361,"@indutny something seems odd here though, if I put a valid response in that location like below, there isn't the same error.

```mjs
import net from 'net';
import http from 'http';
const body = 'HTTP/1.1 200 OK\r\n' +
  'Content-Length: 5\r\n' +
  'Connection: close\r\n' +
  '\r\n' +
  '2ad73HTTP/1.1 200 OK\r\nContent-Length: 0\r\n\r\n'
const server = net.createServer((conn) => conn.end(body));
const port = 9191;
server.listen(port, () => {
  http.get('http://localhost:' + port, (res) => {
    // drain it
    res.on('data', console.log)
    res.on('close', () => server.close());
  }).end();
});
```

This seems problematic given the:

> MUST NOT process, cache, or forward such extra data as a
separate response, since such behavior would be vulnerable to cache
poisoning.

point it does seem to be processing it.","bmeck",234659,"2021-03-09 16:24:33","something seem odd put valid response location isnt error process cache forward extra datum separate response behavior vulnerable cache poison process
"
2216,361,"@bmeck yeah, precisely! I'm thinking about patching this up in llhttp, but it was ported over from http_parser AFAIK so I'm not sure how much servers/clients we'll break...

The reason why this happens is that during the build of llhttp (and http_parser) you have to decide whether to build it in `strict` or `loose` mode. `strict` is rather hardcore, but follows the spec very very closely. `loose` allows certain characters out of the normal range, and overall is more lenient. This leniency includes parsing the second request with `Connection: close`. IMO, this is a bug and I don't mind fixing it if everyone is on the same page about it.","indutny",238531,"2021-03-09 16:30:17","patch llhttp port http_parser server client break reason build llhttp http_parser decide build strict loose strict hardcore spec loose character normal range lenient leniency include parse second request connection close bug mind fix everyone page
"
2217,361,"Is there any reason to error instead of discarding? I would expect not to error in the result and it actually was found due to https://github.com/http-tests/cache-tests being unable to run against node due to the unrecoverable error.","bmeck",234659,"2021-03-09 16:31:34","reason error discard expect error result find unrecoverable error
"
2218,361,"@bmeck yeah, discarding is fine too according to spec. `strict` mode can error, and `loose` can discard. Is this what you are suggesting?","indutny",238531,"2021-03-09 16:32:38","yeah discard fine accord spec strict mode error loose discard suggest
"
2219,361,"@indutny yes, I would prefer discarding since node's http client can actually pass those tests if we do. Also in theory it could be less compute (since we already track the length).","bmeck",234659,"2021-03-09 16:39:02","yes prefer discard node http client pass test theory could less compute track length
"
2220,361,"I agree that discarding would be a good approach.","mcollina",52195,"2021-03-10 09:06:57","agree discard good approach
"
2221,361,"I technically have a patch doing this, but just thought I'd run by you all the tests that no longer pass with discarding of the extra data:

* https://github.com/nodejs/llhttp/blob/242cfd4ebc2b57dd84904cb67b617bf4a6b6fa93/test/request/connection.md#resetting-flags-when-keep-alive-is-off-10-and-parser-is-in-loose-mode
* https://github.com/nodejs/llhttp/blob/242cfd4ebc2b57dd84904cb67b617bf4a6b6fa93/test/request/connection.md#crlf-between-requests-explicit-close-loose-mode
* https://github.com/nodejs/llhttp/blob/242cfd4ebc2b57dd84904cb67b617bf4a6b6fa93/test/response/connection.md#http11-with-keep-alive-disabled-and-204-status-in-loose-mode

It is definitely going to be a major version bump for llhttp, but more importantly I think I have to make it continue work with the lenient flags so that affected users will still have a way of allowing it.","indutny",238531,"2021-03-27 17:25:37","tecnicamente patch teste passar descartar dado major version bump llhttp importante continuar funcionar flag tolerante usuário permitir
"
2225,361,"Fixed in https://github.com/nodejs/llhttp/pull/94 as well as https://github.com/nodejs/node/pull/38146.","mcollina",52195,"2021-04-12 11:06:00","fix
pull
well
"
2227,364,"CI: https://ci.nodejs.org/job/node-test-pull-request/36061/","nodejs-github-bot",18269663,"2021-02-11 19:40:30","CI
"
2228,364,"CI: https://ci.nodejs.org/job/node-test-pull-request/36063/","nodejs-github-bot",18269663,"2021-02-12 08:52:08","CI
"
2229,364,"CI failure seems to be flaking and not related to this PR. Will merge in a few unless otherwise commented","bmeck",234659,"2021-02-12 18:27:48","merge issue flake relate
"
2230,364,"ah, nm needs 1 more collab approval, missed that (will go poking around for one)","bmeck",234659,"2021-02-12 18:47:08","nm need collab approval
"
2231,364,"CI: https://ci.nodejs.org/job/node-test-pull-request/36144/","nodejs-github-bot",18269663,"2021-02-15 17:10:47","CI
"
2232,364,"CI issues seem unrelated, going to merge in a bit","bmeck",234659,"2021-02-15 20:20:43","issue merge
"
2233,364,"~~Landed in fc574dc58380~~","bmeck",234659,"2021-02-15 22:05:52","Landed
"
2234,364,"> Landed in fc574dc58380

Landed in f24e707","Trott",718899,"2021-02-16 05:22:07","land fc574dc58380 land f24e707
"
2235,365,"@legendecas the assumption is that once the environment begins the process of being torn down, no more gc runs will happen. This test AFAICT forces gc runs after `napi_env` teardown, so it is entirely possible that finalizers will be called after `napi_env`'s `FinalizeAll`. TBH the scenario created in the test seems unlikely to happen under normal circumstances. OTOH, it would of course be ideal to handle even unusual circumstances. Nevertheless, please be careful to not re-introduce the problem fixed in c822ba7121b073c7a59a7bab05ba46d6a19eb966!","gabrielschulhof",976081,"2021-02-08 18:04:53","assumption environment begin process tear down gc run happen test force gc run napi env teardown possible finalizer call napi env finalizeall scenario create test seem unlikely normal circumstance otoh ideal handle unusual circumstance nevertheless careful reintroduce problem fix
"
2236,365,"Is this related: https://github.com/nodejs/node/issues/36868?","RaisinTen",42526976,"2021-02-09 09:26:27","relate
"
2237,365,"@gabrielschulhof we just identified the problem in random CI failures on our system. The force GC in the repro is to ensure the reproduce is reliable to show how the problem happens in the case. The crashes do happens in a low rate, but I have to say it's not unlikely to happen: in our internal tests the ratio is roughly 1/6 to crash on exit.","legendecas",8500303,"2021-02-09 17:49:23","identify problem random CI fail system force GC repro ensure reproduce reliable show problem happen case crash happen low rate unlikely happen internal test ratio roughly 1 6 crash exit
"
2238,365,"> Is this related: https://github.com/nodejs/node/issues/36868?

Yes, the crash call stacks seem very similar to the case. I strongly believe it's the same problem.","legendecas",8500303,"2021-02-09 17:51:33","crash call stack similar problem
"
2239,365,"@legendecas I ran the repro and it dies reliably even without `--expose-gc`.","gabrielschulhof",976081,"2021-02-09 21:46:00","repro die reliably expose gc
"
2240,365,"@legendecas
```diff
diff --git a/src/js_native_api_v8.cc b/src/js_native_api_v8.cc
index e037c4297d..22932dc6b9 100644
--- a/src/js_native_api_v8.cc
+++ b/src/js_native_api_v8.cc
@@ -199,7 +199,8 @@ class RefBase : protected Finalizer, RefTracker {
           void* finalize_hint)
        : Finalizer(env, finalize_callback, finalize_data, finalize_hint),
         _refcount(initial_refcount),
-        _delete_self(delete_self) {
+        _delete_self(delete_self),
+        _is_gone(nullptr) {
     Link(finalize_callback == nullptr
         ? &env->reflist
         : &env->finalizing_reflist);
@@ -220,7 +221,10 @@ class RefBase : protected Finalizer, RefTracker {
                        finalize_hint);
   }
 
-  virtual ~RefBase() { Unlink(); }
+  virtual ~RefBase() {
+    if (_is_gone != nullptr) *_is_gone = true;
+    Unlink();
+  }
 
   inline void* Data() {
     return _finalize_data;
@@ -270,10 +274,14 @@ class RefBase : protected Finalizer, RefTracker {
 
  protected:
   inline void Finalize(bool is_env_teardown = false) override {
+    bool reference_is_gone = false;
+    _is_gone = &reference_is_gone;
     if (_finalize_callback != nullptr) {
       _env->CallFinalizer(_finalize_callback, _finalize_data, _finalize_hint);
     }
 
+    if (reference_is_gone) return;
+
     // this is safe because if a request to delete the reference
     // is made in the finalize_callback it will defer deletion
     // to this block and set _delete_self to true
@@ -287,6 +295,7 @@ class RefBase : protected Finalizer, RefTracker {
  private:
   uint32_t _refcount;
   bool _delete_self;
+  bool* _is_gone;
 };
 
 class Reference : public RefBase {
```
seems to avert the problem without breaking the tests.","gabrielschulhof",976081,"2021-02-09 22:49:50","avert problema sem quebra teste
"
2241,365,"@legendecas in your repro you delete `wrapper_` in two places:

1. In the instance data finalizer:
    https://github.com/legendecas/repro-napi-v8impl-refbase-double-free/blob/5b0ae1874b9b26fb0fe453565484a004801c70e4/test.cc#L56
2. In the `napi_wrap` finalizer (which calls `~MyObject`)
    https://github.com/legendecas/repro-napi-v8impl-refbase-double-free/blob/5b0ae1874b9b26fb0fe453565484a004801c70e4/test.cc#L27

So, it looks like the double free is not really caused by anything Node-API does wrong.","gabrielschulhof",976081,"2021-02-10 05:02:20","repro delete wrapper two place instance data finalizer napi wrap finalizer call myobject look double free really cause node api wrong
"
2242,365,"NM. Looks like it crashes even if I remove the `napi_delete_reference` from the instance finalizer.","gabrielschulhof",976081,"2021-02-10 05:07:27","crash remove napi delete reference instance finalizer
"
2243,365,"@legendecas I have been able to reduce the test case to https://github.com/legendecas/repro-napi-v8impl-refbase-double-free/pull/1 while still retaining the crash.","gabrielschulhof",976081,"2021-02-10 05:27:24","reduce test case retain crash
"
2244,365,"I think the key is the `napi_reference_ref` it performs on the reference returned from `napi_wrap`.","gabrielschulhof",976081,"2021-02-10 05:28:09","key napi_reference_ref perform reference return napi_wrap
"
2245,365,"@gabrielschulhof Yeah, you're right. I found I've been mistaken on the repro. In the reproduction, there are strong references to the object, this is not the case I was intended to show in the first place. After reading #37303 and tried the PR on my internal case and it does crash regardlessly, I discovered that my original crash on double free of v8impl::reference is not caused by strong references but weak references. These references were set weak before the process going to exit - there is a uv ref on the corresponding handle so only after the set weak the process is going to exit. I'll double-check the re-production to make a reliable reproduction on weak references.","legendecas",8500303,"2021-02-18 06:34:57","repro mistaken reproduction strong reference case read pr internal case crash regardlessly discover original crash double free v8impl reference cause strong reference weak reference reference set weak process exit uv ref corresponding handle set weak process exit double check reproduction reliable reproduction weak reference
"
2246,365,"The original code causing the crash is built on top of node-addon-api, and there is no `napi_delete_reference` (or `napi_remove_wrap` used directly except from `Napi::~Reference`, which `Napi::ObjectWrap` relies on to remove the wrap (not strictly remove the ""wrap"", but the reference object) on successful construction. So I may take node-addon-api into count for another reliable repro.","legendecas",8500303,"2021-02-18 06:39:21","code crash build node addon api napi delete reference napi remove wrap use napi objectwrap rely remove wrap reference object successful construction may take node addon api count reliable repro
"
2247,365,"https://github.com/legendecas/repro-napi-v8impl-refbase-double-free/blob/master/node_addon_api.cc I crafted a mimic of GC on weak references after addon env teardown. The original environment is running in nyc augmented, there are lots of test cases in the case. So I'm assuming there is a chance that gc may be triggered at the time of clean-up (dumping coverage data to disk). Anyway, the crafted reproduction is a quite valid case of node-addon-api/node-api, I suppose the problem is still valid in the case.

(SideNote: the new case has been ran with the latest main branch with the fix of #37303, it does crash)

@gabrielschulhof ","legendecas",8500303,"2021-02-19 11:42:42","mimic gc weak refer addon env teardown original environment run nyc augment lot test case assume chance gc trigger time clean up dump coverage data disk craft reproduction valid case node addon api node api problem valid case new case run latest main branch fix crash
"
2248,365,"@legendecas this is the crash I was able to reproduce:

```
#0  0x00007ffff7a8de35 in raise () from /lib64/libc.so.6
#1  0x00007ffff7a78895 in abort () from /lib64/libc.so.6
#2  0x00000000010af676 in node::Abort () at ../src/node_errors.cc:254
#3  0x00000000010b04b3 in node::OnFatalError (location=0x7fffffffd150 ""Error::Error"", message=0x5e6a620 ""napi_create_reference"") at ../src/node_errors.cc:441
#4  0x00000000010b035e in node::FatalError (location=0x7fffffffd150 ""Error::Error"", message=0x5e6a620 ""napi_create_reference"") at ../src/node_errors.cc:415
#5  0x000000000105bda1 in napi_fatal_error (location=0x7ffff7fc00cb ""Error::Error"", location_len=18446744073709551615, message=0x7ffff7fc00b5 ""napi_create_reference"", 
    message_len=18446744073709551615) at ../src/node_api.cc:749
#6  0x00007ffff7fbda44 in Napi::Error::Fatal (location=0x7ffff7fc00cb ""Error::Error"", message=0x7ffff7fc00b5 ""napi_create_reference"")
    at /home/nix/repro-napi-v8impl-refbase-double-free/node_modules/node-addon-api/napi-inl.h:2305
#7  0x00007ffff7fbdaf0 in Napi::Error::Error (this=0x7fffffffd270, env=0x5ed4ef0, value=0x5e5b0d8)
    at /home/nix/repro-napi-v8impl-refbase-double-free/node_modules/node-addon-api/napi-inl.h:2317
#8  0x00007ffff7fbd9b4 in Napi::Error::New (env=0x5ed4ef0) at /home/nix/repro-napi-v8impl-refbase-double-free/node_modules/node-addon-api/napi-inl.h:2293
#9  0x00007ffff7fbd79b in Napi::Function::Call (this=0x7fffffffd390, recv=0x5deaf28, argc=0, args=0x0)
    at /home/nix/repro-napi-v8impl-refbase-double-free/node_modules/node-addon-api/napi-inl.h:2045
#10 0x00007ffff7fbd6bc in Napi::Function::Call (this=0x7fffffffd390, recv=0x5deaf28, args=...) at /home/nix/repro-napi-v8impl-refbase-double-free/node_modules/node-addon-api/napi-inl.h:2034
#11 0x00007ffff7fbd674 in Napi::Function::Call (this=0x7fffffffd390, args=...) at /home/nix/repro-napi-v8impl-refbase-double-free/node_modules/node-addon-api/napi-inl.h:2022
#12 0x00007ffff7fbae44 in (anonymous namespace)::MyObject::Finalize (this=0x5ed5630, env=...) at ../node_addon_api.cc:42
#13 0x00007ffff7fbb882 in Napi::ObjectWrap<(anonymous namespace)::MyObject>::FinalizeCallback (env=0x5ed4ef0, data=0x5ed5630)
    at /home/nix/repro-napi-v8impl-refbase-double-free/node_modules/node-addon-api/napi-inl.h:4021
#14 0x000000000105feeb in napi_env__::CallFinalizer(void (*)(napi_env__*, void*, void*), void*, void*)::{lambda(napi_env__*)#1}::operator()(napi_env__*) const (__closure=0x7fffffffd4f0, 
    env=0x5ed4ef0) at ../src/js_native_api_v8.h:107
#15 0x000000000106082d in napi_env__::CallIntoModule<napi_env__::CallFinalizer(void (*)(napi_env__*, void*, void*), void*, void*)::{lambda(napi_env__*)#1}, void (napi_env__*, v8::Local<napi_env__::CallFinalizer(void (*)(napi_env__*, void*, void*), void*, void*)::{lambda(napi_env__*)#1}::Value>)>(napi_env__::CallFinalizer(void (*)(napi_env__*, void*, void*), void*, void*)::{lambda(napi_env__*)#1}&&, void (&&)(napi_env__*, v8::Local<napi_env__::CallFinalizer(void (*)(napi_env__*, void*, void*), void*, void*)::{lambda(napi_env__*)#1}::Value>)) (this=0x5ed4ef0, 
    call=..., handle_exception=@0x10412d6: {void (napi_env__ *, v8::Local<v8::Value>)} 0x10412d6 <napi_env__::HandleThrow(napi_env__*, v8::Local<v8::Value>)>)
    at ../src/js_native_api_v8.h:95
#16 0x000000000105ff4d in napi_env__::CallFinalizer (this=0x5ed4ef0, cb=0x7ffff7fbb80e <Napi::ObjectWrap<(anonymous namespace)::MyObject>::FinalizeCallback(napi_env, void*, void*)>, 
    data=0x5ed5630, hint=0x0) at ../src/js_native_api_v8.h:106
#17 0x0000000001033641 in v8impl::(anonymous namespace)::RefBase::Finalize (this=0x5e7d0d0, is_env_teardown=true) at ../src/js_native_api_v8.cc:281
#18 0x000000000105fcd8 in v8impl::RefTracker::FinalizeAll (list=0x5ed4f28) at ../src/js_native_api_v8.h:43
#19 0x000000000105fdfc in napi_env__::~napi_env__ (this=0x5ed4ef0, __in_chrg=<optimized out>) at ../src/js_native_api_v8.h:66
#20 0x00000000010637ca in node_napi_env__::~node_napi_env__ (this=0x5ed4ef0, __in_chrg=<optimized out>) at ../src/node_api.cc:17
#21 0x00000000010637e6 in node_napi_env__::~node_napi_env__ (this=0x5ed4ef0, __in_chrg=<optimized out>) at ../src/node_api.cc:17
#22 0x00000000010412d3 in napi_env__::Unref (this=0x5ed4ef0) at ../src/js_native_api_v8.h:77
#23 0x0000000001059f94 in v8impl::(anonymous namespace)::<lambda(void*)>::operator()(void *) const (__closure=0x0, arg=0x5ed4ef0) at ../src/node_api.cc:109
#24 0x0000000001059fb4 in v8impl::(anonymous namespace)::<lambda(void*)>::_FUN(void *) () at ../src/node_api.cc:110
#25 0x0000000000ff5309 in node::Environment::RunCleanup (this=0x5ec07d0) at ../src/env.cc:677
#26 0x0000000000f80471 in node::FreeEnvironment (env=0x5ec07d0) at ../src/api/environment.cc:371
#27 0x0000000000f7c626 in node::FunctionDeleter<node::Environment, &node::FreeEnvironment>::operator() (this=0x7fffffffda30, pointer=0x5ec07d0) at ../src/util.h:636
#28 0x0000000000f7bff8 in std::unique_ptr<node::Environment, node::FunctionDeleter<node::Environment, &node::FreeEnvironment> >::~unique_ptr (this=0x7fffffffda30, __in_chrg=<optimized out>)
    at /usr/include/c++/9/bits/unique_ptr.h:292
#29 0x000000000111c2db in node::NodeMainInstance::Run (this=0x7fffffffdad0, env_info=0x5d6f740 <node::env_info>) at ../src/node_main_instance.cc:135
#30 0x000000000105450e in node::Start (argc=3, argv=0x7fffffffdd38) at ../src/node.cc:1079
#31 0x0000000002930b72 in main (argc=3, argv=0x7fffffffdd38) at ../src/node_main.cc:127
```

This crashes at https://github.com/legendecas/repro-napi-v8impl-refbase-double-free/blob/master/node_addon_api.cc#L42 because one cannot call a JS function during environment teardown. It ultimately results in a fatal error, because one cannot throw exceptions in environment teardown either. We really need to distinguish between `napi_pending_exception` and `napi_cannot_call_into_js`, but we've deemed that to be [semver-major](https://github.com/nodejs/node/issues/30327).

@mhdawson we may want to reconsider the semverity of `napi_cannot_call_into_js` because we're seeing more and more cases where things are resulting in a fatal error because of attempts to call into JS during teardown.","gabrielschulhof",976081,"2021-02-19 18:06:39","crash reproduce call js function environment teardown result fatal error distinguish napi pending exception napi cannot call into js semver major reconsider semverity napi cannot call into js see case thing result fatal error attempt call js teardown
"
2249,365,"@mhdawson in support of that, if we were to all of a sudden return `napi_cannot_call_into_js` instead of `napi_pending_exception` yes, we may break some folks who handle the case of `napi_pending_exception`, but I suspect most folks will just crash with the above stack because they do not handle any off-nominal case.","gabrielschulhof",976081,"2021-02-19 18:13:05","support return napi_cannot_call_into_js instead napi_pending_exception yes break folk handle case napi_pending_exception suspect folk crash stack handle off nominal case
"
2250,365,"@legendecas I forgot to mention that I got the above stack with 03806a0bb2f3336bcbf3a668e156993cc2582c71 (IOW with https://github.com/nodejs/node/pull/37303 already landed).","gabrielschulhof",976081,"2021-02-19 18:14:06","forgot mention get stack iow land
"
2251,365,"@gabrielschulhof I tried on a fresh build of main branch, it looks like there is a significant difference between v14.x with 03806a0 cherry-picked and the main branch results. 

On v14.x with 03806a0 cherry-picked, the test case does crash on v8impl::RefBase. However, I believe the initial thought is that there are chances that GC may run on the env teardown (not sure on main branch since it disallow javascript execution on env teardown) and get into race conditions as https://github.com/nodejs/node/blob/master/src/js_native_api_v8.cc#L232 suggests.","legendecas",8500303,"2021-02-20 03:18:36","tent fresh build main branch look significant difference v14 x 03806a0 cherry pick main branch result v14 x 03806a0 cherry pick test case crash v8impl refbase believe initial thought chance gc may run env teardown sure main branch disallow javascript execution env teardown get race condition suggest
"
2252,365,"@legendecas it sounds like the problem is fixed on the main branch but not on v14.x, right? I will try to repro with v14.x + 03806a0 when I get a chance. It sounds like the backport will be non-trivial.","gabrielschulhof",976081,"2021-02-21 19:20:44","problem fix main branch v14 x repro v14 x backport non trivial
"
2253,365,"@gabrielschulhof on main branch calling into js on tear down will get an exception from v8 that we can not call into js at that time. So this reproduction does not work out - which relies on trigger GC by calling global.gc in js. And the exception thrown by v8 is a string, that will crash node-addon-api for https://github.com/nodejs/node-addon-api/issues/912 (the crash above https://github.com/nodejs/node/issues/37236#issuecomment-782243216)

So I tried to backport 03806a0 on v14.x locally and it did crash on v8impl::reference as expected.","legendecas",8500303,"2021-02-22 00:47:16","reproduction work rely trigger gc call global exception throw v8 string crash node addon api crash backport v14 crash v8impl reference expect
"
2254,365,"Has the patch for this issue been merged into Node.js 12.x?

I'm getting a `segmentation fault` error in Node.js 12, is it related to this issue? See https://github.com/yisibl/svg-sprite/pull/3","yisibl",2784308,"2022-03-17 09:57:24","patch issue merge node.js 12 segmentation fault error node.js 12 relate issue
"
2255,366,"Let me work on this.","juanarbol",17013303,"2021-01-29 18:19:00","work
"
2256,367,"This runs correctly in `v15.2.0`:
```zsh
❯ node test.js
<ref *1> B {
  A: A { B: [Circular *1], [b]: [Getter: undefined] },
  [a]: [Getter: undefined]
}
```","RaisinTen",42526976,"2021-01-25 14:04:33","run correctly v15.2 node test js b a getter undefined


**Explicação das etapas:**

1. **Remoção de ruídos:**  A tag de código ````zsh`, a URL implícita `<ref *1>`, os caracteres especiais `*`, `{}`, `[]`, `:` e `.` foram removidos.  `[Circular *1]` e `[Getter: undefined]` foram considerados ruídos contextuais que não contribuem para a classificação e foram substituídos por ""getter undefined"".


2. **Padronização de palavras:**  ""runs"" foi reduzido para ""run"" (remoção da conjugação).  ""B"" foi mantido, pois em um contexto de issue pode ser significativo (nome de uma classe, variável, etc.).


3. **Remoção de stop words:** Palavras como ""in"" e ""the"" foram removidas.  ""A"" foi mantido, pois, similarmente a ""B"", pode ser significativo em um contexto técnico.

O resultado final é uma sequência de palavras-chave que representam o cerne da issue, ideal para posterior processamento em um classificador.  Note que a decisão de manter ou remover algumas palavras (ex: A, B) depende do contexto e do domínio da classificação.  Se o classificador for treinado com dados que usam estas palavras como features,  devem ser mantidas.  Se o foco for outro, podem ser removidas.
"
2257,367,"> This runs correctly in `v15.2.0`:

Can confirm, just tested myself on 15.2 and it worked correctly. Issue happens on 15.3+

","timotejroiko",33236065,"2021-01-25 15:51:43","run correctly v15.2 issue happen v15.3
"
2258,367,"Probably introduced by https://github.com/nodejs/node/pull/36052
","targos",2352663,"2021-01-25 15:52:14","introduce
"
2259,367,"I got a fix locally and I'll submit the PR later on.

```
> console.log(result);
<ref *1> B {
  A: A { B: [Circular *1], [b]: [Getter] [Circular *1] },
  [a]: [Getter] A { B: [Circular *1], [b]: [Getter] [Circular *1] }
}
```","BridgeAR",8822573,"2021-01-26 15:05:39","fix submit pr
"
2260,368,"Any progress on this? Did someone manage to reproduce it? :)","Chaphasilor",18015147,"2021-03-04 21:05:19","progress reproduce
"
2261,368,"I could reproduce this but I'm not sure whether the server response is okay.
Did you go through the similar issues: https://github.com/nodejs/node/issues?q=is%3Aissue+http+parse+error+HPE_INVALID_CONSTANT+is%3Aclosed?
cc @nodejs/http-parser Some help please?","RaisinTen",42526976,"2021-03-05 13:14:09","reproduce sure server response okay go similar issue help
"
2262,368,"I did look at the other issues, but it seemed to me like those were unrelated.

I'm also not sure if the server's response is 100% spec-conform, but since Node handles it without hiccup on all other platforms, and other tools even handle it on this platform, I think this should be fixed.

This issue isn't uncommon either, I've encountered it with a lot of different servers as well :)","Chaphasilor",18015147,"2021-03-05 14:33:07","look issue seem unrelated sure server response spec conform node handle hiccup platform tool handle platform think fix issue uncommon encounter server
"
2263,368,"cc @mscdex @lpinca
Could you please take a look at this issue?","RaisinTen",42526976,"2021-03-11 13:53:14","look issue
"
2264,368,"Can you reproduce the issue on Node.js 12? And if so, is the error still raised with the `--http-parser` CLI option set to `legacy`?","lpinca",1443911,"2021-03-11 14:32:14","reproduce issue node js 12 error raise http parser cli option legacy
"
2265,368,"> Can you reproduce the issue on Node.js 12? And if so, is the error still raised with the `--http-parser` CLI option set to `legacy`?

@lpinca I can reproduce it with Node.js 12.21.0, yes.  
However, the error is not raised using `node --http-parser=legacy test.js` (with Node 12).  

I tried to use the flag with Node 14 as well, but from the [documentation](https://nodejs.org/docs/latest-v14.x/api/cli.html) it looks like it isn't fully supported anymore:  

The Node.js 14 and 15 docs list `--http-parser`, while the Node.js 12 docs list `--http-parser=library`, along with [some more documentation](https://nodejs.org/docs/latest-v12.x/api/cli.html#cli_http_parser_library).","Chaphasilor",18015147,"2021-03-12 08:50:16","reproduce issue node js 12 error raise http parser cli option legacy reproduce node js error raise node http parser legacy flag node documentation support node js doc list http parser node js doc list http parser library documentation
"
2266,368,"Yes the legacy http parser has been removed in Node.js 13 in favor of llhttp.

cc: @indutny ","lpinca",1443911,"2021-03-12 09:29:59","legacy parser remove node favor llhttp
"
2267,368,"So should I open an issue in NodeJS/llhttp?

Or is this still the right place for it? 🤔 ","Chaphasilor",18015147,"2021-03-12 11:07:00","open issue nodejs llhttp right place
"
2268,368,"> Or is this still the right place for it?

I think it is ok.

The strange thing is that the error is not raised on x64 when using the llhttp parser. ","lpinca",1443911,"2021-03-12 11:17:13","right place error raise x64 use llhttp parser
"
2269,368,"> I think it is ok.

Nice.

> The strange thing is that the error is not raised on x64 when using the llhttp parser. 

Just to be clear, I'd prefer if the error wouldn't be raised on armv7 either, instead of on armv7 *and* x64 :P 

Is there anything I could do to help fix/debug this? :)
","Chaphasilor",18015147,"2021-03-12 14:04:37","think ok strange thing error raise x64 use llhttp parser prefer error raise armv7 armv7 x64 help fix debug
"
2270,368,"@lpinca @Chaphasilor im running into the same issue, also only on armv7, not on x64
are there any news / fixes? did you opened an issue in nodejs/llhttp ?","simonhbw",51776776,"2021-04-27 10:49:42","run issue armv7 x64 news fix open issue nodejs llhttp
"
2271,368,"@simonhbw I didn't open another issue as I was told it belonged here :)

I'll try to provide a more reliable example for reproducing the issue, that doesn't rely on an external server. Hopefully this will help people fix the issue...","Chaphasilor",18015147,"2021-04-27 10:52:41","try provide reliable example reproduce issue rely external server hopefully help people fix issue
"
2272,368,"@simonhbw @Chaphasilor  feel free to open a new issue on nodejs/llhttp.","lpinca",1443911,"2021-04-27 11:11:43","open issue nodejs llhttp
"
2273,368,"Should be fixed by https://github.com/nodejs/llparse/pull/44 .","indutny",238531,"2021-05-12 06:32:41","fix
"
2274,368,"Here's the PR for Node: https://github.com/nodejs/node/pull/38665","indutny",238531,"2021-05-13 02:53:06","PR Node
"
2275,368,"@indutny just wanted to let you know that your commit went live in Node.js 16.3.0 today and so far it seems to be working! :D
Thanks a ton, once again!
  
Waiting for it to arrive in Node 14 because that's what I'm mostly using right now and also because the `HPE_INVALID_CONSTANT` error only appears there (probably some API change from 14 to 16 that my test code isn't yet adapted to).  
Will report back after I tested it with Node 14 <3 ","Chaphasilor",18015147,"2021-06-03 21:36:55","commit ir vivo node erro aparecer teste adaptar relatar
"
2276,369,"[`onSocketNT()`](https://github.com/nodejs/node/blob/v15.5.1/lib/_http_client.js#L813-L822) is called before the `'error'` event is emitted but there are no listeners. The listener is added by [`tickOnSocket()`](https://github.com/nodejs/node/blob/v15.5.1/lib/_http_client.js#L820).

cc: @nodejs/http ","lpinca",1443911,"2021-01-14 20:09:53","onSocketNT chamar antes erro evento emitir listener adicionar tickOnSocket
"
2277,369,"https://github.com/nodejs/node/blob/v15.5.1/lib/_http_client.js#L808-L809","ronag",3065230,"2021-01-14 20:58:00","client js
"
2278,369,"@ronag it's not that. The error is emitted after `onSocketNT()` is called. Adding an `'error'` listener here https://github.com/nodejs/node/blob/v15.5.1/lib/_http_client.js#L814-L819 would be sufficient.","lpinca",1443911,"2021-01-15 05:59:48","error emit call add listener sufficient
"
2279,369,"Might have been solved with https://github.com/nodejs/node/pull/36863","ronag",3065230,"2021-01-16 16:08:12","solve
"
2280,369,"Needs a regression test either way.","ronag",3065230,"2021-01-16 16:15:19","regression test
"
2281,369,"https://github.com/nodejs/node/pull/36863 fixes this only if no agent is used. It does not fix the example in the issue description.","lpinca",1443911,"2021-01-16 16:43:17","fix agent us example issu description
"
2282,370,"I can reproduce. I'm preparing a debug build to get a better stack trace.","targos",2352663,"2021-01-08 11:15:12","reproduce prepare debug build get good stack trace
"
2283,370,"```
1: 0xfc5a3d node::DumpBacktrace(_IO_FILE*) [./node_g]
 2: 0x115491d  [./node_g]
 3: 0x115493d  [./node_g]
 4: 0x2b90c87 V8_Fatal(char const*, int, char const*, ...) [./node_g]
 5: 0x2b90cb3  [./node_g]
 6: 0x14df494 v8::internal::Debug::StopSideEffectCheckMode() [./node_g]
 7: 0x14be779 v8::internal::DebugEvaluate::Global(v8::internal::Isolate*, v8::internal::Handle<v8::internal::String>, v8::debug::EvaluateGlobalMode, v8::internal::REPLMode) [./node_g]
 8: 0x13298c0 v8::debug::EvaluateGlobal(v8::Isolate*, v8::Local<v8::String>, v8::debug::EvaluateGlobalMode, bool) [./node_g]
 9: 0x1dc5492 v8_inspector::V8RuntimeAgentImpl::evaluate(v8_inspector::String16 const&, v8_crdtp::detail::ValueMaybe<v8_inspector::String16>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<int>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<double>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<bool>, v8_crdtp::detail::ValueMaybe<bool>, std::unique_ptr<v8_inspector::protocol::Runtime::Backend::EvaluateCallback, std::default_delete<v8_inspector::protocol::Runtime::Backend::EvaluateCallback> >) [./node_g]
10: 0x12dc188 v8_inspector::protocol::Runtime::DomainDispatcherImpl::evaluate(v8_crdtp::Dispatchable const&) [./node_g]
11: 0x1de5aba v8_crdtp::UberDispatcher::DispatchResult::Run() [./node_g]
12: 0x1db4abb v8_inspector::V8InspectorSessionImpl::dispatchProtocolMessage(v8_inspector::StringView) [./node_g]
13: 0x120810f  [./node_g]
14: 0x1208f06 node::inspector::NodeInspectorClient::dispatchMessageFromFrontend(int, v8_inspector::StringView const&) [./node_g]
```

```
(gdb) bt
#0  v8::base::OS::Abort () at ../../deps/v8/src/base/platform/platform-posix.cc:488
#1  0x0000000002b90c98 in V8_Fatal (file=0x3445a68 ""../../deps/v8/src/debug/debug.cc"", line=2273, format=format@entry=0x563c8f2 ""Debug check failed: %s."") at ../../deps/v8/src/base/logging.cc:167
#2  0x0000000002b90cb3 in v8::base::(anonymous namespace)::DefaultDcheckHandler (file=<optimized out>, line=<optimized out>, message=<optimized out>) at ../../deps/v8/src/base/logging.cc:57
#3  0x00000000014df494 in v8::internal::Debug::StopSideEffectCheckMode (this=0x5d89300) at ../../deps/v8/src/debug/debug.cc:2273
#4  0x00000000014be779 in v8::internal::DebugEvaluate::Global (isolate=isolate@entry=0x5dad200, source=..., mode=mode@entry=v8::debug::EvaluateGlobalMode::kDisableBreaksAndThrowOnSideEffect, 
    repl_mode=repl_mode@entry=v8::internal::REPLMode::kYes) at ../../deps/v8/src/execution/isolate.h:1073
#5  0x00000000013298c0 in v8::debug::EvaluateGlobal (isolate=0x5dad200, source=..., mode=mode@entry=v8::debug::EvaluateGlobalMode::kDisableBreaksAndThrowOnSideEffect, repl=repl@entry=true)
    at ../../deps/v8/src/api/api.cc:10202
#6  0x0000000001dc5492 in v8_inspector::V8RuntimeAgentImpl::evaluate (this=0x5eed920, expression=..., objectGroup=..., includeCommandLineAPI=..., silent=..., executionContextId=..., returnByValue=..., generatePreview=..., 
    userGesture=..., maybeAwaitPromise=..., throwOnSideEffect=..., timeout=..., disableBreaks=..., maybeReplMode=..., allowUnsafeEvalBlockedByCSP=..., callback=...) at ../../deps/v8/src/inspector/v8-inspector-impl.h:63
#7  0x00000000012dc188 in v8_inspector::protocol::Runtime::DomainDispatcherImpl::evaluate (this=<optimized out>, dispatchable=...) at /usr/include/c++/8/bits/char_traits.h:96
#8  0x0000000001de5aba in std::function<void ()>::operator()() const (this=0x7fffffff9c98) at /usr/include/c++/8/bits/std_function.h:682
#9  v8_crdtp::UberDispatcher::DispatchResult::Run (this=this@entry=0x7fffffff9c90) at ../../deps/v8/third_party/inspector_protocol/crdtp/dispatch.cc:529
#10 0x0000000001db4abb in v8_inspector::V8InspectorSessionImpl::dispatchProtocolMessage (this=0x5edac50, message=...) at ../../deps/v8/src/inspector/v8-inspector-session-impl.cc:378
#11 0x000000000120810f in node::inspector::(anonymous namespace)::ChannelImpl::dispatchProtocolMessage (this=0x5ed47f0, message=...) at ../../src/inspector_agent.cc:256
#12 0x0000000001208f06 in node::inspector::NodeInspectorClient::dispatchMessageFromFrontend (this=0x5e35740, session_id=1, message=...) at ../../src/inspector_agent.cc:479
#13 0x0000000001204e73 in node::inspector::(anonymous namespace)::SameThreadInspectorSession::Dispatch (this=0x5eeeeb0, message=...) at ../../src/inspector_agent.cc:954
#14 0x00000000012326b9 in node::inspector::(anonymous namespace)::MainThreadSessionState::Dispatch (this=0x5edb6a0, message=std::unique_ptr<v8_inspector::StringBuffer> = {...})
    at ../../src/inspector/main_thread_interface.cc:152
#15 0x00000000012343cc in node::inspector::(anonymous namespace)::AnotherThreadObjectReference<node::inspector::(anonymous namespace)::MainThreadSessionState>::Apply<std::unique_ptr<v8_inspector::StringBuffer> > (
    target=0x5edb6a0, fn=
```","targos",2352663,"2021-01-08 11:42:25","v8 base os abort debug check fail stop side effect mode debug evaluate global debug evaluate global v8 inspector v8 runtime agent impl evaluate v8 inspector protocol runtime domain dispatcher impl evaluate v8 crdtp uber dispatcher dispatch result run v8 inspector v8 inspector session impl dispatch protocol message node inspector channel impl dispatch protocol message node inspector node inspector client dispatch message frontend node inspector main thread session state dispatch
"
2284,370,"This only happens with the Chrome devtools. I cannot reproduce using `node inspect`.","targos",2352663,"2021-01-08 11:55:01","happen chrome devtool reproduce node inspect
"
2285,370,"@nodejs/inspector ","targos",2352663,"2021-01-08 11:55:11","nodejs inspector
"
2286,370,"The code below is simpler and could also reproduce:
```js
// test.js
const inspector = require('inspector');
setInterval(() => {
    inspector.console.log('heartbeat')
}, 1000);
```

`node --inspect test.js` and type `process` in Chrome Devtools.","oyyd",5847587,"2021-01-14 12:02:11","code simpler reproduce test js inspector heartbeat process chrome devtools
"
2287,370,"I am not sure if I am helping at all - but I just found this bug also. I am running node v14.15.4 on Fedora.","tinpotnick",4378166,"2021-02-18 12:29:07","bug run node fedora
"
2288,370,"Node process crash happens even before we have hit `Enter` when devtools tries to evaluate a partial expression.
So we have found a workaround for this issue: turn off ""eager evaluation"" in chrome devtools:
![image](https://user-images.githubusercontent.com/712898/119648578-4aeecd00-be2a-11eb-92ec-d5c30d7584e0.png)
","alex3d",712898,"2021-05-26 11:08:26","node process crash happen even before hit enter devtool try evaluate partial expression find workaround issue turn eager evaluation chrome devtool
"
2289,370,"I just had this issue. But instead of accessing variables, it happens to me whenever I have an array typed in the debugger and when it changes, it crashes. I have a WS array and whenever someone tries connecting, which adds to the array, node crashes if I have a line entered that references the array. If I wait for them to connect and then type the line, it doesn't crash. (tried node 16 and 15)

PS - If anyone has any alternative debugging module for node.js I'd love to hear it","SpeedyCraftah",45142584,"2021-07-06 17:29:27","issue access variable array type debugger change crash ws array someone connect add array node crash line reference array wait connect type line crash try node alternative debug module node
"
2290,370,"I can no longer reproduce this as of node 16.6.0.","jespertheend",2737650,"2021-11-20 17:18:13","reproduce node
"
2291,370,"I'm unable to reproduce this locally, and given that there's been no further discussion or activity on this in years, I'm going to go ahead and close the issue. It can be reopened if necessary.","jasnell",439929,"2025-01-22 20:02:13","unable reproduce locally further discussion activity year go ahead close issue reopen necessary
"
2292,372,"I can reproduce this. Here is the output with the `NODE_DEBUG=*` in case that's useful:

```
REPL 38605: line ""Object.defineProperty(Array.prototype, \""-1\"", { get() { throw new Error(-1); }, enumerable: false });""
REPL 38605: eval ""Object.defineProperty(Array.prototype, \""-1\"", { get() { throw new Error(-1); }, enumerable: false });\n""
REPL 38605: finish null Object(0) []
STREAM 38603: readableAddChunk <Buffer 4f 62 6a 65 63 74 28 30 29 20 5b 5d 0a>
STREAM 38603: maybeReadMore read 0
STREAM 38603: read 0
STREAM 38603: need readable true
STREAM 38603: length less than watermark true
STREAM 38603: do read
NET 38603: _read
STREAM 38603: readableAddChunk <Buffer 3e 20>
STREAM 38603: maybeReadMore read 0
STREAM 38603: read 0
STREAM 38603: need readable true
STREAM 38603: length less than watermark true
STREAM 38603: do read
NET 38603: _read
```

For reference, here's the output when setting `-2` instead of `-1` on `Array.prototype`:

```
REPL 38468: line ""Object.defineProperty(Array.prototype, \""-2\"", { get() { throw new Error(-1); }, enumerable: false });""
REPL 38468: eval ""Object.defineProperty(Array.prototype, \""-2\"", { get() { throw new Error(-1); }, enumerable: false });\n""
REPL 38468: finish null Object(0) []
STREAM 38467: readableAddChunk <Buffer 4f 62 6a 65 63 74 28 30 29 20 5b 5d 0a>
STREAM 38467: maybeReadMore read 0
STREAM 38467: read 0
STREAM 38467: need readable true
STREAM 38467: length less than watermark true
STREAM 38467: do read
STREAM 38468: maybeReadMore read 0
STREAM 38468: read 0
NET 38467: _read
STREAM 38468: need readable true
STREAM 38468: length less than watermark true
STREAM 38468: do read
NET 38468: _read
STREAM 38467: readableAddChunk <Buffer 3e 20>
STREAM 38467: maybeReadMore read 0
STREAM 38467: read 0
STREAM 38467: need readable true
STREAM 38467: length less than watermark true
STREAM 38467: do read
NET 38467: _read
```","aduh95",14309773,"2020-12-28 23:54:07","reproduce output case useful object defineproperty array prototype get throw error enumerable array prototype get throw error enumerable finish object set instead array prototype
"
2293,372,"Try to find the problem through the Profile. And I found out why. The problem is caused by `repl/domain/process.domain._errorHandler` together and only affects `Object.defineProperty(Array.prototype, ""-1"")`.

#### Profile
![image](https://user-images.githubusercontent.com/13161470/103290080-a9528380-4a23-11eb-9b02-c06c075b5b40.png)


#### Error Code
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/domain.js#L240-L241
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/domain.js#L314-L317

#### Details

1. Start Node.js Repl and type `Object.defineProperty(Array.prototype, ""-1"", { get() { throw new Error(-1); }, enumerable: false })`. The `self.eval(cmd)` function will be executed

https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/repl.js#L833-L834

2. `self.eval` is wrapper of node.js domain.
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/repl.js#L576
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/repl.js#L303

3.  execute `self.eval` will run `domain.enter` and `domain.exit`
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/domain.js#L414-L420

4. at `domain.exit`, will set `exports.active` to `stack[stack.length - 1]`. But we defined `Array. prototype[-1]` getter before, so this will trigger an error.
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/domain.js#L322

5. The error is `UncaughtException`, so error will be caught by `Domain.prototype._errorHandler`.
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/readline.js#L1197-L1202
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/domain.js#L224

6. In `Domain.prototype._errorHandler`, there is a while loop and `domain.exit()` will be called. But the stack is empty, so the while will loop indefinitely and cause the process to get stuck
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/domain.js#L240-L241
https://github.com/nodejs/node/blob/e57d8af7e2890b03d865c6edac279e234c43b0ae/lib/domain.js#L314-L317
","Lxxyx",13161470,"2020-12-29 14:08:45","find problem profile find problem cause repl domain process domain errorhandler affect object defineproperty array prototype 1 start nodejs repl type object defineproperty array prototype 1 get throw error enumerable false self eval function execute self eval wrapper nodejs domain execute self eval run domain enter domain exit domain exit set export active stack stack length 1 define array prototype 1 getter trigger error error uncaughtexception error catch domain prototype errorhandler domain prototype errorhandler while loop domain exit call stack empty while loop indefinitely cause process get stuck
"
2294,373,"@chadbrewbaker - personally I have not used macos but `make check` works fine for windows10 os","PoojaDurgad",68735943,"2020-12-28 06:05:21","chadbrewbaker usar macos fazer verificação funcionar windows10
"
2295,373,"I don't know if we have collaborators with an M1 Mac yet.","targos",2352663,"2020-12-28 10:49:23","know collaborator m1 mac
"
2296,373,"I can reproduce on my machine (M1 CPU).","aduh95",14309773,"2020-12-28 21:45:54","reproduce machine cpu
"
2297,373,"For info, `node --prof` always segfaults on Apple Silicon, it's probably a V8 bug. If you don't need this feature, `node` works perfectly fine though.

I'm not able to compile `gdb` though, so I can't really help debug this, sorry. ","aduh95",14309773,"2021-01-04 15:59:32","node segfault apple silicon v8 bug need feature node work perfectly compile gdb debug sorry
"
2298,373,"> I'm not able to compile gdb though, so I can't really help debug this, sorry.

Maybe you can try `lldb` instead?","targos",2352663,"2021-01-04 16:21:18","able compile gdb help debug sorry try lldb
"
2299,373,"`lldb` gave me the info I needed :+1:

I've submitted the fix to https://chromium-review.googlesource.com/c/v8/v8/+/2609413. @nodejs/v8 is there something else I should do to ensure the fix makes it to the next Node.js releases?","aduh95",14309773,"2021-01-04 18:35:53","lldb info submit fix ensure fix make next nodejs release
"
2300,373,"@aduh95 If you want someone to review your CL, you need to mark it as ready for review (it's currently WIP) and ideally add some reviewers.

Edit: it's a bit counter-intuitive, but that's what the ""Start review"" button allows you to do.","targos",2352663,"2021-01-26 11:44:08","want someone review cl need mark ready review currently wip ideally add reviewer bit counter intuitive start review button allow
"
2301,373,"@targos Thanks for the info! I've now submitted the CL for reviews.","aduh95",14309773,"2021-01-26 12:15:10","submit cl review
"
2302,373,"@hashseed can you help get a review of the PR in the V8 changed needed before we can enable testing in the Node.js CI?","mhdawson",9373002,"2021-02-17 15:17:50","review PR V8 change need enable test Node.js CI
"
2303,374,"Yes. This is a problem. I’ll prepare a PR.","ronag",3065230,"2020-12-26 10:04:33","problem prepare pr
"
2304,374,"https://github.com/nodejs/node/issues/36650 has additional info","ronag",3065230,"2020-12-27 21:57:32","info adicional
"
2305,375,"Quick update. The following code seems to work - ie it seems like `stream` is not correctly initialized

```
$ cat gunzip.js 
const stream = require('stream');   // <==== adding this makes things work
const { gunzipSync } = require('zlib');
console.log(gunzipSync('fooobar'))
```","ledbit",6250118,"2020-12-24 05:14:47","code work stream correctly initialize
"
2306,375,"This will be fixed when https://github.com/nodejs/node/pull/36618 is backported to v14.","mcollina",52195,"2020-12-24 15:30:44","fix backport v14
"
2307,376,"Also occurs on 14.15, will look further into it this night","schamberg97",50446906,"2020-12-20 13:52:24","occur 14.15 look night
"
2308,377,"As @ExE-Boss indicated here (https://github.com/nodejs/node/pull/36023#issuecomment-747398178), the `http` request object must now be of a different inheritance level...","rubenstolk",692644,"2020-12-17 12:07:17","ExE-Boss indicar http request object diferente inheritance level
"
2309,377,"`Object.assign` also copies only own enumerable properties, but uses `[[Set]]` instead of `[[Define]]`, so:
```js
const target = {};
Object.assign(
	target,
	JSON.parse(`{
		""__proto__"": null
	}`,
);
```
results in `target` having its prototype set to `null` instead of adding an own `__proto__` property, because of the `Object.prototype.__proto__` accessor.

---

Whereas:
```js
const target = {
	...(JSON.parse(`{
		""__proto__"": null
	}`)),
};
```
Results in an object with an own `__proto__` property set to `null` and a prototype of `Object.prototype`.","ExE-Boss",3889017,"2020-12-17 12:10:13","object assign copy own enumerable property use set define target prototype set null add own proto property object prototype proto accessor target own proto property set null prototype object prototype
"
2310,377,"This likely related to https://github.com/nodejs/node/pull/35281.","aduh95",14309773,"2020-12-17 12:14:11","likely relate
"
2311,377,"This is definitely caused by <https://github.com/nodejs/node/pull/35281>.","ExE-Boss",3889017,"2020-12-17 12:16:15","caused nodejs node pull
"
2312,377,"I think a quick fix would be to do something like:

```js
const dummyReq = { ...req, get headers() { return req.headers }, get trailers() { return req.trailers; } };
```","aduh95",14309773,"2020-12-17 12:22:01","quick fix something like
"
2313,377,"Yep, thanks for that! I have already implemented something similar.","rubenstolk",692644,"2020-12-17 12:31:48","implement similar
"
2314,377,"Opinions on whether this warrants an urgent revert of #35281 and follow-up patch release this week? cc: @ronag @mcollina

(I'd need to get started on that today if so, as i'll be out-of-office/mostly offline from tomorrow until the New Year.)","BethGriggs",8297234,"2020-12-17 13:02:27","opinion warrant urgent revert follow patch release week need start today office offline tomorrow new year
"
2315,377,"I'd just revert it in v14, not v15.","mcollina",52195,"2020-12-17 13:11:54","revert v14 v15
"
2316,377,"I agree with @mcollina that a revert in v14 would amke sense, and it would be good to get a release out.","mhdawson",9373002,"2020-12-17 13:58:49","agree revert v14 make sense good get release
"
2317,377,"Raised a revert PR for Node.js 14 (https://github.com/nodejs/node/pull/36553). Hope to get this into a v14.15.3 very soon so that there are no barriers to adopting the [upcoming security release](https://nodejs.org/en/blog/vulnerability/january-2021-security-releases/) on January 4th.","BethGriggs",8297234,"2020-12-17 15:42:50","revert PR Node.js 14 hope get v14.15.3 soon barrier adopt upcoming security release January 4
"
2318,377,"I've investigated this with a bit more detail, and I don't think it's a bug. __I would recommend against using the spread operator on any stream__. Nevertheless, this should be reverted in v14.x as it was probably a significant breaking change that slipped in a patch release. ","mcollina",52195,"2020-12-17 17:58:43","investigate detail think bug recommend use spread operator stream nevertheless revert v14x probably significant break change slip patch release
"
2319,377,"v14.15.3 has been released reverting the behaviour change. I think we can close this.

Thanks a lot for the report and the repro code @rubenstolk!","aduh95",14309773,"2020-12-17 23:40:53","release revert behaviour change close report repro code
"
2320,377,"How do we continue regarding this in NodeJs 15? The same behavior change is between 15.0.0 and 15.1.0.

Should we document this somehow?
IMHO such a change doesn't match to semver-patch.","Flarna",18708370,"2020-12-17 23:51:33","continue nodejs behavior change document change match semver patch
"
2321,377,"> I've investigated this with a bit more detail, and I don't think it's a bug. **I would recommend against using the spread operator on any stream**. Nevertheless, this should be reverted in v14.x as it was probably a significant breaking change that slipped in a patch release.

Totally agree here!","rubenstolk",692644,"2020-12-18 07:43:23","investigate detail think bug recommend use spread operator stream nevertheless revert v14x significant break change slip patch release agree
"
2322,377,"Thanks for all the immediate hard work here!","rubenstolk",692644,"2020-12-18 07:44:34","Thanks immediate hard work
"
2323,377,"> How do we continue regarding this in NodeJs 15? The same behavior change is between 15.0.0 and 15.1.0.

This change have been out for more than a month and I would not revert it there. I think it would create more friction to revert it there.

> Should we document this somehow?
> IMHO such a change doesn't match to semver-patch.

I would document that `{ ...stream }`, `{ ...req }`, `{ ...res }` and all these ways that copies properties should not be used. These objects are essentially uncloneable.
","mcollina",52195,"2020-12-18 09:42:16","continue regard nodejs behavior change month revert create friction document change match semver patch document copy property object uncloneable
"
2324,377,"> This change have been out for more than a month and I would not revert it there. I think it would create more friction to revert it there.

Well, it's an uneven version and still quite new. More or less any production setup runs on LTS versions only.
Looking into the usage of our customers I see following distribution:
14: 4%
12: 39%
10: 37%
8: 19%

Node 15 (and other uneven versions) are more or less not existing there. So it's likely that we will see this popping up with 16.","Flarna",18708370,"2020-12-18 09:55:27","change month revert create friction revert uneven version production setup run lts version look usage customer distribution node exist likely see pop
"
2325,377,"> Node 15 (and other uneven versions) are more or less not existing there. So it's likely that we will see this popping up with 16.

What would you recommend then?","mcollina",52195,"2020-12-18 10:50:19","node version exist likely see pop
"
2326,377,"If https://github.com/nodejs/node/pull/35281 had been labeled `semver-major` (as it would have been safe to do in retrospective), it would have landed in v16 anyway. Breaking changes are fine in semver major releases, I don't think we should be worried about v16.

Note that if it was reverted on v15, the revert would not be a breaking change, I don't think it would result in friction. I'm fine letting it slide for v15 though, the fact that we didn't get any bug report since it shipped seems to show it doesn't really matter there.","aduh95",14309773,"2020-12-18 11:07:42","revert break change fine worry v16 land v16 break change fine semver major releas bug report matter
"
2327,377,"I think marking `semver-major` would be the usual approach if this change is really needed.

According to https://github.com/nodejs/node/pull/35281#pullrequestreview-515540745 the change is mostly a nop from performance point of view therefore I think reverting this also on master is also an option.

But if general consensus is to keep it in 15 and master as is I'm also ok.


","Flarna",18708370,"2020-12-18 13:44:27","think mark semver major usual approach change need accord change mostly nop performance point view think revert master also option general consensus keep master also ok
"
2328,378,"This isn't really a problem with the documentation I would say, it seems to be caused by a bug introduced in https://github.com/nodejs/node/pull/35348, lib/internal/streams/readable.js, that causes a pipe to be paused initially when the writable buffer needs draining. The problem is that the readable is just never resumed so it gets stuck and fails.
A simple solution would be to add a drain listener on dest after pausing src, like so: https://gist.github.com/HomerSp/07ec63dacf49aac5f55a62b7c09dc313

Maybe this is supposed to be done automatically, but it just isn't? I can't see anything related to this though, so I'm not sure.

Pinging @ronag and @aduh95","HomerSp",487734,"2020-12-18 10:39:20","problem documentation seem cause bug introduce lib internal stream readable js cause pipe pause initially writable buffer need drain problem readable never resume get stuck fail simple solution add drain listener dest pause src suppose automatically see anything relate sure
"
2329,378,"Yea. It's a bug. The drain handler is added lazily in the `ondata` handler which will never get invoked since it's paused.

The fix should probably be something like:

```js
index a004ce20d0..1afa3a2b29 100644
--- a/lib/internal/streams/readable.js
+++ b/lib/internal/streams/readable.js
@@ -794,6 +794,8 @@ Readable.prototype.pipe = function(dest, pipeOpts) {
   if (dest.writableNeedDrain === true) {
     if (state.flowing) {
       src.pause();
+      ondrain = pipeOnDrain(src, dest);
+      dest.on('drain', ondrain);
     }
   } else if (!state.flowing) {
     debug('pipe resume');
```","ronag",3065230,"2020-12-18 10:58:55","bug drain handler add lazily ondata handler invoke pause fix something
"
2330,378,"I probably won't have time to sort this until Sunday or Monday so if someone can take the above patch, make a test and open a PR I would encourage that.

EDIT: I think I have time tonight.","ronag",3065230,"2020-12-18 11:00:19","time sort sunday monday someone take patch make test open pr encourage think time tonight
"
2331,378,"@weedz do you have a minimal repro we could use as a basis for a test?","ronag",3065230,"2020-12-18 11:08:32","minimal repro basis test
"
2332,378,"@ronag Thanks, that also looks to work. I'll write up a small test, though it is a bit annoying since it's pretty random when it'll happen. Piping a bunch of different sources one after the other should trigger it eventually though.","HomerSp",487734,"2020-12-18 11:12:33","work write small test annoy random happen pipe bunch different source trigger eventually
"
2333,378,"Opened PR. Still lacking tests though. https://github.com/nodejs/node/pull/36563","ronag",3065230,"2020-12-18 11:17:46","lack test
"
2334,378,"@HomerSp I think it's enough to bring dst to need drain state and then pipe an additional readable.","ronag",3065230,"2020-12-18 11:18:57","think enough bring dst need drain state pipe additional readable
"
2335,379,"/cc @nodejs/workers ","jasnell",439929,"2020-12-15 18:12:45","nodejs worker
"
2336,379,"Just switching the initialization order here should be fine, I think:

```diff
diff --git a/lib/internal/main/worker_thread.js b/lib/internal/main/worker_thread.js
index 7734aaa2c201..6c7c4acb3759 100644
--- a/lib/internal/main/worker_thread.js
+++ b/lib/internal/main/worker_thread.js
@@ -120,10 +120,6 @@ port.on('message', (message) => {
     initializeCJSLoader();
     initializeESMLoader();
 
-    const CJSLoader = require('internal/modules/cjs/loader');
-    assert(!CJSLoader.hasLoadedAnyUserCJSModule);
-    loadPreloadModules();
-    initializeFrozenIntrinsics();
     if (argv !== undefined) {
       process.argv = ArrayPrototypeConcat(process.argv, argv);
     }
@@ -146,6 +142,11 @@ port.on('message', (message) => {
     };
     workerIo.sharedCwdCounter = cwdCounter;
 
+    const CJSLoader = require('internal/modules/cjs/loader');
+    assert(!CJSLoader.hasLoadedAnyUserCJSModule);
+    loadPreloadModules();
+    initializeFrozenIntrinsics();
+
     if (!hasStdin)
       process.stdin.push(null);
 
```

Just note that your program still won’t work as it’s written right now, because `Worker`s inherit their parent thread’s `execArgv` by default, and so they will also see `-r create-worker.js`, and spawn new `Worker`s recursively. ","addaleax",899444,"2020-12-15 21:17:29","switch initialization order fine program work written worker inherit parent thread execargv default also see spawn new worker recursively
"
2337,379,"When I catch the error with `process.on('error'`, preventing the worker from terminating, I only see the one worker.  It does not recursively spawn workers, even though the worker has stayed alive.

Are you saying that the fix you're proposing will cause it to start spawning workers recursively?","cspotcode",376504,"2020-12-15 21:26:00","catch error prevent worker terminate see worker recursively spawn worker worker stay alive say fix propose cause start spawn worker recursively
"
2338,379,"> Are you saying that the fix you're proposing will cause it to start spawning workers recursively?

Yes, that would be the expected (and documented) behavior for the code you shared here.

> When I catch the error with `process.on('error'`, preventing the worker from terminating, I only see the one worker. It does not recursively spawn workers, even though the worker has stayed alive.

That’s because the Worker never gets around to spawning its main script, I assume.","addaleax",899444,"2020-12-15 21:30:19","fix propose cause start spawn worker recursively expect document behavior code catch error prevent worker terminate see worker recursively spawn worker worker stay alive worker get around spawn main script assume
"
2339,379,"I can put `setInterval(logAMessage, 1000)` into the worker's JS file and see those messages logging from the worker.  (When doing this, I'm not using empty.js in 2 different places)  So the worker's main script *does* execute.  But perhaps node's bootstrapping logic which handles `--require` gets terminated early by the error.

What is the recommended approach to avoid recursive thread spawning?  Read `workerData` and check for a flag passed from the parent thread?","cspotcode",376504,"2020-12-15 21:36:26","worker js file message log worker use empty js place worker main script execute node bootstrap logic handle require terminate early error recommend approach avoid recursive thread spawn read workerdata check flag pass parent thread
"
2340,379,"`require('worker_threads').isMainThread` is `false` in worker threads","targos",2352663,"2020-12-15 22:01:18","require worker thread is false worker thread
"
2341,379,"@cspotcode Maybe to clarify: It’s not the *first* worker, the one you want to spawn, that throws the exception. It’s the inner, second worker, that’s already being spawned by the first one as a preload module, that fails.

So it’s not that Workers can’t be spawned from preload scripts in the main thread, it’s that Workers can’t be spawned from the preload scripts of other Worker threads.","addaleax",899444,"2020-12-15 22:18:49","worker clarifir first worker spawn exception inner second worker spawn first preload modul fail worker spawn preload script main thread worker spawn preload script worker thread
"
2342,379,"Thanks for the clarification, I see what you mean.  This is tricky.

If I'm writing a library that internally uses worker_threads to do useful things, and I want the library's implementation to be properly opaque, then I should *always* be passing an empty `execArgv` array to each worker thread, right?  Otherwise users utilizing `--require` will accidentally have their code executed multiple times and possibly break my threads.","cspotcode",376504,"2020-12-16 03:57:06","clarification tricky write library internally use worker_thread useful thing want library implementation properly opaque always pass empty execArgv array worker thread user utilize require accidentally code execute multiple time possibly break thread
"
2343,379,"Is a preload script supposed to have access to `workerData` and `argv` synchronously, or does it need to wait asynchronously?  I'm not sure if I should file that as a separate bug or if it's intended.","cspotcode",376504,"2020-12-16 04:36:35","preload script access workerdata argv synchronously need wait asynchronously file separate bug intend
"
2344,379,"> If I'm writing a library that internally uses worker_threads to do useful things, and I want the library's implementation to be properly opaque, then I should _always_ be passing an empty `execArgv` array to each worker thread, right? Otherwise users utilizing `--require` will accidentally have their code executed multiple times and possibly break my threads.

I mean, that really depends … it’s hard to know what the correct behavior would be without knowing the concrete circumstances. Sometimes a user using `--require` might want their script also loaded in Workers, sometimes not, I guess.

> Is a preload script supposed to have access to `workerData` and `argv` synchronously, or does it need to wait asynchronously? 

I think it should have that, yes.

> I'm not sure if I should file that as a separate bug or if it's intended.

:woman_shrugging: The patch that I suggested above would also resolve this problem as well. You can open a PR with it, if you like, it just needs a test to come with, I think.","addaleax",899444,"2020-12-16 09:22:53","write library internally use worker thread useful thing want library implement properly opaque always pass empty execargv array worker thread right otherwise user utilize require accidentally code execute multiple time possibly break thread mean really depend hard know correct behavior without know concrete circumstance sometimes user use require might want script also load worker sometimes think preload script suppose access workerdata argv synchronously need wait asynchronously think should patch suggest also resolve problem well open pr like need test come think
"
2345,379,"Ok thanks, I did not fully understand that `--require` preload scripts are always expected to run in all child processes and worker_threads.  Better not to override `execArgv` and `NODE_OPTIONS`.

One note on https://github.com/nodejs/node/issues/36531#issuecomment-745594989, checking `isMainThread` isn't necessarily the best option if you expect a library's code to be invoked from within a consumer's worker_thread.  But we can always use a different entry-point `.js` for the thread, and we can pass it `workerData`","cspotcode",376504,"2020-12-16 15:31:57","ok thanks fully understand require preload script always expect run child process worker_thread better override execArgv node_options note check ismainthread necessarily best option expect library code invoke consumer worker_thread always use different entry_point js thread pass workerdata
"
2346,379,"PR: https://github.com/nodejs/node/pull/37481","jasnell",439929,"2021-02-22 21:00:26","PR
"
2347,380,"is this only happened in windows enviroment ?

i tsted in linux,it works 
```

Welcome to Node.js v12.18.2.
Type "".help"" for more information.
> const fs = require(""fs"");
undefined
> const path = ""./to-delete/s:d"";
undefined
> fs.mkdir(path, { recursive: true }, (err) => {
...   if (err) {
.....     console.log(err);
.....     return;
.....   }
...   console.log(""success"");
... });
undefined
> success

>
>
>
```
","navegador5",55095363,"2020-12-12 11:16:10","happen window enviroment test linux work
"
2348,380,"I'm not able to test it on linux. I've only tested it in Windows 10","GeorgianStan",25796932,"2020-12-12 12:13:13","test linux test window
"
2349,380,"Can you test with the latest 12.x version? I remember this issue and I think it was fixed recently .","targos",2352663,"2020-12-12 12:35:15","test latest version remember issue fix recently
"
2350,380,"I tested against Node v14.15.1. Same problem","GeorgianStan",25796932,"2020-12-12 15:53:06","test node problem
"
2351,380,"I can confirm it happens on v12.20.0 and v14.15.1.","Xstoudi",2575182,"2020-12-12 19:38:00","confirm happen v12.20.0 v14.15.1
"
2352,380,"It seems to be the same issue as https://github.com/nodejs/node/issues/31177.
https://github.com/libuv/libuv/pull/2601 is supposed to fix it.","targos",2352663,"2020-12-12 21:11:43","issue same fix
"
2353,380,"The fix landed yesterday in libuv: https://github.com/libuv/libuv/commit/dd8662b6d28236b60bb419390ea083695bbb2173","Xstoudi",2575182,"2020-12-29 15:20:01","fix land yesterday libuv
"
2354,380,"Thank you. In what version is the fix available?","GeorgianStan",25796932,"2021-01-02 15:20:20","fix version available
"
2355,380,"Can confirm that the issue has been fixed in the 15.x line at least. Not sure about 14.x or 12.x.","jasnell",439929,"2021-03-05 18:48:39","confirm issue fix line sure
"
2356,380,"Can confirm it still happens on v12.22.1 and v14.16.1","pd4d10",9524411,"2021-05-04 07:54:31","confirm happen v12 v14
"
2357,380,"Seem like this has been solved in the latest master branch version

![image](https://user-images.githubusercontent.com/16450761/125023780-24bb7e80-e0b2-11eb-86dc-441f623a645d.png)
","wwwzbwcom",16450761,"2021-07-09 04:36:06","solve latest master branch version
"
2358,380,"This should be fixed in all active releases as the fix was released in libuv `1.41.0`.","santigimeno",1084056,"2022-11-05 19:59:07","fix release libuv
"
2359,381,"That's a bug, it should pass the error to the callback. PR is welcome :)","aduh95",14309773,"2020-11-23 21:14:36","bug pass error callback PR welcome
"
2360,381,"I'm working on this issue.","Lxxyx",13161470,"2020-11-24 05:22:32","work issue
"
2361,381,"You guys were quick - I opened this issue at 2am local time and it was solved by the noon, next day. :)
Thank you!","valango",191752,"2020-11-25 12:45:36","quick open issue am local time solve noon next day thank
"
2362,382,"Conditional exports were added in https://github.com/nodejs/node/pull/29978 and the flag was removed in https://github.com/nodejs/node/pull/31001. It looks like that both PRs were indeed backported to v12.16.0. Maybe are you using another feature that was not backported until v12.17.0? Can you share a repro code that shows the feature is missing?","aduh95",14309773,"2020-11-18 09:02:56","export condicional adicionar flag remover parecer pr backport v12.16.0 talvez usar feature backport v12.17.0 compartilhar repro código mostrar feature faltar
"
2363,382,"This issue/PR was marked as stalled, it will be automatically closed in 30 days. If it should remain open, please leave a comment explaining why it should remain open.","github-actions[bot]",41898282,"2020-12-23 10:59:19","issue mark stall automat close day remain open leave comment explain remain open
"
2364,382,"I've created a reproduction here https://github.com/gpoole/node-missing-export-map. While I was doing that I think I realised the problem is actually that the conditional exports do work in 12.16, but only if the `--experimental-modules` option is set. So the output I get from the sample is:

12.16 with `node index.js`: `missing map hello`
12.17 with `node index.js`: `common hello`
12.16 with `node --experimental-modules index.js`: `common hello`

It seems that conditional exports are tied to module support. I think this makes sense, but I think the history section doesn't make it clear and to me it says that 12.16 uses conditional exports without any flags, which it doesn't.","gpoole",2898433,"2020-12-23 12:02:25","conditional export work option set output sample miss map hello common hello seem conditional export tie module support make sense history section clear say use conditional export flag
"
2365,382,"Thanks for the clarification, it's probably worth clarifying the documentation indeed. Do you see the same bahavior for [package self-reference](https://nodejs.org/api/packages.html#packages_self_referencing_a_package_using_its_name) in Node.js v12.16.0?","aduh95",14309773,"2021-03-21 15:24:23","clarification worth clarify documentation see behavior package self reference node v12
"
2366,382,"Yes, I see the same behaviour. After adding [`reference.cjs`](https://github.com/gpoole/node-missing-export-map/blob/master/node_modules/inner/reference.cjs) to the inner package I see the following:

```sh
cd node_modules/inner
node reference.cjs
# missing map hello
node --experimental-modules reference.cjs
# common hello
# (node:36203) ExperimentalWarning: The ESM module loader is experimental.
```","gpoole",2898433,"2021-03-22 11:43:33","yes see behaviour add package see follow cd node module inner node reference cjs miss map hello node experimental module reference cjs common hello node experimentalwarning esm module loader experimental
"
